\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph:
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Dissertation Defense: Numerical Methods for Approximating High-Dimensional Posterior Distributions},
  pdfauthor={Jameson Quinn},
  pdfborder={0 0 0},
  breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\newif\ifbibliography
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-2}

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{tikz}
\usetikzlibrary{bayesnet}
\usetikzlibrary{arrows}
\usetikzlibrary{cd}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{lastpage}
\usepackage{mathrsfs}
\usepackage[makeroom]{cancel}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usetikzlibrary{fit,positioning}
\tikzset{font={\fontsize{9pt}{12}\selectfont}}
\setbeamertemplate{footline}{\begin{flushright}\thepage/\pageref{LastPage}~~.\\\end{flushright}}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{xcolor}
\definecolor{blue1}{HTML}{4466FF}
\definecolor{blue2}{HTML}{0022AA}


\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\orange}[1]{\textcolor{orange}{#1}}
\newcommand{\yellow}[1]{\textcolor{yellow}{#1}}
\newcommand{\green}[1]{\textcolor[rgb]{0,.5,0}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\purple}[1]{\textcolor{purple}{#1}}

\title{Dissertation Defense: Numerical Methods for Approximating
High-Dimensional Posterior Distributions}
\author{Jameson Quinn}
\date{12/9/19}

\begin{document}
\frame{\titlepage}

\begin{frame}{}
\protect\hypertarget{section}{}

\[\huge{P(\theta|x)=\frac{P(x|\theta)P(\theta)}{\int_{\theta'\in\Theta} P(x|\theta')P(\theta')d\theta'}}\]

\textcolor{red}{{\scriptsize Always good to start a stats talk with Bayes' Thm. \\You've all seen this before.\\     As you know, the trickiest part is the denominator. \\If integral is over hi-D space, naive numerical methods for estimating will have unacceptably high variance. \\So you need tricks.}}

\end{frame}

\begin{frame}{Structure of thesis}
\protect\hypertarget{structure-of-thesis}{}

\begin{itemize}
\tightlist
\item
  Chapter 1: online data assimilation in spatiotemporal systems
\item
  Chapter 2: new method for variational inference on latent variable
  models

  \begin{itemize}
  \tightlist
  \item
    Contributions: Laplace guide families; analytic amortization
  \end{itemize}
\item
  Chapter 3: application to ecological inference (EI)

  \begin{itemize}
  \tightlist
  \item
    Contributions: Extensible model for EI; full algorithm and
    implementation of Laplace VI for this model
  \end{itemize}
\end{itemize}

\textcolor{red}{{\scriptsize SAY VI XXXXXXXXXXXXXX\\Ch. 2: The VI framework is to assume the posterior is well-approximated... construct a new guide family that's able to...\\Ch 3: More than a simple application. The model is more realistic and more extensible than the most common method, and applying VI here requires several tricks.\\You will notice a few changes to what I sent you, particularly in the chapter 3 results; I will point them out as we go along}}

\end{frame}

\begin{frame}{Collaborator on Ch. 2-3: Mira Bernstein}
\protect\hypertarget{collaborator-on-ch.-2-3-mira-bernstein}{}

\begin{itemize}
\tightlist
\item
  On most things, equal collaborator and coauthor
\item
  All the major motivating ideas, and \textgreater{}95\% of the coding,
  is mine
\item
  We checked that this is OK
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Variational Inference}
\protect\hypertarget{variational-inference}{}

Approximate w/ guide distribution \(q_{\bm{\phi}}(\bm{\theta})\); choose
\(\bm{\phi}\) to mimize KL:
\[\hat{{\bm{\phi}}}=\mathrm{argmin}_{\bm{\phi}}\left[D_{\mathrm{KL}} \left(\;q_{\bm{\phi}}(\bm{\theta})\;\big|\big|\; p(\bm{\theta}|\bm{x})\;\right)\right].\]
Equivalent to maximizing ELBO:
\[\mathrm{ELBO}({\bm{\phi}}):=E_{q_{\bm{\phi}}}
\left[\mathrm{log} p(\bm{x},\bm{\theta})-\mathrm{log} q_{\bm{\phi}}(\bm{\theta})\right]\]

\includegraphics{defense_files/figure-beamer/unnamed-chunk-4-1.pdf}

\begin{verbatim}
## \textcolor{red}{{\scriptsize Re center, breathe. minimizing KL-divergence, ELBO ('this quantity')\\Note model parameters here and guide parameters there\\point to terms in ELBO b4 picture \\hill-climing means AD for gradient of the ELBO, so...}}
\end{verbatim}

\end{frame}

\begin{frame}{Computational tool: Pyro}
\protect\hypertarget{computational-tool-pyro}{}

Released in 2017 and still under very active development, pyro is a
cutting-edge python package for black-box VI.

\begin{itemize}
\tightlist
\item
  Stochastic optimization (hill-climbing)
\item
  Automatic differentiation via PyTorch ML
\end{itemize}

\textcolor{red}{{\scriptsize Explain automatic differentiation\\All the significant software engineering I had to do}}

\end{frame}

\begin{frame}{Choosing a guide family}
\protect\hypertarget{choosing-a-guide-family}{}

This talk will focus on Gaussian guide families.

The first obvious possibility for the guide family of a \(d\)-parameter
model is just the unrestricted set of Gaussians.

\begin{itemize}
\tightlist
\item
  Mean: \(d\) guide parameters (1 per model parameter)
\item
  Covariances: \(\mathcal{O}(d^2)\) guide parameters
\end{itemize}

\textcolor{red}{{\scriptsize can’t capture posterior correlations\\systematically underestimates posterior marginals}}

\begin{center}\includegraphics[width=150px]{meanfield_covar_figure} \end{center}

\end{frame}

\begin{frame}{Meanfield guide family}
\protect\hypertarget{meanfield-guide-family}{}

A common assumption is posterior independence of parameters, referred to
as ``meanfield'' guides. Thus guide parameters:

\begin{itemize}
\tightlist
\item
  Mean: \(d\) guide parameters (1 per model parameter)
\item
  Variances: \(d\) guide parameters (1 per model parameter; diagonal
  covariance matrix)
\end{itemize}

Problem:

\textcolor{red}{{\scriptsize can’t capture posterior correlations\\systematically underestimates posterior marginals}}

\begin{center}\includegraphics[width=150px]{meanfield_covar_figure} \end{center}

\end{frame}

\begin{frame}{Who will guide us?}
\protect\hypertarget{who-will-guide-us}{}

Among Gaussian guide families:

\begin{itemize}
\tightlist
\item
  Set of all normals, with unrestricted covariance, is too big
\item
  Meanfield subfamily doesn't actually contain any good approximations
\item
  We want subfamily that contains at least some good approximations
  without being too big
\end{itemize}

\end{frame}

\begin{frame}{Introducing: Laplace family}
\protect\hypertarget{introducing-laplace-family}{}

Let's guarantee that the family contains the Laplace approximation
around any posterior mode. This allows us to parametrize only the mean,
and then derive the precision matrix by the taking the observed
information of the posterior:

\(\mathcal{I}_p\left(\bm{\theta}^*\right) := -H\left[\log p(\bm{\theta})\right]\bigg\rvert_{\bm{\theta}^*}\)

Thus, the guide parameters for a model \(p(\theta)\) would be
\(\theta^*\), defining the point at which to take a Laplace
approximation.

\begin{itemize}
\tightlist
\item
  Means (\(\theta^*\)): \(d\) guide parameters (1 per model parameter)
\item
  Covariance: 0 guide parameters! Just compute
  \(\mathcal{I}_p(\theta^*)\).
\end{itemize}

\textcolor{red}{{\scriptsize Don't ignore correlation. Don't optimize over it. Just get it by calculus.}}

\end{frame}

\begin{frame}{Boosting function}
\protect\hypertarget{boosting-function}{}

\(\mathcal{I}_p\) not guaranteed to be positive definite. So define
``boosting'' function \(f(\mathcal{I}_p)\) s.t.:

\begin{itemize}
\tightlist
\item
  Guaranteed p.d.
\item
  Smooth almost everywhere.
\item
  \(f(\mathcal{I}_p)\approx\mathcal{I}_p\) if \(\mathcal{I}_p\) already
  p.d.
\end{itemize}

A similar problem arises in optimization (quasi-Newton methods); solved
via modified Cholesky algorithms (Surveyed in Fang, 2008; we use GMW81
by Gill, Murray, \& Wright)

\end{frame}

\begin{frame}{Boosting family}
\protect\hypertarget{boosting-family}{}

xxxxx

Furthermore, we can parametrize \(f\) to create a boosting family
\(f_{\bm{\psi}}\), for \(\psi_i\in\mathbb{R}^D_+\), s.t. as
\(\bm{\psi}\rightarrow\vec{\bm{0}}\),
\(f(\mathcal{I}_p)\rightarrow\mathcal{I}_p\) if \(\mathcal{I}_p\)
already p.d.

\textcolor{red}{{\scriptsize Boosting family is better than just boosting function.\\D-dimensional so we can boost dif params dif.\\Version of thesis sent previously has quasi-boosting which we’re no longer using}}

\end{frame}

\begin{frame}{Formal definition of Laplace family}
\protect\hypertarget{formal-definition-of-laplace-family}{}

Let \(p(\bm{\theta})\) be a (twice-differentiable) probability density
over \(\mathbb{R}^d\).

Let \(\Theta \subseteq \mathbb{R}^d\),
\(\Psi \subseteq \mathbb{R}^d_+\), and let \(f_\Psi\) be a boosting
family.

Laplace guide:
\(q_{\bm{\theta}^*\in\Theta,\bm{\psi}\in\Psi}(\bm{\theta})\), a
\(d\)-dimensional Gaussian with mean \(\bm{\theta}^*\) and precision
precision matrix
\(f_{\bm{\psi}} \left(\mathcal{I}_p(\bm{\theta}^*)\right)\).

Laplace guide family \(\mathcal{L}_{\Theta\times\Psi} (p,f_\Psi)\):
\(\{q_{\bm{\theta}^*,\bm{\psi}}:\bm{\theta}^*\in\Theta,\;\bm{\psi}\in\Psi\}\)

Thus, \(2d\) guide parameters.

\textcolor{red}{{\scriptsize Note that capital greek letters can be subspaces\\theta-star tells mean; psi tells how aggressively to boost}}

\end{frame}

\begin{frame}{Toy model}
\protect\hypertarget{toy-model}{}

We want: \(p(T_1,T_2|x=7)\) \[x= T_1+T_2+\epsilon\]
\[T_i\sim StudentT_{\nu}(0,1); i\in\{1,2\}\]
\[\epsilon\sim \mathcal{N}(0,\sigma^2)\]

\begin{center}\includegraphics[width=150px]{beforemeanfield} \end{center}

\textcolor{red}{{\scriptsize Simple model with bimodal posterior\\Shows several things: Importance of covariance; case where laplace of MAP isn't optimal; case where boosting is necessary, and boosting family is better than boosting function\\saddle point is ideal in this case, probably not always}}

\end{frame}

\begin{frame}{Toy model}
\protect\hypertarget{toy-model-1}{}

\[x= T_1+T_2+\epsilon\] \[T_i\sim StudentT_{\nu}(0,1); i\in\{1,2\}\]
\[\epsilon\sim \mathcal{N}(0,\sigma^2)\]

\begin{center}\includegraphics[width=150px]{beforelaplace} \end{center}

\textcolor{red}{{\scriptsize Simple model with bimodal posterior\\Shows several things: Importance of covariance; case where laplace of MAP isn't optimal; case where boosting is necessary, and boosting family is better than boosting function\\saddle point is ideal in this case, probably not always}}

\end{frame}

\begin{frame}{Toy model}
\protect\hypertarget{toy-model-2}{}

\[x= T_1+T_2+\epsilon\] \[T_i\sim StudentT_{\nu}(0,1); i\in\{1,2\}\]
\[\epsilon\sim \mathcal{N}(0,\sigma^2)\]

\begin{center}\includegraphics[width=150px]{full} \end{center}

\textcolor{red}{{\scriptsize Simple model with bimodal posterior\\Shows several things: Importance of covariance; case where laplace of MAP isn't optimal; case where boosting is necessary, and boosting family is better than boosting function\\saddle point is ideal in this case, probably not always}}

\end{frame}

\begin{frame}{Latent variable models (or: why hi-D?)}
\protect\hypertarget{latent-variable-models-or-why-hi-d}{}

A latent variable model has 3 core elements:

\begin{itemize}
\tightlist
\item
  Global parameters: \(\bm{\gamma}\in\Gamma \cong \mathbb{R}^g\),
\item
  Latent parameter vectors:
  \(\bm{\lambda}_1,\dots,\bm{\lambda}_N\in\Lambda \cong \mathbb{R}^l\)
\item
  Observation vectors: \(\bm{x}_1,\dots,\bm{x}_N\)
\end{itemize}

\[p\left(\bm{\gamma}, \bm{\lambda}_1,\dots,\bm{\lambda}_N,\bm{x}_1,\dots,\bm{x}_N\right) = p(\bm{\gamma})\prod_{i=1}^N p(\bm{\lambda}_i|\bm{\gamma})\; p(\bm{x}_i|\bm{\lambda}_i,\bm{\gamma})\]

Laplace guide parameters:
\(\bm{\gamma}^*,\bm{\lambda}^*_1...\bm{\lambda}^*_N,\bm{\psi}\)

\textcolor{red}{{\scriptsize conditional independence\\This is why we need a high-dimensional solution.}}

\end{frame}

\begin{frame}{Latent variable models: Block Arrowhead Hessians}
\protect\hypertarget{latent-variable-models-block-arrowhead-hessians}{}

\[\mathcal{I}_p(\bm{\theta}^*) = \left(\begin{array}{cccccc}
    & \textcolor{blue}{\bm{\gamma}} & \textcolor{blue}{\bm{\lambda}_1} & \textcolor{blue}{\bm{\lambda}_2} & \textcolor{blue}{\dots} & \textcolor{blue}{\bm{\lambda}_N} \\
   \textcolor{blue}{\bm{\gamma}} & G & C_1 & C_2 & \dots & C_N \\
   \textcolor{blue}{\bm{\lambda}_1} & C_1^T & U_1 & 0 & \dots & 0 \\
   \textcolor{blue}{\bm{\lambda}_1} & C_2^T & 0 & U_2 & \dots & 0 \\
   \textcolor{blue}{\vdots} & \vdots & 0 & 0 & \ddots & 0 \\
   \textcolor{blue}{\bm{\lambda}_N} & C_N^T & 0 & 0 & \dots & U_N
   \end{array}\right)\]

\begin{itemize}
\tightlist
\item
  Easy to boost.
\item
  Easy to sample from. Note that marginal covariance for \(\bm{\gamma}\)
  is
  \([\mathcal{I}_p(\bm{\theta}^*)^{-1}]_{\Gamma,\Gamma}=(G-\sum_i C_iU_i^{-1}C_i^T)^{-1}\)
\end{itemize}

\textcolor{red}{{\scriptsize easy to sample from and easy to boost.}}

\end{frame}

\begin{frame}{SVI (Stochastic Variational Inference)}
\protect\hypertarget{svi-stochastic-variational-inference}{}

\textcolor{red}{{\scriptsize Two methods useful w/ LVM. Conceptually independent, but combine. 1st, standard:}}

Let S be a sample xxxxxxx with p(i\inS)=\pi\_i

Replace
\[\mathrm{log}\;p(\bm{\theta},\bm{x}) := \mathrm{log}\;p(\bm{\gamma})+\sum_{i= 1}^N \Big[\mathrm{log}\;p(\bm{\lambda}_{i}|\bm{\gamma})\; +\mathrm{log}\;p(\bm{x}_{i}|\bm{\lambda}_{i},\bm{\gamma})\Big]\]
with unbiased estimator
\[\mathrm{log}\;p_\mathcal{S}(\bm{\theta}_\mathcal{S},\bm{x}_\mathcal{S}) := \mathrm{log}\;p(\bm{\gamma})+\frac{1}{\pi_{i}}\sum_{i\in \mathcal{S}} \Big[\mathrm{log}\;p(\bm{\lambda}_{i}|\bm{\gamma})\; +\mathrm{log}\;p(\bm{x}_{i}|\bm{\lambda}_{i},\bm{\gamma})\Big]\]
With Laplace guide, this makes:

\begin{itemize}
\tightlist
\item
  Guide covariance of globals for given \(\bm{\theta}^*\): Up to
  boosting, unbiased for both conditional precision and ``marginal
  precision'' (inverse of marginal covariance).
\item
  ELBO and ELBO gradient: Not unbiased (unlike meanfield)
\end{itemize}

\textcolor{red}{{\scriptsize If cheap way to predict bigger terms, weights; we haven't implemented\\ELBO \& gradient not unbiased as in meanfield, but seem to work well}}

\end{frame}

\begin{frame}{Amortization}
\protect\hypertarget{amortization}{}

Lower-dimensional subfamily

\begin{itemize}
\tightlist
\item
  Restrict \(\Theta\): reduce the number of guide parameters by setting
  \(\bm{\lambda^*}_i\) to \(f(\bm{\gamma^*},\bm{x}_i)\)
\item
  (Also restrict \(\Psi\): reuse the same boosting parameters for each
  unit)
\end{itemize}

The aim is to find an analytic a priori function that sets the latents
to (approximately) their conditional MAP values.

Laplace guide parameters:
\(\bm{\gamma}^*,\bm{\psi}_\gamma,\bm{\psi}_\lambda\)

\textcolor{red}{{\scriptsize Note that it's MAP not MLE. \\MAP is not perfect but it's close.\\computationally cheap refinement is available}}

\end{frame}

\begin{frame}{Multisite model}
\protect\hypertarget{multisite-model}{}

\[d := \log(\nu-\nu_{\min})\sim \mathcal{N}(1,1.5^2)\]
\[\varsigma := \log(\sigma-\sigma_{\min})\sim \mathcal{N}(0,2^2)\]
\[\mu\sim\mathcal{N}(0,20)\nonumber\]
\[\nu_{\min}=2.5,\;\sigma_{\min}=\max(s_i)*1.9\]

\end{frame}

\begin{frame}{Results}
\protect\hypertarget{results}{}

\includegraphics[width=3.65in]{ECHSfits.pdf}

\textcolor{red}{{\scriptsize Changes: df; boosting (once for each diagonal block)}}

\end{frame}

\begin{frame}{Ecological inference (EI)}
\protect\hypertarget{ecological-inference-ei}{}

EI: inferring individual behavior from aggregated data.

Motivating example: voting behavior by racial or other groups

\resizebox{99in}{1.25in}{%
\begin{tikzpicture}[thick,scale=0.9, every node/.style={transform shape},
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {1.25,1,.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\draw[-latex] (7,0) -- +(1,1) node[below right,midway,rotate=45] {precinct};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (3.99,3.7) {Candidate};


\node (w) at (3.5,2) {$\begin{array}{r|ccc|l}
& X & Y & Z & n_u\\
\hline
White & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 400 \\
Black & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 200   \\
Hispanic & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 100   \\
Other & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 100   \\
\hline
v_u & 400 & 200 & 200 & 800\end{array}$};

%\node (w) at (4.5,-1) [text width=8.25cm]{Observed data for one hypothetical precinct};
\end{tikzpicture}}

\textcolor{red}{{\scriptsize Mainly comes up in voting rights cases, so I’ll talk about it in this setting.\\     Z could represent not voting.}}

\end{frame}

\begin{frame}{Ecological inference (EI)}
\protect\hypertarget{ecological-inference-ei-1}{}

EI: inferring individual behavior from aggregated data.

Motivating example: voting behavior by racial or other groups

\resizebox{99in}{1.25in}{%
\begin{tikzpicture}[thick,scale=0.9, every node/.style={transform shape},
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {1.25,1,.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\draw[-latex] (7,0) -- +(1,1) node[below right,midway,rotate=45] {precinct};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (3.99,3.7) {Candidate};



\node (w) at (3.5,2) {$\begin{array}{r|ccc|l}
& X & Y & Z & n_u\\
\hline
White & \textcolor{red}{400} & 0 & 0 & 400 \\
Black & 0 & \textcolor{red}{200} & 0 & 200   \\
Hispanic & 0 & 0 & \textcolor{red}{100} & 100   \\
Other & 0 & 0 & \textcolor{red}{100} & 100   \\
\hline
 v_u & 400 & 200 & 200 & 800\end{array}$};


%\node (w) at (4.5,-1) [text width=8.25cm]{Possible underlying data A: assuming largest groups vote for most-popular candidates};




\foreach \x in {1.25,1,.75,0.5,0.25,0}\pic at (9+\x,\x){squared notebook};
\draw[-latex] (16,0) -- +(1,1) node[below right,midway,rotate=45] {precinct};
\node[rotate=90] (h) at (9.5,2) {Race};
\node (w) at (12.99,3.7) {Candidate};



\node (w) at (12.5,2) {$\begin{array}{r|ccc|l}
& X & Y & Z & n_u\\
\hline
White & \textcolor{red}{200} & \textcolor{red}{100} & \textcolor{red}{100} & 400 \\
Black & \textcolor{red}{100} & \textcolor{red}{50} & \textcolor{red}{50} & 200   \\
Hispanic & \textcolor{red}{50} & \textcolor{red}{25} & \textcolor{red}{25} & 100   \\
Other & \textcolor{red}{50} & \textcolor{red}{25} & \textcolor{red}{25} & 100   \\
\hline
v_u & 400 & 200 & 200 & 800\end{array}$};

%\node (w) at (13,-1) [text width=8.25cm]{Possible underlying data B: assuming candidate's percent support is independent of race};

\end{tikzpicture}}

\end{frame}

\begin{frame}{\emph{Thornburg v. Gingles}, 1986}
\protect\hypertarget{thornburg-v.-gingles-1986}{}

When you can show racially polarized voting, a minority community is
entitled to a majority-minority district. Result:

\includegraphics{defense_files/figure-beamer/unnamed-chunk-21-1.pdf}

\end{frame}

\begin{frame}{First attempt: Ecological regression (ER)}
\protect\hypertarget{first-attempt-ecological-regression-er}{}

\includegraphics[width=\textwidth,height=2in]{brexit_ER.png}

Brexit voting data. (Example by Adam Jacobs.)

\textcolor{red}{{\scriptsize Want to know how Brexit support differed by education. So...}}

\end{frame}

\begin{frame}{First attempt: Ecological regression (ERrrrr\ldots{})}
\protect\hypertarget{first-attempt-ecological-regression-errrrr}{}

\includegraphics[width=\textwidth,height=2in]{brexit_ER_oops.png}

Brexit support: -16\% of those with a degree???

\textcolor{red}{{\scriptsize Strong model assumption, which is incorrect: no precinct-level variation}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models}{}

\resizebox{99in}{3in}{% ER only
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {};
  \node[const, below=1.8 of level, align=center]          (global) {\textcolor{orange}{Global voting propensities}\\\textcolor{orange}{(for each race)}};
  \node[const, below=9.8 of level, align=center]          (observed) {\textcolor{purple}{Precinct vote totals}\\\textcolor{purple}{by candidate (observed)}};
  \node[const, below=10.9 of level]          (issues) {Advantages};
  \node[const, below=12.2 of level, align=center]          (issues) {Issues\\ \\ \\};
  
  
  
  %ER
  \node[const, align=center, right=3.5 of level]          (ERyear) {(1953)};
  \node[const, align=center, above=.1 of ERyear]          (ER) {$\textcolor[rgb]{1,1,1}{y}$ER$\textcolor[rgb]{1,1,1}{y}$};
  
  \node[latent, below=2 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=10 of ER]  (ERx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of ER] {ERdot} {} {} {};
  \node[obs, left=.5 of ERdot] (ERn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  \edge[-] {ERdot} {ERn} ;
  
  \node[const, align=center, below=11.2 of ER]      (ERpro) {Simple.};
  \node[const, align=center, below=12.5 of ER]      (ERcon) {Impossible\\estimates.};
  
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-1}{}

\resizebox{99in}{3in}{% King advantages
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {};
  \node[const, below=.8 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=1.8 of level, align=center]          (global) {\textcolor{orange}{Global voting propensities}\\\textcolor{orange}{(for each race)}};
  \node[const, below=3.8 of level, align=center]          (latent) {\textcolor[rgb]{0,.5,0}{Precinct-level variation}\\\textcolor[rgb]{0,.5,0}{(for each race)}};
  \node[const, below=7.8 of level, align=center]          (unobserved) {\textcolor{blue}{Precinct vote totals}\\\textcolor{blue}{by race \& candidate}\\\textcolor{blue}{(unobserved)}};
  \node[const, below=9.8 of level, align=center]          (observed) {\textcolor{purple}{Precinct vote totals}\\\textcolor{purple}{by candidate (observed)}};
  \node[const, below=10.9 of level]          (issues) {Advantages};
  \node[const, below=12.2 of level, align=center]          (issues) {Issues\\ \\ \\};
  
  
  
  %ER
  \node[const, align=center, right=3.5 of level]          (ERyear) {(1953)};
  \node[const, align=center, above=.1 of ERyear]          (ER) {$\textcolor[rgb]{1,1,1}{y}$ER$\textcolor[rgb]{1,1,1}{y}$};
  
  \node[latent, below=2 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=10 of ER]  (ERx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of ER] {ERdot} {} {} {};
  \node[obs, left=.5 of ERdot] (ERn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  \edge[-] {ERdot} {ERn} ;
  
  \node[const, align=center, below=11.2 of ER]      (ERpro) {Simple.};
  \node[const, align=center, below=12.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, align=center, right=7 of level]          (Kingyear) {(1997)};
  \node[const, align=center, above=.1 of Kingyear]           (King) {King's EI};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=8 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of King] {Kingdot} {} {} {};
  \node[obs, left=.5 of Kingdot] (Kingn) {$\textcolor{purple}{n_r}$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  
  
  \node[const, align=center, below=11.2 of King]      (Kingpro) {Uses constraints;\\Precinct-level variation};
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-2}{}

\resizebox{99in}{3in}{% King disadvantages
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {};
  \node[const, below=.8 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=1.8 of level, align=center]          (global) {\textcolor{orange}{Global voting propensities}\\\textcolor{orange}{(for each race)}};
  \node[const, below=3.8 of level, align=center]          (latent) {\textcolor[rgb]{0,.5,0}{Precinct-level variation}\\\textcolor[rgb]{0,.5,0}{(for each race)}};
  \node[const, below=7.8 of level, align=center]          (unobserved) {\textcolor{blue}{Precinct vote totals}\\\textcolor{blue}{by race \& candidate}\\\textcolor{blue}{(unobserved)}};
  \node[const, below=9.8 of level, align=center]          (observed) {\textcolor{purple}{Precinct vote totals}\\\textcolor{purple}{by candidate (observed)}};
  \node[const, below=10.9 of level]          (issues) {Advantages};
  \node[const, below=12.2 of level, align=center]          (issues) {Issues\\ \\ \\};
  
  
  
  %ER
  \node[const, align=center, right=3.5 of level]          (ERyear) {(1953)};
  \node[const, align=center, above=.1 of ERyear]          (ER) {$\textcolor[rgb]{1,1,1}{y}$ER$\textcolor[rgb]{1,1,1}{y}$};
  
  \node[latent, below=2 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=10 of ER]  (ERx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of ER] {ERdot} {} {} {};
  \node[obs, left=.5 of ERdot] (ERn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  \edge[-] {ERdot} {ERn} ;
  
  \node[const, align=center, below=11.2 of ER]      (ERpro) {Simple.};
  \node[const, align=center, below=12.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, align=center, right=7 of level]          (Kingyear) {(1997)};
  \node[const, align=center, above=.1 of Kingyear]           (King) {King's EI};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=8 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of King] {Kingdot} {} {} {};
  \node[obs, left=.5 of Kingdot] (Kingn) {$\textcolor{purple}{n_r}$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  
  
  \node[const, align=center, below=11.2 of King]      (Kingpro) {Uses constraints;\\Precinct-level variation};
  \node[const, align=center, below=12.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
\end{tikzpicture}}

\end{frame}

\begin{frame}{Polytope}
\protect\hypertarget{polytope}{}

\resizebox{99in}{1.5in}{%
\begin{tikzpicture}[
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (4,3.5) {Candidate};

%separator
\draw[style=-] (8,0) -- +(0,5) node[below left=.25cm,anchor=base,midway,rotate=-45] {};

\node (w) at (3.5,2) {$\begin{array}{r|ll|l}
& X & Y & \bm{n}_u\\
\hline
\textit{White} & \textcolor{red}{50} & 50 & 100 \\
\textit{Black} & 70 & 70 & 140   \\
\hline
\bm{v}_u & 120 & 120 & 240\end{array}$};

\draw[blue,fill=blue] (11.75,2.25) circle (.5ex);
\node[] at (11.75,1.85)   (c) {$\dot{\bm{Y}}$};

\node[] at (12, -1.1)   (c) {$\mathcal{Y}_u$};

%polytope
\draw[style=-] (13,0.5) -- +(1,0) node[below = .3cm,anchor=base,midway] {$\textcolor{black}{y_{p12}>0}$};
\draw[style=-] (10,3.5) -- +(0,1) node[left = .2cm,anchor=base,midway,rotate=90] {$\textcolor{red}{y_{p11}}>0$};
\draw[style=-] (10,4) -- +(3.5,-3.5) node[left = .2cm,anchor=base,midway,rotate=90] {};


\end{tikzpicture}}

\resizebox{99in}{1.5in}{%
\begin{tikzpicture}[
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (4,3.5) {Candidate};

%separator
\draw[style=-] (8,0) -- +(0,5) node[below left=.25cm,anchor=base,midway,rotate=-45] {};

\node (w) at (3.5,2) {$\begin{array}{r|lll|l}
& X & Y & Z & \bm{n}_u\\
\hline
\textit{White} & \textcolor{red}{50} & \textcolor{red}{50} & 50 & 150 \\
\textit{Black} & 70 & 70 & 70 & 210   \\
\hline
\bm{v}_u & 120 & 120 & 120 & 360\end{array}$};

\draw[blue,fill=blue] (11.667,1.667) circle (.5ex);
\node[] at (11.667,1.267)   (c) {$\dot{\bm{Y}}$};

%\tkzDefPoint(7.667,1.667){M}
%\tkzLabelPoint[right,below](M){Independence}

\node[] at (12, -1.1)   (c) {$\mathcal{Y}_u$};

%polytope
\draw[style=-] (11,0) -- +(-1,1) node[below left=.25cm,anchor=base,midway,rotate=-45] {$y_{p23}>0$};
\draw[style=-] (11,0) -- +(3,0) node[below=.3cm,anchor=base,midway] {$\textcolor{red}{y_{p12}}>0$};
\draw[style=-] (14,0) -- +(0,1) node[right = .3cm,anchor=base,midway,rotate=90] {$\textcolor{black}{y_{p21}>0}$};
\draw[style=-] (14,1) -- +(-3,3) node[above right=.15cm,anchor=base,midway,rotate=-45] {$y_{p13}>0$};
\draw[style=-] (11,4) -- +(-1,0) node[above=.2cm,anchor=base,midway] {$\textcolor{black}{y_{p22}>0}$};
\draw[style=-] (10,1) -- +(0,3) node[left = .2cm,anchor=base,midway,rotate=90] {$\textcolor{red}{y_{p11}}>0$};


\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-3}{}

\resizebox{99in}{3in}{% RJKT advantages
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {};
  \node[const, below=.8 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=1.8 of level, align=center]          (global) {\textcolor{orange}{Global voting propensities}\\\textcolor{orange}{(for each race)}};
  \node[const, below=3.8 of level, align=center]          (latent) {\textcolor[rgb]{0,.5,0}{Precinct-level variation}\\\textcolor[rgb]{0,.5,0}{(for each race)}};
  \node[const, below=7.8 of level, align=center]          (unobserved) {\textcolor{blue}{Precinct vote totals}\\\textcolor{blue}{by race \& candidate}\\\textcolor{blue}{(unobserved)}};
  \node[const, below=9.8 of level, align=center]          (observed) {\textcolor{purple}{Precinct vote totals}\\\textcolor{purple}{by candidate (observed)}};
  \node[const, below=10.9 of level]          (issues) {Advantages};
  \node[const, below=12.2 of level, align=center]          (issues) {Issues\\ \\ \\};
  
  
  
  %ER
  \node[const, align=center, right=3.5 of level]          (ERyear) {(1953)};
  \node[const, align=center, above=.1 of ERyear]          (ER) {$\textcolor[rgb]{1,1,1}{y}$ER$\textcolor[rgb]{1,1,1}{y}$};
  
  \node[latent, below=2 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=10 of ER]  (ERx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of ER] {ERdot} {} {} {};
  \node[obs, left=.5 of ERdot] (ERn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  \edge[-] {ERdot} {ERn} ;
  
  \node[const, align=center, below=11.2 of ER]      (ERpro) {Simple.};
  \node[const, align=center, below=12.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, align=center, right=7 of level]          (Kingyear) {(1997)};
  \node[const, align=center, above=.1 of Kingyear]           (King) {King's EI};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=8 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of King] {Kingdot} {} {} {};
  \node[obs, left=.5 of Kingdot] (Kingn) {$\textcolor{purple}{n_r}$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  
  
  \node[const, align=center, below=11.2 of King]      (Kingpro) {Uses constraints;\\Precinct-level variation};
  \node[const, align=center, below=12.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, align=center, right=10.5 of level]          (RJKTyear) {(2001)};
  \node[const, align=center, above=.1 of RJKTyear]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=6 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=10 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, left=.5 of RJKTdot] (RJKTn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  
  
  \node[const, align=center, below=11.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-4}{}

\resizebox{99in}{3in}{% RJKT disadvantages
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {};
  \node[const, below=.8 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=1.8 of level, align=center]          (global) {\textcolor{orange}{Global voting propensities}\\\textcolor{orange}{(for each race)}};
  \node[const, below=3.8 of level, align=center]          (latent) {\textcolor[rgb]{0,.5,0}{Precinct-level variation}\\\textcolor[rgb]{0,.5,0}{(for each race)}};
  \node[const, below=7.8 of level, align=center]          (unobserved) {\textcolor{blue}{Precinct vote totals}\\\textcolor{blue}{by race \& candidate}\\\textcolor{blue}{(unobserved)}};
  \node[const, below=9.8 of level, align=center]          (observed) {\textcolor{purple}{Precinct vote totals}\\\textcolor{purple}{by candidate (observed)}};
  \node[const, below=10.9 of level]          (issues) {Advantages};
  \node[const, below=12.2 of level, align=center]          (issues) {Issues\\ \\ \\};
  
  
  
  %ER
  \node[const, align=center, right=3.5 of level]          (ERyear) {(1953)};
  \node[const, align=center, above=.1 of ERyear]          (ER) {$\textcolor[rgb]{1,1,1}{y}$ER$\textcolor[rgb]{1,1,1}{y}$};
  
  \node[latent, below=2 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=10 of ER]  (ERx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of ER] {ERdot} {} {} {};
  \node[obs, left=.5 of ERdot] (ERn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  \edge[-] {ERdot} {ERn} ;
  
  \node[const, align=center, below=11.2 of ER]      (ERpro) {Simple.};
  \node[const, align=center, below=12.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, align=center, right=7 of level]          (Kingyear) {(1997)};
  \node[const, align=center, above=.1 of Kingyear]           (King) {King's EI};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=8 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of King] {Kingdot} {} {} {};
  \node[obs, left=.5 of Kingdot] (Kingn) {$\textcolor{purple}{n_r}$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  
  
  \node[const, align=center, below=11.2 of King]      (Kingpro) {Uses constraints;\\Precinct-level variation};
  \node[const, align=center, below=12.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, align=center, right=10.5 of level]          (RJKTyear) {(2001)};
  \node[const, align=center, above=.1 of RJKTyear]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=6 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=10 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, left=.5 of RJKTdot] (RJKTn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  
  
  \node[const, align=center, below=11.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
  \node[const, align=center, below=12.5 of RJKT]      (RJKTcon) {Cheats a bit on\\constraints: no $y$.};
  
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-5}{}

\resizebox{99in}{3in}{% Us advantages
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {};
  \node[const, below=.8 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=1.8 of level, align=center]          (global) {\textcolor{orange}{Global voting propensities}\\\textcolor{orange}{(for each race)}};
  \node[const, below=3.8 of level, align=center]          (latent) {\textcolor[rgb]{0,.5,0}{Precinct-level variation}\\\textcolor[rgb]{0,.5,0}{(for each race)}};
  \node[const, below=7.8 of level, align=center]          (unobserved) {\textcolor{blue}{Precinct vote totals}\\\textcolor{blue}{by race \& candidate}\\\textcolor{blue}{(unobserved)}};
  \node[const, below=9.8 of level, align=center]          (observed) {\textcolor{purple}{Precinct vote totals}\\\textcolor{purple}{by candidate (observed)}};
  \node[const, below=10.9 of level]          (issues) {Advantages};
  \node[const, below=12.2 of level, align=center]          (issues) {Issues\\ \\ \\};
  
  
  
  %ER
  \node[const, align=center, right=3.5 of level]          (ERyear) {(1953)};
  \node[const, align=center, above=.1 of ERyear]          (ER) {$\textcolor[rgb]{1,1,1}{y}$ER$\textcolor[rgb]{1,1,1}{y}$};
  
  \node[latent, below=2 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=10 of ER]  (ERx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of ER] {ERdot} {} {} {};
  \node[obs, left=.5 of ERdot] (ERn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  \edge[-] {ERdot} {ERn} ;
  
  \node[const, align=center, below=11.2 of ER]      (ERpro) {Simple.};
  \node[const, align=center, below=12.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, align=center, right=7 of level]          (Kingyear) {(1997)};
  \node[const, align=center, above=.1 of Kingyear]           (King) {King's EI};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=8 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of King] {Kingdot} {} {} {};
  \node[obs, left=.5 of Kingdot] (Kingn) {$\textcolor{purple}{n_r}$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  
  
  \node[const, align=center, below=11.2 of King]      (Kingpro) {Uses constraints;\\Precinct-level variation};
  \node[const, align=center, below=12.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, align=center, right=10.5 of level]          (RJKTyear) {(2001)};
  \node[const, align=center, above=.1 of RJKTyear]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=6 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=10 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, left=.5 of RJKTdot] (RJKTn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  
  
  \node[const, align=center, below=11.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
  \node[const, align=center, below=12.5 of RJKT]      (RJKTcon) {Cheats a bit on\\constraints: no $y$.};
  
  
  %Us
  \node[const, align=center, right=14 of level]          (usyear) {(2019)};
  \node[const, align=center, above=.1 of usyear]           (us) {Us};
  
  \node[const, below=1.2 of us]           (usprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of us] (usglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of us] (uslatent) {$\textcolor[rgb]{0,.5,0}{\nu}$};
  \node[latent, below=8 of us] (usy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of us]  (usx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of us] {usdot} {} {} {};
  \node[obs, left=.5 of usdot] (usn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {usprior} {usglobal} ;
  \edge {usglobal} {uslatent} ;
  \factoredge {uslatent,usn} {usdot} {usy} ; 
  \edge {usy} {usx} ;
  
  \node[const, align=center, below=11.2 of us]      (uspro) {Respects constraints;\\$R\times C$; "multinomial".};
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-6}{}

\resizebox{99in}{3in}{% Us more advantages
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {};
  \node[const, below=.8 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=1.8 of level, align=center]          (global) {\textcolor{orange}{Global voting propensities}\\\textcolor{orange}{(for each race)}};
  \node[const, below=3.8 of level, align=center]          (latent) {\textcolor[rgb]{0,.5,0}{Precinct-level variation}\\\textcolor[rgb]{0,.5,0}{(for each race)}};
  \node[const, below=7.8 of level, align=center]          (unobserved) {\textcolor{blue}{Precinct vote totals}\\\textcolor{blue}{by race \& candidate}\\\textcolor{blue}{(unobserved)}};
  \node[const, below=9.8 of level, align=center]          (observed) {\textcolor{purple}{Precinct vote totals}\\\textcolor{purple}{by candidate (observed)}};
  \node[const, below=10.9 of level]          (issues) {Advantages};
  \node[const, below=12.2 of level, align=center]          (issues) {Issues\\ \\ \\};
  
  
  
  %ER
  \node[const, align=center, right=3.5 of level]          (ERyear) {(1953)};
  \node[const, align=center, above=.1 of ERyear]          (ER) {$\textcolor[rgb]{1,1,1}{y}$ER$\textcolor[rgb]{1,1,1}{y}$};
  
  \node[latent, below=2 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=10 of ER]  (ERx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of ER] {ERdot} {} {} {};
  \node[obs, left=.5 of ERdot] (ERn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  \edge[-] {ERdot} {ERn} ;
  
  \node[const, align=center, below=11.2 of ER]      (ERpro) {Simple.};
  \node[const, align=center, below=12.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, align=center, right=7 of level]          (Kingyear) {(1997)};
  \node[const, align=center, above=.1 of Kingyear]           (King) {King's EI};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=8 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of King] {Kingdot} {} {} {};
  \node[obs, left=.5 of Kingdot] (Kingn) {$\textcolor{purple}{n_r}$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  
  
  \node[const, align=center, below=11.2 of King]      (Kingpro) {Uses constraints;\\Precinct-level variation};
  \node[const, align=center, below=12.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, align=center, right=10.5 of level]          (RJKTyear) {(2001)};
  \node[const, align=center, above=.1 of RJKTyear]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=6 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=10 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, left=.5 of RJKTdot] (RJKTn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  
  
  \node[const, align=center, below=11.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
  \node[const, align=center, below=12.5 of RJKT]      (RJKTcon) {Cheats a bit on\\constraints: no $y$.};
  
  
  %Us
  \node[const, align=center, right=14 of level]          (usyear) {(2019)};
  \node[const, align=center, above=.1 of usyear]           (us) {Us};
  
  \node[const, below=1.2 of us]           (usprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=2 of us] (usglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4 of us] (uslatent) {$\textcolor[rgb]{0,.5,0}{\nu}$};
  \node[latent, below=8 of us] (usy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=10 of us]  (usx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of us] {usdot} {} {} {};
  \node[obs, left=.5 of usdot] (usn) {$\textcolor{purple}{n_r}$};
  
  % Connect the nodes
  \edge {usprior} {usglobal} ;
  \edge {usglobal} {uslatent} ;
  \factoredge {uslatent,usn} {usdot} {usy} ; 
  \edge {usy} {usx} ;
  
  \node[const, align=center, below=11.2 of us]      (uspro) {Respects constraints;\\$R\times C$; "multinomial".\\Extensible!};
\end{tikzpicture}}

\end{frame}

\begin{frame}{Our model}
\protect\hypertarget{our-model}{}

\resizebox{99in}{2.5in}{%
\begin{tikzpicture}
  % Define nodes
  \node[latent]           (beta) {$\textcolor{orange}{\bm{\beta}_r}$};
  \node[const, above=0.4 of beta] (rbighide) {};
  \node[const, above=of beta] (sdb) {$\textcolor{red}{\sigma_{\beta}}$};
  \node[latent, left=of beta]  (alpha) {$\textcolor{orange}{\bm{\alpha}}$};
  \node[const, above=of alpha] (sda) {$\textcolor{red}{\sigma_{\alpha}}$};
  \node[latent, right=2 of beta]            (gamma) {$\textcolor[rgb]{0,.5,0}{\bm{\nu}_{u,r}}$};
  \node[latent, above=of gamma] (sdg) {$\textcolor{orange}{\sigma_{\nu}}$};
  \node[det, below=.7of gamma]            (pi) {$\textcolor[rgb]{0,.5,0}{\bm{\pi}_{u,r}}$};
  \factor[below=.4 of pi] {multi} {right:$\mathrm{Multi}$} {} {};
  \node[obs, left=of multi]            (n) {$n_{u,r}$};
  \node[latent, below=.5 of multi]            (y) {$\textcolor{blue}{\bm{y}_{u,r}}$};
  \node[obs, diamond, below=of y]            (v) {$\textcolor{purple}{\bm{x}_{u}}$};
  \node[const, right=0.6 of y, yshift=-1.6cm] (ubighide) {};
  \node[const, right=1.2 of y] (rbighide) {};

  % Connect the nodes
  \edge {sda} {alpha} ;
  \edge {sdb} {beta} ;
  \edge {sdg} {gamma} ; 
  \edge {alpha,beta,gamma} {pi} ;
  \factoredge {pi,n} {multi} {y} ; 
  \edge {y} {v} ;

  % Plates
  \plate {U} {(gamma)(y)(multi)(pi)(n)(v)(ubighide)} {$U$} ;
  \plate {R} {(beta)(gamma)(y)(rbighide)(U.north east)} {$R$} ;
\end{tikzpicture}}

\textcolor{red}{{\scriptsize Talk briefly about how you could add other Christmas tree ornaments\\Talk about why this is hard to make a guide for}}

\end{frame}

\begin{frame}{Modified model}
\protect\hypertarget{modified-model}{}

\resizebox{99in}{2.5in}{%
\begin{tikzpicture}
  % Define nodes
  \node[latent]           (beta) {$\textcolor{orange}{\bm{\beta}^-_r}$};
  \node[const, above=0.4 of beta] (rbighide) {};
  \node[const, above=of beta] (sdb) {$\textcolor{red}{\sigma_{\beta}}$};
  \node[latent, left=of beta]  (alpha) {$\textcolor{orange}{\bm{\alpha}^-}$};
  \node[const, above=of alpha] (sda) {$\textcolor{red}{\sigma_{\alpha}}$};
  \node[latent, right=2 of beta]            (gamma) {$\textcolor[rgb]{0,.5,0}{\bm{\nu}_{u,r}}$};
  \node[latent, above=of gamma] (sdg) {$\textcolor{orange}{\sigma_{\nu}}$};
  \node[det, below=.7of gamma]            (pi) {$\textcolor[rgb]{0,.5,0}{\bm{\pi}_{u,r}}$};
  \factor[below=.4 of pi] {multi} {right:$\mathrm{CMult}$} {} {};
  \node[obs, left=of multi]            (n) {$n_{u,r}$};
  \node[latent, below=.5 of multi]            (y) {$\textcolor{blue}{\bm{y}_{u,r}}$};
  \node[const, right=0.8 of y, yshift=-1.6cm] (ubighide) {};
  \node[const, right=1.4 of y] (rbighide) {};
  \node[det, below=of y]            (W) {$\textcolor{blue}{W_{u}}$};
  \node[obs, diamond, left=.66 of W]            (v) {$\textcolor{purple}{\bm{x}_{u}}$};

  % Connect the nodes
  \edge {sda} {alpha} ;
  \edge {sdb} {beta} ;
  \edge {sdg} {gamma}; 
  \edge {alpha,beta,gamma} {pi} ;
  \factoredge {pi,n} {multi} {y} ; 
  \edge[<->] {y} {W} ; 
  \edge[dashed,<->] {W} {v} ; 
  \edge[dashed] {y} {v} ; 

  % Plates
  \plate {U} {(gamma)(y)(multi)(pi)(n)(W)(v)(ubighide)} {$U$} ;
  \plate {R} {(beta)(gamma)(y)(rbighide)(U.north east)} {$R$} ;
\end{tikzpicture}}

\textcolor{red}{{\scriptsize Cmult; Polytopize: ae smooth bijective map from $R^n$ to polytope\\Pseudovoters because of boundary issues that arise from Cmult and polytopize\\All of these make the model itself slightly less-realistic, but make VI work.}}

\end{frame}

\begin{frame}{Polytopize}
\protect\hypertarget{polytopize}{}

\resizebox{4in}{99in}{%
\begin{tikzpicture}

%axes
\draw[dashed,-latex] (4,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[dashed,-latex] (2,2) -- +(-2.5,0) node[below right,midway,rotate=45] {};
\draw[dashed,-latex] (2,2) -- +(0,2) node[below right,midway,rotate=45] {};
\draw[dashed,-latex] (2,2) -- +(0,-2) node[below right,midway,rotate=45] {};

%vectors in y'
\draw[-latex] (2,2) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.3,2.4) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.6,2.8) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.9,3.2) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[fill=black] (3.2, 3.6) circle (.3ex);
\node[above left=0pt of {(3.2, 3.6)}]  {$\bm{w}_1$};


\draw[-latex] (2,2) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (1.6,1.7) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (1.2,1.4) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (0.8,1.1) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[fill=black] (0.4, 0.8) circle (.3ex);
\node[below right=0pt of {(0.4, 0.8)}]  {$\bm{w}_3$};

\draw[-latex] (2,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (2.5,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (3,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (3.5,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[fill=black] (4, 2) circle (.3ex);
\node[below=0pt of {(4, 2)}]  {$\bm{w}_2$};

%function connector
\node[] at (6, 2)   (a) {$m_u(\bm{w})$};
\node[] at (6, 1.5)   (b) {$\longrightarrow$};

%labels for spaces
\node[] at (2, -1.1)   (c) {};
\node[] at (10, -1.1)   (d) {$\mathcal{Y}_u$};


%polytope
\draw[style=-] (9,0) -- +(-1,1) node[below left=.25cm,anchor=base,midway,rotate=-45] {};
\draw[style=-] (9,0) -- +(3,0) node[below=.3cm,anchor=base,midway] {};
\draw[style=-] (12,0) -- +(0,1) node[right = .3cm,anchor=base,midway,rotate=90] {};
\draw[style=-] (12,1) -- +(-3,3) node[above right=.15cm,anchor=base,midway,rotate=-45] {};
\draw[style=-] (9,4) -- +(-1,0) node[above=.2cm,anchor=base,midway] {};
\draw[style=-] (8,1) -- +(0,3) node[left = .2cm,anchor=base,midway,rotate=90] {};


%vectors in polytope
\draw[-latex] (9.5,1.5) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (9.8,1.9) -- +(.2,.266) node[below right,midway,rotate=45] {};
\draw[-latex] (10.0,2.166) -- +(.133,.177) node[below right,midway,rotate=45] {};
\draw[-latex] (10.133,2.344) -- +(.0889,.1185) node[below right,midway,rotate=45] {};
\draw[fill=black] (10.222, 2.4625) circle (.3ex);
\node[above left=0pt of {(10.222, 2.4625)}]  {$m_u(\bm{w}_1)$};



\draw[-latex] (9.5,1.5) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (9.1,1.2) -- +(-.2667,-.2) node[below right,midway,rotate=45] {};
\draw[-latex] (8.833,1.0) -- +(-.1778,-.133) node[below right,midway,rotate=45] {};
\draw[-latex] (8.655,.866) -- +(-.1185,-.0889) node[below right,midway,rotate=45] {};
\draw[fill=black] (8.5366, 0.777) circle (.3ex);
\node[below right=0pt of {(8.5366, 0.777)}]  {$m_u(\bm{w}_3)$};

\draw[-latex] (9.5,1.5) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (10,1.5) -- +(.375,0) node[below right,midway,rotate=45] {};
\draw[-latex] (10.375,1.5) -- +(.281,0) node[below right,midway,rotate=45] {};
\draw[-latex] (10.656,1.5) -- +(.211,0) node[below right,midway,rotate=45] {};
\draw[fill=black] (10.8777, 1.5) circle (.3ex);
\node[below=0pt of {(10.8777, 1.5)}]  {$m_u(\bm{w}_2)$};

%dots at 0,0 and independence

\draw[red,fill=red] (9.5,1.5) circle (.3ex);
\node[above left=0pt of {(9.5,1.5)}]  {$\textcolor{red}{m_u(\vec{0})}$};
\node[below=0pt of {(9.5,1.5)}]  {$\textcolor{red}{\dot{\bm{Y}}}$};
\draw[red,fill=red] (2,2) circle (.3ex);
\node[above left=0pt of {(2,2)}]  {$\textcolor{red}{\vec{0}}$};

\end{tikzpicture}}

Let \(m_u(\bm{w}) := g(a(\bm{w}))\), where \(a\) is affine projection,
\(g\) is retraction

\(b(M)\): the intersection of ray \(\overrightarrow{\dot{Y} M}\) with
boundary of \(\mathcal{Y}_u\) \[
        g(M) := \left\{
        \begin{array}{cl}
            \dot{Y}&\text{if } M = \dot{Y}, \\
            \dot{Y} + \exp\left(-\frac{\vert b(M)-\dot{Y}\vert}{\vert M-\dot{Y}\vert}\right)\cdot(b(M)-\dot{Y})&\text{ otherwise}.
        \end{array}\right.
\]

\begin{itemize}
\tightlist
\item
  Note that \(m_u(\bm{0}) = \dot{Y}\).
\end{itemize}

\(| 4 \vert\)

\end{frame}

\begin{frame}{Testing our EI on simulated data}
\protect\hypertarget{testing-our-ei-on-simulated-data}{}

\begin{itemize}
\tightlist
\item
  Data cleaning on racial breakdown by precinct in NC
\item
  Used exit polls to calculate realistic \(\bm{\alpha}\) and
  \(\bm{\beta}\) for 2016 presidential election
\item
  \(3\times 3\):

  \begin{itemize}
  \tightlist
  \item
    Races: White/Black/Other
  \item
    Candidates: Trump/Clinton/Other (where ``other'' includes both 3rd
    party and not voting)
  \end{itemize}
\item
  Simulated datasets from our model using three choices of
  \(\sigma_\nu\): 0.02, 0.1, 0.3
\item
  Ran LVI using pyro, RJKT using eiPack in R.
\item
  Reporting \(\bar{Q}\) and \(s_Q\) for each race and candidate: the
  mean and s.d. of \(Q(z_i)\) where \(z_i\) is a sample from the fitted
  posterior and \(Q\) gives the percent of the given race who voted for
  the given candidate.
\end{itemize}

\end{frame}

\begin{frame}{EI results}
\protect\hypertarget{ei-results}{}

Results for \(\sigma_\nu=0.02\)

\begin{table}[htbp]
 \label{results0.3}
 \begin{tabular}{cc|cc|cc|cc}
       \multicolumn{2}{c}{}   & \multicolumn{2}{c}{Other/none} & \multicolumn{2}{c}{Clinton (D)} & \multicolumn{2}{c}{Trump (R)} \\
                   &$\mathcal{A}$       &  $\overline{Q}$         &   $s_Q$       &  $\overline{Q}$         &   $s_Q$     &  $\overline{Q}$         &   $s_Q$          \\
 \hline
\multirow{3}{*}{White} & Truth & 32.4\% &  & 22.6\% &  & 45.0\% &  \\ 
   & RJKT & 32.3\% & 0.059\% & 22.5\% & 0.069\% & 45.0\% & 0.057\% \\ 
   & LVI & 32.3\% & 0.028\% & 22.7\% & 0.028\% & 45.0\% & 0.030\% \\ 
   \hline 
  \multirow{3}{*}{Black} & Truth & 38.1\% &  & 56.6\% &  & 5.28\% &  \\ 
   & RJKT & 38.4\% & 0.32\% & 56.2\% & 0.19\% & 4.87\% & 0.19\% \\ 
   & LVI & 37.9\% & 0.067\% & 56.3\% & 0.058\% & 5.79\% & 0.046\% \\ 
   \hline 
  \multirow{3}{*}{Other} & Truth & 43.4\% &  & 32.7\% &  & 24.0\% &  \\ 
   & RJKT & 41.5\% & 0.65\% & 32.9\% & 0.41\% & 24.2\% & 0.72\% \\ 
   & LVI & 44.4\% & 0.25\% & 32.4\% & 0.21\% & 23.3\% & 0.25\% \\ 
   \hline 
 \end{tabular}
 \end{table}

\textcolor{red}{{\scriptsize Point out that this is different (better!) than what you originally sent, because:\\does not underestimate variance (fixed bug)\\corrected alphas and betas (so that overall percentages of people of each race voting for each candidate approximate the true 2016 data, as intended)\\improved amortization (optimize Y <U+2192> optimize W)\\Conclusion: We are as good as RJKT, but we’re just getting started}}

\end{frame}

\begin{frame}{EI results}
\protect\hypertarget{ei-results-1}{}

Results for \(\sigma_\nu=0.3\)

\begin{table}[htbp]
 \label{results0.3}
 \begin{tabular}{cc|cc|cc|cc}
       \multicolumn{2}{c}{}   & \multicolumn{2}{c}{Other/none} & \multicolumn{2}{c}{Clinton (D)} & \multicolumn{2}{c}{Trump (R)} \\
                   &$\mathcal{A}$       &  $\overline{Q}$         &   $s_Q$       &  $\overline{Q}$         &   $s_Q$     &  $\overline{Q}$         &   $s_Q$          \\
 \hline
\multirow{3}{*}{White} & Truth & 32.3\% &  & 22.7\% &  & 45.0\% &  \\ 
                       & RJKT & 32.3\% & 0.080\% & 22.8\% & 0.11\% & 44.8\% & 0.14\% \\ 
                       & LVI & 33.2\% & 0.067\% & 23.5\% & 0.049\% & 43.0\% & 0.070\% \\ 
   \hline
  \multirow{3}{*}{Black} & Truth & 38.9\% &  & 55.6\% &  & 5.48\% &  \\ 
   & RJKT & 40.4\% & 0.39\% & 53.7\% & 0.38\% & 5.33\% & 0.20\% \\ 
   & LVI & 36.3\% & 0.17\% & 54.6\% & 0.15\% & 9.21\% & 0.16\% \\ 
   \hline
  \multirow{3}{*}{Other} & Truth & 43.0\% &  & 32.7\% &  & 24.3\% &  \\ 
   & RJKT & 38.3\% & 1.1\% & 35.4\% & 0.52\% & 24.9\% & 1.1\% \\ 
   & LVI & 45.0\% & 0.46\% & 33.6\% & 0.40\% & 21.7\% & 0.47\% \\ 
   \hline
 \end{tabular}
 \end{table}

\textcolor{red}{{\scriptsize Point out that this is different (better!) than what you originally sent, because:\\does not underestimate variance (fixed bug)\\corrected alphas and betas (so that overall percentages of people of each race voting for each candidate approximate the true 2016 data, as intended)\\did NOT improve amortization (optimize Y -> optimize W)\\Conclusion: We are as good as RJKT, but we’re just getting started}}

\end{frame}

\begin{frame}{Discussion/future work (Ch. 3)}
\protect\hypertarget{discussionfuture-work-ch.-3}{}

\begin{itemize}
\tightlist
\item
  Including racial makeup of precinct as a covariate
\item
  Hierarchical model (counties)
\item
  Multiple elections
\item
  Actual NC data
\item
  Compare hierachical model without EI, Standard RJKT, and our model
\item
  Cross-validation
\end{itemize}

\textcolor{red}{{\scriptsize Say that this is the stuff we plan to include in final paper}}

\end{frame}

\begin{frame}{Discussion/future work (Ch. 2)}
\protect\hypertarget{discussionfuture-work-ch.-2}{}

\begin{itemize}
\tightlist
\item
  More on subsampling:

  \begin{itemize}
  \tightlist
  \item
    General theory of how to assign weights to minimize variance of
    estimator in subsampling
  \item
    Some theory to help choose sample size for SVI
  \end{itemize}
\item
  Investigate replacing normal with T in guide
\end{itemize}

\textcolor{red}{{\scriptsize (use Ch 3 as example)\\Say that this will not be in current paper, which is basically done}}

\end{frame}

\begin{frame}{Thanks}
\protect\hypertarget{thanks}{}

Thank you!

\end{frame}

\begin{frame}{Directory of extra slides}
\protect\hypertarget{directory-of-extra-slides}{}

\begin{itemize}
\tightlist
\item
  Prior work
\item
  EI amortization
\item
  \emph{Thornburg v. Gingles}
\item
  Model (for discussing extensions)
\end{itemize}

\end{frame}

\begin{frame}{Non-meanfield prior work}
\protect\hypertarget{non-meanfield-prior-work}{}

\begin{itemize}
\tightlist
\item
  Copula VI (Han et al 2015): create arbitrary transformations, to allow
  ``quasi-correlation matrices'' for non-Gaussian families. The values
  for such matrices are unrestricted, though.
\item
  Time-series (Zhang et al 2017): model-specific tricks.
\item
  Hierarchical VI (Ranganath et al 2015): put a prior on the guide then
  marginalize it out. Relies on conjugacy.
\item
  Variational Boosting (Miller et al 2016): Correlation structure:
  low-rank plus diagonal.
\item
  Normalizing flows (Rezende et al 2015): Kinda like adding a step of
  MCMC after sampling from guide.
\item
  ``Laplace Variational Inference'' (Wang \& Blei, 2012): Use Laplace
  approximation to approve update step in a conjugate meanfield VI.
\item
  Imaging (Zhang et al 2017): Use Laplace approximation around posterior
  mode for certain fixed-size subsets of parameters. No boosting.
\end{itemize}

\end{frame}

\begin{frame}{How our EI amortization works}
\protect\hypertarget{how-our-ei-amortization-works}{}

Which variables are we amortizing: Y, nu, sigma\_nu

Steps:

\begin{itemize}
\tightlist
\item
  Find approximate mode of
  \(p(\bm{Y}|\bm{\alpha}, \bm{\beta};\bm{\nu}=0)\) constrained to lie on
  polytope (this is linear algebra plus Stirling's approximation)
\item
  Not yet done: One-dimensional Newton's method to find approximate mode
  of W. (Not the same thing, because there's Jacobian, mode of W is
  further away from boundary)
\item
  Find approximate mode of
  \(p(\bm{\nu}_u, \sigma_{\nu}| \bm{\gamma}, \bm{W}_u)\) (ad hoc
  algorithm, but see next step)
\item
  Newton's method (for free!!)
\end{itemize}

\end{frame}

\begin{frame}{\emph{Thornburg v Gingles}, 1986}
\protect\hypertarget{thornburg-v-gingles-1986}{}

A majority-minority district must be created if:

\begin{enumerate}
\item
  A minority group is ``sufficiently numerous and compact to form a
  majority in a single-member district''; and
\item
  The minority group is
  \textcolor{red}{\textbf{"politically cohesive"}}; and
\item
  The ``majority \textcolor{red}{\textbf{votes sufficiently as a bloc}}
  to enable it \ldots{} usually to defeat the minority's preferred
  candidate.''
\end{enumerate}

\end{frame}

\begin{frame}{Flexible model}
\protect\hypertarget{flexible-model}{}

\includegraphics[width=0.3\textwidth,height=\textheight]{holidaytree_bare.jpg}
\includegraphics[width=0.3\textwidth,height=\textheight]{holidaytree_decorated.png}

\[\vec{y}_{p,r}=y_{p,r,c}\vert_{c=1}^C\sim \operatorname{CMult}\left(n_{p,r},\frac{exp(\alpha_c+\beta_{r,c}\textcolor{red}{+\nu_{r,c,p}})\vert_{c=1}^C}{\sum_{c=1}^Cexp(\alpha_c+\beta_{r,c}\textcolor{red}{+\nu_{r,c,p}})}\right)\]

\[\alpha_c\sim\mathcal{N}(0,2)\]

\[\beta_{r,c}\sim\mathcal{N}(0,2)\]

\[\textcolor{red}{\nu_{r,c,p}\sim\mathcal{N}(0,\sigma_\beta)}~~~~~~~\sigma_\lambda\sim\operatorname{LogNormal}(-1.5,.5)\]
\(\nu\) handles overdispersion. Note: Bayesian Occam's Razor.

\end{frame}

\end{document}
