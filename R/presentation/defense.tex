\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph:
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Dissertation Defense: Numerical Methods for Approximating High-Dimensional Posterior Distributions},
  pdfauthor={Jameson Quinn},
  pdfborder={0 0 0},
  breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\newif\ifbibliography
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-2}

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{tikz}
\usetikzlibrary{bayesnet}
\usetikzlibrary{arrows}
\usetikzlibrary{cd}
\usepackage{pgfplots}
\usepackage{lastpage}
\usepackage{mathrsfs}
\usepackage[makeroom]{cancel}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usetikzlibrary{fit,positioning}
\tikzset{font={\fontsize{9pt}{12}\selectfont}}
\setbeamertemplate{footline}{\begin{flushright}\thepage/\pageref{LastPage}~~.\\\end{flushright}}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{xcolor}
\definecolor{blue1}{HTML}{4466FF}
\definecolor{blue2}{HTML}{0022AA}


\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\orange}[1]{\textcolor{orange}{#1}}
\newcommand{\yellow}[1]{\textcolor{yellow}{#1}}
\newcommand{\green}[1]{\textcolor[rgb]{0,.5,0}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\purple}[1]{\textcolor{purple}{#1}}

\title{Dissertation Defense: Numerical Methods for Approximating
High-Dimensional Posterior Distributions}
\author{Jameson Quinn}
\date{}

\begin{document}
\frame{\titlepage}

\begin{frame}{Big picture overview}
\protect\hypertarget{big-picture-overview}{}

\[P(\theta|x)=\frac{P(x|\theta)P(\theta)}{\int_{\theta'\in\Theta} P(x|\theta')P(\theta')d\theta'}\]
If \(\Theta\) is high-D, any estimator of the denominator that amounts
to numerical integration will fail; variance exponential in dim.

\begin{itemize}
\tightlist
\item
  Chapter 1: online data assimilation on spatiotemporal system
\item
  Chapter 2: new method applicable to latent variable models
\item
  Chapter 3: application of method, extension of existing models
\end{itemize}

\textcolor{red}{{\scriptsize You will notice a few changes to what I sent you, particularly in the chapter 3 results; I will point them out as we go along\\Talk about Mira\\the major motivating ideas (idea of Laplace family, idea of applying VI to EI) come from me\\I did all the coding in Pyro\\otherwise Mira is equal collaborator and coauthor\\we checked that this is allowed}}

\end{frame}

\begin{frame}{Variational Inference}
\protect\hypertarget{variational-inference}{}

Approximate posterior with a guide distribution
\(q_{\bm{\phi}}(\bm{\theta})\) and choose \(\bm{\phi}\) to mimize KL:
\[\hat{{\bm{\phi}}}=\mathrm{argmin}_{\bm{\phi}}\left[D_{\mathrm{KL}} \left(\;q_{\bm{\phi}}(\bm{\theta})\;\big|\big|\; p(\bm{\theta}|\bm{x})\;\right)\right].\]
Equivalent to maximizing ELBO:
\[\mathrm{ELBO}({\bm{\phi}}):=E_{q_{\bm{\phi}}}
\left[\mathrm{log} p(\bm{x},\bm{\theta})-\mathrm{log} q_{\bm{\phi}}(\bm{\theta})\right]\]

\textcolor{red}{{\scriptsize Emphasize conceptual part (minimizing KL-divergence)\\Be sure to be clear about difference between model parameters and guide parameters\\Talk about why entropy term is important\\Mention EUBO}}

\end{frame}

\begin{frame}{Pyro}
\protect\hypertarget{pyro}{}

Released in 2017 and still under very active development, pyro is a
cutting-edge python package for black-box VI. * Automatic
differentiation via PyTorch ML * Stochastic optimization * BBVI seems
empirically robust

\textcolor{red}{{\scriptsize Explain automatic differentiation\\All the impressive software engineering I had to do}}

\end{frame}

\begin{frame}{Problem with existing (mainstream) VI method}
\protect\hypertarget{problem-with-existing-mainstream-vi-method}{}

This talk will focus on MVN guide families.

A common assumption is posterior independence of parameters, referred to
as ``meanfield'' guides. Problem:

\textcolor{red}{{\scriptsize can’t capture posterior correlations\\systematically underestimates posterior marginals}}

\begin{center}\includegraphics[width=150px]{meanfield_covar_figure} \end{center}

\end{frame}

\begin{frame}{Introduce Laplace family VI (1)}
\protect\hypertarget{introduce-laplace-family-vi-1}{}

Among MVN guide families:

\begin{itemize}
\tightlist
\item
  Set of all normals, unrestricted covariance, is too big
\item
  Meanfield subset doesn't actually contain any good approximations
\item
  We want subfamily that contains at least some good approximations
  without being too big
\end{itemize}

\end{frame}

\begin{frame}{Introduce Laplace family VI (2)}
\protect\hypertarget{introduce-laplace-family-vi-2}{}

Let's guarantee that the family contains the Laplace approximation
around any posterior mode.

Define covariance matrix using observed information of posterior;
negative of Hessian of unnormalized log-density:

\(\mathcal{I}_p\left(\bm{\theta}^*\right) := -H\left[\log p(\bm{\theta})\right]\bigg\rvert_{\bm{\theta}^*}\)

\end{frame}

\begin{frame}{Boosting}
\protect\hypertarget{boosting}{}

\(\mathcal{I}_p\) not guaranteed to be positive definite. So define
``boosting'' function \(f(\mathcal{I}_p)\) s.t.:

\begin{itemize}
\tightlist
\item
  Smooth almost everywhere.
\item
  \(f(\mathcal{I}_p)\approx\mathcal{I}_p\) if \(\mathcal{I}_p\) already
  p.d. A similar problem arises in optimization (quasi-Newton methods);
  solved via modified Cholesky algorithms (Fang, 2008)
\end{itemize}

Furthermore, we can parametrize \(f\) to create a boosting family
\(f_{\bm{\psi}}\), for \(\psi_i>0\), s.t.:

\begin{itemize}
\tightlist
\item
  Each dimension of \(\bm{\psi}\) corresponds to a model parameter
\item
  As \(\bm{\psi}\rightarrow\vec{\bm{0}}\) from above,
  \(f(\mathcal{I}_p)\rightarrow\mathcal{I}_p\) if \(\mathcal{I}_p\)
  already p.d.
\end{itemize}

\textcolor{red}{{\scriptsize Explain why boosting family is better than just boosting function\\Version of thesis sent previously has quasi-boosting which we’re no longer using\\Citation for method that we’re actually using}}

\end{frame}

\begin{frame}{Formal definition of Laplace family (1)}
\protect\hypertarget{formal-definition-of-laplace-family-1}{}

Let \(p(\bm{\theta})\) be a (possibly unnormalized) probability
distribution on \(\mathbb{R}^d\). Let \(\Theta \subseteq \mathbb{R}^d\),
\(\Psi \subseteq \mathbb{R}^D_+\), and let \(f_\Psi\) be a boosting
family.

The Laplace guide family \(\mathcal{L}_{\Theta\times\Psi} (p,f_\Psi)\)
is the set of \(d\)-dimesnional normal distributions
\(\{q_{\bm{\theta}^*,\bm{\psi}}:\bm{\theta}^*\in\Theta,\;\bm{\psi}\in\Psi\}\),
where \(q_{\bm{\theta}^*,\bm{\psi}}\) has mean \(\bm{\theta}^*\) and
precision matrix
\(f_{\bm{\psi}} \left(\mathcal{I}_p(\bm{\theta}^*)\right)\).

\end{frame}

\begin{frame}{Toy model results}
\protect\hypertarget{toy-model-results}{}

Comparison of Laplace family fit with meanfield fit on simple model with
a bimodal posterior:

\begin{center}\includegraphics[width=150px]{simplegraph} \end{center}

\textcolor{red}{{\scriptsize Simple model with bimodal posterior\\Shows several things: Importance of covariance; case where laplace of MAP isn't optimal; case where boosting is necessary, and boosting family is better than boosting function}}

\end{frame}

\begin{frame}{Latent variable models (or: why hi-D?)}
\protect\hypertarget{latent-variable-models-or-why-hi-d}{}

A latent variable model has 3 core elements:

\begin{itemize}
\tightlist
\item
  Global parameters: \(\bm{\gamma}\in\Gamma \cong \mathbb{R}^g\),
\item
  ``iid'' latent parameter vectors:
  \(\bm{\lambda}_1,\dots,\bm{\lambda}_N\in\Lambda \cong \mathbb{R}^l\)
\item
  Observation vectors: \(\bm{x}_1,\dots,\bm{x}_N\), also independent
  conditional on globals and relevant locals.
\end{itemize}

In other words,
\[p\left(\bm{\gamma}, \bm{\lambda}_1,\dots,\bm{\lambda}_N,\bm{x}_1,\dots,\bm{x}_N\right) = p(\bm{\gamma})\prod_{i=1}^N p(\bm{\lambda}_i|\bm{\gamma})\; p(\bm{x}_i|\bm{\lambda}_i,\bm{\gamma})\]

\textcolor{red}{{\scriptsize This is why we need a high-dimensional solution.}}

\end{frame}

\begin{frame}{Block arrowhead matrices}
\protect\hypertarget{block-arrowhead-matrices}{}

\[\mathcal{I}_p(\bm{\theta}^*) = \left(\begin{array}{ccccc}
    G & C_1 & C_2 & \dots & C_N \\
    C_1^T & U_1 & 0 & \dots & 0 \\
    C_2^T & 0 & U_2 & \dots & 0 \\
    \vdots & 0 & 0 & \ddots & 0 \\
    C_N^T & 0 & 0 & \dots & U_N
    \end{array}\right)\]

Useful fact: if this is viewed as a precision matrix, then the
``marginal precision''
\(([\mathcal{I}_p(\bm{\theta}^*)^{-1}]_{\Gamma,\Gamma})^{-1}=G-\sum_i C_iU_i^{-1}C_i^T\)

\textcolor{red}{{\scriptsize easy to sample from and easy to boost.}}

\end{frame}

\begin{frame}{Additional methods for LV models 1: SVI}
\protect\hypertarget{additional-methods-for-lv-models-1-svi}{}

\textcolor{red}{{\scriptsize Two methods that are useful with LV models. Conceptually independent, but go well together. First is:}}

SVI (Stochastic Variational Inference)

Basic idea: since unnormalized log density is a sum of unit-level terms,
use only a randomly-sampled subset of those terms. For a given sampling
scheme (possibly weighted), there are obvious estimators for:

\begin{itemize}
\tightlist
\item
  Posterior log density; unbiased
\item
  Hessian thereof. Up to boosting, unbiased for both conditional
  precision \(G\) and marginal precision
  \(([\mathcal{I}_p(\bm{\theta}^*)^{-1}]_{\Gamma,\Gamma})^{-1}=G-\sum_i C_iU_i^{-1}C_i^T\)
\item
  ELBO and ELBO gradient wrt guide parameters, using the above. Not
  unbiased, even without boosting; but seem to work well.
\end{itemize}

\textcolor{red}{{\scriptsize Mention weights, say we haven’t yet implemented them anywhere\\think about exactly what you want to say about its qusi-unbiasedness (have hidden slides with slide with details)}}

\end{frame}

\begin{frame}{Additional methods for LV models 2: amortization}
\protect\hypertarget{additional-methods-for-lv-models-2-amortization}{}

restricting to subspace of the guide where latents are approximate MAPs
relative to globals,

\textbackslash{}textcolor\{red\}\{\{\scriptsize guide parameters are now
just gamma, psi\_gamma, psi\_lambda\textbackslash{}possibly mention
Newton's method, but Mira thinks not\}\}

\end{frame}

\begin{frame}{Ch 1 Results}
\protect\hypertarget{ch-1-results}{}

Improved version from thesis Very brief explanation only, but mention
transforming parameters

\end{frame}

\begin{frame}{Ch 2: Ecological inference. Introduction}
\protect\hypertarget{ch-2-ecological-inference.-introduction}{}

\resizebox{99in}{1.5in}{%
\begin{tikzpicture}[thick,scale=0.9, every node/.style={transform shape},
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {1.25,1,.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\draw[-latex] (7,0) -- +(1,1) node[below right,midway,rotate=45] {precinct};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (3.99,3.7) {Candidate};


\node (w) at (3.5,2) {$\begin{array}{r|ccc|l}
& X & Y & Z & n_u\\
\hline
White & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 400 \\
Black & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 200   \\
Hispanic & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 100   \\
Other & \textcolor{red}{?} & \textcolor{red}{?} & \textcolor{red}{?} & 100   \\
\hline
v_u & 400 & 200 & 200 & 800\end{array}$};

%\node (w) at (4.5,-1) [text width=8.25cm]{Observed data for one hypothetical precinct};
\end{tikzpicture}}

\textcolor{red}{{\scriptsize Mainly comes up in voting rights cases, so I’ll talk about it in this setting.\\     Z could represent not voting.}}

\end{frame}

\begin{frame}{EI: example matrices}
\protect\hypertarget{ei-example-matrices}{}

\resizebox{99in}{1.5in}{%
\begin{tikzpicture}[thick,scale=0.9, every node/.style={transform shape},
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {1.25,1,.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\draw[-latex] (7,0) -- +(1,1) node[below right,midway,rotate=45] {precinct};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (3.99,3.7) {Candidate};



\node (w) at (3.5,2) {$\begin{array}{r|ccc|l}
& X & Y & Z & n_u\\
\hline
White & \textcolor{red}{400} & 0 & 0 & 400 \\
Black & 0 & \textcolor{red}{200} & 0 & 200   \\
Hispanic & 0 & 0 & \textcolor{red}{100} & 100   \\
Other & 0 & 0 & \textcolor{red}{100} & 100   \\
\hline
 v_u & 400 & 200 & 200 & 800\end{array}$};


%\node (w) at (4.5,-1) [text width=8.25cm]{Possible underlying data A: assuming largest groups vote for most-popular candidates};




\foreach \x in {1.25,1,.75,0.5,0.25,0}\pic at (9+\x,\x){squared notebook};
\draw[-latex] (16,0) -- +(1,1) node[below right,midway,rotate=45] {precinct};
\node[rotate=90] (h) at (9.5,2) {Race};
\node (w) at (12.99,3.7) {Candidate};



\node (w) at (12.5,2) {$\begin{array}{r|ccc|l}
& X & Y & Z & n_u\\
\hline
White & \textcolor{red}{200} & \textcolor{red}{100} & \textcolor{red}{100} & 400 \\
Black & \textcolor{red}{100} & \textcolor{red}{50} & \textcolor{red}{50} & 200   \\
Hispanic & \textcolor{red}{50} & \textcolor{red}{25} & \textcolor{red}{25} & 100   \\
Other & \textcolor{red}{50} & \textcolor{red}{25} & \textcolor{red}{25} & 100   \\
\hline
v_u & 400 & 200 & 200 & 800\end{array}$};

%\node (w) at (13,-1) [text width=8.25cm]{Possible underlying data B: assuming candidate's percent support is independent of race};

\end{tikzpicture}}

\end{frame}

\begin{frame}{Relevance: Thornburg v. Gingles}
\protect\hypertarget{relevance-thornburg-v.-gingles}{}

Mention Gingles SCOTUS case briefly show Gingles graph

\end{frame}

\begin{frame}{History of attempted solutions: ER}
\protect\hypertarget{history-of-attempted-solutions-er}{}

\includegraphics{defense_files/figure-beamer/unnamed-chunk-14-1.pdf}

Brexit voting data. (Example from ``The Stats Guy'' blog by Adam
Jacobs.) Valid under certain (strong) assumptions.

\end{frame}

\begin{frame}{History of attempted solutions: ERrrrr\ldots{}}
\protect\hypertarget{history-of-attempted-solutions-errrrr}{}

\includegraphics{defense_files/figure-beamer/unnamed-chunk-15-1.pdf}

Brexit supported by 79\% of people without a degree\ldots{} and -16\% of
those with one??? Ecological fallacy, Simpson's paradox, etc.

\end{frame}

\begin{frame}{King's EI: 2x2 case (1)}
\protect\hypertarget{kings-ei-2x2-case-1}{}

Key insight:

\end{frame}

\begin{frame}{King's EI: 2x2 case (2)}
\protect\hypertarget{kings-ei-2x2-case-2}{}

\end{frame}

\begin{frame}{Rosen, Jiang, King, \& Tanner: RxC case (1)}
\protect\hypertarget{rosen-jiang-king-tanner-rxc-case-1}{}

Explain model

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models}{}

\resizebox{99in}{3in}{%
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {Level};
  \node[const, below=1.2 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=3.2 of level]          (global) {\textcolor{orange}{Global}};
  \node[const, below=5.2 of level]          (latent) {\textcolor[rgb]{0,.5,0}{Latent}};
  \node[const, below=7.2 of level]          (unobserved) {\textcolor{blue}{unobserved}};
  \node[const, below=9.2 of level]          (observed) {\textcolor{purple}{observed}};
  \node[const, below=10.2 of level]          (issues) {Advantages};
  \node[const, below=11.5 of level]          (issues) {Issues};
  
  
  
  %ER
  \node[const, right=2.5 of level]          (ER) {ER};
  
  \node[latent, below=3 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=9 of ER]  (ERx) {$\textcolor{purple}{x}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  
  \node[const, align=center, below=10.2 of ER]      (ERpro) {It's a thing.};
  \node[const, align=center, below=11.5 of ER]      (ERcon) {Impossible\\estimates.};
  
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-1}{}

\resizebox{99in}{3in}{%
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {Level};
  \node[const, below=1.2 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=3.2 of level]          (global) {\textcolor{orange}{Global}};
  \node[const, below=5.2 of level]          (latent) {\textcolor[rgb]{0,.5,0}{Latent}};
  \node[const, below=7.2 of level]          (unobserved) {\textcolor{blue}{unobserved}};
  \node[const, below=9.2 of level]          (observed) {\textcolor{purple}{observed}};
  \node[const, below=10.2 of level]          (issues) {Advantages};
  \node[const, below=11.5 of level]          (issues) {Issues\\ \\ \\.};
  
  
  
  %ER
  \node[const, right=2.5 of level]          (ER) {ER};
  
  \node[latent, below=3 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=9 of ER]  (ERx) {$\textcolor{purple}{x}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  
  \node[const, align=center, below=10.2 of ER]      (ERpro) {It's a thing.};
  \node[const, align=center, below=11.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, right=2.5 of ER]           (King) {King (97)};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=5 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=7 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=6.25 of King] {Kingdot} {} {} {};
  \node[obs, right=.5 of Kingdot] (Kingn) {$n_r$};
  \factor[below=4.25 of King] {KingdotN} {} {} {};
  \node[obs, right=.5 of KingdotN] (KingN) {$n?$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  \edge[dashed,-] {KingdotN} {KingN} ;
  
  \node[const, align=center, below=10.2 of King]      (Kingpro) {Respects constraints.};
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-2}{}

\resizebox{99in}{3in}{%
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {Level};
  \node[const, below=1.2 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=3.2 of level]          (global) {\textcolor{orange}{Global}};
  \node[const, below=5.2 of level]          (latent) {\textcolor[rgb]{0,.5,0}{Latent}};
  \node[const, below=7.2 of level]          (unobserved) {\textcolor{blue}{unobserved}};
  \node[const, below=9.2 of level]          (observed) {\textcolor{purple}{observed}};
  \node[const, below=10.2 of level]          (issues) {Advantages};
  \node[const, below=11.5 of level]          (issues) {Issues\\ \\ \\.};
  
  
  
  %ER
  \node[const, right=2.5 of level]          (ER) {ER};
  
  \node[latent, below=3 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=9 of ER]  (ERx) {$\textcolor{purple}{x}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  
  \node[const, align=center, below=10.2 of ER]      (ERpro) {It's a thing.};
  \node[const, align=center, below=11.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, right=2.5 of ER]           (King) {King (97)};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=5 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=7 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=6.25 of King] {Kingdot} {} {} {};
  \node[obs, right=.5 of Kingdot] (Kingn) {$n_r$};
  \factor[below=4.25 of King] {KingdotN} {} {} {};
  \node[obs, right=.5 of KingdotN] (KingN) {$n?$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  \edge[dashed,-] {KingdotN} {KingN} ;
  
  
  \node[const, align=center, below=10.2 of King]      (Kingpro) {Respects constraints.};
  \node[const, align=center, below=11.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-3}{}

\resizebox{99in}{3in}{%
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {Level};
  \node[const, below=1.2 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=3.2 of level]          (global) {\textcolor{orange}{Global}};
  \node[const, below=5.2 of level]          (latent) {\textcolor[rgb]{0,.5,0}{Latent}};
  \node[const, below=7.2 of level]          (unobserved) {\textcolor{blue}{unobserved}};
  \node[const, below=9.2 of level]          (observed) {\textcolor{purple}{observed}};
  \node[const, below=10.2 of level]          (issues) {Advantages};
  \node[const, below=11.5 of level]          (issues) {Issues\\ \\ \\.};
  
  
  
  %ER
  \node[const, right=2.5 of level]          (ER) {ER};
  
  \node[latent, below=3 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=9 of ER]  (ERx) {$\textcolor{purple}{x}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  
  \node[const, align=center, below=10.2 of ER]      (ERpro) {It's a thing.};
  \node[const, align=center, below=11.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, right=2.5 of ER]           (King) {King (97)};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=5 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=7 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=6.25 of King] {Kingdot} {} {} {};
  \node[obs, right=.5 of Kingdot] (Kingn) {$n_r$};
  \factor[below=4.25 of King] {KingdotN} {} {} {};
  \node[obs, right=.5 of KingdotN] (KingN) {$n?$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  \edge[dashed,-] {KingdotN} {KingN} ;
  
  
  \node[const, align=center, below=10.2 of King]      (Kingpro) {Respects constraints.};
  \node[const, align=center, below=11.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, right=2.5 of King]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4.3 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=5.7 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=9 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, right=.5 of RJKTdot] (RJKTn) {$n_r$};
  \factor[below=8.25 of RJKT] {RJKTdotN} {} {} {};
  \node[obs, right=.5 of RJKTdotN] (RJKTN) {$n$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  \edge[-] {RJKTdotN} {RJKTN} ;
  
  
  \node[const, align=center, below=10.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-4}{}

\resizebox{99in}{3in}{%
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {Level};
  \node[const, below=1.2 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=3.2 of level]          (global) {\textcolor{orange}{Global}};
  \node[const, below=5.2 of level]          (latent) {\textcolor[rgb]{0,.5,0}{Latent}};
  \node[const, below=7.2 of level]          (unobserved) {\textcolor{blue}{unobserved}};
  \node[const, below=9.2 of level]          (observed) {\textcolor{purple}{observed}};
  \node[const, below=10.2 of level]          (issues) {Advantages};
  \node[const, below=11.5 of level]          (issues) {Issues\\ \\ \\.};
  
  
  
  %ER
  \node[const, right=2.5 of level]          (ER) {ER};
  
  \node[latent, below=3 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=9 of ER]  (ERx) {$\textcolor{purple}{x}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  
  \node[const, align=center, below=10.2 of ER]      (ERpro) {It's a thing.};
  \node[const, align=center, below=11.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, right=2.5 of ER]           (King) {King (97)};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=5 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=7 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=6.25 of King] {Kingdot} {} {} {};
  \node[obs, right=.5 of Kingdot] (Kingn) {$n_r$};
  \factor[below=4.25 of King] {KingdotN} {} {} {};
  \node[obs, right=.5 of KingdotN] (KingN) {$n?$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  \edge[dashed,-] {KingdotN} {KingN} ;
  
  
  \node[const, align=center, below=10.2 of King]      (Kingpro) {Respects constraints.};
  \node[const, align=center, below=11.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, right=2.5 of King]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4.3 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=5.7 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=9 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, right=.5 of RJKTdot] (RJKTn) {$n_r$};
  \factor[below=8.25 of RJKT] {RJKTdotN} {} {} {};
  \node[obs, right=.5 of RJKTdotN] (RJKTN) {$n$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  \edge[-] {RJKTdotN} {RJKTN} ;
  
  
  \node[const, align=center, below=10.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
  \node[const, align=center, below=11.5 of RJKT]      (RJKTcon) {No $y$; cheats a bit\\on constraints.};
  
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-5}{}

\resizebox{99in}{3in}{%
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {Level};
  \node[const, below=1.2 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=3.2 of level]          (global) {\textcolor{orange}{Global}};
  \node[const, below=5.2 of level]          (latent) {\textcolor[rgb]{0,.5,0}{Latent}};
  \node[const, below=7.2 of level]          (unobserved) {\textcolor{blue}{unobserved}};
  \node[const, below=9.2 of level]          (observed) {\textcolor{purple}{observed}};
  \node[const, below=10.2 of level]          (issues) {Advantages};
  \node[const, below=11.5 of level]          (issues) {Issues\\ \\ \\.};
  
  
  
  %ER
  \node[const, right=2.5 of level]          (ER) {ER};
  
  \node[latent, below=3 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=9 of ER]  (ERx) {$\textcolor{purple}{x}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  
  \node[const, align=center, below=10.2 of ER]      (ERpro) {It's a thing.};
  \node[const, align=center, below=11.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, right=2.5 of ER]           (King) {King (97)};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=5 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=7 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=6.25 of King] {Kingdot} {} {} {};
  \node[obs, right=.5 of Kingdot] (Kingn) {$n_r$};
  \factor[below=4.25 of King] {KingdotN} {} {} {};
  \node[obs, right=.5 of KingdotN] (KingN) {$n?$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  \edge[dashed,-] {KingdotN} {KingN} ;
  
  
  \node[const, align=center, below=10.2 of King]      (Kingpro) {Respects constraints.};
  \node[const, align=center, below=11.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, right=2.5 of King]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4.3 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=5.7 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=9 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, right=.5 of RJKTdot] (RJKTn) {$n_r$};
  \factor[below=8.25 of RJKT] {RJKTdotN} {} {} {};
  \node[obs, right=.5 of RJKTdotN] (RJKTN) {$n$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  \edge[-] {RJKTdotN} {RJKTN} ;
  
  
  \node[const, align=center, below=10.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
  \node[const, align=center, below=11.5 of RJKT]      (RJKTcon) {No $y$; cheats a bit\\on constraints.};
  
  
  %Us
  \node[const, right=2.5 of RJKT]           (us) {Us};
  
  \node[const, below=1.2 of us]           (usprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of us] (usglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4.3 of us] (uslatent) {$\textcolor[rgb]{0,.5,0}{\nu}$};
  \node[latent, diamond, below=5.7 of us] (usnu) {$\textcolor[rgb]{0,.5,0}{\pi}$};
  \node[latent, below=7 of us] (usy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of us]  (usx) {$\textcolor{purple}{x}$};
  \factor[below=6.55 of us] {usdot} {} {} {};
  \node[obs, right=.5 of usdot] (usn) {$n_r$};
  
  % Connect the nodes
  \edge {usprior} {usglobal} ;
  \edge {usglobal} {uslatent} ;
  \edge[<->] {usnu} {uslatent} ;
  \factoredge {usnu,usn} {usdot} {usy} ; 
  \edge {usy} {usx} ;
  
  \node[const, align=center, below=10.2 of us]      (uspro) {Respects constraints;\\$R\times C$; "multinomial".};
  %\node[const, align=center, below=11.5 of us]      (uscon) {Few — let me\\describe it first};

  % Plates
  %\plate {U} {(gamma)(y)(multi)(pi)(n)(v)(ubighide)} {$U$} ;
  %\plate {R} {(beta)(gamma)(y)(rbighide)(U.north east)} {$R$} ;
\end{tikzpicture}}

\end{frame}

\begin{frame}{Comparison of models}
\protect\hypertarget{comparison-of-models-6}{}

\resizebox{99in}{3in}{%
\begin{tikzpicture}
  % Define nodes
  
  %Row headers
  \node[const]                          (level) {Level};
  \node[const, below=1.2 of level]          (prior) {\textcolor{red}{Prior}};
  \node[const, below=3.2 of level]          (global) {\textcolor{orange}{Global}};
  \node[const, below=5.2 of level]          (latent) {\textcolor[rgb]{0,.5,0}{Latent}};
  \node[const, below=7.2 of level]          (unobserved) {\textcolor{blue}{unobserved}};
  \node[const, below=9.2 of level]          (observed) {\textcolor{purple}{observed}};
  \node[const, below=10.2 of level]          (issues) {Advantages};
  \node[const, below=11.5 of level]          (issues) {Issues\\ \\ \\.};
  
  
  
  %ER
  \node[const, right=2.5 of level]          (ER) {ER};
  
  \node[latent, below=3 of ER] (ERglobal) {$\textcolor{orange}{\gamma}$};
  \node[obs, below=9 of ER]  (ERx) {$\textcolor{purple}{x}$};
  
  % Connect the nodes
  \edge {ERglobal} {ERx} ;
  
  \node[const, align=center, below=10.2 of ER]      (ERpro) {It's a thing.};
  \node[const, align=center, below=11.5 of ER]      (ERcon) {Impossible\\estimates.};
  
  
  % King
  \node[const, right=2.5 of ER]           (King) {King (97)};
  
  \node[const, below=1.2 of King]           (Kingprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of King] (Kingglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=5 of King] (Kinglatent) {$\textcolor[rgb]{0,.5,0}{\lambda}$};
  \node[latent, diamond, below=7 of King] (Kingy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of King]  (Kingx) {$\textcolor{purple}{x}$};
  \factor[below=6.25 of King] {Kingdot} {} {} {};
  \node[obs, right=.5 of Kingdot] (Kingn) {$n_r$};
  \factor[below=4.25 of King] {KingdotN} {} {} {};
  \node[obs, right=.5 of KingdotN] (KingN) {$n?$};
  
  
  % Connect the nodes
  \edge {Kingprior} {Kingglobal} ;
  \edge {Kingglobal} {Kinglatent} ;
  \factoredge {Kinglatent,Kingn} {Kingdot} {Kingy} ; 
  \edge {Kingy} {Kingx} ;
  \edge[<->] {Kingy} {Kinglatent} ;
  \edge[dashed,-] {KingdotN} {KingN} ;
  
  
  \node[const, align=center, below=10.2 of King]      (Kingpro) {Respects constraints.};
  \node[const, align=center, below=11.5 of King]      (Kingcon) {Only $2\times 2$;\\No voter-level\\randomness.};
  
  
  
  
  %RJKT
  \node[const, right=2.5 of King]           (RJKT) {RJKT};
  
  \node[const, below=1.2 of RJKT]           (RJKTprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of RJKT] (RJKTglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4.3 of RJKT] (RJKTlatent) {$\textcolor[rgb]{0,.5,0}{\beta}$};
  \node[latent, diamond, below=5.7 of RJKT] (RJKTtheta) {$\textcolor[rgb]{0,.5,0}{\theta}$};
  \node[obs, below=9 of RJKT]  (RJKTx) {$\textcolor{purple}{x}$};
  \factor[below=5.25 of RJKT] {RJKTdot} {} {} {};
  \node[obs, right=.5 of RJKTdot] (RJKTn) {$n_r$};
  \factor[below=8.25 of RJKT] {RJKTdotN} {} {} {};
  \node[obs, right=.5 of RJKTdotN] (RJKTN) {$n$};
  
  % Connect the nodes
  \edge {RJKTprior} {RJKTglobal} ;
  \edge {RJKTglobal} {RJKTlatent} ;
  \factoredge {RJKTlatent,RJKTn} {RJKTdot} {RJKTtheta} ; 
  \edge {RJKTtheta} {RJKTx} ;
  \edge[<->] {RJKTtheta} {RJKTlatent} ;
  \edge[-] {RJKTdotN} {RJKTN} ;
  
  
  \node[const, align=center, below=10.2 of RJKT]      (RJKTpro) {$R\times C$; includes\\voter multinomial.};
  \node[const, align=center, below=11.5 of RJKT]      (RJKTcon) {No $y$; cheats a bit\\on constraints.};
  
  
  %Us
  \node[const, right=2.5 of RJKT]           (us) {Us};
  
  \node[const, below=1.2 of us]           (usprior) {$\textcolor{red}{\Pi}$};
  \node[latent, below=3 of us] (usglobal) {$\textcolor{orange}{\gamma}$};
  \node[latent, below=4.3 of us] (uslatent) {$\textcolor[rgb]{0,.5,0}{\nu}$};
  \node[latent, diamond, below=5.7 of us] (usnu) {$\textcolor[rgb]{0,.5,0}{\pi}$};
  \node[latent, below=7 of us] (usy) {$\textcolor{blue}{y}$};
  \node[obs, diamond, below=9 of us]  (usx) {$\textcolor{purple}{x}$};
  \factor[below=6.55 of us] {usdot} {} {} {};
  \node[obs, right=.5 of usdot] (usn) {$n_r$};
  
  % Connect the nodes
  \edge {usprior} {usglobal} ;
  \edge {usglobal} {uslatent} ;
  \edge[<->] {usnu} {uslatent} ;
  \factoredge {usnu,usn} {usdot} {usy} ; 
  \edge {usy} {usx} ;
  
  \node[const, align=center, below=10.2 of us]      (uspro) {Respects constraints;\\$R\times C$; "multinomial".\\
  Extensible! VI!};
  %\node[const, align=center, below=11.5 of us]      (uscon) {Few — let me\\describe it first};

  % Plates
  %\plate {U} {(gamma)(y)(multi)(pi)(n)(v)(ubighide)} {$U$} ;
  %\plate {R} {(beta)(gamma)(y)(rbighide)(U.north east)} {$R$} ;
\end{tikzpicture}}

\end{frame}

\begin{frame}{Our model}
\protect\hypertarget{our-model}{}

\resizebox{99in}{2.5in}{%
\begin{tikzpicture}
  % Define nodes
  \node[latent]           (beta) {$\textcolor{orange}{\bm{\beta}_r}$};
  \node[const, above=0.4 of beta] (rbighide) {};
  \node[const, above=of beta] (sdb) {$\textcolor{red}{\sigma_{\beta}}$};
  \node[latent, left=of beta]  (alpha) {$\textcolor{orange}{\bm{\alpha}}$};
  \node[const, above=of alpha] (sda) {$\textcolor{red}{\sigma_{\alpha}}$};
  \node[latent, right=2 of beta]            (gamma) {$\textcolor[rgb]{0,.5,0}{\bm{\nu}_{u,r}}$};
  \node[latent, above=of gamma] (sdg) {$\textcolor{orange}{\sigma_{\nu}}$};
  \node[det, below=.7of gamma]            (pi) {$\textcolor[rgb]{0,.5,0}{\bm{\pi}_{u,r}}$};
  \factor[below=.4 of pi] {multi} {right:$\mathrm{Multi}$} {} {};
  \node[obs, left=of multi]            (n) {$n_{u,r}$};
  \node[latent, below=.5 of multi]            (y) {$\textcolor{blue}{\bm{y}_{u,r}}$};
  \node[obs, diamond, below=of y]            (v) {$\textcolor{purple}{\bm{v}_{u}}$};
  \node[const, right=0.6 of y, yshift=-1.6cm] (ubighide) {};
  \node[const, right=1.2 of y] (rbighide) {};

  % Connect the nodes
  \edge {sda} {alpha} ;
  \edge {sdb} {beta} ;
  \edge {sdg} {gamma} ; 
  \edge {alpha,beta,gamma} {pi} ;
  \factoredge {pi,n} {multi} {y} ; 
  \edge {y} {v} ;

  % Plates
  \plate {U} {(gamma)(y)(multi)(pi)(n)(v)(ubighide)} {$U$} ;
  \plate {R} {(beta)(gamma)(y)(rbighide)(U.north east)} {$R$} ;
\end{tikzpicture}}

\textcolor{red}{{\scriptsize Talk briefly about how you could add other Christmas tree ornaments\\Talk about why this is hard to make a guide for}}

\end{frame}

\begin{frame}{Modified model}
\protect\hypertarget{modified-model}{}

\resizebox{99in}{2.5in}{%
\begin{tikzpicture}
  % Define nodes
  \node[latent]           (beta) {$\textcolor{orange}{\bm{\beta}^-_r}$};
  \node[const, above=0.4 of beta] (rbighide) {};
  \node[const, above=of beta] (sdb) {$\textcolor{red}{\sigma_{\beta}}$};
  \node[latent, left=of beta]  (alpha) {$\textcolor{orange}{\bm{\alpha}^-}$};
  \node[const, above=of alpha] (sda) {$\textcolor{red}{\sigma_{\alpha}}$};
  \node[latent, right=2 of beta]            (gamma) {$\textcolor[rgb]{0,.5,0}{\bm{\nu}_{u,r}}$};
  \node[latent, above=of gamma] (sdg) {$\textcolor{orange}{\sigma_{\nu}}$};
  \node[det, below=.7of gamma]            (pi) {$\textcolor[rgb]{0,.5,0}{\bm{\pi}_{u,r}}$};
  \factor[below=.4 of pi] {multi} {right:$\mathrm{CMult}$} {} {};
  \node[obs, left=of multi]            (n) {$n_{u,r}$};
  \node[latent, below=.5 of multi]            (y) {$\textcolor{blue}{\bm{y}_{u,r}}$};
  \node[const, right=0.8 of y, yshift=-1.6cm] (ubighide) {};
  \node[const, right=1.4 of y] (rbighide) {};
  \node[det, below=of y]            (W) {$\textcolor{blue}{W_{u}}$};
  \node[obs, diamond, left=.66 of W]            (v) {$\textcolor{purple}{\bm{v}_{u}}$};

  % Connect the nodes
  \edge {sda} {alpha} ;
  \edge {sdb} {beta} ;
  \edge {sdg} {gamma}; 
  \edge {alpha,beta,gamma} {pi} ;
  \factoredge {pi,n} {multi} {y} ; 
  \edge[] {y} {W} ; 
  \edge[] {v} {W} ; 
  \edge[] {y} {v} ; 

  % Plates
  \plate {U} {(gamma)(y)(multi)(pi)(n)(W)(v)(ubighide)} {$U$} ;
  \plate {R} {(beta)(gamma)(y)(rbighide)(U.north east)} {$R$} ;
\end{tikzpicture}}

\textcolor{red}{{\scriptsize Cmult; Polytopize: ae smooth bijective map from $R^n$ to polytope\\Pseudovoters because of boundary issues that arise from Cmult and polytopize\\All of these make the model itself slightly less-realistic, but make VI work.}}

\end{frame}

\begin{frame}{Polytopize (1)}
\protect\hypertarget{polytopize-1}{}

\resizebox{4in}{99in}{%
\begin{tikzpicture}[
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (4,3.5) {Candidate};

%separator
\draw[style=-] (8,0) -- +(0,5) node[below left=.25cm,anchor=base,midway,rotate=-45] {};

\node (w) at (3.5,2) {$\begin{array}{r|lll|l}
& X & Y & Z & \bm{n}_u\\
\hline
\textit{White} & \textcolor{red}{50} & \textcolor{red}{50} & 50 & 150 \\
\textit{Black} & 70 & 70 & 70 & 210   \\
\hline
\bm{v}_u & 120 & 120 & 120 & 360\end{array}$};

\draw[red,fill=red] (11.667,1.667) circle (.5ex);
\node[] at (11.667,1.267)   (c) {$\dot{\bm{Y}}$};

%\tkzDefPoint(7.667,1.667){M}
%\tkzLabelPoint[right,below](M){Independence}

\node[] at (12, -1.1)   (c) {$\mathcal{Y}_u$};

%polytope
\draw[style=-] (11,0) -- +(-1,1) node[below left=.25cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}>\textcolor{black}{30}$};
\draw[style=-] (11,0) -- +(3,0) node[below=.3cm,anchor=base,midway] {$\textcolor{black}{y_{p12}}>0$};
\draw[style=-] (14,0) -- +(0,1) node[right = .3cm,anchor=base,midway,rotate=90] {$\textcolor{black}{y_{p11}<120}$};
\draw[style=-] (14,1) -- +(-3,3) node[above right=.15cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}<\textcolor{black}{150}$};
\draw[style=-] (11,4) -- +(-1,0) node[above=.2cm,anchor=base,midway] {$\textcolor{black}{y_{p12}<120}$};
\draw[style=-] (10,1) -- +(0,3) node[left = .2cm,anchor=base,midway,rotate=90] {$\textcolor{black}{y_{p11}}>0$};


\end{tikzpicture}}

\end{frame}

\begin{frame}{Polytopize (2)}
\protect\hypertarget{polytopize-2}{}

\resizebox{4in}{99in}{%
\begin{tikzpicture}

%axes
\draw[dashed,-latex] (4,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[dashed,-latex] (2,2) -- +(-2.5,0) node[below right,midway,rotate=45] {};
\draw[dashed,-latex] (2,2) -- +(0,2) node[below right,midway,rotate=45] {};
\draw[dashed,-latex] (2,2) -- +(0,-2) node[below right,midway,rotate=45] {};

%vectors in y'
\draw[-latex] (2,2) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.3,2.4) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.6,2.8) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.9,3.2) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[fill=black] (3.2, 3.6) circle (.3ex);
\node[above left=0pt of {(3.2, 3.6)}]  {$\bm{w}_1$};


\draw[-latex] (2,2) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (1.6,1.7) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (1.2,1.4) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (0.8,1.1) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[fill=black] (0.4, 0.8) circle (.3ex);
\node[below right=0pt of {(0.4, 0.8)}]  {$\bm{w}_3$};

\draw[-latex] (2,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (2.5,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (3,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (3.5,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[fill=black] (4, 2) circle (.3ex);
\node[below=0pt of {(4, 2)}]  {$\bm{w}_2$};

%function connector
\node[] at (6, 2)   (a) {$m_u(\bm{w})$};
\node[] at (6, 1.5)   (b) {$\longrightarrow$};

%labels for spaces
\node[] at (2, -1.1)   (c) {};
\node[] at (10, -1.1)   (d) {$\mathcal{Y}_u$};


%polytope
\draw[style=-] (9,0) -- +(-1,1) node[below left=.25cm,anchor=base,midway,rotate=-45] {};
\draw[style=-] (9,0) -- +(3,0) node[below=.3cm,anchor=base,midway] {};
\draw[style=-] (12,0) -- +(0,1) node[right = .3cm,anchor=base,midway,rotate=90] {};
\draw[style=-] (12,1) -- +(-3,3) node[above right=.15cm,anchor=base,midway,rotate=-45] {};
\draw[style=-] (9,4) -- +(-1,0) node[above=.2cm,anchor=base,midway] {};
\draw[style=-] (8,1) -- +(0,3) node[left = .2cm,anchor=base,midway,rotate=90] {};


%vectors in polytope
\draw[-latex] (9.5,1.5) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (9.8,1.9) -- +(.2,.266) node[below right,midway,rotate=45] {};
\draw[-latex] (10.0,2.166) -- +(.133,.177) node[below right,midway,rotate=45] {};
\draw[-latex] (10.133,2.344) -- +(.0889,.1185) node[below right,midway,rotate=45] {};
\draw[fill=black] (10.222, 2.4625) circle (.3ex);
\node[above left=0pt of {(10.222, 2.4625)}]  {$m_u(\bm{w}_1)$};



\draw[-latex] (9.5,1.5) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (9.1,1.2) -- +(-.2667,-.2) node[below right,midway,rotate=45] {};
\draw[-latex] (8.833,1.0) -- +(-.1778,-.133) node[below right,midway,rotate=45] {};
\draw[-latex] (8.655,.866) -- +(-.1185,-.0889) node[below right,midway,rotate=45] {};
\draw[fill=black] (8.5366, 0.777) circle (.3ex);
\node[below right=0pt of {(8.5366, 0.777)}]  {$m_u(\bm{w}_3)$};

\draw[-latex] (9.5,1.5) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (10,1.5) -- +(.375,0) node[below right,midway,rotate=45] {};
\draw[-latex] (10.375,1.5) -- +(.281,0) node[below right,midway,rotate=45] {};
\draw[-latex] (10.656,1.5) -- +(.211,0) node[below right,midway,rotate=45] {};
\draw[fill=black] (10.8777, 1.5) circle (.3ex);
\node[below=0pt of {(10.8777, 1.5)}]  {$m_u(\bm{w}_2)$};

%dots at 0,0 and independence

\draw[red,fill=red] (9.5,1.5) circle (.3ex);
\node[above left=0pt of {(9.5,1.5)}]  {$\textcolor{red}{m_u(\vec{0})}$};
\node[below=0pt of {(9.5,1.5)}]  {$\textcolor{red}{\dot{\bm{Y}}}$};
\draw[red,fill=red] (2,2) circle (.3ex);
\node[above left=0pt of {(2,2)}]  {$\textcolor{red}{\vec{0}}$};

\end{tikzpicture}}

\end{frame}

\begin{frame}{Guide, with amortization}
\protect\hypertarget{guide-with-amortization}{}

\resizebox{99in}{2.5in}{%
\begin{tikzpicture}

  % Define nodes
  \node[const]                                          (hats) {$\textcolor{orange}{\bm{\gamma}^*}$};
  \node[det, below=1 of hats,  align=center, xshift=3.5cm]            (yhat) {$\textcolor[rgb]{0,.5,0}{\bm{\lambda}}^{\textcolor{blue}{*}}_{\textcolor{blue}{u}}$};
  \node[latent, diamond, below=2 of hats, xshift=.7cm]            (sighat) {$\textcolor{orange}{\sigma_{\nu}^*}$};
  
  \node[latent, diamond, aspect=2.5, below=3 of hats]            (Iparams) {$\mathcal{I}^{-1}(\bm{\gamma}^*)$};
  \factor[left=of Iparams] {paramdist} {left:$\mathcal{N}$} {} {};
  \node[latent, below=of paramdist]            (params) {$\textcolor{orange}{\bm{\gamma}}$};
  

  
  \node[latent, diamond, aspect=3,  below=3 of hats,  align=center, xshift=3.5cm]  (Ifull) {$\mathcal{I}^{-1}(\bm{\gamma}^*,\bm{\lambda}^*_{u})$};
  \factor[right=of Ifull] {fulldist} {right:$\mathcal{N}$} {} {};
  \factor[below=1.25 of fulldist] {condfulldist} {right:$\mathcal{N}|\bm{\gamma}$} {} {};
  \node[latent, below=of condfulldist]            (W) {$\textcolor[rgb]{0,.5,0}{\bm{\lambda}}_{\textcolor{blue}{u}}$};
  %\node[const, below=0.2 of W,xshift=-0.2cm]            (uhide) {};
  \node[const, below=0 of W,xshift=.8cm]            (uhide2) {};

  % Connect the nodes
  \edge[] {hats,sighat,yhat} {Iparams} ;        %  |/
  \edge[] {yhat} {sighat} ;                %   ⟋
  \edge[-] {hats} {paramdist} ;           % /
  \edge {hats} {yhat} ;             %   ⟍
  \edge {hats,yhat,sighat} {Ifull} ;       %   \|
  \edge[-] {Iparams} {paramdist} ;        % - 
  \edge {paramdist} {params} ;            % \
  \edge[-] {Ifull} {fulldist}  ; 
  \edge[-] {fulldist} {condfulldist}  ; 
  \edge[-] {params} {condfulldist}; 
  \edge[-] {yhat} {fulldist} ; 
  \edge {condfulldist} {W} ; 

  % Plates
  \plate {U} {(Ifull)(fulldist)(W)(uhide2)(yhat)} {$U$} ;
\end{tikzpicture}}

picture from paper, but remade to look more sane!!!! Maybe a list of
things to note (changes form model)

\end{frame}

\begin{frame}{Testing our EI on simulated data}
\protect\hypertarget{testing-our-ei-on-simulated-data}{}

Describe how we got the simulated NC data actual demographics realistic
alpha and beta we get to experiment sigma\_nu

\end{frame}

\begin{frame}{EI results (1)}
\protect\hypertarget{ei-results-1}{}

Show updated tables from paper

\textcolor{red}{{\scriptsize Point out that this is different (better!) than what you originally sent, because:\\does not underestimate variance (fixed bug)\\corrected alphas and betas (so that overall percentages of people of each race voting for each candidate approximate the true 2016 data, as intended)\\improved amortization (optimize Y <U+2192> optimize W)\\Conclusion: We are as good as RJKT, but we’re just getting started}}

\end{frame}

\begin{frame}{EI results (2)}
\protect\hypertarget{ei-results-2}{}

\end{frame}

\begin{frame}{Discussion/future work (Ch. 3)}
\protect\hypertarget{discussionfuture-work-ch.-3}{}

\begin{itemize}
\tightlist
\item
  Including the covariate
\item
  Multiple elections
\item
  Actual NC data
\item
  Compare hierachical model without EI, Standard RJKT, and our model
\item
  Cross-validation
\end{itemize}

\textcolor{red}{{\scriptsize Say that this is the stuff we plan to include in final paper}}

\end{frame}

\begin{frame}{Discussion/future work (Ch. 2)}
\protect\hypertarget{discussionfuture-work-ch.-2}{}

\begin{itemize}
\item
  More on subsampling:

  \begin{itemize}
  \tightlist
  \item
    general theory of how to assign weights to minimize variance of
    estimator in subsampling (use Ch 3 as example)
  \item
    maybe some theory to help choose sample size for SVI
  \end{itemize}
\item
  Replace normal with T in guide
\end{itemize}

\textcolor{red}{{\scriptsize Say that this will not be in current paper, which is basically done}}

\end{frame}

\begin{frame}{Thanks}
\protect\hypertarget{thanks}{}

\end{frame}

\begin{frame}{Directory of extra slides}
\protect\hypertarget{directory-of-extra-slides}{}

\end{frame}

\begin{frame}{Non-meanfield prior work}
\protect\hypertarget{non-meanfield-prior-work}{}

Just the list from the paper Give example of actual theorem you can
prove when you have conjugate model structure

\end{frame}

\begin{frame}{Details on toy model}
\protect\hypertarget{details-on-toy-model}{}

Just the model

\end{frame}

\begin{frame}{More on block-arrowhead matrices}
\protect\hypertarget{more-on-block-arrowhead-matrices}{}

Formulas for boosting Formulas for sampling

(basically just the stuff in the appendix)

\end{frame}

\begin{frame}{What we expect from subsampling}
\protect\hypertarget{what-we-expect-from-subsampling}{}

HARD

\end{frame}

\begin{frame}{Details of ECHS}
\protect\hypertarget{details-of-echs}{}

The actual model Result tables

\end{frame}

\begin{frame}{More details on RJKT}
\protect\hypertarget{more-details-on-rjkt}{}

\end{frame}

\begin{frame}{Possible extensions to our EI model}
\protect\hypertarget{possible-extensions-to-our-ei-model}{}

\end{frame}

\begin{frame}{Boundary issues with polytope; pseudovoters}
\protect\hypertarget{boundary-issues-with-polytope-pseudovoters}{}

HARD

\end{frame}

\begin{frame}{How our EI amortization works (1)}
\protect\hypertarget{how-our-ei-amortization-works-1}{}

Which variables are we amortizing: Y, nu, sigma\_nu Steps: Find
approximate mode of p(Y\textbar{}alpha, beta, nu) constrained to lie on
polytope (this is linear algebra plus stirling's approximation)
One-dimensional Newton's method to find approximate mode of W. (Not the
same thing, because there's Jacobian, mode of W is further away from
boundary) Find approximate mode of p(nu, sigma\_nu\textbar{} gamma, W)
Newton's method (for free!!)

\end{frame}

\begin{frame}{How our EI amortization works (2)}
\protect\hypertarget{how-our-ei-amortization-works-2}{}

Details on how we get nu and sigma\_nu

\end{frame}

\begin{frame}{More EI results}
\protect\hypertarget{more-ei-results}{}

\end{frame}

\begin{frame}{END DEFENSE, START OLD PRESENTATION}
\protect\hypertarget{end-defense-start-old-presentation}{}

\end{frame}

\begin{frame}{Teaser}
\protect\hypertarget{teaser}{}

\includegraphics{defense_files/figure-beamer/unnamed-chunk-21-1.pdf}

\end{frame}

\begin{frame}{Thornburg v Gingles, 1986}
\protect\hypertarget{thornburg-v-gingles-1986}{}

A majority-minority district must be created if:

\begin{enumerate}
\item
  A minority group is ``sufficiently numerous and compact to form a
  majority in a single-member district''; and
\item
  The minority group is
  \textcolor{red}{\textbf{"politically cohesive"}}; and
\item
  The ``majority \textcolor{red}{\textbf{votes sufficiently as a bloc}}
  to enable it \ldots{} usually to defeat the minority's preferred
  candidate.''
\end{enumerate}

\end{frame}

\begin{frame}{Ecological data}
\protect\hypertarget{ecological-data}{}

\end{frame}

\begin{frame}{Independence?}
\protect\hypertarget{independence}{}

\begin{tikzpicture}[
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (6.5,4);
\draw[ultra thick](0,0) rectangle (6.5,4);}
]
\foreach \x in {2,1.75,1.5,1.25,1,.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\draw[-latex] (7,0) -- +(1.5,1.5) node[below right,midway,rotate=45] {\textcolor{purple}{precinct}};
\node[rotate=90] (h) at (.5,2) {Race};
\node (w) at (3.5,3.5) {\textcolor{purple}{Candidate}};



\node (w) at (3.5,2) {$\begin{array}{l|lll|l}
& R & D & No & \\
\hline
White & \textcolor{red}{200} & \textcolor{red}{100} & \textcolor{red}{100} & 400 \\
Black & \textcolor{red}{100} & \textcolor{red}{50} & \textcolor{red}{50} & 200   \\
Hispanic & \textcolor{red}{50} & \textcolor{red}{25} & \textcolor{red}{25} & 100   \\
Other & \textcolor{red}{50} & \textcolor{red}{25} & \textcolor{red}{25} & 100   \\
\hline
 & 400 & 200 & 200 & 800\end{array}$};

\end{tikzpicture}

\end{frame}

\begin{frame}{Structure}
\protect\hypertarget{structure}{}

\begin{itemize}
\tightlist
\item
  Pose the ecological problem (done)
\item
  Quick review of prior approaches
\item
  A basic, extensible model for EI
\item
  Why and how to reparameterize
\item
  Review of variational inference
\item
  Applying variational inference to EI
\item
  Guide (aka variational distribution) based on observed information
\end{itemize}

\end{frame}

\begin{frame}{Ecological regression (for \(2\times 2\) cases)}
\protect\hypertarget{ecological-regression-for-2times-2-cases}{}

\includegraphics{defense_files/figure-beamer/unnamed-chunk-22-1.pdf}

Brexit voting data. (Example from ``The Stats Guy'' blog by Adam
Jacobs.) Valid under certain (strong) assumptions.

\end{frame}

\begin{frame}{Ecological regression: uh oh}
\protect\hypertarget{ecological-regression-uh-oh}{}

\includegraphics{defense_files/figure-beamer/unnamed-chunk-23-1.pdf}

Brexit supported by 79\% of people without a degree\ldots{} and -16\% of
those with one??? Ecological fallacy, Simpson's paradox, etc.

\end{frame}

\begin{frame}{Infer latents, not parameters}
\protect\hypertarget{infer-latents-not-parameters}{}

Insight from King, Rosen, Tanner 1999: instead of focusing on population
parameters, which are not directly constrained by the data, focus on
latent parameters, which are.

Refined by Rosen, King, Jiang, Tanner (2001):

\begin{itemize}
\item
  Fully Bayesian model
\item
  extends to \(R\neq 2 \neq C\)
\item
  fast, moment-based estimator
\item
  now widely used.
\end{itemize}

\end{frame}

\begin{frame}{Issues with RKJT 2001:}
\protect\hypertarget{issues-with-rkjt-2001}{}

The RKJT model can, in principle, be extended to handle additional
factors such as:

\begin{itemize}
\tightlist
\item
  inter-row or inter-column correlations
\item
  covariates
\item
  multiple elections
\item
  exit polling data
\item
  etc.
\end{itemize}

However:

\begin{itemize}
\tightlist
\item
  the moment-based estimator breaks down,
\item
  MCMC on such a high-dimensional latent space can be challenging.
\end{itemize}

\end{frame}

\begin{frame}{Flexible model (1)}
\protect\hypertarget{flexible-model-1}{}

\end{frame}

\begin{frame}{Flexible model (3)}
\protect\hypertarget{flexible-model-3}{}

\includegraphics[width=0.3\textwidth,height=\textheight]{holidaytree_bare.jpg}
\includegraphics[width=0.3\textwidth,height=\textheight]{holidaytree_decorated.png}

\[\vec{y}_{p,r}=y_{p,r,c}\Vert_{c=1}^C\sim \operatorname{CMult}\left(n_{p,r},\frac{exp(\alpha_c+\beta_{r,c}\textcolor{red}{+\lambda_{r,c,p}})\Vert_{c=1}^C}{\sum_{c=1}^Cexp(\alpha_c+\beta_{r,c}\textcolor{red}{+\lambda_{r,c,p}})}\right)\]

\[\alpha_c\sim\mathcal{N}(0,\sigma_\alpha)~~~~~~~\sigma_\alpha\sim\operatorname{Expo}(5)\]

\[\beta_{r,c}\sim\mathcal{N}(0,\sigma_\beta)~~~~~~~\sigma_\beta\sim\operatorname{Expo}(5)\]

\[\textcolor{red}{\lambda_{r,c,p}\sim\mathcal{N}(0,\sigma_\beta)}~~~~~~~\sigma_\lambda\sim\operatorname{Expo}(5)\]
\(\lambda\) handles overdispersion. Note: Bayesian Occam's Razor.

\end{frame}

\begin{frame}{Standard Bayesian approach (simplified)}
\protect\hypertarget{standard-bayesian-approach-simplified}{}

\(\begin{array}{cl} \operatorname{priors}~\pi & \\ \downarrow & \\ \operatorname{parameters}~\theta & \\ \downarrow & \\ \operatorname{latent~variables}~y & \\ \downarrow & \\ \operatorname{data}~z & \end{array}\)

\end{frame}

\begin{frame}{Standard Bayesian approach (cont'd)}
\protect\hypertarget{standard-bayesian-approach-contd}{}

\(\begin{array}{cl} \operatorname{priors}~\pi & \\ \downarrow & \operatorname{(parameterizes~distribution)}\\ \operatorname{parameters}~\theta & \operatorname{(unobservable~quantities~of~interest;~low-D)}\\ \downarrow & \operatorname{(parameterizes~distribution)}\\ \operatorname{latent~variables}~y & \operatorname{(unobservable~nuisance~parameters;~high-D)}\\ \downarrow & \operatorname{(parameterizes~distribution)}\\ \operatorname{data}~z & \end{array}\)

\end{frame}

\begin{frame}{Ecological Inference}
\protect\hypertarget{ecological-inference}{}

\(\begin{array}{cl} \operatorname{priors}~\pi & \\ \downarrow & \operatorname{(parameterizes~distribution)}\\ \operatorname{parameters}~\theta & \operatorname{(unobservable~\textcolor{red}{nuisance~parameters};~low-D\textcolor{red}{?})}\\ \downarrow & \operatorname{(parameterizes~distribution)}\\ \operatorname{latent~variables}~y & \operatorname{(unobserv\textcolor{red}{ed~quantities~of~interest};~high-D)}\\ \downarrow & \operatorname{\textcolor{red}{(deterministic~function)}}\\ \operatorname{data}~z & \end{array}\)

A likelihood from a deterministic function is an indicator function!

\end{frame}

\begin{frame}{Ecological case}
\protect\hypertarget{ecological-case}{}

Since the likelihood is just an indicator function, the posterior is
just the prior, restricted to the set of values where the likelihood is
1 and renormalized. For each precinct, this set turns out to be a
polytope \(\mathcal{Y}_{z_p}\) in an \((R-1)(C-1)\) dimensional subspace
of the full \(\mathbb{R}^{RC}\).

\begin{tikzpicture}[
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (4,4);
\draw[ultra thick](0,0) rectangle (4,4);}
]
\foreach \x in {.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\node[rotate=90] (h) at (.2,2) {Race};
\node (w) at (2,3.5) {Candidate};



\node (w) at (2.2,2) {$\begin{array}{lll|l}
R & D & No & \\
\hline
\textcolor{red}{y_{p11}} & \textcolor{blue}{y_{p12}} & y_{p13} & \textcolor{olive}{500} \\
y_{p21} & y_{p22} & y_{p23} & \textcolor{purple}{700}   \\
\hline
\textcolor{red}{400} & \textcolor{blue}{400} & 400 & 1200\end{array}$};











\node[] at (8, -1.1)   (c) {$\mathcal{Y}_{z_p}\subset\mathbb{R}^{(R-1)(C-1)}\longleftrightarrow\mathbb{R}^{RC} $};

%polytope
\draw[style=-] (7,0) -- +(-1,1) node[below left=.25cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}>\textcolor{purple}{100}$};
\draw[style=-] (7,0) -- +(3,0) node[below=.3cm,anchor=base,midway] {$\textcolor{blue}{y_{p12}}>0$};
\draw[style=-] (10,0) -- +(0,1) node[right = .3cm,anchor=base,midway,rotate=90] {$\textcolor{red}{y_{p11}<400}$};
\draw[style=-] (10,1) -- +(-3,3) node[above right=.15cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}<\textcolor{olive}{500}$};
\draw[style=-] (7,4) -- +(-1,0) node[above=.2cm,anchor=base,midway] {$\textcolor{blue}{y_{p12}<400}$};
\draw[style=-] (6,1) -- +(0,3) node[left = .2cm,anchor=base,midway,rotate=90] {$\textcolor{red}{y_{p11}}>0$};


\end{tikzpicture}

\end{frame}

\begin{frame}{Independence point}
\protect\hypertarget{independence-point}{}

\begin{tikzpicture}[
squared notebook/.pic={\clip[postaction={shade,left color=white}](0,0) rectangle (4,4);
\draw[ultra thick](0,0) rectangle (4,4);}
]
\foreach \x in {.75,0.5,.25,0}\pic at (\x,\x){squared notebook};
\node[rotate=90] (h) at (.2,2) {Race};
\node (w) at (2,3.5) {Candidate};



\node (w) at (2.2,2) {$\begin{array}{lll|l}
R & D & No & \\
\hline
\textcolor{red}{167} & \textcolor{red}{167} & 167 & 500 \\
233 & 233 & 233 & 700   \\
\hline
400 & 400 & 400 & 1200\end{array}$};



\draw[red,fill=red] (7.667,1.667) circle (.5ex);

\node[] at (7.667,1.267)   (c) {Independence};

%\tkzDefPoint(7.667,1.667){M}
%\tkzLabelPoint[right,below](M){Independence}






\node[] at (8, -1.1)   (c) {$\mathcal{Y}_{z_p}\subset\mathbb{R}^{(R-1)(C-1)}\longleftrightarrow\mathbb{R}^{RC}$};

%polytope
\draw[style=-] (7,0) -- +(-1,1) node[below left=.25cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}>\textcolor{black}{100}$};
\draw[style=-] (7,0) -- +(3,0) node[below=.3cm,anchor=base,midway] {$\textcolor{black}{y_{p12}}>0$};
\draw[style=-] (10,0) -- +(0,1) node[right = .3cm,anchor=base,midway,rotate=90] {$\textcolor{black}{y_{p11}<400}$};
\draw[style=-] (10,1) -- +(-3,3) node[above right=.15cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}<\textcolor{black}{500}$};
\draw[style=-] (7,4) -- +(-1,0) node[above=.2cm,anchor=base,midway] {$\textcolor{black}{y_{p12}<400}$};
\draw[style=-] (6,1) -- +(0,3) node[left = .2cm,anchor=base,midway,rotate=90] {$\textcolor{black}{y_{p11}}>0$};


\end{tikzpicture}

\end{frame}

\begin{frame}{Diffeomorphic function
\(g(y'):\mathbb{R}^{(R-1)(C-1)}\rightarrow\mathcal{Y}_{z_p}\)}
\protect\hypertarget{diffeomorphic-function-gymathbbrr-1c-1rightarrowmathcaly_z_p}{}

\begin{tikzpicture}

%axes
\draw[-latex] (2,2) -- +(2,0) node[below right,midway,rotate=45] {};
\draw[-latex] (2,2) -- +(-2,0) node[below right,midway,rotate=45] {};
\draw[-latex] (2,2) -- +(0,2) node[below right,midway,rotate=45] {};
\draw[-latex] (2,2) -- +(0,-2) node[below right,midway,rotate=45] {};

%vectors in y'
\draw[-latex] (2,2) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.3,2.4) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.6,2.8) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (2.9,3.2) -- +(.3,.4) node[below right,midway,rotate=45] {};


\draw[-latex] (2,2) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (1.6,1.7) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (1.2,1.4) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (0.8,1.1) -- +(-.4,-.3) node[below right,midway,rotate=45] {};

\draw[-latex] (2,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (2.5,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (3,2) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (3.5,2) -- +(.5,0) node[below right,midway,rotate=45] {};

%function connector
\node[] at (5, -.7)   (a) {$g(y')$};
\node[] at (5, -1.1)   (b) {$\longrightarrow$};

%labels for spaces
\node[] at (2, -1.1)   (c) {$\mathbb{R}^{(R-1)(C-1)}$};
\node[] at (8, -1.1)   (c) {$\mathcal{Y}_{z_p}\subset\mathbb{R}^{(R-1)(C-1)}\longleftrightarrow\mathbb{R}^{RC}$};


%polytope
\draw[style=-] (7,0) -- +(-1,1) node[below left=.25cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}>100$};
\draw[style=-] (7,0) -- +(3,0) node[below=.3cm,anchor=base,midway] {$y_{p12}>0$};
\draw[style=-] (10,0) -- +(0,1) node[right = .3cm,anchor=base,midway,rotate=90] {$y_{p11}<400$};
\draw[style=-] (10,1) -- +(-3,3) node[above right=.15cm,anchor=base,midway,rotate=-45] {$y_{p11}+y_{p12}<500$};
\draw[style=-] (7,4) -- +(-1,0) node[above=.2cm,anchor=base,midway] {$y_{p12}<400$};
\draw[style=-] (6,1) -- +(0,3) node[left = .2cm,anchor=base,midway,rotate=90] {$y_{p11}>0$};


%vectors in polytope
\draw[-latex] (7.5,1.5) -- +(.3,.4) node[below right,midway,rotate=45] {};
\draw[-latex] (7.8,1.9) -- +(.2,.266) node[below right,midway,rotate=45] {};
\draw[-latex] (8.0,2.166) -- +(.133,.177) node[below right,midway,rotate=45] {};
\draw[-latex] (8.133,2.344) -- +(.0889,.1185) node[below right,midway,rotate=45] {};



\draw[-latex] (7.5,1.5) -- +(-.4,-.3) node[below right,midway,rotate=45] {};
\draw[-latex] (7.1,1.2) -- +(-.2667,-.2) node[below right,midway,rotate=45] {};
\draw[-latex] (6.833,1.0) -- +(-.1778,-.133) node[below right,midway,rotate=45] {};
\draw[-latex] (6.655,.866) -- +(-.1185,-.0889) node[below right,midway,rotate=45] {};

\draw[-latex] (7.5,1.5) -- +(.5,0) node[below right,midway,rotate=45] {};
\draw[-latex] (8,1.5) -- +(.375,0) node[below right,midway,rotate=45] {};
\draw[-latex] (8.375,1.5) -- +(.281,0) node[below right,midway,rotate=45] {};
\draw[-latex] (8.656,1.5) -- +(.211,0) node[below right,midway,rotate=45] {};

%dots at 0,0 and independence

\draw[red,fill=red] (7.5,1.5) circle (.5ex);
\draw[red,fill=red] (2,2) circle (.5ex);

\end{tikzpicture}

\[\frac{d \Vert g(y')-g(0)\Vert }{d\Vert y'\Vert}=y_{p11}y_{p12}(400-y_{p11})(400-y_{p12})(500-y_{p11}-y_{p12})\cdots\]

\end{frame}

\begin{frame}{Stochastic variational inference (Hoffman et al., 2013)}
\protect\hypertarget{stochastic-variational-inference-hoffman-et-al.-2013}{}

Goal: approximate \textcolor{blue}{unnormalized} posterior density
\(p(\theta,y|z)\propto p(z|\theta,y)p_\pi(\theta,y)\) with sampleable
parametric distribution \(q_\phi(\theta,y)\). (Called a \textbf{guide}
in the pyro SVI package for python)

Maximize negative K-L divergence from guide to
\textcolor{blue}{normalized} posterior
\(p(z|\theta,y)p_\pi(\theta,y)/p(z)\):

\[E_{q_\phi}\left(\log\frac{p(z|\textcolor{purple}{\theta},y)p_{\textcolor{purple}{\pi}}(\theta,y)}
{q_\phi(\theta,y)p(z)}\right)<0\]

\[E_{q_\phi}\left(\log[p(z|y)p(\theta,y)]-\log
[q_\phi(\theta,y)]-\textcolor{purple}{\log(p(z))}\right)<0\]

\[E_{q_\phi}\left(\log[p(z|y)p(\theta,y)]-\log
[q_\phi(\theta,y)]\right)<\log(p(z))\]

LHS is the \textbf{ELBO}; goal is to find \(\phi\) which maximizes it.

\end{frame}

\begin{frame}[fragile]{ELBO terms}
\protect\hypertarget{elbo-terms}{}

\(E_{q_\phi}\left(\log[p(z|y)p(\theta,y)]\right)\) is \textbf{energy}
term. Maximized if \(q\) is a \(\delta\) (dirac mass) at MLE for
\((\theta,y|z)\). Unboundedly negative if \(q\) has probability mass
where \(p\) doesn't.

\(E_{q_\phi}\left(-\log[q_\phi(\theta,y)]\right)\) is \textbf{entropy}
term. Maximized by making q diffuse. For example, if \(q\) is
\(\mathcal{N}(\bm{\mu},\Sigma)\), then this is inversely proportional to
\(\mathrm{det}(\Sigma)\). In principle unboundedly negative, but in
practice, it's easier to control than energy term.

Together, they're maximized if \(q_\phi\) ``imitates'' \(p\).

\begin{verbatim}
## Warning: package 'ggplot2' was built under R version 3.6.1
\end{verbatim}

\begin{verbatim}
## Warning: package 'data.table' was built under R version 3.6.1
\end{verbatim}

\includegraphics{defense_files/figure-beamer/unnamed-chunk-24-1.pdf}

\end{frame}

\begin{frame}{EI case}
\protect\hypertarget{ei-case}{}

Reparameterize with \(y=g(y')\), and approximate \(p(\theta,g(y'))]\)
using \(q_{\phi,z}(\theta,y')\). ELBO over \(y'\) then becomes:

\[E_{q_{\phi,z}}\left(\log[p(\theta,g(y'))\operatorname{det}(J(g(y')))]-\vphantom{\Big|}\log
[q_{\phi,z}(\theta,y')]\right)\]

A common form of variational inference uses a ``mean field'' guide which
factorizes across all parameters and latents; frequently, one that's
Normal in each dimension. This ignores the dependence induced by
conditioning on the data; which is particularly strong in the case of
EI.

\end{frame}

\begin{frame}{Laplace family}
\protect\hypertarget{laplace-family}{}

\includegraphics[width=60px]{stay_puft_2}
\textcolor{red}{{\scriptsize staypuft}} \emph{``Choose the form of your
posterior''}

Take \(q(\theta,y')\) to be a multivariate Normal, and assume that once
the ELBO is maximized, its mode \((\hat{\theta},\hat{y})\) coincides
with a mode of the posterior. What should its covariance matrix be?

There's an obvious way to approximate a twice-differentiable,
unnormalized distribution with a Normal: a Laplace approximation.

That is, use the observed information matrix:

\[\mathcal{I}(\hat{\bm{y}}',\hat{\theta})=D^2\left(\log[p(\hat{\theta},g(\hat{y}'))\operatorname{det}(J(g(y')))]\right)\]
as the precision matrix of \(q\).

\end{frame}

\begin{frame}{Graphical posterior}
\protect\hypertarget{graphical-posterior}{}

\begin{tikzpicture}

  % Define nodes
  \node[const]           (hats) {$\hat{\bm{\theta}}$};
  \node[const, right=2.5 of hats]            (What) {$\hat{W}_{u}$};
  
  \factor[below=of hats,yshift=-.3cm] {paramdist} {right:$\mathcal{N}$} {} {};
  \node[latent, diamond, aspect=2.5, left=.8 of paramdist]            (Iparams) {$\mathcal{I}^{-1}(\hat{\bm{\theta}})$};
  \node[latent, below=of paramdist]            (params) {$\bm{\theta}$};
  
  
  
  \node[const, below=1.5 of What,xshift=-3cm] (stuff) {};
  
  \factor[below=2.11 of What] {fulldist} {above left:$\mathcal{N}$} {} {};
  \node[latent, diamond, aspect=2.5, right=.8 of fulldist]            (Ifull) {$\mathcal{I}^{-1}(\hat{\bm{\theta}},\hat{W}_{u})$};
  \node[latent, below=of fulldist]            (W) {$W_u$};
  \node[const, right=0.3 of W]            (detour) {};
  \node[det, below=0.6 of W]            (gamma) {$\bm{\gamma}_{u,r}$};
  \node[const, below=0.2 of gamma,xshift=-0.8cm]            (uhide) {};

  % Connect the nodes
  \edge[] {hats} {Iparams} ;
  \edge[-] {hats} {paramdist} ; 
  \edge[-] {Iparams} {paramdist} ; 
  \edge {paramdist} {params} ; 
  \edge {hats,What} {Ifull} ;
  \edge[-] {params} {fulldist}; 
  \edge[-] {Ifull} {fulldist}  ; 
  \edge[-] {What} {fulldist} ; 
  \edge {fulldist} {W} ; 
  \edge[] {W,params} {gamma} ;

  % Plates
  \plate {U} {(gamma)} {$R$} ;
  \plate {U} {(Ifull)(fulldist)(W)(gamma)(uhide)(What)} {$U$} ;
\end{tikzpicture}

\end{frame}

\begin{frame}{Computability}
\protect\hypertarget{computability}{}

\begin{itemize}
\tightlist
\item
  Using pyro, a variational inference package for python.
\item
  \(\mathcal{I}(\hat{\bm{y}}',\hat{\theta})\) can be calculated using
  automated differentiation.
\item
  \(\mathcal{I}(\hat{\bm{y}}',\hat{\theta})\) is high-dimensional, but
  due to the structure of the model, sparse (block arrowhead format), so
  working with it is reasonably efficient. In practice, this means doing
  sampling ``top down''
  (hyperparameters-\textgreater{}parameters-\textgreater{}hyperlatents-\textgreater{}latents),
  one precinct at a time at the lower levels.
\end{itemize}

\end{frame}

\begin{frame}{Thanks}
\protect\hypertarget{thanks-1}{}

Thanks to Mira Bernstein, Luke Miratrix, Gary King

\end{frame}

\begin{frame}{Lower-D posterior (1)}
\protect\hypertarget{lower-d-posterior-1}{}

Recall our model:

\(\vec{y}_{p,r}=y_{p,r,c}\Vert_{c=1}^C\sim \operatorname{CMult}\left(n_{p,r},\frac{exp(\alpha_c+\beta_{r,c}\textcolor{red}{+\lambda_{r,c,p}})\Vert_{c=1}^C}{\sum_{c=1}^Cexp(\alpha_c+\beta_{r,c}\textcolor{red}{+\lambda_{r,c,p}})}\right)\)

\(\alpha_c\sim\mathcal{N}(0,\sigma_\alpha)~~~~~~~\sigma_\alpha\sim\operatorname{Expo}(5)\)

\(\beta_{r,c}\sim\mathcal{N}(0,\sigma_\beta)~~~~~~~\sigma_\beta\sim\operatorname{Expo}(5)\)

\(\textcolor{red}{\lambda_{r,c,p}\sim\mathcal{N}(0,\sigma_\beta)}~~~~~~~\sigma_\lambda\sim\operatorname{Expo}(5)\)

Not only does the dimension of \(y\) grow linearly with the number of
precincts \(P\); because of the latent \(\lambda\) parameters, the
dimension of \(\theta\) does too. This is an issue both in estimating
the ELBO and in maximizing it.

\end{frame}

\begin{frame}{Lower-D posterior (2)}
\protect\hypertarget{lower-d-posterior-2}{}

Solution: replace \(\lambda_{p,r,c}\Vert_{c=1}^C\) with its MAP value
conditional on all the variables connected to it (not conditionally
independent): \(y_{p,r,c}\Vert_{c=1}^C\), \(\alpha_c\Vert_{c=1}^C\),
\(\beta_{r,c}\Vert_{c=1}^C\), and \(\sigma_\lambda\). Because of the
form of the model, this is available analytically, and we can trust that
the Laplace approximation will still be reasonably good away from the
MAP.

This is related to, but somewhat more aggressive than, the idea of
``amortized variational inference'' developed by Rezende and Mohammed
(2015).

\end{frame}

\end{document}
