{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "This is a jupyter notebook for testing / coding. So far, each code block is a separate test; unlike an ordinary notebook, they are not meant to run sequentially.\n",
    "\n",
    "Let's do MCMC:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, running \"ei\". This started out as a copy of Fritz's code but it's evolved into a working version of ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 5 :\n",
      "Reloading polytopize.\n",
      "ei_post_results_fixedalpha/scenario_SIG0.3_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.2802, grad_fn=<StdBackward0>) tensor(0.2671, requires_grad=True) tensor(0.2432, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-47080535.0304, grad_fn=<AddBackward0>)\n",
      "     tensor(-2789.4670, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 7.31E+08, mean_loss=7.31E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-44760798.6790, grad_fn=<AddBackward0>)\n",
      "     tensor(-1941.7600, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-44759986.0381, grad_fn=<AddBackward0>)\n",
      "     tensor(-1939.0101, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-41644681.8079, grad_fn=<AddBackward0>)\n",
      "     tensor(-2135.2253, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-41895644.0003, grad_fn=<AddBackward0>)\n",
      "     tensor(-2325.7894, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-42124256.4982, grad_fn=<AddBackward0>)\n",
      "     tensor(-2257.3265, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n",
      "     tensor(-42171162.9263, grad_fn=<AddBackward0>)\n",
      "     tensor(-2128.1778, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-43890676.8946, grad_fn=<AddBackward0>)\n",
      "     tensor(-2164.4416, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-44330521.6985, grad_fn=<AddBackward0>)\n",
      "     tensor(-2154.5737, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-48823673.9789, grad_fn=<AddBackward0>)\n",
      "     tensor(-2222.2483, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.2986, grad_fn=<StdBackward0>) tensor(0.2811, requires_grad=True) tensor(0.2591, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0326, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 6.55E+08, mean_loss=7.26E+08;\n",
      " logitstar = tensor([[-0.0276, -0.0528,  0.0804],\n",
      "        [-0.0418, -0.0592,  0.1011],\n",
      "        [-0.0285, -0.0530,  0.0815]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.3266, grad_fn=<StdBackward0>) tensor(0.3156, requires_grad=True) tensor(0.2916, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0158, -0.1008], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 7.21E+08, mean_loss=7.22E+08;\n",
      " logitstar = tensor([[-0.0038, -0.1052,  0.1090],\n",
      "        [-0.0291, -0.1055,  0.1347],\n",
      "        [-0.0145, -0.0916,  0.1061]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.3312, grad_fn=<StdBackward0>) tensor(0.3163, requires_grad=True) tensor(0.2894, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0020, -0.1131], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 6.55E+08, mean_loss=7.22E+08;\n",
      " logitstar = tensor([[ 0.0079, -0.1263,  0.1184],\n",
      "        [ 0.0077, -0.1156,  0.1079],\n",
      "        [-0.0215, -0.0973,  0.1188]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.3438, grad_fn=<StdBackward0>) tensor(0.3291, requires_grad=True) tensor(0.2935, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0217, -0.0905], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 6.88E+08, mean_loss=7.19E+08;\n",
      " logitstar = tensor([[ 0.0216, -0.1129,  0.0913],\n",
      "        [ 0.0225, -0.0798,  0.0573],\n",
      "        [ 0.0211, -0.0786,  0.0576]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.3260, grad_fn=<StdBackward0>) tensor(0.3150, requires_grad=True) tensor(0.2911, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0392, -0.0812], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.64E+08, mean_loss=7.17E+08;\n",
      " logitstar = tensor([[ 0.0557, -0.1007,  0.0449],\n",
      "        [ 0.0260, -0.0678,  0.0418],\n",
      "        [ 0.0359, -0.0752,  0.0393]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3147, grad_fn=<StdBackward0>) tensor(0.3037, requires_grad=True) tensor(0.2749, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0351, -0.0992], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 7.00E+08, mean_loss=7.15E+08;\n",
      " logitstar = tensor([[ 0.0530, -0.1272,  0.0743],\n",
      "        [ 0.0108, -0.0889,  0.0781],\n",
      "        [ 0.0414, -0.0815,  0.0401]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.3261, grad_fn=<StdBackward0>) tensor(0.3176, requires_grad=True) tensor(0.2873, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0283, -0.1161], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 7.50E+08, mean_loss=7.15E+08;\n",
      " logitstar = tensor([[ 0.0429, -0.1440,  0.1011],\n",
      "        [ 0.0228, -0.0982,  0.0753],\n",
      "        [ 0.0192, -0.1061,  0.0870]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2796, grad_fn=<StdBackward0>) tensor(0.2643, requires_grad=True) tensor(0.2442, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0390, -0.1003], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 6.53E+08, mean_loss=7.14E+08;\n",
      " logitstar = tensor([[ 0.0523, -0.1186,  0.0664],\n",
      "        [ 0.0231, -0.0838,  0.0608],\n",
      "        [ 0.0418, -0.0985,  0.0567]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.2944, grad_fn=<StdBackward0>) tensor(0.2801, requires_grad=True) tensor(0.2478, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0572, -0.1004], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 6.69E+08, mean_loss=7.13E+08;\n",
      " logitstar = tensor([[ 0.0735, -0.1256,  0.0522],\n",
      "        [ 0.0405, -0.0773,  0.0368],\n",
      "        [ 0.0575, -0.0983,  0.0408]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3083, grad_fn=<StdBackward0>) tensor(0.2961, requires_grad=True) tensor(0.2692, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0537, -0.1167], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 6.76E+08, mean_loss=7.12E+08;\n",
      " logitstar = tensor([[ 0.0752, -0.1502,  0.0750],\n",
      "        [ 0.0414, -0.1013,  0.0599],\n",
      "        [ 0.0444, -0.0987,  0.0543]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds: tensor(0.2813, grad_fn=<StdBackward0>) tensor(0.2614, requires_grad=True) tensor(0.2425, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0542, -0.1246], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 6.48E+08, mean_loss=7.12E+08;\n",
      " logitstar = tensor([[ 0.0677, -0.1603,  0.0926],\n",
      "        [ 0.0442, -0.1035,  0.0593],\n",
      "        [ 0.0508, -0.1101,  0.0593]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3458, grad_fn=<StdBackward0>) tensor(0.3323, requires_grad=True) tensor(0.3079, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0619, -0.1187], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 7.24E+08, mean_loss=7.10E+08;\n",
      " logitstar = tensor([[ 0.0843, -0.1462,  0.0619],\n",
      "        [ 0.0454, -0.1009,  0.0554],\n",
      "        [ 0.0560, -0.1091,  0.0531]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.2762, grad_fn=<StdBackward0>) tensor(0.2671, requires_grad=True) tensor(0.2485, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0586, -0.1151], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 7.20E+08, mean_loss=7.12E+08;\n",
      " logitstar = tensor([[ 0.0757, -0.1449,  0.0691],\n",
      "        [ 0.0558, -0.1004,  0.0446],\n",
      "        [ 0.0442, -0.1000,  0.0558]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2812, grad_fn=<StdBackward0>) tensor(0.2667, requires_grad=True) tensor(0.2450, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0436, -0.1086], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 7.11E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0570, -0.1238,  0.0669],\n",
      "        [ 0.0351, -0.0938,  0.0587],\n",
      "        [ 0.0387, -0.1082,  0.0696]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3235, grad_fn=<StdBackward0>) tensor(0.3155, requires_grad=True) tensor(0.2925, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0333, -0.1135], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 8.80E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0441, -0.1354,  0.0913],\n",
      "        [ 0.0146, -0.0977,  0.0830],\n",
      "        [ 0.0412, -0.1073,  0.0661]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2960, grad_fn=<StdBackward0>) tensor(0.2826, requires_grad=True) tensor(0.2604, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0471, -0.1085], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 7.72E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0625, -0.1358,  0.0733],\n",
      "        [ 0.0318, -0.0812,  0.0493],\n",
      "        [ 0.0470, -0.1086,  0.0616]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.3028, grad_fn=<StdBackward0>) tensor(0.2864, requires_grad=True) tensor(0.2643, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0467, -0.1104], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 6.92E+08, mean_loss=7.10E+08;\n",
      " logitstar = tensor([[ 0.0595, -0.1317,  0.0722],\n",
      "        [ 0.0332, -0.0878,  0.0547],\n",
      "        [ 0.0475, -0.1117,  0.0643]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3219, grad_fn=<StdBackward0>) tensor(0.3083, requires_grad=True) tensor(0.2756, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0599, -0.1013], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 6.58E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0710, -0.1178,  0.0468],\n",
      "        [ 0.0507, -0.0864,  0.0358],\n",
      "        [ 0.0581, -0.0996,  0.0415]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3149, grad_fn=<StdBackward0>) tensor(0.2992, requires_grad=True) tensor(0.2650, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0562, -0.1034], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 6.47E+08, mean_loss=7.08E+08;\n",
      " logitstar = tensor([[ 0.0727, -0.1293,  0.0566],\n",
      "        [ 0.0398, -0.0892,  0.0494],\n",
      "        [ 0.0560, -0.0918,  0.0358]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2841, grad_fn=<StdBackward0>) tensor(0.2726, requires_grad=True) tensor(0.2540, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0366, -0.1095], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 6.96E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0490, -0.1391,  0.0901],\n",
      "        [ 0.0329, -0.0869,  0.0540],\n",
      "        [ 0.0280, -0.1026,  0.0746]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3307, grad_fn=<StdBackward0>) tensor(0.3171, requires_grad=True) tensor(0.2886, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0302, -0.1008], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 7.86E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0485, -0.1225,  0.0740],\n",
      "        [ 0.0083, -0.0855,  0.0772],\n",
      "        [ 0.0339, -0.0945,  0.0606]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3227, grad_fn=<StdBackward0>) tensor(0.3114, requires_grad=True) tensor(0.2820, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0415, -0.0955], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 7.14E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0529, -0.1202,  0.0672],\n",
      "        [ 0.0289, -0.0707,  0.0418],\n",
      "        [ 0.0428, -0.0956,  0.0528]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3349, grad_fn=<StdBackward0>) tensor(0.3209, requires_grad=True) tensor(0.2892, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0478, -0.0967], grad_fn=<SliceBackward>)\n",
      "epoch 230 loss = 6.93E+08, mean_loss=7.07E+08;\n",
      " logitstar = tensor([[ 0.0623, -0.1230,  0.0607],\n",
      "        [ 0.0293, -0.0757,  0.0464],\n",
      "        [ 0.0518, -0.0915,  0.0397]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3032, grad_fn=<StdBackward0>) tensor(0.2882, requires_grad=True) tensor(0.2635, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0479, -0.1041], grad_fn=<SliceBackward>)\n",
      "epoch 240 loss = 6.00E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0680, -0.1363,  0.0683],\n",
      "        [ 0.0345, -0.0719,  0.0374],\n",
      "        [ 0.0412, -0.1040,  0.0627]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2951, grad_fn=<StdBackward0>) tensor(0.2835, requires_grad=True) tensor(0.2611, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0453, -0.1068], grad_fn=<SliceBackward>)\n",
      "epoch 250 loss = 7.01E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0598, -0.1458,  0.0861],\n",
      "        [ 0.0221, -0.0674,  0.0453],\n",
      "        [ 0.0540, -0.1073,  0.0532]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 256\n",
      "guide:begin line 51 256\n",
      "lp:  line 51 256\n",
      "guide:end line 51 256\n",
      "model:end line 51 512\n",
      "sds: tensor(0.3172, grad_fn=<StdBackward0>) tensor(0.3038, requires_grad=True) tensor(0.2819, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0377, -0.1027], grad_fn=<SliceBackward>)\n",
      "epoch 260 loss = 7.73E+08, mean_loss=7.08E+08;\n",
      " logitstar = tensor([[ 0.0510, -0.1406,  0.0897],\n",
      "        [ 0.0153, -0.0681,  0.0529],\n",
      "        [ 0.0468, -0.0994,  0.0525]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2986, grad_fn=<StdBackward0>) tensor(0.2888, requires_grad=True) tensor(0.2574, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0482, -0.0930], grad_fn=<SliceBackward>)\n",
      "epoch 270 loss = 6.95E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0665, -0.1235,  0.0571],\n",
      "        [ 0.0247, -0.0633,  0.0386],\n",
      "        [ 0.0535, -0.0921,  0.0386]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2920, grad_fn=<StdBackward0>) tensor(0.2776, requires_grad=True) tensor(0.2547, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0451, -0.0988], grad_fn=<SliceBackward>)\n",
      "epoch 280 loss = 7.76E+08, mean_loss=7.10E+08;\n",
      " logitstar = tensor([[ 0.0616, -0.1321,  0.0705],\n",
      "        [ 0.0294, -0.0675,  0.0381],\n",
      "        [ 0.0443, -0.0967,  0.0524]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 51 1 :\n",
      "     710097478.3820825\n",
      "     708110060.1482035\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.0451, -0.0988],\n",
      "        [ 0.0165, -0.0333],\n",
      "        [-0.0157,  0.0313]], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "jsonizing 2\n",
      "np complete? line 1312 1 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 1 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 2 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 2 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 3 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 3 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 4 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 4 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 5 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 5 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 6 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 6 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 7 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 7 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 8 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 8 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 9 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 9 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 10 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 10 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 16\n",
      "sampleYs line 1420 16\n",
      "np complete? line 1312 32\n",
      "sampleYs line 1420 32\n",
      "np complete? line 1312 64\n",
      "sampleYs line 1420 64\n",
      "np complete? line 1312 128\n",
      "sampleYs line 1420 128\n",
      "np complete? line 1312 256\n",
      "sampleYs line 1420 256\n",
      "np complete? line 1312 512\n",
      "sampleYs line 1420 512\n",
      "denses line 1434 1 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 694 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 1 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1312 1024\n",
      "sampleYs line 1420 1024\n",
      "denses line 1434 2 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 1388 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 2 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1312 2048\n",
      "sampleYs line 1420 2048\n",
      "denses line 1434 3 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 2082 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 3 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1434 4 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "ei_post_results_fixedalpha/scenario_SIG0.1_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.2632, grad_fn=<StdBackward0>) tensor(0.2471, requires_grad=True) tensor(0.2229, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-44624498.6271, grad_fn=<AddBackward0>)\n",
      "     tensor(-2765.3185, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([ 0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 6.93E+08, mean_loss=6.93E+08;\n",
      " logitstar = tensor([[ 0.0100,  0.0000, -0.0100],\n",
      "        [ 0.0100,  0.0000, -0.0100],\n",
      "        [-0.0050, -0.0150,  0.0200]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-46137755.3136, grad_fn=<AddBackward0>)\n",
      "     tensor(-1987.6752, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-44069369.9545, grad_fn=<AddBackward0>)\n",
      "     tensor(-1883.7531, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-43741593.0867, grad_fn=<AddBackward0>)\n",
      "     tensor(-1883.5879, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-45192771.8286, grad_fn=<AddBackward0>)\n",
      "     tensor(-1865.2526, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-47160565.3387, grad_fn=<AddBackward0>)\n",
      "     tensor(-1869.3490, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     tensor(-43915369.4303, grad_fn=<AddBackward0>)\n",
      "     tensor(-1817.1742, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-43096066.8481, grad_fn=<AddBackward0>)\n",
      "     tensor(-1782.5932, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-41260085.0733, grad_fn=<AddBackward0>)\n",
      "     tensor(-1698.3945, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-47350109.7823, grad_fn=<AddBackward0>)\n",
      "     tensor(-1651.0974, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.2294, grad_fn=<StdBackward0>) tensor(0.2148, requires_grad=True) tensor(0.1808, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0286, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 6.29E+08, mean_loss=6.93E+08;\n",
      " logitstar = tensor([[-0.0335, -0.0780,  0.1115],\n",
      "        [-0.0306, -0.0518,  0.0823],\n",
      "        [-0.0218, -0.0353,  0.0571]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.2531, grad_fn=<StdBackward0>) tensor(0.2445, requires_grad=True) tensor(0.2064, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0328, -0.0930], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 6.38E+08, mean_loss=6.93E+08;\n",
      " logitstar = tensor([[-0.0177, -0.1275,  0.1451],\n",
      "        [-0.0244, -0.0841,  0.1085],\n",
      "        [-0.0564, -0.0675,  0.1239]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.2795, grad_fn=<StdBackward0>) tensor(0.2713, requires_grad=True) tensor(0.2368, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0061, -0.0933], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 7.10E+08, mean_loss=6.94E+08;\n",
      " logitstar = tensor([[ 0.0126, -0.1583,  0.1457],\n",
      "        [-0.0056, -0.0684,  0.0740],\n",
      "        [-0.0253, -0.0532,  0.0784]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.2712, grad_fn=<StdBackward0>) tensor(0.2667, requires_grad=True) tensor(0.2347, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0114, -0.0917], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 6.51E+08, mean_loss=6.91E+08;\n",
      " logitstar = tensor([[ 0.0254, -0.1998,  0.1744],\n",
      "        [ 0.0033, -0.0401,  0.0368],\n",
      "        [ 0.0056, -0.0353,  0.0297]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.2653, grad_fn=<StdBackward0>) tensor(0.2558, requires_grad=True) tensor(0.2268, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0232, -0.0720], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.25E+08, mean_loss=6.92E+08;\n",
      " logitstar = tensor([[ 0.0243, -0.2231,  0.1988],\n",
      "        [ 0.0165,  0.0142, -0.0308],\n",
      "        [ 0.0287, -0.0073, -0.0214]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2057, grad_fn=<StdBackward0>) tensor(0.1907, requires_grad=True) tensor(0.1606, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0520, -0.0326], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 6.36E+08, mean_loss=6.93E+08;\n",
      " logitstar = tensor([[ 0.0337, -0.2293,  0.1956],\n",
      "        [ 0.0590,  0.0984, -0.1574],\n",
      "        [ 0.0632,  0.0332, -0.0965]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.1902, grad_fn=<StdBackward0>) tensor(0.1821, requires_grad=True) tensor(0.1447, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.0689, 0.0063], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 6.88E+08, mean_loss=6.92E+08;\n",
      " logitstar = tensor([[ 0.0137, -0.2390,  0.2253],\n",
      "        [ 0.0866,  0.1854, -0.2719],\n",
      "        [ 0.1065,  0.0724, -0.1789]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1677, grad_fn=<StdBackward0>) tensor(0.1581, requires_grad=True) tensor(0.1187, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.0950, 0.0469], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 7.09E+08, mean_loss=6.93E+08;\n",
      " logitstar = tensor([[ 0.0023, -0.2479,  0.2455],\n",
      "        [ 0.1349,  0.2753, -0.4102],\n",
      "        [ 0.1476,  0.1131, -0.2608]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.1369, grad_fn=<StdBackward0>) tensor(0.1240, requires_grad=True) tensor(0.0860, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1267, 0.0845], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 6.90E+08, mean_loss=6.92E+08;\n",
      " logitstar = tensor([[ 0.0105, -0.2601,  0.2495],\n",
      "        [ 0.2047,  0.3627, -0.5674],\n",
      "        [ 0.1648,  0.1508, -0.3156]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1614, grad_fn=<StdBackward0>) tensor(0.1247, requires_grad=True) tensor(0.0817, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1518, 0.1140], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 6.19E+08, mean_loss=6.90E+08;\n",
      " logitstar = tensor([[ 0.0020, -0.2805,  0.2785],\n",
      "        [ 0.2636,  0.4422, -0.7058],\n",
      "        [ 0.1897,  0.1803, -0.3701]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1351, grad_fn=<StdBackward0>) tensor(0.1124, requires_grad=True) tensor(0.0707, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1843, 0.1480], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 7.13E+08, mean_loss=6.91E+08;\n",
      " logitstar = tensor([[ 0.0038, -0.2964,  0.2926],\n",
      "        [ 0.3349,  0.5262, -0.8610],\n",
      "        [ 0.2141,  0.2144, -0.4285]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1470, grad_fn=<StdBackward0>) tensor(0.1127, requires_grad=True) tensor(0.0643, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2021, 0.1813], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 6.82E+08, mean_loss=6.89E+08;\n",
      " logitstar = tensor([[-0.0108, -0.3040,  0.3149],\n",
      "        [ 0.3988,  0.6094, -1.0081],\n",
      "        [ 0.2184,  0.2385, -0.4569]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.1368, grad_fn=<StdBackward0>) tensor(0.1159, requires_grad=True) tensor(0.0646, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2216, 0.2025], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 6.48E+08, mean_loss=6.87E+08;\n",
      " logitstar = tensor([[-0.0113, -0.3181,  0.3294],\n",
      "        [ 0.4668,  0.6806, -1.1475],\n",
      "        [ 0.2091,  0.2451, -0.4542]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1431, grad_fn=<StdBackward0>) tensor(0.1120, requires_grad=True) tensor(0.0613, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2341, 0.2122], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 7.22E+08, mean_loss=6.84E+08;\n",
      " logitstar = tensor([[-0.0079, -0.3320,  0.3399],\n",
      "        [ 0.5261,  0.7403, -1.2664],\n",
      "        [ 0.1839,  0.2283, -0.4122]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1439, grad_fn=<StdBackward0>) tensor(0.1207, requires_grad=True) tensor(0.0622, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2289, 0.2192], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 6.91E+08, mean_loss=6.83E+08;\n",
      " logitstar = tensor([[-0.0165, -0.3264,  0.3428],\n",
      "        [ 0.5463,  0.7973, -1.3436],\n",
      "        [ 0.1568,  0.1866, -0.3434]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1927, grad_fn=<StdBackward0>) tensor(0.1499, requires_grad=True) tensor(0.0663, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2283, 0.2194], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 6.27E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[-0.0133, -0.3335,  0.3468],\n",
      "        [ 0.5677,  0.8475, -1.4152],\n",
      "        [ 0.1305,  0.1441, -0.2746]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.1515, grad_fn=<StdBackward0>) tensor(0.1303, requires_grad=True) tensor(0.0630, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2356, 0.2192], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 7.67E+08, mean_loss=6.83E+08;\n",
      " logitstar = tensor([[ 9.2313e-04, -3.3648e-01,  3.3556e-01],\n",
      "        [ 5.8170e-01,  8.9458e-01, -1.4763e+00],\n",
      "        [ 1.2422e-01,  9.9459e-02, -2.2368e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1694, grad_fn=<StdBackward0>) tensor(0.1398, requires_grad=True) tensor(0.0568, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2355, 0.2058], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 7.09E+08, mean_loss=6.81E+08;\n",
      " logitstar = tensor([[-0.0055, -0.3507,  0.3563],\n",
      "        [ 0.5764,  0.9143, -1.4907],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 0.1354,  0.0540, -0.1894]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1752, grad_fn=<StdBackward0>) tensor(0.1484, requires_grad=True) tensor(0.0648, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2427, 0.2004], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 7.13E+08, mean_loss=6.80E+08;\n",
      " logitstar = tensor([[ 7.0969e-04, -3.4456e-01,  3.4385e-01],\n",
      "        [ 5.7677e-01,  9.2172e-01, -1.4985e+00],\n",
      "        [ 1.5067e-01,  2.4068e-02, -1.7474e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1821, grad_fn=<StdBackward0>) tensor(0.1521, requires_grad=True) tensor(0.0646, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2441, 0.1956], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 7.03E+08, mean_loss=6.81E+08;\n",
      " logitstar = tensor([[-0.0038, -0.3449,  0.3487],\n",
      "        [ 0.5778,  0.9133, -1.4911],\n",
      "        [ 0.1582,  0.0183, -0.1765]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1488, grad_fn=<StdBackward0>) tensor(0.1264, requires_grad=True) tensor(0.0557, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2431, 0.1939], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 7.26E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0093, -0.3379,  0.3472],\n",
      "        [ 0.5750,  0.9117, -1.4868],\n",
      "        [ 0.1637,  0.0077, -0.1714]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1999, grad_fn=<StdBackward0>) tensor(0.1587, requires_grad=True) tensor(0.0639, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2447, 0.1890], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 7.43E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[-0.0076, -0.3364,  0.3440],\n",
      "        [ 0.5722,  0.9059, -1.4781],\n",
      "        [ 0.1694, -0.0025, -0.1669]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2001, grad_fn=<StdBackward0>) tensor(0.1589, requires_grad=True) tensor(0.0675, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2423, 0.1854], grad_fn=<SliceBackward>)\n",
      "epoch 230 loss = 6.43E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[-0.0128, -0.3337,  0.3464],\n",
      "        [ 0.5637,  0.8977, -1.4613],\n",
      "        [ 0.1760, -0.0078, -0.1682]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1904, grad_fn=<StdBackward0>) tensor(0.1546, requires_grad=True) tensor(0.0636, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2456, 0.1856], grad_fn=<SliceBackward>)\n",
      "epoch 240 loss = 6.61E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0090, -0.3345,  0.3435],\n",
      "        [ 0.5575,  0.9008, -1.4583],\n",
      "        [ 0.1883, -0.0096, -0.1787]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1764, grad_fn=<StdBackward0>) tensor(0.1437, requires_grad=True) tensor(0.0604, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2494, 0.1818], grad_fn=<SliceBackward>)\n",
      "epoch 250 loss = 6.82E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[-0.0062, -0.3425,  0.3487],\n",
      "        [ 0.5617,  0.9056, -1.4674],\n",
      "        [ 0.1927, -0.0178, -0.1749]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 256\n",
      "guide:begin line 51 256\n",
      "lp:  line 51 256\n",
      "guide:end line 51 256\n",
      "model:end line 51 512\n",
      "sds: tensor(0.2031, grad_fn=<StdBackward0>) tensor(0.1700, requires_grad=True) tensor(0.0644, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2597, 0.1856], grad_fn=<SliceBackward>)\n",
      "epoch 260 loss = 6.91E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[ 0.0069, -0.3407,  0.3338],\n",
      "        [ 0.5691,  0.9165, -1.4856],\n",
      "        [ 0.2030, -0.0190, -0.1839]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1881, grad_fn=<StdBackward0>) tensor(0.1555, requires_grad=True) tensor(0.0604, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2517, 0.1841], grad_fn=<SliceBackward>)\n",
      "epoch 270 loss = 5.99E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0123, -0.3466,  0.3589],\n",
      "        [ 0.5600,  0.9036, -1.4635],\n",
      "        [ 0.2076, -0.0048, -0.2028]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2071, grad_fn=<StdBackward0>) tensor(0.1728, requires_grad=True) tensor(0.0672, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2559, 0.1968], grad_fn=<SliceBackward>)\n",
      "epoch 280 loss = 6.24E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0037, -0.3267,  0.3304],\n",
      "        [ 0.5719,  0.9210, -1.4929],\n",
      "        [ 0.1996, -0.0037, -0.1959]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1777, grad_fn=<StdBackward0>) tensor(0.1419, requires_grad=True) tensor(0.0624, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2486, 0.1866], grad_fn=<SliceBackward>)\n",
      "epoch 290 loss = 7.06E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0162, -0.3511,  0.3673],\n",
      "        [ 0.5806,  0.9034, -1.4840],\n",
      "        [ 0.1815,  0.0074, -0.1889]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1951, grad_fn=<StdBackward0>) tensor(0.1550, requires_grad=True) tensor(0.0654, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2553, 0.1978], grad_fn=<SliceBackward>)\n",
      "epoch 300 loss = 6.38E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0018, -0.3388,  0.3369],\n",
      "        [ 0.5844,  0.9013, -1.4857],\n",
      "        [ 0.1798,  0.0308, -0.2106]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1953, grad_fn=<StdBackward0>) tensor(0.1598, requires_grad=True) tensor(0.0691, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2416, 0.1948], grad_fn=<SliceBackward>)\n",
      "epoch 310 loss = 6.90E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0172, -0.3473,  0.3645],\n",
      "        [ 0.5730,  0.8928, -1.4659],\n",
      "        [ 0.1689,  0.0388, -0.2077]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1489, grad_fn=<StdBackward0>) tensor(0.1203, requires_grad=True) tensor(0.0614, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2468, 0.2017], grad_fn=<SliceBackward>)\n",
      "epoch 320 loss = 6.33E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0050, -0.3331,  0.3381],\n",
      "        [ 0.5765,  0.9129, -1.4895],\n",
      "        [ 0.1688,  0.0252, -0.1940]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1646, grad_fn=<StdBackward0>) tensor(0.1333, requires_grad=True) tensor(0.0606, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2438, 0.1971], grad_fn=<SliceBackward>)\n",
      "epoch 330 loss = 7.13E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[-0.0104, -0.3422,  0.3526],\n",
      "        [ 0.5708,  0.9195, -1.4903],\n",
      "        [ 0.1709,  0.0139, -0.1847]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1544, grad_fn=<StdBackward0>) tensor(0.1309, requires_grad=True) tensor(0.0604, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2457, 0.1927], grad_fn=<SliceBackward>)\n",
      "epoch 340 loss = 6.42E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0063, -0.3508,  0.3571],\n",
      "        [ 0.5734,  0.9174, -1.4908],\n",
      "        [ 0.1700,  0.0116, -0.1816]], grad_fn=<AddBackward0>)\n",
      "types? line 100 1024\n",
      "sds: tensor(0.2165, grad_fn=<StdBackward0>) tensor(0.1806, requires_grad=True) tensor(0.0701, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2494, 0.1930], grad_fn=<SliceBackward>)\n",
      "epoch 350 loss = 6.67E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0072, -0.3442,  0.3370],\n",
      "        [ 0.5793,  0.9308, -1.5101],\n",
      "        [ 0.1615, -0.0077, -0.1538]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1866, grad_fn=<StdBackward0>) tensor(0.1520, requires_grad=True) tensor(0.0645, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2405, 0.1848], grad_fn=<SliceBackward>)\n",
      "epoch 360 loss = 5.94E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0027, -0.3580,  0.3607],\n",
      "        [ 0.5611,  0.9272, -1.4883],\n",
      "        [ 0.1631, -0.0148, -0.1484]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2115, grad_fn=<StdBackward0>) tensor(0.1702, requires_grad=True) tensor(0.0735, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2407, 0.1903], grad_fn=<SliceBackward>)\n",
      "epoch 370 loss = 6.29E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 0.0063, -0.3462,  0.3399],\n",
      "        [ 0.5564,  0.9304, -1.4868],\n",
      "        [ 0.1593, -0.0134, -0.1459]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1849, grad_fn=<StdBackward0>) tensor(0.1561, requires_grad=True) tensor(0.0622, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2362, 0.1942], grad_fn=<SliceBackward>)\n",
      "epoch 380 loss = 6.82E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0022, -0.3385,  0.3363],\n",
      "        [ 0.5688,  0.9176, -1.4864],\n",
      "        [ 0.1376,  0.0034, -0.1410]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1921, grad_fn=<StdBackward0>) tensor(0.1536, requires_grad=True) tensor(0.0637, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2289, 0.1945], grad_fn=<SliceBackward>)\n",
      "epoch 390 loss = 6.04E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0158, -0.3416,  0.3574],\n",
      "        [ 0.5664,  0.9007, -1.4671],\n",
      "        [ 0.1362,  0.0243, -0.1606]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds: tensor(0.1698, grad_fn=<StdBackward0>) tensor(0.1398, requires_grad=True) tensor(0.0620, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2328, 0.1964], grad_fn=<SliceBackward>)\n",
      "epoch 400 loss = 6.64E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0049, -0.3381,  0.3430],\n",
      "        [ 0.5657,  0.9021, -1.4678],\n",
      "        [ 0.1377,  0.0251, -0.1628]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1514, grad_fn=<StdBackward0>) tensor(0.1300, requires_grad=True) tensor(0.0633, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2315, 0.1905], grad_fn=<SliceBackward>)\n",
      "epoch 410 loss = 7.45E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0057, -0.3468,  0.3525],\n",
      "        [ 0.5664,  0.9038, -1.4702],\n",
      "        [ 0.1337,  0.0145, -0.1482]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 51 1 :\n",
      "     676304643.2404435\n",
      "     673162865.0632945\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.2315,  0.1905],\n",
      "        [-0.2372, -0.5373],\n",
      "        [ 0.3350,  0.7133]], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "jsonizing 2\n",
      "np complete? line 1312 1 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 1 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 2 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 2 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 3 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 3 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 4 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 4 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 5 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 5 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 6 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 6 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 7 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 7 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 8 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 8 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 9 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 9 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 10 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 10 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 16\n",
      "sampleYs line 1420 16\n",
      "np complete? line 1312 32\n",
      "sampleYs line 1420 32\n",
      "np complete? line 1312 64\n",
      "sampleYs line 1420 64\n",
      "np complete? line 1312 128\n",
      "sampleYs line 1420 128\n",
      "np complete? line 1312 256\n",
      "sampleYs line 1420 256\n",
      "np complete? line 1312 512\n",
      "sampleYs line 1420 512\n",
      "denses line 1434 1 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 694 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 1 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1312 1024\n",
      "sampleYs line 1420 1024\n",
      "denses line 1434 2 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 1388 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 2 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1312 2048\n",
      "sampleYs line 1420 2048\n",
      "denses line 1434 3 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 2082 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 3 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1434 4 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "ei_post_results_fixedalpha/scenario_SIG0.02_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.2740, grad_fn=<StdBackward0>) tensor(0.2588, requires_grad=True) tensor(0.2231, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-50134633.0890, grad_fn=<AddBackward0>)\n",
      "     tensor(-2787.6841, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 7.76E+08, mean_loss=7.76E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-43947871.4901, grad_fn=<AddBackward0>)\n",
      "     tensor(-1964.5108, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-43574791.2267, grad_fn=<AddBackward0>)\n",
      "     tensor(-2024.4196, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-46191513.0286, grad_fn=<AddBackward0>)\n",
      "     tensor(-2220.5876, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-45984053.7092, grad_fn=<AddBackward0>)\n",
      "     tensor(-2728.8220, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-45421664.9499, grad_fn=<AddBackward0>)\n",
      "     tensor(-2195.0357, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n",
      "     tensor(-41100153.0101, grad_fn=<AddBackward0>)\n",
      "     tensor(-2295.8808, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-41772829.1511, grad_fn=<AddBackward0>)\n",
      "     tensor(-2497.8961, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-49091502.7603, grad_fn=<AddBackward0>)\n",
      "     tensor(-2383.5253, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-43611673.0170, grad_fn=<AddBackward0>)\n",
      "     tensor(-2178.7078, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.2399, grad_fn=<StdBackward0>) tensor(0.2293, requires_grad=True) tensor(0.2004, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0550, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 6.95E+08, mean_loss=7.65E+08;\n",
      " logitstar = tensor([[-0.0487, -0.0487,  0.0974],\n",
      "        [-0.0541, -0.0584,  0.1126],\n",
      "        [-0.0621, -0.0578,  0.1200]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.2143, grad_fn=<StdBackward0>) tensor(0.1976, requires_grad=True) tensor(0.1784, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0844, -0.0855], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 6.24E+08, mean_loss=7.56E+08;\n",
      " logitstar = tensor([[-0.0751, -0.1022,  0.1773],\n",
      "        [-0.0767, -0.1012,  0.1779],\n",
      "        [-0.1015, -0.0531,  0.1546]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.2595, grad_fn=<StdBackward0>) tensor(0.2457, requires_grad=True) tensor(0.2154, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0610, -0.0704], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 6.99E+08, mean_loss=7.48E+08;\n",
      " logitstar = tensor([[-0.0504, -0.0947,  0.1451],\n",
      "        [-0.0450, -0.0808,  0.1258],\n",
      "        [-0.0876, -0.0358,  0.1234]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.2062, grad_fn=<StdBackward0>) tensor(0.1969, requires_grad=True) tensor(0.1668, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0218, -0.0597], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 6.85E+08, mean_loss=7.42E+08;\n",
      " logitstar = tensor([[-0.0108, -0.1075,  0.1183],\n",
      "        [-0.0083, -0.0499,  0.0581],\n",
      "        [-0.0463, -0.0218,  0.0681]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.2770, grad_fn=<StdBackward0>) tensor(0.2655, requires_grad=True) tensor(0.2242, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0077, -0.0751], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 6.73E+08, mean_loss=7.34E+08;\n",
      " logitstar = tensor([[-0.0036, -0.1605,  0.1642],\n",
      "        [ 0.0013, -0.0594,  0.0581],\n",
      "        [-0.0206, -0.0053,  0.0259]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2259, grad_fn=<StdBackward0>) tensor(0.2259, requires_grad=True) tensor(0.1939, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0003, -0.0999], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 7.45E+08, mean_loss=7.29E+08;\n",
      " logitstar = tensor([[-1.2945e-04, -2.1721e-01,  2.1734e-01],\n",
      "        [ 2.6917e-02, -5.8819e-02,  3.1902e-02],\n",
      "        [-2.5745e-02, -2.3579e-02,  4.9324e-02]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.2135, grad_fn=<StdBackward0>) tensor(0.2068, requires_grad=True) tensor(0.1742, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0339, -0.0802], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 6.56E+08, mean_loss=7.27E+08;\n",
      " logitstar = tensor([[ 0.0278, -0.2318,  0.2040],\n",
      "        [ 0.0514, -0.0158, -0.0356],\n",
      "        [ 0.0225,  0.0069, -0.0294]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2152, grad_fn=<StdBackward0>) tensor(0.2051, requires_grad=True) tensor(0.1627, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0677, -0.0484], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 6.63E+08, mean_loss=7.19E+08;\n",
      " logitstar = tensor([[ 0.0313, -0.2370,  0.2057],\n",
      "        [ 0.0708,  0.0556, -0.1264],\n",
      "        [ 0.1011,  0.0364, -0.1375]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.1521, grad_fn=<StdBackward0>) tensor(0.1481, requires_grad=True) tensor(0.1141, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0781, -0.0167], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 6.41E+08, mean_loss=7.15E+08;\n",
      " logitstar = tensor([[ 0.0033, -0.2509,  0.2476],\n",
      "        [ 0.0798,  0.1336, -0.2133],\n",
      "        [ 0.1514,  0.0672, -0.2187]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1369, grad_fn=<StdBackward0>) tensor(0.1324, requires_grad=True) tensor(0.0899, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1121, 0.0269], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 7.00E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0112, -0.2557,  0.2445],\n",
      "        [ 0.1194,  0.2259, -0.3453],\n",
      "        [ 0.2057,  0.1106, -0.3163]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1507, grad_fn=<StdBackward0>) tensor(0.1443, requires_grad=True) tensor(0.1031, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1442, 0.0747], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 6.96E+08, mean_loss=7.07E+08;\n",
      " logitstar = tensor([[ 0.0096, -0.2574,  0.2478],\n",
      "        [ 0.1657,  0.3232, -0.4890],\n",
      "        [ 0.2573,  0.1582, -0.4156]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1340, grad_fn=<StdBackward0>) tensor(0.1238, requires_grad=True) tensor(0.0843, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1706, 0.1174], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 7.11E+08, mean_loss=7.04E+08;\n",
      " logitstar = tensor([[-0.0055, -0.2645,  0.2700],\n",
      "        [ 0.2184,  0.4158, -0.6342],\n",
      "        [ 0.2988,  0.2009, -0.4997]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.1398, grad_fn=<StdBackward0>) tensor(0.1040, requires_grad=True) tensor(0.0529, grad_fn=<StdBackward0>)\n",
      "ps2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ecstar = tensor([0.1978, 0.1499], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 6.81E+08, mean_loss=7.01E+08;\n",
      " logitstar = tensor([[-0.0090, -0.2820,  0.2910],\n",
      "        [ 0.2860,  0.4982, -0.7842],\n",
      "        [ 0.3163,  0.2334, -0.5497]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1292, grad_fn=<StdBackward0>) tensor(0.0969, requires_grad=True) tensor(0.0432, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2183, 0.1790], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 6.95E+08, mean_loss=6.99E+08;\n",
      " logitstar = tensor([[-0.0184, -0.2963,  0.3147],\n",
      "        [ 0.3531,  0.5773, -0.9305],\n",
      "        [ 0.3200,  0.2560, -0.5760]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0889, grad_fn=<StdBackward0>) tensor(0.0820, requires_grad=True) tensor(0.0324, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2330, 0.2011], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 7.07E+08, mean_loss=6.96E+08;\n",
      " logitstar = tensor([[-0.0124, -0.3152,  0.3275],\n",
      "        [ 0.4168,  0.6494, -1.0661],\n",
      "        [ 0.2947,  0.2689, -0.5636]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1483, grad_fn=<StdBackward0>) tensor(0.1119, requires_grad=True) tensor(0.0343, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2390, 0.2217], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 6.78E+08, mean_loss=6.93E+08;\n",
      " logitstar = tensor([[-0.0151, -0.3324,  0.3475],\n",
      "        [ 0.4649,  0.7200, -1.1850],\n",
      "        [ 0.2672,  0.2775, -0.5447]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.1483, grad_fn=<StdBackward0>) tensor(0.1154, requires_grad=True) tensor(0.0345, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2407, 0.2294], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 6.77E+08, mean_loss=6.92E+08;\n",
      " logitstar = tensor([[-0.0103, -0.3489,  0.3592],\n",
      "        [ 0.4908,  0.7698, -1.2606],\n",
      "        [ 0.2416,  0.2673, -0.5089]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1736, grad_fn=<StdBackward0>) tensor(0.1314, requires_grad=True) tensor(0.0330, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2414, 0.2429], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 6.13E+08, mean_loss=6.90E+08;\n",
      " logitstar = tensor([[-0.0084, -0.3452,  0.3536],\n",
      "        [ 0.5092,  0.8254, -1.3346],\n",
      "        [ 0.2235,  0.2485, -0.4719]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1354, grad_fn=<StdBackward0>) tensor(0.1119, requires_grad=True) tensor(0.0264, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2405, 0.2373], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 6.16E+08, mean_loss=6.84E+08;\n",
      " logitstar = tensor([[ 1.2494e-03, -3.6378e-01,  3.6254e-01],\n",
      "        [ 5.2206e-01,  8.6709e-01, -1.3891e+00],\n",
      "        [ 1.9818e-01,  2.0863e-01, -4.0681e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1403, grad_fn=<StdBackward0>) tensor(0.1176, requires_grad=True) tensor(0.0304, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2322, 0.2334], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 7.17E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[ 0.0037, -0.3620,  0.3583],\n",
      "        [ 0.5189,  0.9047, -1.4236],\n",
      "        [ 0.1740,  0.1576, -0.3316]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1698, grad_fn=<StdBackward0>) tensor(0.1392, requires_grad=True) tensor(0.0359, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2292, 0.2276], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 6.45E+08, mean_loss=6.80E+08;\n",
      " logitstar = tensor([[ 0.0030, -0.3649,  0.3619],\n",
      "        [ 0.5247,  0.9027, -1.4274],\n",
      "        [ 0.1599,  0.1449, -0.3048]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1508, grad_fn=<StdBackward0>) tensor(0.1284, requires_grad=True) tensor(0.0281, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2351, 0.2265], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 6.71E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[ 0.0168, -0.3551,  0.3383],\n",
      "        [ 0.5280,  0.9040, -1.4320],\n",
      "        [ 0.1604,  0.1306, -0.2911]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1376, grad_fn=<StdBackward0>) tensor(0.1164, requires_grad=True) tensor(0.0309, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2250, 0.2144], grad_fn=<SliceBackward>)\n",
      "epoch 230 loss = 7.12E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[ 0.0015, -0.3648,  0.3632],\n",
      "        [ 0.5135,  0.8977, -1.4112],\n",
      "        [ 0.1599,  0.1103, -0.2702]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1851, grad_fn=<StdBackward0>) tensor(0.1535, requires_grad=True) tensor(0.0327, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2296, 0.2165], grad_fn=<SliceBackward>)\n",
      "epoch 240 loss = 6.90E+08, mean_loss=6.79E+08;\n",
      " logitstar = tensor([[ 0.0091, -0.3487,  0.3395],\n",
      "        [ 0.5065,  0.8981, -1.4046],\n",
      "        [ 0.1733,  0.1001, -0.2734]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1923, grad_fn=<StdBackward0>) tensor(0.1494, requires_grad=True) tensor(0.0327, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2374, 0.2127], grad_fn=<SliceBackward>)\n",
      "epoch 250 loss = 7.21E+08, mean_loss=6.79E+08;\n",
      " logitstar = tensor([[ 0.0068, -0.3522,  0.3454],\n",
      "        [ 0.5034,  0.8958, -1.3992],\n",
      "        [ 0.2020,  0.0944, -0.2964]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 256\n",
      "guide:begin line 51 256\n",
      "lp:  line 51 256\n",
      "guide:end line 51 256\n",
      "model:end line 51 512\n",
      "sds: tensor(0.1659, grad_fn=<StdBackward0>) tensor(0.1217, requires_grad=True) tensor(0.0307, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2409, 0.2127], grad_fn=<SliceBackward>)\n",
      "epoch 260 loss = 5.95E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[ 0.0054, -0.3516,  0.3463],\n",
      "        [ 0.5061,  0.8993, -1.4054],\n",
      "        [ 0.2113,  0.0905, -0.3018]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1363, grad_fn=<StdBackward0>) tensor(0.1160, requires_grad=True) tensor(0.0292, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2460, 0.2136], grad_fn=<SliceBackward>)\n",
      "epoch 270 loss = 7.45E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[ 0.0069, -0.3552,  0.3483],\n",
      "        [ 0.5141,  0.9023, -1.4163],\n",
      "        [ 0.2171,  0.0938, -0.3109]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1408, grad_fn=<StdBackward0>) tensor(0.1112, requires_grad=True) tensor(0.0286, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2439, 0.2107], grad_fn=<SliceBackward>)\n",
      "epoch 280 loss = 6.23E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0090, -0.3620,  0.3710],\n",
      "        [ 0.5153,  0.9032, -1.4185],\n",
      "        [ 0.2255,  0.0908, -0.3163]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1612, grad_fn=<StdBackward0>) tensor(0.1360, requires_grad=True) tensor(0.0307, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2517, 0.2149], grad_fn=<SliceBackward>)\n",
      "epoch 290 loss = 7.51E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0027, -0.3473,  0.3500],\n",
      "        [ 0.5094,  0.9068, -1.4162],\n",
      "        [ 0.2484,  0.0852, -0.3336]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1844, grad_fn=<StdBackward0>) tensor(0.1504, requires_grad=True) tensor(0.0333, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2512, 0.2076], grad_fn=<SliceBackward>)\n",
      "epoch 300 loss = 6.39E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0068, -0.3542,  0.3611],\n",
      "        [ 0.5068,  0.9099, -1.4167],\n",
      "        [ 0.2537,  0.0671, -0.3208]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1705, grad_fn=<StdBackward0>) tensor(0.1393, requires_grad=True) tensor(0.0307, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2523, 0.2074], grad_fn=<SliceBackward>)\n",
      "epoch 310 loss = 6.75E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[-0.0057, -0.3501,  0.3558],\n",
      "        [ 0.5097,  0.9050, -1.4146],\n",
      "        [ 0.2531,  0.0674, -0.3205]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1412, grad_fn=<StdBackward0>) tensor(0.1182, requires_grad=True) tensor(0.0322, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2529, 0.2102], grad_fn=<SliceBackward>)\n",
      "epoch 320 loss = 6.75E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[-0.0049, -0.3482,  0.3532],\n",
      "        [ 0.5121,  0.8956, -1.4077],\n",
      "        [ 0.2516,  0.0832, -0.3348]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1519, grad_fn=<StdBackward0>) tensor(0.1225, requires_grad=True) tensor(0.0273, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2549, 0.2064], grad_fn=<SliceBackward>)\n",
      "epoch 330 loss = 6.98E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[-0.0067, -0.3536,  0.3603],\n",
      "        [ 0.5072,  0.8982, -1.4055],\n",
      "        [ 0.2643,  0.0747, -0.3390]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1575, grad_fn=<StdBackward0>) tensor(0.1302, requires_grad=True) tensor(0.0290, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2622, 0.2029], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 340 loss = 6.86E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[ 7.8197e-04, -3.5995e-01,  3.5917e-01],\n",
      "        [ 5.1056e-01,  9.0611e-01, -1.4167e+00],\n",
      "        [ 2.7518e-01,  6.2478e-02, -3.3765e-01]], grad_fn=<AddBackward0>)\n",
      "types? line 100 1024\n",
      "sds: tensor(0.1528, grad_fn=<StdBackward0>) tensor(0.1245, requires_grad=True) tensor(0.0384, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2618, 0.2032], grad_fn=<SliceBackward>)\n",
      "epoch 350 loss = 6.87E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0038, -0.3565,  0.3603],\n",
      "        [ 0.5185,  0.9121, -1.4305],\n",
      "        [ 0.2707,  0.0540, -0.3248]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1721, grad_fn=<StdBackward0>) tensor(0.1291, requires_grad=True) tensor(0.0271, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2577, 0.2010], grad_fn=<SliceBackward>)\n",
      "epoch 360 loss = 6.68E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0058, -0.3452,  0.3510],\n",
      "        [ 0.5049,  0.9002, -1.4051],\n",
      "        [ 0.2741,  0.0479, -0.3220]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1519, grad_fn=<StdBackward0>) tensor(0.1264, requires_grad=True) tensor(0.0295, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2583, 0.1976], grad_fn=<SliceBackward>)\n",
      "epoch 370 loss = 6.18E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0052, -0.3442,  0.3494],\n",
      "        [ 0.5046,  0.8945, -1.3991],\n",
      "        [ 0.2756,  0.0426, -0.3182]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1834, grad_fn=<StdBackward0>) tensor(0.1449, requires_grad=True) tensor(0.0335, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2649, 0.1953], grad_fn=<SliceBackward>)\n",
      "epoch 380 loss = 6.33E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[ 0.0018, -0.3405,  0.3388],\n",
      "        [ 0.5087,  0.9030, -1.4117],\n",
      "        [ 0.2841,  0.0236, -0.3077]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1319, grad_fn=<StdBackward0>) tensor(0.1073, requires_grad=True) tensor(0.0276, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2570, 0.1929], grad_fn=<SliceBackward>)\n",
      "epoch 390 loss = 6.69E+08, mean_loss=6.69E+08;\n",
      " logitstar = tensor([[-0.0132, -0.3507,  0.3640],\n",
      "        [ 0.5035,  0.9044, -1.4078],\n",
      "        [ 0.2808,  0.0252, -0.3059]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1776, grad_fn=<StdBackward0>) tensor(0.1445, requires_grad=True) tensor(0.0343, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2558, 0.1969], grad_fn=<SliceBackward>)\n",
      "epoch 400 loss = 6.92E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0136, -0.3474,  0.3610],\n",
      "        [ 0.5050,  0.9156, -1.4206],\n",
      "        [ 0.2759,  0.0226, -0.2984]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1586, grad_fn=<StdBackward0>) tensor(0.1342, requires_grad=True) tensor(0.0301, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2604, 0.1974], grad_fn=<SliceBackward>)\n",
      "epoch 410 loss = 6.69E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[-0.0040, -0.3426,  0.3466],\n",
      "        [ 0.5188,  0.9027, -1.4215],\n",
      "        [ 0.2665,  0.0321, -0.2985]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1322, grad_fn=<StdBackward0>) tensor(0.1090, requires_grad=True) tensor(0.0269, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2572, 0.1906], grad_fn=<SliceBackward>)\n",
      "epoch 420 loss = 6.85E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0044, -0.3422,  0.3466],\n",
      "        [ 0.5179,  0.8869, -1.4048],\n",
      "        [ 0.2583,  0.0271, -0.2853]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1453, grad_fn=<StdBackward0>) tensor(0.1160, requires_grad=True) tensor(0.0302, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2587, 0.1948], grad_fn=<SliceBackward>)\n",
      "epoch 430 loss = 6.52E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0085, -0.3402,  0.3487],\n",
      "        [ 0.5061,  0.9056, -1.4116],\n",
      "        [ 0.2786,  0.0191, -0.2977]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1425, grad_fn=<StdBackward0>) tensor(0.1201, requires_grad=True) tensor(0.0300, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2622, 0.1932], grad_fn=<SliceBackward>)\n",
      "epoch 440 loss = 6.99E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0049, -0.3469,  0.3519],\n",
      "        [ 0.5057,  0.9040, -1.4097],\n",
      "        [ 0.2857,  0.0227, -0.3083]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1680, grad_fn=<StdBackward0>) tensor(0.1339, requires_grad=True) tensor(0.0328, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2662, 0.1911], grad_fn=<SliceBackward>)\n",
      "epoch 450 loss = 6.52E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0047, -0.3478,  0.3525],\n",
      "        [ 0.5145,  0.9090, -1.4235],\n",
      "        [ 0.2888,  0.0122, -0.3010]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1295, grad_fn=<StdBackward0>) tensor(0.1126, requires_grad=True) tensor(0.0255, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2719, 0.1922], grad_fn=<SliceBackward>)\n",
      "epoch 460 loss = 7.03E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0088, -0.3491,  0.3579],\n",
      "        [ 0.5088,  0.9113, -1.4201],\n",
      "        [ 0.3158,  0.0144, -0.3302]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1830, grad_fn=<StdBackward0>) tensor(0.1460, requires_grad=True) tensor(0.0433, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2744, 0.1935], grad_fn=<SliceBackward>)\n",
      "epoch 470 loss = 5.98E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0050, -0.3415,  0.3465],\n",
      "        [ 0.5068,  0.9144, -1.4212],\n",
      "        [ 0.3213,  0.0075, -0.3289]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1597, grad_fn=<StdBackward0>) tensor(0.1290, requires_grad=True) tensor(0.0293, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2712, 0.1851], grad_fn=<SliceBackward>)\n",
      "epoch 480 loss = 6.86E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0097, -0.3497,  0.3593],\n",
      "        [ 0.5018,  0.8990, -1.4008],\n",
      "        [ 0.3213,  0.0060, -0.3273]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1742, grad_fn=<StdBackward0>) tensor(0.1403, requires_grad=True) tensor(0.0310, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2684, 0.1880], grad_fn=<SliceBackward>)\n",
      "epoch 490 loss = 7.01E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0145, -0.3440,  0.3586],\n",
      "        [ 0.4974,  0.9137, -1.4111],\n",
      "        [ 0.3223, -0.0057, -0.3166]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1451, grad_fn=<StdBackward0>) tensor(0.1189, requires_grad=True) tensor(0.0286, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2798, 0.1832], grad_fn=<SliceBackward>)\n",
      "epoch 500 loss = 6.06E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0034, -0.3505,  0.3539],\n",
      "        [ 0.5114,  0.9099, -1.4213],\n",
      "        [ 0.3313, -0.0097, -0.3216]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1632, grad_fn=<StdBackward0>) tensor(0.1266, requires_grad=True) tensor(0.0291, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2794, 0.1853], grad_fn=<SliceBackward>)\n",
      "epoch 510 loss = 6.86E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0036, -0.3391,  0.3427],\n",
      "        [ 0.5017,  0.9182, -1.4199],\n",
      "        [ 0.3402, -0.0231, -0.3171]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 512\n",
      "guide:begin line 51 512\n",
      "lp:  line 51 512\n",
      "guide:end line 51 512\n",
      "model:end line 51 1024\n",
      "sds: tensor(0.1260, grad_fn=<StdBackward0>) tensor(0.1097, requires_grad=True) tensor(0.0278, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2743, 0.1834], grad_fn=<SliceBackward>)\n",
      "epoch 520 loss = 7.43E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0129, -0.3457,  0.3586],\n",
      "        [ 0.4958,  0.9203, -1.4161],\n",
      "        [ 0.3400, -0.0243, -0.3157]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 51 1 :\n",
      "     673713020.54654\n",
      "     669105059.0213786\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.2743,  0.1834],\n",
      "        [-0.2872, -0.5291],\n",
      "        [ 0.2215,  0.7369]], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "jsonizing 2\n",
      "np complete? line 1312 1 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 1 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 2 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 2 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 3 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 3 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 4 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 4 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 5 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 5 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 6 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 6 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 7 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 7 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 8 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 8 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 9 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 9 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 10 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1420 10 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1312 16\n",
      "sampleYs line 1420 16\n",
      "np complete? line 1312 32\n",
      "sampleYs line 1420 32\n",
      "np complete? line 1312 64\n",
      "sampleYs line 1420 64\n",
      "np complete? line 1312 128\n",
      "sampleYs line 1420 128\n",
      "np complete? line 1312 256\n",
      "sampleYs line 1420 256\n",
      "np complete? line 1312 512\n",
      "sampleYs line 1420 512\n",
      "denses line 1434 1 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 694 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 1 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1312 1024\n",
      "sampleYs line 1420 1024\n",
      "denses line 1434 2 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 1388 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 2 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1312 2048\n",
      "sampleYs line 1420 2048\n",
      "denses line 1434 3 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 2082 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1385 3 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1434 4 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "ei_post_results_fixedalpha/scenario_SIG0.3_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.3138, grad_fn=<StdBackward0>) tensor(0.3015, requires_grad=True) tensor(0.2748, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-45188664.1191, grad_fn=<AddBackward0>)\n",
      "     tensor(-2697.0302, grad_fn=<AddBackward0>)\n",
      "     806\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0e13c70531b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msigma_nu\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;36m.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m.02\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#.02,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m#%prun result = trainGuide(nsamps=nsamps,subsample_n=subn)#inits = inits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtrainGuide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsamps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnsamps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubsample_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigmanu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma_nu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_full\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#,inits = inits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;31m#modelQvar(sigmanu=sigma_nu)#,samps=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\ei_multisampleQ.py\u001b[0m in \u001b[0;36mtrainGuide\u001b[1;34m(subsample_n, filebase, nsteps, sigmanu, dummydata, nsamps, dversion, inits, num_y_samps, force_full)\u001b[0m\n\u001b[0;32m   1576\u001b[0m         \u001b[0mddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"svi.step(...\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindeps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1577\u001b[0m         loss = svi.step(subset,scale,True,do_print=(i % 10 == 0),nsamps=nsamps,\n\u001b[1;32m-> 1578\u001b[1;33m                 inits=inits)\n\u001b[0m\u001b[0;32m   1579\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetachRecursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#I hate memory leaks!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# get loss and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m# grab a trace from the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \"\"\"\n\u001b[0;32m     51\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[1;32m---> 52\u001b[1;33m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[1;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \"\"\"\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mguide_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[0;32m     45\u001b[0m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\ei_multisampleQ.py\u001b[0m in \u001b[0;36mguide\u001b[1;34m(data, scale, include_nuisance, do_print, inits, nsamps, icky_sigma, *args, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;31m#dp(f\"HW2:{big_HWs[p//B].size()},{list(full_indices)}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             conditional_mean, conditional_cov = big_arrow.conditional_ll_mcov(p,g_delta,\n\u001b[1;32m--> 965\u001b[1;33m                                     all_means.index_select(0,precinct_indices))\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;31m#precinct_cov = big_arrow.llinvs[p] #for Newton's method, not for sampling #TODO: This is actually the same as conditional_cov; remove?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\utilities\\arrowhead_precision.py\u001b[0m in \u001b[0;36mconditional_ll_mcov\u001b[1;34m(self, i, g_delta, l_mean)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m#combined_gg = self._mgg + torch.mm(torch.mm(gl,llinv),gl.t())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         new_mean = l_mean - torch.mv(torch.mm(llinv,gl.t()),\n\u001b[0m\u001b[0;32m    145\u001b[0m                                             g_delta)\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mllinv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei_multisampleQ #import *\n",
    "reload(ei_multisampleQ)\n",
    "from ei_multisampleQ import *\n",
    "import cProfile as profile\n",
    "\n",
    "#ec,erc = legible_values(3,3)\n",
    "#print(ec,\"\\n\",erc,\"\\n\",ec+erc)\n",
    "#inits = good_inits(1.)\n",
    "#del inits[\"ercstar_raw\"]\n",
    "for (nsamps,subn) in [(15,100)]:#[(2,60),(5,60),(2,30),(20,30),(40,5)]:\n",
    "    \n",
    "    for i in range(4):\n",
    "        for sigma_nu in [ .3,.1,  .02,]: #.02, \n",
    "            #%prun result = trainGuide(nsamps=nsamps,subsample_n=subn)#inits = inits)\n",
    "            trainGuide(nsamps=nsamps,subsample_n=subn,sigmanu=sigma_nu,dversion=i, force_full=True)#,inits = inits)\n",
    "            #modelQvar(sigmanu=sigma_nu)#,samps=5)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 3 :\n",
      "Reloading polytopize.\n",
      "tensor([[ 0.0500, -0.9100,  1.2200],\n",
      "        [ 0.2100,  0.0100, -0.9500],\n",
      "        [ 0.3400, -0.5400,  0.5800]])\n",
      "0.15\n",
      "0.15\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei_multisample #import *\n",
    "reload(ei_multisample)\n",
    "from ei_multisample import *\n",
    "import cProfile as profile\n",
    "\n",
    "inits = dict() #good_inits()\n",
    "#del inits[\"ercstar_raw\"]\n",
    "#%prun result = trainGuide(inits = inits)\n",
    "\n",
    "NCparams = EIData.load(\"NC_Data/NC_2016_statewide_alpha_and_beta.csv\")\n",
    "print(NCparams.alpha + NCparams.beta)\n",
    "#print(\"components\")\n",
    "#print(NCparams.alpha)\n",
    "#\n",
    "#print(NCparams.beta)\n",
    "print(SIM_SIGMA_NU)\n",
    "SIM_SIGMA_NU = 0.001\n",
    "print(ei_multisample.SIM_SIGMA_NU)\n",
    "ei_multisample.SIM_SIGMA_NU = .0001\n",
    "print(ei_multisample.SIM_SIGMA_NU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hessian transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hess tensor([[6., 0., 0., 0.],\n",
      "        [0., 6., 0., 0.],\n",
      "        [0., 0., 6., 0.],\n",
      "        [0., 0., 0., 6.]], grad_fn=<CopySlices>)\n",
      "d  tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "d  tensor(12., grad_fn=<SumBackward0>)\n",
      "ddd  (tensor([[6., 6.],\n",
      "        [6., 6.]]),)\n",
      "(tensor([[72., 72.],\n",
      "        [72., 72.]]),)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ts = torch.tensor\n",
    "os = torch.ones\n",
    "zs = torch.zeros\n",
    "from importlib import reload\n",
    "import myhessian\n",
    "reload(myhessian)\n",
    "\n",
    "t1 = os(2,2,requires_grad=True)\n",
    "r = torch.sum(t1 * t1 * t1)\n",
    "\n",
    "h = myhessian.hessian(r,t1)\n",
    "print(\"hess\",h)\n",
    "r2 = torch.sum(h * h)\n",
    "[r3] = torch.autograd.grad(r,t1,create_graph=True,retain_graph=True)\n",
    "print(\"d \",r3)\n",
    "print(\"d \",torch.sum(r3))\n",
    "[r4] = torch.autograd.grad(torch.sum(r3),t1,create_graph=True,retain_graph=True)\n",
    "print(\"ddd \",torch.autograd.grad(torch.sum(r4),t1,create_graph=True,retain_graph=True))\n",
    "print(torch.autograd.grad(r2,t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I will run.\n",
      "Yes, I will run.\n",
      "ge fail\n",
      "loc tensor([[ 0.3147],\n",
      "        [ 2.4440],\n",
      "        [-4.0535],\n",
      "        [ 2.2007]])\n",
      "polytopedLoc tensor([[ 2.1063e-01,  2.1136e-02],\n",
      "        [ 2.8514e-01, -1.8626e-09],\n",
      "        [ 3.4959e-01,  9.9957e-02],\n",
      "        [ 3.5462e-01,  1.1892e-02],\n",
      "        [ 2.5462e+00,  3.2228e-01]])\n",
      "ge fail\n",
      "loc tensor([[-5.8855],\n",
      "        [-5.2805],\n",
      "        [ 5.4654],\n",
      "        [ 0.1889]])\n",
      "polytopedLoc tensor([[ 2.8885e-01,  1.1871e+00],\n",
      "        [ 8.5629e-01,  2.0505e+00],\n",
      "        [ 3.9984e-01, -1.4901e-08],\n",
      "        [ 9.5542e-01,  1.5538e+00],\n",
      "        [ 1.0063e+00,  9.9522e-01]])\n",
      "Reloading cmult...\n",
      "callable? <bound method TorchDistributionMixin.__call__ of Multinomial()>\n",
      "callable? <bound method TorchDistributionMixin.__call__ of TorchCMult()>\n",
      "Sampling multinomial: tensor([1., 2.])\n",
      "Sampling cm2: tensor([0., 3.])\n",
      "tensor(5.6022, grad_fn=<NegBackward>) tensor([[112.2500]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hessian\n",
    "\n",
    "from importlib import reload\n",
    "import polytopize #import *\n",
    "reload(polytopize)\n",
    "from polytopize import *\n",
    "\n",
    "import tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test rank1torch (to get yhat from pi,n,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimize_Q (50 tests): \n",
      "R=3, C=5, tolerance=0.001\n",
      "==================================================\n",
      "Oh no! In test 3, Q has some negative entries:\n",
      "\t trueQ[2][4]=0.00010659269901225343, \n",
      "\t     Q[2][4]=-0.00021605131041724235\n",
      "Oh no! In test 5, Q has some negative entries:\n",
      "\t trueQ[1][4]=0.00011974151857430115, \n",
      "\t     Q[1][4]=-1.1631345842033625e-06\n",
      "Oh no! In test 8, Q has some negative entries:\n",
      "\t trueQ[0][1]=2.882161788875237e-05, \n",
      "\t     Q[0][1]=-0.0004783869662787765\n",
      "Oh no! In test 15, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.0007846675580367446, \n",
      "\t     Q[2][3]=-6.166117964312434e-05\n",
      "Oh no! In test 28, Q has some negative entries:\n",
      "\t trueQ[0][4]=8.13114020274952e-05, \n",
      "\t     Q[0][4]=-0.00018321917741559446\n",
      "Oh no! In test 40, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.00032634526723995805, \n",
      "\t     Q[2][3]=-0.000617634505033493\n",
      "Oh no! In test 47, Q has some negative entries:\n",
      "\t trueQ[2][1]=0.00017936740186996758, \n",
      "\t     Q[2][1]=-0.00041433278238400817\n",
      "Oh no! In test 48, Q has some negative entries:\n",
      "\t trueQ[0][0]=4.524858377408236e-05, \n",
      "\t     Q[0][0]=-0.0006647921400144696\n",
      "\n",
      "Cumulative results for the 50 tests \n",
      "(R=3, C=5, tolerance=0.001):\n",
      "-------------------------------------------\n",
      "Worst error in entry of Q: 0.0019194334745407104\n",
      "\n",
      "To get within tolerance, it took us:\n",
      "002 iterations: ***** 5.0 times\n",
      "003 iterations: ********** 10.0 times\n",
      "004 iterations: *********** 11.0 times\n",
      "005 iterations: ****** 6.0 times\n",
      "006 iterations: **** 4.0 times\n",
      "007 iterations: **** 4.0 times\n",
      "008 iterations: ****** 6.0 times\n",
      "010 iterations: *** 3.0 times\n",
      "013 iterations: * 1.0 times\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import rank1torch #import *\n",
    "reload(rank1torch)\n",
    "from rank1torch import *\n",
    "\n",
    "test_solver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Most SVI problems in pyro are coded as a model, a generic guide (such as: multivariate Gaussian in all parameters), and specific observations/data (passed as arguments to svi.step). For EI, that's going to be different; the observations are going to be built into the guide function, leaving nothing to include in the \"data\" argument to svi.step.\n",
    "\n",
    "That means there is a lot of work for the guide to do. As usual, it must establish reasonable distributional families for the posterior of each of the hyperparameters. But for the latent parameters, the job of the guide is to take a \"relative strength\" number for each race/candidate/precinct combo, and turn that into a number of votes for each combo, such that those numbers obey all the constraints set by observations. This means that for each precinct (considered separately), the latent guide must:\n",
    "\n",
    "-Find the \"center point\" where candidate preference is independent of race.\n",
    "\n",
    "-Find the \"basis vectors\" (actually, there are more than enough of them to form a basis) which determine the directions to move in the space.\n",
    "\n",
    "-For any given set of \"relative strengths\" which is a distance $d$ in a direction $\\theta$, find the first constraint violated when moving in that direction, and the distance $r$ between the origin and that constraint.\n",
    "\n",
    "-Project the \"relative strengths\" onto the numbers of votes, by moving $r(1-e^{-d})$ in direction $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a = zs(2,2,2,2)\n",
    "a[0,1,1,1] = 2\n",
    "print(a[1,1])\n",
    "print(a[0,1])\n",
    "print(torch.max(a))\n",
    "print(torch.distributions.exponential.Exponential(ts([1])).sample(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
