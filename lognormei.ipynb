{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "This is a jupyter notebook for testing / coding. So far, each code block is a separate test; unlike an ordinary notebook, they are not meant to run sequentially.\n",
    "\n",
    "First, test to see jupyter is running correctly at all:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi!!!\n",
      "hi!!!\n",
      "hi!!!\n",
      "hi!!!\n",
      "hi!!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"hi!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, running \"toypyro\". This started out as a copy of Fritz's code but I hope it evolves into a working version of ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I will run.\n",
      "Reloading polytopize.\n",
      "ec:tensor([0.0000, 0.5000, 0.0000])\n",
      "erc:tensor([[0., 1., 2.],\n",
      "        [2., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "y[0]:tensor([[ 25., 171., 237.],\n",
      "        [238.,  50.,  34.],\n",
      "        [ 69.,  80.,  58.],\n",
      "        [ 21.,  42.,  25.]])\n",
      "ps2\n",
      "epoch 0 loss = 20420.983406424522; logsdrchat = 1.9950000047683716;\n",
      " erchat = tensor([[ 0.0050,  0.0050, -0.0050],\n",
      "        [-0.0050, -0.0050,  0.0050],\n",
      "        [-0.0050, -0.0050,  0.0050],\n",
      "        [-0.0050, -0.0050,  0.0050]], requires_grad=True)\n",
      " pnsml = 0.004999999422580004\n",
      "ps2\n",
      "epoch 10 loss = 19987.858937621117; logsdrchat = 1.9450000524520874;\n",
      " erchat = tensor([[ 0.0091, -0.0092, -0.0091],\n",
      "        [-0.0024, -0.0010,  0.0024],\n",
      "        [-0.0174,  0.0050,  0.0132],\n",
      "        [-0.0550, -0.0550,  0.0550]], requires_grad=True)\n",
      " pnsml = 0.05499999225139618\n",
      "ps2\n",
      "epoch 20 loss = 17995.230388998985; logsdrchat = 1.8950001001358032;\n",
      " erchat = tensor([[ 0.0340,  0.0075, -0.0340],\n",
      "        [ 0.0188,  0.0209, -0.0257],\n",
      "        [-0.0050,  0.0225, -0.0063],\n",
      "        [-0.1050, -0.1050,  0.1050]], requires_grad=True)\n",
      " pnsml = 0.10499996691942215\n",
      "ps2\n",
      "epoch 30 loss = 15913.31238424778; logsdrchat = 1.845000147819519;\n",
      " erchat = tensor([[ 0.0765,  0.0475, -0.0765],\n",
      "        [ 0.0593,  0.0561, -0.0649],\n",
      "        [ 0.0233,  0.0514, -0.0384],\n",
      "        [-0.1550, -0.1550,  0.1550]], requires_grad=True)\n",
      " pnsml = 0.15499994158744812\n",
      "ps2\n",
      "epoch 40 loss = 13938.776213407516; logsdrchat = 1.7950001955032349;\n",
      " erchat = tensor([[ 0.1240,  0.0942, -0.1240],\n",
      "        [ 0.1061,  0.0987, -0.1088],\n",
      "        [ 0.0604,  0.0862, -0.0743],\n",
      "        [-0.2050, -0.2050,  0.2050]], requires_grad=True)\n",
      " pnsml = 0.2049998939037323\n",
      "ps2\n",
      "epoch 50 loss = 12272.483421385288; logsdrchat = 1.7450002431869507;\n",
      " erchat = tensor([[ 0.1732,  0.1431, -0.1732],\n",
      "        [ 0.1550,  0.1462, -0.1567],\n",
      "        [ 0.1060,  0.1210, -0.1147],\n",
      "        [-0.2550, -0.2550,  0.2550]], requires_grad=True)\n",
      " pnsml = 0.2549998462200165\n",
      "ps2\n",
      "epoch 60 loss = 10555.839492321014; logsdrchat = 1.6950002908706665;\n",
      " erchat = tensor([[ 0.2229,  0.1927, -0.2229],\n",
      "        [ 0.2046,  0.1891, -0.1998],\n",
      "        [ 0.1504,  0.1585, -0.1554],\n",
      "        [-0.3050, -0.3050,  0.3050]], requires_grad=True)\n",
      " pnsml = 0.30499979853630066\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei #import *\n",
    "reload(ei)\n",
    "from ei import *\n",
    "import cProfile as profile\n",
    "\n",
    "%prun result = trainGuide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run \"polytopize\", which has all of my pre-Fritz attempts to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echat:\n",
      "tensor([ 0.2325, -0.3407,  0.3230], requires_grad=True)\n",
      "erchat:\n",
      "tensor([[-0.0440, -0.0448,  0.1284],\n",
      "        [-0.0490, -0.0334,  0.1120],\n",
      "        [-0.0486, -0.0243,  0.0850],\n",
      "        [-0.0567, -0.0134,  0.0715]], requires_grad=True)\n",
      "globalpsi:\n",
      "tensor([0.0116, 0.0103, 0.0103, 0.0103, 0.0103, 0.0097, 0.0097, 0.0103, 0.0097,\n",
      "        0.0103, 0.0097, 0.0103, 0.0097, 0.0103, 0.0103, 0.0097],\n",
      "       grad_fn=<AddBackward0>)\n",
      "logsdrchat:\n",
      "-3.1609883308410645\n",
      "precinctpsi:\n",
      "tensor([0.0010, 0.0023, 0.0028, 0.0030, 0.0031, 0.0037],\n",
      "       grad_fn=<AddBackward0>)\n",
      "what_0:\n",
      "tensor([[-0.3764, -0.7578],\n",
      "        [-0.0823,  0.0420],\n",
      "        [ 0.0860,  0.2053]], requires_grad=True)\n",
      "what_1:\n",
      "tensor([[-0.4335, -0.9360],\n",
      "        [-0.1274, -0.0898],\n",
      "        [ 0.0445,  0.1291]], requires_grad=True)\n",
      "what_10:\n",
      "tensor([[-0.5429, -1.4944],\n",
      "        [-0.2548, -0.4453],\n",
      "        [-0.1268, -0.1337]], requires_grad=True)\n",
      "what_11:\n",
      "tensor([[-0.5426, -1.5142],\n",
      "        [-0.2566, -0.4580],\n",
      "        [-0.1367, -0.1516]], requires_grad=True)\n",
      "what_12:\n",
      "tensor([[-0.5500, -1.5297],\n",
      "        [-0.2677, -0.4727],\n",
      "        [-0.1482, -0.1624]], requires_grad=True)\n",
      "what_13:\n",
      "tensor([[-0.5487, -1.5444],\n",
      "        [-0.2768, -0.4859],\n",
      "        [-0.1556, -0.1675]], requires_grad=True)\n",
      "what_14:\n",
      "tensor([[-0.5613, -1.5378],\n",
      "        [-0.2790, -0.4802],\n",
      "        [-0.1672, -0.1669]], requires_grad=True)\n",
      "what_15:\n",
      "tensor([[-0.5573, -1.5768],\n",
      "        [-0.2793, -0.5079],\n",
      "        [-0.1586, -0.1812]], requires_grad=True)\n",
      "what_16:\n",
      "tensor([[-0.5658, -1.5756],\n",
      "        [-0.2871, -0.5023],\n",
      "        [-0.1763, -0.1884]], requires_grad=True)\n",
      "what_17:\n",
      "tensor([[-0.5605, -1.5844],\n",
      "        [-0.2880, -0.5201],\n",
      "        [-0.1745, -0.1947]], requires_grad=True)\n",
      "what_18:\n",
      "tensor([[-0.5670, -1.5898],\n",
      "        [-0.2922, -0.5195],\n",
      "        [-0.1853, -0.1984]], requires_grad=True)\n",
      "what_19:\n",
      "tensor([[-0.5668, -1.6073],\n",
      "        [-0.2923, -0.5324],\n",
      "        [-0.1851, -0.2088]], requires_grad=True)\n",
      "what_2:\n",
      "tensor([[-0.4496, -1.1027],\n",
      "        [-0.1434, -0.1717],\n",
      "        [ 0.0311,  0.0826]], requires_grad=True)\n",
      "what_20:\n",
      "tensor([[-0.5749, -1.5886],\n",
      "        [-0.3004, -0.5337],\n",
      "        [-0.1948, -0.2113]], requires_grad=True)\n",
      "what_21:\n",
      "tensor([[-0.5662, -1.5963],\n",
      "        [-0.2950, -0.5376],\n",
      "        [-0.1929, -0.2156]], requires_grad=True)\n",
      "what_22:\n",
      "tensor([[-0.5719, -1.6033],\n",
      "        [-0.3015, -0.5465],\n",
      "        [-0.1969, -0.2207]], requires_grad=True)\n",
      "what_23:\n",
      "tensor([[-0.5730, -1.6178],\n",
      "        [-0.3035, -0.5471],\n",
      "        [-0.1990, -0.2209]], requires_grad=True)\n",
      "what_24:\n",
      "tensor([[-0.5648, -1.6084],\n",
      "        [-0.3039, -0.5486],\n",
      "        [-0.2003, -0.2236]], requires_grad=True)\n",
      "what_25:\n",
      "tensor([[-0.5788, -1.6413],\n",
      "        [-0.3077, -0.5559],\n",
      "        [-0.2076, -0.2281]], requires_grad=True)\n",
      "what_26:\n",
      "tensor([[-0.5721, -1.6315],\n",
      "        [-0.3114, -0.5614],\n",
      "        [-0.2089, -0.2308]], requires_grad=True)\n",
      "what_27:\n",
      "tensor([[-0.5783, -1.6350],\n",
      "        [-0.3128, -0.5636],\n",
      "        [-0.2113, -0.2327]], requires_grad=True)\n",
      "what_28:\n",
      "tensor([[-0.5783, -1.6306],\n",
      "        [-0.3155, -0.5608],\n",
      "        [-0.2155, -0.2328]], requires_grad=True)\n",
      "what_29:\n",
      "tensor([[-0.5736, -1.6409],\n",
      "        [-0.3163, -0.5718],\n",
      "        [-0.2123, -0.2375]], requires_grad=True)\n",
      "what_3:\n",
      "tensor([[-0.4694, -1.2148],\n",
      "        [-0.1658, -0.2361],\n",
      "        [-0.0096,  0.0295]], requires_grad=True)\n",
      "what_4:\n",
      "tensor([[-0.4828, -1.2900],\n",
      "        [-0.1844, -0.2978],\n",
      "        [-0.0261, -0.0146]], requires_grad=True)\n",
      "what_5:\n",
      "tensor([[-0.5027, -1.3526],\n",
      "        [-0.2033, -0.3333],\n",
      "        [-0.0667, -0.0539]], requires_grad=True)\n",
      "what_6:\n",
      "tensor([[-0.5270, -1.3855],\n",
      "        [-0.2244, -0.3561],\n",
      "        [-0.0855, -0.0666]], requires_grad=True)\n",
      "what_7:\n",
      "tensor([[-0.5254, -1.4090],\n",
      "        [-0.2271, -0.3789],\n",
      "        [-0.0950, -0.0875]], requires_grad=True)\n",
      "what_8:\n",
      "tensor([[-0.5396, -1.4520],\n",
      "        [-0.2406, -0.4042],\n",
      "        [-0.1128, -0.1037]], requires_grad=True)\n",
      "what_9:\n",
      "tensor([[-0.5372, -1.4922],\n",
      "        [-0.2439, -0.4274],\n",
      "        [-0.1219, -0.1270]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pyroStore = pyro.get_param_store()\n",
    "for (key, val) in sorted(pyroStore.items()):\n",
    "    print(f\"{key}:\\n{val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3764, -0.7578],\n",
      "        [-0.0823,  0.0420],\n",
      "        [ 0.0860,  0.2053]], requires_grad=True)\n",
      "tensor([[-0.0440, -0.0448,  0.1284],\n",
      "        [-0.0490, -0.0334,  0.1120],\n",
      "        [-0.0486, -0.0243,  0.0850],\n",
      "        [-0.0567, -0.0134,  0.0715]], requires_grad=True)\n",
      "tensor([[ 0.0031, -0.0173,  0.0341],\n",
      "        [-0.0019, -0.0059,  0.0177],\n",
      "        [-0.0015,  0.0032, -0.0093],\n",
      "        [-0.0096,  0.0141, -0.0227]], grad_fn=<SubBackward0>)\n",
      "tensor(-3.1610, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "yhat1 = polytopize(4,3,pyro.get_param_store()[\"what_0\"],\n",
    "                 get_indep(4,3,ts([68.,20,25,56]),ts([63.,32,74])))\n",
    "\n",
    "erchat = pyro.get_param_store()[\"erchat\"]\n",
    "\n",
    "print(pyro.get_param_store()[\"what_0\"])\n",
    "print(erchat)\n",
    "print(recenter_rc(erchat))\n",
    "print(pyro.get_param_store()[\"logsdrchat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats(runstats)\n",
    "p.strip_dirs().sort_stats(-1).print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I will run.\n",
      "Yes, I will run.\n",
      "ge fail\n",
      "loc tensor([[ 0.3147],\n",
      "        [ 2.4440],\n",
      "        [-4.0535],\n",
      "        [ 2.2007]])\n",
      "polytopedLoc tensor([[ 2.1063e-01,  2.1136e-02],\n",
      "        [ 2.8514e-01, -1.8626e-09],\n",
      "        [ 3.4959e-01,  9.9957e-02],\n",
      "        [ 3.5462e-01,  1.1892e-02],\n",
      "        [ 2.5462e+00,  3.2228e-01]])\n",
      "ge fail\n",
      "loc tensor([[-5.8855],\n",
      "        [-5.2805],\n",
      "        [ 5.4654],\n",
      "        [ 0.1889]])\n",
      "polytopedLoc tensor([[ 2.8885e-01,  1.1871e+00],\n",
      "        [ 8.5629e-01,  2.0505e+00],\n",
      "        [ 3.9984e-01, -1.4901e-08],\n",
      "        [ 9.5542e-01,  1.5538e+00],\n",
      "        [ 1.0063e+00,  9.9522e-01]])\n",
      "Reloading cmult...\n",
      "callable? <bound method TorchDistributionMixin.__call__ of Multinomial()>\n",
      "callable? <bound method TorchDistributionMixin.__call__ of TorchCMult()>\n",
      "Sampling multinomial: tensor([1., 2.])\n",
      "Sampling cm2: tensor([0., 3.])\n",
      "tensor(5.6022, grad_fn=<NegBackward>) tensor([[112.2500]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hessian\n",
    "\n",
    "from importlib import reload\n",
    "import polytopize #import *\n",
    "reload(polytopize)\n",
    "from polytopize import *\n",
    "\n",
    "import tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc2\n",
    "\n",
    "result = polytopize(R,C,loc2,indep)\n",
    "\n",
    "loc3 = depolytopize(R,C,result,indep)\n",
    "\n",
    "print(loc2)\n",
    "print(result-indep)\n",
    "print(loc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this is a cell for directly experimenting with pytorch and/or pyro. Basically, for getting the tensor syntax right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cmult\n",
    "import pyro\n",
    "from importlib import reload\n",
    "reload(cmult)\n",
    "from cmult import CMult\n",
    "\n",
    "#print(CMult(probs=torch.tensor([1., 1., 1., 1.])).log_prob(torch.tensor([1.2, 1.5, 1., 1.])))\n",
    "\n",
    "#print(CMult(100, torch.tensor([ 1., 1., 1., 1.])).sample())\n",
    "\n",
    "R, C = (3,4)\n",
    "\n",
    "y = pyro.distributions.Normal(0.,4.).sample(torch.Size([R-1,C-1]))\n",
    "\n",
    "\n",
    "w = torch.cat((y,-y.sum(1).unsqueeze(1)),1)\n",
    "w = torch.cat((w,-w.sum(0).unsqueeze(0)),0)\n",
    "\n",
    "#print(w)\n",
    "b = w.argmax()\n",
    "print(b)\n",
    "print(w,w[b//C,b % C])\n",
    "\n",
    "tt = torch.zeros(R,C)\n",
    "print(tt,R,C,tt[:(R-1),:(C-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Most SVI problems in pyro are coded as a model, a generic guide (such as: multivariate Gaussian in all parameters), and specific observations/data (passed as arguments to svi.step). For EI, that's going to be different; the observations are going to be built into the guide function, leaving nothing to include in the \"data\" argument to svi.step.\n",
    "\n",
    "That means there is a lot of work for the guide to do. As usual, it must establish reasonable distributional families for the posterior of each of the hyperparameters. But for the latent parameters, the job of the guide is to take a \"relative strength\" number for each race/candidate/precinct combo, and turn that into a number of votes for each combo, such that those numbers obey all the constraints set by observations. This means that for each precinct (considered separately), the latent guide must:\n",
    "\n",
    "-Find the \"center point\" where candidate preference is independent of race.\n",
    "\n",
    "-Find the \"basis vectors\" (actually, there are more than enough of them to form a basis) which determine the directions to move in the space.\n",
    "\n",
    "-For any given set of \"relative strengths\" which is a distance $d$ in a direction $\\theta$, find the first constraint violated when moving in that direction, and the distance $r$ between the origin and that constraint.\n",
    "\n",
    "-Project the \"relative strengths\" onto the numbers of votes, by moving $r(1-e^{-d})$ in direction $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a = zs(2,2,2,2)\n",
    "a[0,1,1,1] = 2\n",
    "print(a[1,1])\n",
    "print(a[0,1])\n",
    "print(torch.max(a))\n",
    "print(torch.distributions.exponential.Exponential(ts([1])).sample(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\",\"world\")\n",
    "a = zs(2,2,2,2)\n",
    "a[0,1,1,1] = 2 \n",
    "print(torch.max(a[0,1])) \n",
    "print(pyro.distributions.Exponential(1.).sample(torch.Size([3])))\n",
    "a.add_(torch.ones(2,2,2))\n",
    "print(torch.exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
