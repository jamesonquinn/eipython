{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "This is a jupyter notebook for testing / coding. So far, each code block is a separate test; unlike an ordinary notebook, they are not meant to run sequentially.\n",
    "\n",
    "Let's do MCMC:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, running \"ei\". This started out as a copy of Fritz's code but it's evolved into a working version of ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 1 :\n",
      "Reloading cmult...\n",
      "Reloading polytopize.\n",
      "Reloading polytopize.\n",
      "base:Yes, I will run. line 5 2 :\n",
      "Reloading polytopize.\n",
      "eiresults/scenario_SIG0.1_0_N2774.csv from file\n",
      "svi.step(... line 41 1 : 0 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 1 : 55.48 True\n",
      "types? line 100 1 : [torch.float64, torch.float64]\n",
      "types? line 100 2 : [torch.float64, torch.float64]\n",
      "types? line 100 3 : [torch.float64, torch.float64]\n",
      "sds: tensor(0.5966, grad_fn=<StdBackward0>) tensor(0.6011, grad_fn=<AddBackward0>) tensor(0.5603, grad_fn=<StdBackward0>)\n",
      "model:end line 41 1 :\n",
      "lp:  line 41 1 : tensor(-52960512.1959, grad_fn=<AddBackward0>) tensor(-1247.0594, grad_fn=<AddBackward0>) 780\n",
      "ps2\n",
      "guide:end line 41 1 :\n",
      "model:end line 41 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 9.65E+08, mean_loss=9.65E+08;\n",
      " logitstar = tensor([[-0.0100, -0.0100,  0.0200],\n",
      "        [-0.0100, -0.0100,  0.0200],\n",
      "        [ 0.0050,  0.0050, -0.0100]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 2 : 1 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 2 : 55.48 True\n",
      "types? line 100 4 : [torch.float64, torch.float64]\n",
      "types? line 100 5 : [torch.float64, torch.float64]\n",
      "types? line 100 6 : [torch.float64, torch.float64]\n",
      "model:end line 41 3 :\n",
      "lp:  line 41 2 : tensor(-41233719.9899, grad_fn=<AddBackward0>) tensor(-875.0885, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 2 :\n",
      "model:end line 41 4 :\n",
      "svi.step(... line 41 3 : 2 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 3 : 55.48 True\n",
      "types? line 100 7 : [torch.float64, torch.float64]\n",
      "types? line 100 8 : [torch.float64, torch.float64]\n",
      "types? line 100 9 : [torch.float64, torch.float64]\n",
      "model:end line 41 5 :\n",
      "lp:  line 41 3 : tensor(-45927784.9969, grad_fn=<AddBackward0>) tensor(-733.3174, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 3 :\n",
      "model:end line 41 6 :\n",
      "svi.step(... line 41 4 : 3 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 4 : 55.48 True\n",
      "types? line 100 10 : [torch.float64, torch.float64]\n",
      "model:end line 41 7 :\n",
      "lp:  line 41 4 : tensor(-43616539.1370, grad_fn=<AddBackward0>) tensor(-715.4783, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 4 :\n",
      "model:end line 41 8 :\n",
      "svi.step(... line 41 5 : 4 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 5 : 55.48 True\n",
      "model:end line 41 9 :\n",
      "lp:  line 41 5 : tensor(-45611943.3479, grad_fn=<AddBackward0>) tensor(-745.6564, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 5 :\n",
      "model:end line 41 10 :\n",
      "svi.step(... line 41 6 : 5 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 6 : 55.48 True\n",
      "types? line 100 16\n",
      "lp:  line 41 6 : tensor(-43938895.2600, grad_fn=<AddBackward0>) tensor(-744.2587, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 6 :\n",
      "svi.step(... line 41 7 : 6 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 7 : 55.48 True\n",
      "lp:  line 41 7 : tensor(-42521134.6273, grad_fn=<AddBackward0>) tensor(-777.5822, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 7 :\n",
      "svi.step(... line 41 8 : 7 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 8 : 55.48 True\n",
      "lp:  line 41 8 : tensor(-40798922.9083, grad_fn=<AddBackward0>) tensor(-876.7121, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 8 :\n",
      "model:end line 41 16\n",
      "svi.step(... line 41 9 : 8 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 9 : 55.48 True\n",
      "lp:  line 41 9 : tensor(-46086961.0328, grad_fn=<AddBackward0>) tensor(-948.7236, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 9 :\n",
      "svi.step(... line 41 10 : 9 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 10 : 55.48 True\n",
      "lp:  line 41 10 : tensor(-37731599.5364, grad_fn=<AddBackward0>) tensor(-1038.0501, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.5259, grad_fn=<StdBackward0>) tensor(0.5308, grad_fn=<AddBackward0>) tensor(0.4857, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0550, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 8.48E+08, mean_loss=9.47E+08;\n",
      " logitstar = tensor([[-0.0516, -0.0516,  0.1031],\n",
      "        [-0.0544, -0.0489,  0.1033],\n",
      "        [-0.0590, -0.0646,  0.1236]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 16\n",
      "guide:begin line 41 16\n",
      "lp:  line 41 16\n",
      "guide:end line 41 16\n",
      "model:end line 41 32\n",
      "sds: tensor(0.5241, grad_fn=<StdBackward0>) tensor(0.5294, grad_fn=<AddBackward0>) tensor(0.4692, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1050, -0.1050], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 8.45E+08, mean_loss=9.32E+08;\n",
      " logitstar = tensor([[-0.1036, -0.1036,  0.2073],\n",
      "        [-0.1131, -0.1022,  0.2153],\n",
      "        [-0.0982, -0.1091,  0.2074]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.4834, grad_fn=<StdBackward0>) tensor(0.4881, grad_fn=<AddBackward0>) tensor(0.4305, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1550, -0.1550], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 8.59E+08, mean_loss=9.19E+08;\n",
      " logitstar = tensor([[-0.1454, -0.1411,  0.2864],\n",
      "        [-0.1725, -0.1549,  0.3273],\n",
      "        [-0.1472, -0.1691,  0.3162]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 32\n",
      "guide:begin line 41 32\n",
      "lp:  line 41 32\n",
      "guide:end line 41 32\n",
      "model:end line 41 64\n",
      "sds: tensor(0.4283, grad_fn=<StdBackward0>) tensor(0.4228, grad_fn=<AddBackward0>) tensor(0.3719, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.2050, -0.2050], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 8.41E+08, mean_loss=9.05E+08;\n",
      " logitstar = tensor([[-0.2081, -0.1998,  0.4079],\n",
      "        [-0.2162, -0.1988,  0.4150],\n",
      "        [-0.1907, -0.2164,  0.4071]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.3781, grad_fn=<StdBackward0>) tensor(0.3620, grad_fn=<AddBackward0>) tensor(0.3169, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.2446, -0.2550], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.84E+08, mean_loss=8.95E+08;\n",
      " logitstar = tensor([[-0.2711, -0.2666,  0.5378],\n",
      "        [-0.2507, -0.2427,  0.4934],\n",
      "        [-0.2121, -0.2557,  0.4678]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3540, grad_fn=<StdBackward0>) tensor(0.3429, grad_fn=<AddBackward0>) tensor(0.2973, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.2403, -0.3050], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 1.00E+09, mean_loss=8.89E+08;\n",
      " logitstar = tensor([[-0.2556, -0.3181,  0.5737],\n",
      "        [-0.2309, -0.2679,  0.4988],\n",
      "        [-0.2344, -0.3290,  0.5633]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 64\n",
      "guide:begin line 41 64\n",
      "lp:  line 41 64\n",
      "guide:end line 41 64\n",
      "model:end line 41 128\n",
      "sds: tensor(0.3353, grad_fn=<StdBackward0>) tensor(0.3128, grad_fn=<AddBackward0>) tensor(0.2672, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.2062, -0.3550], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 9.04E+08, mean_loss=8.79E+08;\n",
      " logitstar = tensor([[-0.2151, -0.3985,  0.6136],\n",
      "        [-0.1901, -0.3025,  0.4926],\n",
      "        [-0.2133, -0.3640,  0.5774]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3021, grad_fn=<StdBackward0>) tensor(0.2857, grad_fn=<AddBackward0>) tensor(0.2498, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1728, -0.4050], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 8.33E+08, mean_loss=8.69E+08;\n",
      " logitstar = tensor([[-0.2085, -0.4916,  0.7001],\n",
      "        [-0.1341, -0.3228,  0.4569],\n",
      "        [-0.1759, -0.4006,  0.5765]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.2750, grad_fn=<StdBackward0>) tensor(0.2554, grad_fn=<AddBackward0>) tensor(0.2267, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1432, -0.4550], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 7.80E+08, mean_loss=8.62E+08;\n",
      " logitstar = tensor([[-0.2173, -0.5892,  0.8065],\n",
      "        [-0.0640, -0.3370,  0.4010],\n",
      "        [-0.1482, -0.4388,  0.5871]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2230, grad_fn=<StdBackward0>) tensor(0.2055, grad_fn=<AddBackward0>) tensor(0.1712, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1007, -0.4865], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 8.44E+08, mean_loss=8.49E+08;\n",
      " logitstar = tensor([[-0.1888, -0.6698,  0.8586],\n",
      "        [ 0.0252, -0.3252,  0.3000],\n",
      "        [-0.1384, -0.4644,  0.6028]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2281, grad_fn=<StdBackward0>) tensor(0.2055, grad_fn=<AddBackward0>) tensor(0.1754, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0533, -0.4943], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 7.79E+08, mean_loss=8.35E+08;\n",
      " logitstar = tensor([[-0.1652, -0.7274,  0.8926],\n",
      "        [ 0.1204, -0.2854,  0.1650],\n",
      "        [-0.1150, -0.4701,  0.5852]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds: tensor(0.1837, grad_fn=<StdBackward0>) tensor(0.1653, grad_fn=<AddBackward0>) tensor(0.1325, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0134, -0.4862], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 7.33E+08, mean_loss=8.21E+08;\n",
      " logitstar = tensor([[-0.1556, -0.7691,  0.9248],\n",
      "        [ 0.2040, -0.2281,  0.0241],\n",
      "        [-0.0886, -0.4613,  0.5499]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 128\n",
      "guide:begin line 41 128\n",
      "lp:  line 41 128\n",
      "guide:end line 41 128\n",
      "model:end line 41 256\n",
      "sds: tensor(0.1843, grad_fn=<StdBackward0>) tensor(0.1656, grad_fn=<AddBackward0>) tensor(0.1268, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0235, -0.4761], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 7.80E+08, mean_loss=8.08E+08;\n",
      " logitstar = tensor([[-0.1469, -0.8090,  0.9559],\n",
      "        [ 0.2888, -0.1683, -0.1205],\n",
      "        [-0.0713, -0.4510,  0.5222]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1470, grad_fn=<StdBackward0>) tensor(0.1189, grad_fn=<AddBackward0>) tensor(0.0787, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0622, -0.4701], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 7.55E+08, mean_loss=7.99E+08;\n",
      " logitstar = tensor([[-0.1272, -0.8530,  0.9802],\n",
      "        [ 0.3766, -0.1124, -0.2643],\n",
      "        [-0.0629, -0.4448,  0.5078]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1577, grad_fn=<StdBackward0>) tensor(0.1272, grad_fn=<AddBackward0>) tensor(0.0726, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0937, -0.4617], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 7.28E+08, mean_loss=7.93E+08;\n",
      " logitstar = tensor([[-0.1152, -0.8919,  1.0071],\n",
      "        [ 0.4579, -0.0540, -0.4039],\n",
      "        [-0.0616, -0.4391,  0.5007]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1216, grad_fn=<StdBackward0>) tensor(0.1149, grad_fn=<AddBackward0>) tensor(0.0688, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1041, -0.4610], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 6.88E+08, mean_loss=7.80E+08;\n",
      " logitstar = tensor([[-0.1206, -0.9265,  1.0470],\n",
      "        [ 0.5182, -0.0034, -0.5148],\n",
      "        [-0.0854, -0.4532,  0.5386]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.1439, grad_fn=<StdBackward0>) tensor(0.1161, grad_fn=<AddBackward0>) tensor(0.0583, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1249, -0.4401], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 6.88E+08, mean_loss=7.67E+08;\n",
      " logitstar = tensor([[-0.0997, -0.9291,  1.0288],\n",
      "        [ 0.5781,  0.0675, -0.6456],\n",
      "        [-0.1037, -0.4588,  0.5625]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1028, grad_fn=<StdBackward0>) tensor(0.0947, grad_fn=<AddBackward0>) tensor(0.0504, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1168, -0.4348], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 6.38E+08, mean_loss=7.52E+08;\n",
      " logitstar = tensor([[-0.1283, -0.9543,  1.0826],\n",
      "        [ 0.5737,  0.1229, -0.6965],\n",
      "        [-0.0950, -0.4730,  0.5680]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1094, grad_fn=<StdBackward0>) tensor(0.0960, grad_fn=<AddBackward0>) tensor(0.0504, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1266, -0.4176], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 8.73E+08, mean_loss=7.49E+08;\n",
      " logitstar = tensor([[-0.1130, -0.9506,  1.0636],\n",
      "        [ 0.5751,  0.1782, -0.7533],\n",
      "        [-0.0822, -0.4804,  0.5626]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1577, grad_fn=<StdBackward0>) tensor(0.0978, grad_fn=<AddBackward0>) tensor(0.0439, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1202, -0.4215], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 6.93E+08, mean_loss=8.92E+08;\n",
      " logitstar = tensor([[-0.1216, -0.9684,  1.0900],\n",
      "        [ 0.5492,  0.2025, -0.7518],\n",
      "        [-0.0670, -0.4986,  0.5657]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 41 1 : 891902967.2504096 888853866.8908931\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.1202, -0.4215],\n",
      "        [-0.2418, -0.5469],\n",
      "        [ 0.4290,  0.6240]], grad_fn=<SliceBackward>) (10 elems)\n",
      "globalpsi:\n",
      "tensor([0.0154, 0.0113, 0.0143, 0.0123, 0.0133, 0.0121],\n",
      "       grad_fn=<SliceBackward>) (10 elems)\n",
      "precinctpsi:\n",
      "tensor([0.0260, 0.0272, 0.0267, 0.0272, 0.0273, 0.0205, 0.0273, 0.0273, 0.0273,\n",
      "        0.0237], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "sdprc line 1353 1 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 1 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 1 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 2 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 2 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 2 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 3 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 3 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 3 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 4 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 4 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 4 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 5 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 5 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 5 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 6 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 6 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 6 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 7 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 7 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 7 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 8 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 8 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 8 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 9 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 9 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 9 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 10 : \n",
      "    Size 0: [1]; noNAN\n",
      "np complete? line 1282 10 : \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [1]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1359 10 : \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 6]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "sdprc line 1353 16\n",
      "np complete? line 1282 16\n",
      "sampleYs line 1359 16\n",
      "sdprc line 1353 32\n",
      "np complete? line 1282 32\n",
      "sampleYs line 1359 32\n",
      "sdprc line 1353 64\n",
      "np complete? line 1282 64\n",
      "sampleYs line 1359 64\n",
      "sdprc line 1353 128\n",
      "np complete? line 1282 128\n",
      "sampleYs line 1359 128\n",
      "sdprc line 1353 256\n",
      "np complete? line 1282 256\n",
      "sampleYs line 1359 256\n",
      "sdprc line 1353 512\n",
      "np complete? line 1282 512\n",
      "sampleYs line 1359 512\n",
      "denses line 1363 1 : \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 694 None 694\n",
      "sampleYs0 line 1325 1 : \n",
      "    Size 0: [400, 6]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sdprc line 1353 1024\n",
      "np complete? line 1282 1024\n",
      "sampleYs line 1359 1024\n",
      "denses line 1363 2 : \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 1388 None 694\n",
      "sampleYs0 line 1325 2 : \n",
      "    Size 0: [400, 6]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sdprc line 1353 2048\n",
      "np complete? line 1282 2048\n",
      "sampleYs line 1359 2048\n",
      "denses line 1363 3 : \n",
      "    Size 0: [400, 4]; noNAN\n",
      "    rerunGuide 2774 2082 None 694\n",
      "sampleYs0 line 1325 3 : \n",
      "    Size 0: [400, 6]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1363 4 : \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "eiresults/scenario_SIG0.3_0_N2774.csv from file\n",
      "svi.step(... line 41 1 : 0 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 1 : 55.48 True\n",
      "types? line 100 1 : [torch.float64, torch.float64]\n",
      "types? line 100 2 : [torch.float64, torch.float64]\n",
      "types? line 100 3 : [torch.float64, torch.float64]\n",
      "sds: tensor(0.5834, grad_fn=<StdBackward0>) tensor(0.5751, grad_fn=<AddBackward0>) tensor(0.5229, grad_fn=<StdBackward0>)\n",
      "model:end line 41 1 :\n",
      "lp:  line 41 1 : tensor(-38710987.4346, grad_fn=<AddBackward0>) tensor(-1071.1010, grad_fn=<AddBackward0>) 780\n",
      "ps2\n",
      "guide:end line 41 1 :\n",
      "model:end line 41 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 7.04E+08, mean_loss=7.04E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 2 : 1 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 2 : 55.48 True\n",
      "types? line 100 4 : [torch.float64, torch.float64]\n",
      "types? line 100 5 : [torch.float64, torch.float64]\n",
      "types? line 100 6 : [torch.float64, torch.float64]\n",
      "model:end line 41 3 :\n",
      "lp:  line 41 2 : tensor(-51545559.1386, grad_fn=<AddBackward0>) tensor(-958.2236, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 2 :\n",
      "model:end line 41 4 :\n",
      "svi.step(... line 41 3 : 2 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 3 : 55.48 True\n",
      "types? line 100 7 : [torch.float64, torch.float64]\n",
      "types? line 100 8 : [torch.float64, torch.float64]\n",
      "types? line 100 9 : [torch.float64, torch.float64]\n",
      "model:end line 41 5 :\n",
      "lp:  line 41 3 : tensor(-44997480.9627, grad_fn=<AddBackward0>) tensor(-941.8156, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 3 :\n",
      "model:end line 41 6 :\n",
      "svi.step(... line 41 4 : 3 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 4 : 55.48 True\n",
      "types? line 100 10 : [torch.float64, torch.float64]\n",
      "model:end line 41 7 :\n",
      "lp:  line 41 4 : tensor(-43477120.0140, grad_fn=<AddBackward0>) tensor(-973.0332, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 4 :\n",
      "model:end line 41 8 :\n",
      "svi.step(... line 41 5 : 4 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 5 : 55.48 True\n",
      "model:end line 41 9 :\n",
      "lp:  line 41 5 : tensor(-35514214.8310, grad_fn=<AddBackward0>) tensor(-1047.0551, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 5 :\n",
      "model:end line 41 10 :\n",
      "svi.step(... line 41 6 : 5 55.48 torch.Size([50, 9])\n",
      "guide:begin line 41 6 : 55.48 True\n",
      "types? line 100 16\n",
      "lp:  line 41 6 : tensor(-38482811.0066, grad_fn=<AddBackward0>) tensor(-1008.1993, grad_fn=<AddBackward0>) 780\n",
      "guide:end line 41 6 :\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-413bc21076c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msigma_nu\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#.02,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m#%prun result = trainGuide(nsamps=nsamps,subsample_n=subn)#inits = inits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtrainGuide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsamps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnsamps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubsample_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigmanu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma_nu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_full\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#inits = inits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\ei_multisample.py\u001b[0m in \u001b[0;36mtrainGuide\u001b[1;34m(subsample_n, filebase, nsteps, sigmanu, dummydata, nsamps, dversion, inits, num_y_samps, force_full)\u001b[0m\n\u001b[0;32m   1473\u001b[0m         \u001b[0mddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"svi.step(...\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindeps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m         loss = svi.step(subset,scale,True,do_print=(i % 10 == 0),nsamps=nsamps,\n\u001b[1;32m-> 1475\u001b[1;33m                 inits=inits)\n\u001b[0m\u001b[0;32m   1476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m             \u001b[0mmean_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# get loss and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurrogate_loss_particle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'requires_grad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0msurrogate_loss_particle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mwarn_if_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei_multisample #import *\n",
    "reload(ei_multisample)\n",
    "from ei_multisample import *\n",
    "import cProfile as profile\n",
    "\n",
    "#ec,erc = legible_values(3,3)\n",
    "#print(ec,\"\\n\",erc,\"\\n\",ec+erc)\n",
    "inits = good_inits(0.)\n",
    "#del inits[\"ercstar_raw\"]\n",
    "for (nsamps,subn) in [(15,50)]:#[(2,60),(5,60),(2,30),(20,30),(40,5)]:\n",
    "    \n",
    "    for i in range(5):\n",
    "        for sigma_nu in [.1, .3, .02, ]: #.02, \n",
    "            #%prun result = trainGuide(nsamps=nsamps,subsample_n=subn)#inits = inits)\n",
    "            trainGuide(nsamps=nsamps,subsample_n=subn,sigmanu=sigma_nu,dversion=i, force_full=True)#inits = inits)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 3 :\n",
      "Reloading polytopize.\n",
      "tensor([[ 0.0500, -0.9100,  1.2200],\n",
      "        [ 0.2100,  0.0100, -0.9500],\n",
      "        [ 0.3400, -0.5400,  0.5800]])\n",
      "0.15\n",
      "0.15\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei_multisample #import *\n",
    "reload(ei_multisample)\n",
    "from ei_multisample import *\n",
    "import cProfile as profile\n",
    "\n",
    "inits = dict() #good_inits()\n",
    "#del inits[\"ercstar_raw\"]\n",
    "#%prun result = trainGuide(inits = inits)\n",
    "\n",
    "NCparams = EIData.load(\"NC_Data/NC_2016_statewide_alpha_and_beta.csv\")\n",
    "print(NCparams.alpha + NCparams.beta)\n",
    "#print(\"components\")\n",
    "#print(NCparams.alpha)\n",
    "#\n",
    "#print(NCparams.beta)\n",
    "print(SIM_SIGMA_NU)\n",
    "SIM_SIGMA_NU = 0.001\n",
    "print(ei_multisample.SIM_SIGMA_NU)\n",
    "ei_multisample.SIM_SIGMA_NU = .0001\n",
    "print(ei_multisample.SIM_SIGMA_NU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hessian transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hess tensor([[6., 0., 0., 0.],\n",
      "        [0., 6., 0., 0.],\n",
      "        [0., 0., 6., 0.],\n",
      "        [0., 0., 0., 6.]], grad_fn=<CopySlices>)\n",
      "d  tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "Σd  tensor(12., grad_fn=<SumBackward0>)\n",
      "dΣdΣd  (tensor([[6., 6.],\n",
      "        [6., 6.]]),)\n",
      "(tensor([[72., 72.],\n",
      "        [72., 72.]]),)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ts = torch.tensor\n",
    "os = torch.ones\n",
    "zs = torch.zeros\n",
    "from importlib import reload\n",
    "import myhessian\n",
    "reload(myhessian)\n",
    "\n",
    "t1 = os(2,2,requires_grad=True)\n",
    "r = torch.sum(t1 * t1 * t1)\n",
    "\n",
    "h = myhessian.hessian(r,t1)\n",
    "print(\"hess\",h)\n",
    "r2 = torch.sum(h * h)\n",
    "[r3] = torch.autograd.grad(r,t1,create_graph=True,retain_graph=True)\n",
    "print(\"d \",r3)\n",
    "print(\"Σd \",torch.sum(r3))\n",
    "[r4] = torch.autograd.grad(torch.sum(r3),t1,create_graph=True,retain_graph=True)\n",
    "print(\"dΣdΣd \",torch.autograd.grad(torch.sum(r4),t1,create_graph=True,retain_graph=True))\n",
    "print(torch.autograd.grad(r2,t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I will run.\n",
      "Yes, I will run.\n",
      "ge fail\n",
      "loc tensor([[ 0.3147],\n",
      "        [ 2.4440],\n",
      "        [-4.0535],\n",
      "        [ 2.2007]])\n",
      "polytopedLoc tensor([[ 2.1063e-01,  2.1136e-02],\n",
      "        [ 2.8514e-01, -1.8626e-09],\n",
      "        [ 3.4959e-01,  9.9957e-02],\n",
      "        [ 3.5462e-01,  1.1892e-02],\n",
      "        [ 2.5462e+00,  3.2228e-01]])\n",
      "ge fail\n",
      "loc tensor([[-5.8855],\n",
      "        [-5.2805],\n",
      "        [ 5.4654],\n",
      "        [ 0.1889]])\n",
      "polytopedLoc tensor([[ 2.8885e-01,  1.1871e+00],\n",
      "        [ 8.5629e-01,  2.0505e+00],\n",
      "        [ 3.9984e-01, -1.4901e-08],\n",
      "        [ 9.5542e-01,  1.5538e+00],\n",
      "        [ 1.0063e+00,  9.9522e-01]])\n",
      "Reloading cmult...\n",
      "callable? <bound method TorchDistributionMixin.__call__ of Multinomial()>\n",
      "callable? <bound method TorchDistributionMixin.__call__ of TorchCMult()>\n",
      "Sampling multinomial: tensor([1., 2.])\n",
      "Sampling cm2: tensor([0., 3.])\n",
      "tensor(5.6022, grad_fn=<NegBackward>) tensor([[112.2500]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hessian\n",
    "\n",
    "from importlib import reload\n",
    "import polytopize #import *\n",
    "reload(polytopize)\n",
    "from polytopize import *\n",
    "\n",
    "import tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test rank1torch (to get yhat from pi,n,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimize_Q (50 tests): \n",
      "R=3, C=5, tolerance=0.001\n",
      "==================================================\n",
      "Oh no! In test 3, Q has some negative entries:\n",
      "\t trueQ[2][4]=0.00010659269901225343, \n",
      "\t     Q[2][4]=-0.00021605131041724235\n",
      "Oh no! In test 5, Q has some negative entries:\n",
      "\t trueQ[1][4]=0.00011974151857430115, \n",
      "\t     Q[1][4]=-1.1631345842033625e-06\n",
      "Oh no! In test 8, Q has some negative entries:\n",
      "\t trueQ[0][1]=2.882161788875237e-05, \n",
      "\t     Q[0][1]=-0.0004783869662787765\n",
      "Oh no! In test 15, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.0007846675580367446, \n",
      "\t     Q[2][3]=-6.166117964312434e-05\n",
      "Oh no! In test 28, Q has some negative entries:\n",
      "\t trueQ[0][4]=8.13114020274952e-05, \n",
      "\t     Q[0][4]=-0.00018321917741559446\n",
      "Oh no! In test 40, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.00032634526723995805, \n",
      "\t     Q[2][3]=-0.000617634505033493\n",
      "Oh no! In test 47, Q has some negative entries:\n",
      "\t trueQ[2][1]=0.00017936740186996758, \n",
      "\t     Q[2][1]=-0.00041433278238400817\n",
      "Oh no! In test 48, Q has some negative entries:\n",
      "\t trueQ[0][0]=4.524858377408236e-05, \n",
      "\t     Q[0][0]=-0.0006647921400144696\n",
      "\n",
      "Cumulative results for the 50 tests \n",
      "(R=3, C=5, tolerance=0.001):\n",
      "-------------------------------------------\n",
      "Worst error in entry of Q: 0.0019194334745407104\n",
      "\n",
      "To get within tolerance, it took us:\n",
      "002 iterations: ***** 5.0 times\n",
      "003 iterations: ********** 10.0 times\n",
      "004 iterations: *********** 11.0 times\n",
      "005 iterations: ****** 6.0 times\n",
      "006 iterations: **** 4.0 times\n",
      "007 iterations: **** 4.0 times\n",
      "008 iterations: ****** 6.0 times\n",
      "010 iterations: *** 3.0 times\n",
      "013 iterations: * 1.0 times\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import rank1torch #import *\n",
    "reload(rank1torch)\n",
    "from rank1torch import *\n",
    "\n",
    "test_solver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Most SVI problems in pyro are coded as a model, a generic guide (such as: multivariate Gaussian in all parameters), and specific observations/data (passed as arguments to svi.step). For EI, that's going to be different; the observations are going to be built into the guide function, leaving nothing to include in the \"data\" argument to svi.step.\n",
    "\n",
    "That means there is a lot of work for the guide to do. As usual, it must establish reasonable distributional families for the posterior of each of the hyperparameters. But for the latent parameters, the job of the guide is to take a \"relative strength\" number for each race/candidate/precinct combo, and turn that into a number of votes for each combo, such that those numbers obey all the constraints set by observations. This means that for each precinct (considered separately), the latent guide must:\n",
    "\n",
    "-Find the \"center point\" where candidate preference is independent of race.\n",
    "\n",
    "-Find the \"basis vectors\" (actually, there are more than enough of them to form a basis) which determine the directions to move in the space.\n",
    "\n",
    "-For any given set of \"relative strengths\" which is a distance $d$ in a direction $\\theta$, find the first constraint violated when moving in that direction, and the distance $r$ between the origin and that constraint.\n",
    "\n",
    "-Project the \"relative strengths\" onto the numbers of votes, by moving $r(1-e^{-d})$ in direction $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a = zs(2,2,2,2)\n",
    "a[0,1,1,1] = 2\n",
    "print(a[1,1])\n",
    "print(a[0,1])\n",
    "print(torch.max(a))\n",
    "print(torch.distributions.exponential.Exponential(ts([1])).sample(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
