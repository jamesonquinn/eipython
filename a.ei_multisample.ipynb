{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "This is a jupyter notebook for testing / coding. So far, each code block is a separate test; unlike an ordinary notebook, they are not meant to run sequentially.\n",
    "\n",
    "Let's do MCMC:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, running \"ei\". This started out as a copy of Fritz's code but it's evolved into a working version of ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 1 :\n",
      "Reloading cmult...\n",
      "Reloading polytopize.\n",
      "Reloading polytopize.\n",
      "base:Yes, I will run. line 5 2 :\n",
      "Reloading polytopize.\n",
      "eiresults/scenario_N527.csv from file\n",
      "svi.step(... line 41 1 : 0 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 1 : 17.566666666666666 True\n",
      "types? line 100 1 : [torch.float64, torch.float64]\n",
      "types? line 100 2 : [torch.float64, torch.float64]\n",
      "types? line 100 3 : [torch.float64, torch.float64]\n",
      "sds: tensor(0.6255, grad_fn=<StdBackward0>) tensor(0.6019, grad_fn=<AddBackward0>) tensor(0.5909, grad_fn=<StdBackward0>)\n",
      "sampled y line 514 1 : tensor([[ 681.4963,  374.1754, 1834.3283],\n",
      "        [ 122.8623,   67.8277,  329.3099],\n",
      "        [  97.6413,   53.9969,  261.3618]], grad_fn=<SelectBackward>)\n",
      "model:end line 41 1 :\n",
      "lp:  line 41 1 : tensor(-10321554.6048, grad_fn=<AddBackward0>) tensor(1.5291, grad_fn=<AddBackward0>) 760\n",
      "ps2\n",
      "guide:end line 41 1 :\n",
      "sampled y line 514 2 : tensor([[7.6634e+02, 4.7514e+02, 1.6485e+03],\n",
      "        [8.5417e+01, 2.0705e+01, 4.1388e+02],\n",
      "        [5.0245e+01, 1.5573e-01, 3.6260e+02]], grad_fn=<SelectBackward>)\n",
      "sampled y line 514 3 : tensor([[7.7511e+02, 4.7028e+02, 1.6446e+03],\n",
      "        [9.3883e+01, 2.5608e+01, 4.0051e+02],\n",
      "        [3.3004e+01, 1.1105e-01, 3.7988e+02]], grad_fn=<SelectBackward>)\n",
      "sampled y line 514 4 : tensor([[7.7822e+02, 4.7834e+02, 1.6334e+03],\n",
      "        [7.8783e+01, 1.7481e+01, 4.2374e+02],\n",
      "        [4.4992e+01, 1.7770e-01, 3.6783e+02]], grad_fn=<SelectBackward>)\n",
      "sampled y line 514 5 : tensor([[7.5170e+02, 4.7216e+02, 1.6661e+03],\n",
      "        [9.8198e+01, 2.3703e+01, 3.9810e+02],\n",
      "        [5.2103e+01, 1.4070e-01, 3.6076e+02]], grad_fn=<SelectBackward>)\n",
      "sampled y line 514 6 : tensor([[7.6079e+02, 4.9143e+02, 1.6378e+03],\n",
      "        [1.0738e+02, 4.8924e-01, 4.1213e+02],\n",
      "        [3.3830e+01, 4.0789e+00, 3.7509e+02]], grad_fn=<SelectBackward>)\n",
      "model:end line 41 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 5.34E+07, mean_loss=5.34E+07; sds = {'rc': 0.9950124793500076};\n",
      " logitstar = tensor([[-0.0100,  0.0000,  0.0100],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0050, -0.0150,  0.0200]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 2 : 1 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 2 : 17.566666666666666 True\n",
      "types? line 100 4 : [torch.float64, torch.float64]\n",
      "types? line 100 5 : [torch.float64, torch.float64]\n",
      "types? line 100 6 : [torch.float64, torch.float64]\n",
      "sampled y line 514 7 : tensor([[ 333.4860,  136.4015, 1228.1126],\n",
      "        [   5.5770,    2.8395,   17.5835],\n",
      "        [  12.9370,    5.7590,   45.3039]], grad_fn=<SelectBackward>)\n",
      "model:end line 41 3 :\n",
      "lp:  line 41 2 : tensor(-7873117.5026, grad_fn=<AddBackward0>) tensor(1.7686, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 2 :\n",
      "sampled y line 514 8 : tensor([[3.4332e+02, 1.4427e+02, 1.2104e+03],\n",
      "        [3.1633e+00, 7.0322e-08, 2.2837e+01],\n",
      "        [5.5160e+00, 7.3462e-01, 5.7749e+01]], grad_fn=<SelectBackward>)\n",
      "sampled y line 514 9 : tensor([[3.4399e+02, 1.4421e+02, 1.2098e+03],\n",
      "        [2.9347e+00, 8.8535e-09, 2.3065e+01],\n",
      "        [5.0796e+00, 7.9423e-01, 5.8126e+01]], grad_fn=<SelectBackward>)\n",
      "sampled y line 514 10 : tensor([[3.4345e+02, 1.4468e+02, 1.2099e+03],\n",
      "        [2.7706e+00, 7.2159e-08, 2.3229e+01],\n",
      "        [5.7823e+00, 3.2186e-01, 5.7896e+01]], grad_fn=<SelectBackward>)\n",
      "model:end line 41 4 :\n",
      "svi.step(... line 41 3 : 2 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 3 : 17.566666666666666 True\n",
      "types? line 100 7 : [torch.float64, torch.float64]\n",
      "types? line 100 8 : [torch.float64, torch.float64]\n",
      "types? line 100 9 : [torch.float64, torch.float64]\n",
      "model:end line 41 5 :\n",
      "lp:  line 41 3 : tensor(-7737327.4870, grad_fn=<AddBackward0>) tensor(2.0810, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 3 :\n",
      "sampled y line 514 16\n",
      "model:end line 41 6 :\n",
      "svi.step(... line 41 4 : 3 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 4 : 17.566666666666666 True\n",
      "types? line 100 10 : [torch.float64, torch.float64]\n",
      "model:end line 41 7 :\n",
      "lp:  line 41 4 : tensor(-8470093.9598, grad_fn=<AddBackward0>) tensor(2.8857, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 4 :\n",
      "model:end line 41 8 :\n",
      "svi.step(... line 41 5 : 4 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 5 : 17.566666666666666 True\n",
      "model:end line 41 9 :\n",
      "lp:  line 41 5 : tensor(-8403724.0349, grad_fn=<AddBackward0>) tensor(3.3250, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 5 :\n",
      "model:end line 41 10 :\n",
      "svi.step(... line 41 6 : 5 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 6 : 17.566666666666666 True\n",
      "types? line 100 16\n",
      "lp:  line 41 6 : tensor(-9328101.2777, grad_fn=<AddBackward0>) tensor(1.9553, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 6 :\n",
      "sampled y line 514 32\n",
      "svi.step(... line 41 7 : 6 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 7 : 17.566666666666666 True\n",
      "lp:  line 41 7 : tensor(-6819706.5901, grad_fn=<AddBackward0>) tensor(3.6034, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 7 :\n",
      "svi.step(... line 41 8 : 7 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 8 : 17.566666666666666 True\n",
      "lp:  line 41 8 : tensor(-8686578.6218, grad_fn=<AddBackward0>) tensor(2.9145, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 8 :\n",
      "model:end line 41 16\n",
      "svi.step(... line 41 9 : 8 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 9 : 17.566666666666666 True\n",
      "lp:  line 41 9 : tensor(-9034885.1471, grad_fn=<AddBackward0>) tensor(2.2836, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 9 :\n",
      "svi.step(... line 41 10 : 9 17.566666666666666 torch.Size([30, 9])\n",
      "guide:begin line 41 10 : 17.566666666666666 True\n",
      "lp:  line 41 10 : tensor(-8568612.8099, grad_fn=<AddBackward0>) tensor(3.6060, grad_fn=<AddBackward0>) 760\n",
      "guide:end line 41 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.5711, grad_fn=<StdBackward0>) tensor(0.5429, grad_fn=<AddBackward0>) tensor(0.5261, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      "sampled y line 514 64\n",
      " ecstar = tensor([-0.0550, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 4.56E+07, mean_loss=5.28E+07; sds = {'rc': 0.9464851487507765};\n",
      " logitstar = tensor([[-0.0956, -0.0556,  0.1512],\n",
      "        [-0.0168, -0.0099,  0.0268],\n",
      "        [-0.0525, -0.0995,  0.1520]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 16\n",
      "guide:begin line 41 16\n",
      "lp:  line 41 16\n",
      "guide:end line 41 16\n",
      "model:end line 41 32\n",
      "sds: tensor(0.5006, grad_fn=<StdBackward0>) tensor(0.4630, grad_fn=<AddBackward0>) tensor(0.4492, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1050, -0.1050], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 4.35E+07, mean_loss=5.22E+07; sds = {'rc': 0.9003245237006247};\n",
      " logitstar = tensor([[-0.1925, -0.1226,  0.3151],\n",
      "        [-0.0256, -0.0139,  0.0395],\n",
      "        [-0.0969, -0.1785,  0.2755]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sampled y line 514 128\n",
      "sds: tensor(0.4361, grad_fn=<StdBackward0>) tensor(0.3903, grad_fn=<AddBackward0>) tensor(0.3721, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1550, -0.1550], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 3.40E+07, mean_loss=5.17E+07; sds = {'rc': 0.8564151788095237};\n",
      " logitstar = tensor([[-0.2915, -0.2128,  0.5043],\n",
      "        [-0.0282, -0.0150,  0.0432],\n",
      "        [-0.1453, -0.2372,  0.3825]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 32\n",
      "guide:begin line 41 32\n",
      "lp:  line 41 32\n",
      "guide:end line 41 32\n",
      "model:end line 41 64\n",
      "sds: tensor(0.3614, grad_fn=<StdBackward0>) tensor(0.3093, grad_fn=<AddBackward0>) tensor(0.3021, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1958, -0.2050], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 4.27E+07, mean_loss=5.09E+07; sds = {'rc': 0.8146473178882553};\n",
      " logitstar = tensor([[-0.3766, -0.3095,  0.6861],\n",
      "        [-0.0199, -0.0154,  0.0353],\n",
      "        [-0.1910, -0.2901,  0.4810]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sampled y line 514 256\n",
      "sds: tensor(0.3443, grad_fn=<StdBackward0>) tensor(0.3135, grad_fn=<AddBackward0>) tensor(0.2915, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1838, -0.2550], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 5.55E+07, mean_loss=5.05E+07; sds = {'rc': 0.7749164995478804};\n",
      " logitstar = tensor([[-0.3632, -0.4037,  0.7669],\n",
      "        [ 0.0418, -0.0156, -0.0263],\n",
      "        [-0.2301, -0.3458,  0.5758]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds: tensor(0.2701, grad_fn=<StdBackward0>) tensor(0.2065, grad_fn=<AddBackward0>) tensor(0.1983, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1470, -0.3050], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 4.19E+07, mean_loss=5.00E+07; sds = {'rc': 0.7371233760584002};\n",
      " logitstar = tensor([[-0.3030, -0.4998,  0.8029],\n",
      "        [ 0.1285, -0.0156, -0.1129],\n",
      "        [-0.2665, -0.3996,  0.6661]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 64\n",
      "guide:begin line 41 64\n",
      "lp:  line 41 64\n",
      "guide:end line 41 64\n",
      "model:end line 41 128\n",
      "sds: tensor(0.2211, grad_fn=<StdBackward0>) tensor(0.1567, grad_fn=<AddBackward0>) tensor(0.1480, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.1131, -0.3550], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 4.03E+07, mean_loss=4.96E+07; sds = {'rc': 0.7011734449323349};\n",
      " logitstar = tensor([[-0.2731, -0.5985,  0.8715],\n",
      "        [ 0.2124, -0.0156, -0.1968],\n",
      "        [-0.2786, -0.4509,  0.7295]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1805, grad_fn=<StdBackward0>) tensor(0.1229, grad_fn=<AddBackward0>) tensor(0.1078, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0876, -0.3989], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 4.61E+07, mean_loss=4.92E+07; sds = {'rc': 0.666976812621088};\n",
      " logitstar = tensor([[-0.2636, -0.6919,  0.9555],\n",
      "        [ 0.2878, -0.0114, -0.2764],\n",
      "        [-0.2872, -0.4933,  0.7805]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sampled y line 514 512\n",
      "sds: tensor(0.1565, grad_fn=<StdBackward0>) tensor(0.0802, grad_fn=<AddBackward0>) tensor(0.0636, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0548, -0.4248], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 3.92E+07, mean_loss=4.86E+07; sds = {'rc': 0.6344479697350961};\n",
      " logitstar = tensor([[-0.2229, -0.7584,  0.9813],\n",
      "        [ 0.3706, -0.0045, -0.3661],\n",
      "        [-0.3123, -0.5117,  0.8239]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1363, grad_fn=<StdBackward0>) tensor(0.0642, grad_fn=<AddBackward0>) tensor(0.0434, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0178, -0.4357], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 4.25E+07, mean_loss=4.83E+07; sds = {'rc': 0.6035055772262604};\n",
      " logitstar = tensor([[-0.1753, -0.8029,  0.9782],\n",
      "        [ 0.4576,  0.0157, -0.4733],\n",
      "        [-0.3359, -0.5197,  0.8556]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1328, grad_fn=<StdBackward0>) tensor(0.0698, grad_fn=<AddBackward0>) tensor(0.0413, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0005, -0.4501], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 3.56E+07, mean_loss=4.77E+07; sds = {'rc': 0.5740722629982165};\n",
      " logitstar = tensor([[-0.1660, -0.8499,  1.0159],\n",
      "        [ 0.5215,  0.0316, -0.5531],\n",
      "        [-0.3571, -0.5320,  0.8891]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1325, grad_fn=<StdBackward0>) tensor(0.0566, grad_fn=<AddBackward0>) tensor(0.0362, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0272, -0.4391], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 3.94E+07, mean_loss=4.76E+07; sds = {'rc': 0.547252334296798};\n",
      " logitstar = tensor([[-0.1400, -0.8712,  1.0113],\n",
      "        [ 0.5672,  0.0691, -0.6362],\n",
      "        [-0.3456, -0.5150,  0.8607]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 41 128\n",
      "guide:begin line 41 128\n",
      "lp:  line 41 128\n",
      "guide:end line 41 128\n",
      "model:end line 41 256\n",
      "sds: tensor(0.1135, grad_fn=<StdBackward0>) tensor(0.0592, grad_fn=<AddBackward0>) tensor(0.0284, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0468, -0.4300], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 4.15E+07, mean_loss=4.71E+07; sds = {'rc': 0.5300113470773411};\n",
      " logitstar = tensor([[-0.1346, -0.8951,  1.0297],\n",
      "        [ 0.5674,  0.1047, -0.6721],\n",
      "        [-0.2924, -0.4996,  0.7920]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0954, grad_fn=<StdBackward0>) tensor(0.0576, grad_fn=<AddBackward0>) tensor(0.0255, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0702, -0.4282], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 4.35E+07, mean_loss=4.68E+07; sds = {'rc': 0.5229847737469229};\n",
      " logitstar = tensor([[-0.1248, -0.9272,  1.0520],\n",
      "        [ 0.5674,  0.1272, -0.6946],\n",
      "        [-0.2320, -0.4845,  0.7165]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1128, grad_fn=<StdBackward0>) tensor(0.0620, grad_fn=<AddBackward0>) tensor(0.0313, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0855, -0.4216], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 4.57E+07, mean_loss=4.65E+07; sds = {'rc': 0.5221385153889216};\n",
      " logitstar = tensor([[-0.1126, -0.9455,  1.0581],\n",
      "        [ 0.5465,  0.1497, -0.6962],\n",
      "        [-0.1774, -0.4690,  0.6464]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0874, grad_fn=<StdBackward0>) tensor(0.0565, grad_fn=<AddBackward0>) tensor(0.0198, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0960, -0.4136], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 3.33E+07, mean_loss=4.63E+07; sds = {'rc': 0.5224814280535006};\n",
      " logitstar = tensor([[-0.1078, -0.9573,  1.0651],\n",
      "        [ 0.5209,  0.1728, -0.6937],\n",
      "        [-0.1251, -0.4563,  0.5814]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.0884, grad_fn=<StdBackward0>) tensor(0.0496, grad_fn=<AddBackward0>) tensor(0.0208, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      "sampled y line 514 1024\n",
      " ecstar = tensor([ 0.1012, -0.4154], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 4.71E+07, mean_loss=4.61E+07; sds = {'rc': 0.521802256773581};\n",
      " logitstar = tensor([[-0.1110, -0.9724,  1.0835],\n",
      "        [ 0.4936,  0.1824, -0.6760],\n",
      "        [-0.0790, -0.4563,  0.5353]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0984, grad_fn=<StdBackward0>) tensor(0.0606, grad_fn=<AddBackward0>) tensor(0.0248, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1173, -0.4049], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 4.57E+07, mean_loss=4.59E+07; sds = {'rc': 0.5196002653107878};\n",
      " logitstar = tensor([[-0.0840, -0.9708,  1.0547],\n",
      "        [ 0.4934,  0.2019, -0.6953],\n",
      "        [-0.0576, -0.4457,  0.5033]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0899, grad_fn=<StdBackward0>) tensor(0.0580, grad_fn=<AddBackward0>) tensor(0.0246, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1197, -0.4179], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 4.26E+07, mean_loss=4.56E+07; sds = {'rc': 0.5172115996205389};\n",
      " logitstar = tensor([[-0.0850, -1.0078,  1.0928],\n",
      "        [ 0.4901,  0.1873, -0.6774],\n",
      "        [-0.0460, -0.4333,  0.4793]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0957, grad_fn=<StdBackward0>) tensor(0.0450, grad_fn=<AddBackward0>) tensor(0.0157, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1325, -0.4172], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 4.81E+07, mean_loss=4.54E+07; sds = {'rc': 0.5160913904609075};\n",
      " logitstar = tensor([[-0.0673, -1.0102,  1.0775],\n",
      "        [ 0.4838,  0.1941, -0.6779],\n",
      "        [-0.0190, -0.4357,  0.4546]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0782, grad_fn=<StdBackward0>) tensor(0.0632, grad_fn=<AddBackward0>) tensor(0.0256, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1366, -0.4215], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 4.96E+07, mean_loss=4.52E+07; sds = {'rc': 0.5150649210630484};\n",
      " logitstar = tensor([[-0.0660, -1.0200,  1.0859],\n",
      "        [ 0.4814,  0.2008, -0.6821],\n",
      "        [-0.0057, -0.4452,  0.4508]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.0923, grad_fn=<StdBackward0>) tensor(0.0515, grad_fn=<AddBackward0>) tensor(0.0197, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.1439, -0.4164], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 4.55E+07, mean_loss=4.49E+07; sds = {'rc': 0.5161052661658211};\n",
      " logitstar = tensor([[-0.0657, -1.0230,  1.0887],\n",
      "        [ 0.4769,  0.2236, -0.7006],\n",
      "        [ 0.0205, -0.4499,  0.4293]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei_multisample #import *\n",
    "reload(ei_multisample)\n",
    "from ei_multisample import *\n",
    "import cProfile as profile\n",
    "\n",
    "#ec,erc = legible_values(3,3)\n",
    "#print(ec,\"\\n\",erc,\"\\n\",ec+erc)\n",
    "inits = good_inits(0.)\n",
    "#del inits[\"ercstar_raw\"]\n",
    "%prun result = trainGuide(nsamps=5)#inits = inits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Now, \"toypyro\", a minimal model to narrow in on and reproduce any bugs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 5 :\n",
      "Reloading polytopize.\n",
      "tensor([[ 0.0500, -0.9100,  1.2200],\n",
      "        [ 0.2100,  0.0100, -0.9500],\n",
      "        [ 0.3400, -0.5400,  0.5800]])\n",
      "components\n",
      "tensor([ 0.2000, -0.4800,  0.2800])\n",
      "tensor([[-0.1500, -0.4300,  0.9400],\n",
      "        [ 0.0100,  0.4900, -1.2300],\n",
      "        [ 0.1400, -0.0600,  0.3000]])\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei2 #import *\n",
    "reload(ei2)\n",
    "from ei2 import *\n",
    "import cProfile as profile\n",
    "\n",
    "inits = dict() #good_inits()\n",
    "#del inits[\"ercstar_raw\"]\n",
    "#%prun result = trainGuide(inits = inits)\n",
    "\n",
    "NCparams = EIData.load(\"NC_Data/NC_2016_statewide_alpha_and_beta.csv\")\n",
    "print(NCparams.alpha + NCparams.beta)\n",
    "#print(\"components\")\n",
    "#print(NCparams.alpha)\n",
    "#\n",
    "print(NCparams.beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hessian transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hess tensor([[6., 0., 0., 0.],\n",
      "        [0., 6., 0., 0.],\n",
      "        [0., 0., 6., 0.],\n",
      "        [0., 0., 0., 6.]], grad_fn=<CopySlices>)\n",
      "d  tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "Σd  tensor(12., grad_fn=<SumBackward0>)\n",
      "dΣdΣd  (tensor([[6., 6.],\n",
      "        [6., 6.]]),)\n",
      "(tensor([[72., 72.],\n",
      "        [72., 72.]]),)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ts = torch.tensor\n",
    "os = torch.ones\n",
    "zs = torch.zeros\n",
    "from importlib import reload\n",
    "import myhessian\n",
    "reload(myhessian)\n",
    "\n",
    "t1 = os(2,2,requires_grad=True)\n",
    "r = torch.sum(t1 * t1 * t1)\n",
    "\n",
    "h = myhessian.hessian(r,t1)\n",
    "print(\"hess\",h)\n",
    "r2 = torch.sum(h * h)\n",
    "[r3] = torch.autograd.grad(r,t1,create_graph=True,retain_graph=True)\n",
    "print(\"d \",r3)\n",
    "print(\"Σd \",torch.sum(r3))\n",
    "[r4] = torch.autograd.grad(torch.sum(r3),t1,create_graph=True,retain_graph=True)\n",
    "print(\"dΣdΣd \",torch.autograd.grad(torch.sum(r4),t1,create_graph=True,retain_graph=True))\n",
    "print(torch.autograd.grad(r2,t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I will run.\n",
      "Yes, I will run.\n",
      "ge fail\n",
      "loc tensor([[ 0.3147],\n",
      "        [ 2.4440],\n",
      "        [-4.0535],\n",
      "        [ 2.2007]])\n",
      "polytopedLoc tensor([[ 2.1063e-01,  2.1136e-02],\n",
      "        [ 2.8514e-01, -1.8626e-09],\n",
      "        [ 3.4959e-01,  9.9957e-02],\n",
      "        [ 3.5462e-01,  1.1892e-02],\n",
      "        [ 2.5462e+00,  3.2228e-01]])\n",
      "ge fail\n",
      "loc tensor([[-5.8855],\n",
      "        [-5.2805],\n",
      "        [ 5.4654],\n",
      "        [ 0.1889]])\n",
      "polytopedLoc tensor([[ 2.8885e-01,  1.1871e+00],\n",
      "        [ 8.5629e-01,  2.0505e+00],\n",
      "        [ 3.9984e-01, -1.4901e-08],\n",
      "        [ 9.5542e-01,  1.5538e+00],\n",
      "        [ 1.0063e+00,  9.9522e-01]])\n",
      "Reloading cmult...\n",
      "callable? <bound method TorchDistributionMixin.__call__ of Multinomial()>\n",
      "callable? <bound method TorchDistributionMixin.__call__ of TorchCMult()>\n",
      "Sampling multinomial: tensor([1., 2.])\n",
      "Sampling cm2: tensor([0., 3.])\n",
      "tensor(5.6022, grad_fn=<NegBackward>) tensor([[112.2500]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hessian\n",
    "\n",
    "from importlib import reload\n",
    "import polytopize #import *\n",
    "reload(polytopize)\n",
    "from polytopize import *\n",
    "\n",
    "import tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test rank1torch (to get yhat from pi,n,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimize_Q (50 tests): \n",
      "R=3, C=5, tolerance=0.001\n",
      "==================================================\n",
      "Oh no! In test 3, Q has some negative entries:\n",
      "\t trueQ[2][4]=0.00010659269901225343, \n",
      "\t     Q[2][4]=-0.00021605131041724235\n",
      "Oh no! In test 5, Q has some negative entries:\n",
      "\t trueQ[1][4]=0.00011974151857430115, \n",
      "\t     Q[1][4]=-1.1631345842033625e-06\n",
      "Oh no! In test 8, Q has some negative entries:\n",
      "\t trueQ[0][1]=2.882161788875237e-05, \n",
      "\t     Q[0][1]=-0.0004783869662787765\n",
      "Oh no! In test 15, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.0007846675580367446, \n",
      "\t     Q[2][3]=-6.166117964312434e-05\n",
      "Oh no! In test 28, Q has some negative entries:\n",
      "\t trueQ[0][4]=8.13114020274952e-05, \n",
      "\t     Q[0][4]=-0.00018321917741559446\n",
      "Oh no! In test 40, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.00032634526723995805, \n",
      "\t     Q[2][3]=-0.000617634505033493\n",
      "Oh no! In test 47, Q has some negative entries:\n",
      "\t trueQ[2][1]=0.00017936740186996758, \n",
      "\t     Q[2][1]=-0.00041433278238400817\n",
      "Oh no! In test 48, Q has some negative entries:\n",
      "\t trueQ[0][0]=4.524858377408236e-05, \n",
      "\t     Q[0][0]=-0.0006647921400144696\n",
      "\n",
      "Cumulative results for the 50 tests \n",
      "(R=3, C=5, tolerance=0.001):\n",
      "-------------------------------------------\n",
      "Worst error in entry of Q: 0.0019194334745407104\n",
      "\n",
      "To get within tolerance, it took us:\n",
      "002 iterations: ***** 5.0 times\n",
      "003 iterations: ********** 10.0 times\n",
      "004 iterations: *********** 11.0 times\n",
      "005 iterations: ****** 6.0 times\n",
      "006 iterations: **** 4.0 times\n",
      "007 iterations: **** 4.0 times\n",
      "008 iterations: ****** 6.0 times\n",
      "010 iterations: *** 3.0 times\n",
      "013 iterations: * 1.0 times\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import rank1torch #import *\n",
    "reload(rank1torch)\n",
    "from rank1torch import *\n",
    "\n",
    "test_solver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Most SVI problems in pyro are coded as a model, a generic guide (such as: multivariate Gaussian in all parameters), and specific observations/data (passed as arguments to svi.step). For EI, that's going to be different; the observations are going to be built into the guide function, leaving nothing to include in the \"data\" argument to svi.step.\n",
    "\n",
    "That means there is a lot of work for the guide to do. As usual, it must establish reasonable distributional families for the posterior of each of the hyperparameters. But for the latent parameters, the job of the guide is to take a \"relative strength\" number for each race/candidate/precinct combo, and turn that into a number of votes for each combo, such that those numbers obey all the constraints set by observations. This means that for each precinct (considered separately), the latent guide must:\n",
    "\n",
    "-Find the \"center point\" where candidate preference is independent of race.\n",
    "\n",
    "-Find the \"basis vectors\" (actually, there are more than enough of them to form a basis) which determine the directions to move in the space.\n",
    "\n",
    "-For any given set of \"relative strengths\" which is a distance $d$ in a direction $\\theta$, find the first constraint violated when moving in that direction, and the distance $r$ between the origin and that constraint.\n",
    "\n",
    "-Project the \"relative strengths\" onto the numbers of votes, by moving $r(1-e^{-d})$ in direction $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a = zs(2,2,2,2)\n",
    "a[0,1,1,1] = 2\n",
    "print(a[1,1])\n",
    "print(a[0,1])\n",
    "print(torch.max(a))\n",
    "print(torch.distributions.exponential.Exponential(ts([1])).sample(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
