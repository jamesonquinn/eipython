{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "This is a jupyter notebook for testing / coding. So far, each code block is a separate test; unlike an ordinary notebook, they are not meant to run sequentially.\n",
    "\n",
    "Let's do MCMC:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, running \"ei\". This started out as a copy of Fritz's code but it's evolved into a working version of ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 3 :\n",
      "Reloading polytopize.\n",
      "ei_post_results_MSEbiasterm/scenario_SIG0.3_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.2802, grad_fn=<StdBackward0>) tensor(0.2671, requires_grad=True) tensor(0.2432, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-47080535.0304, grad_fn=<AddBackward0>)\n",
      "     tensor(-2789.4670, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 7.31E+08, mean_loss=7.31E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-44760798.6790, grad_fn=<AddBackward0>)\n",
      "     tensor(-1941.7600, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-44759986.0381, grad_fn=<AddBackward0>)\n",
      "     tensor(-1939.0101, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-41644681.8079, grad_fn=<AddBackward0>)\n",
      "     tensor(-2135.2253, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-41895644.0003, grad_fn=<AddBackward0>)\n",
      "     tensor(-2325.7894, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-42124256.4982, grad_fn=<AddBackward0>)\n",
      "     tensor(-2257.3265, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n",
      "     tensor(-42171162.9263, grad_fn=<AddBackward0>)\n",
      "     tensor(-2128.1778, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-43890676.8946, grad_fn=<AddBackward0>)\n",
      "     tensor(-2164.4416, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-44330521.6985, grad_fn=<AddBackward0>)\n",
      "     tensor(-2154.5737, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-48823673.9789, grad_fn=<AddBackward0>)\n",
      "     tensor(-2222.2483, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.2986, grad_fn=<StdBackward0>) tensor(0.2811, requires_grad=True) tensor(0.2591, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0326, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 6.55E+08, mean_loss=7.26E+08;\n",
      " logitstar = tensor([[-0.0276, -0.0528,  0.0804],\n",
      "        [-0.0418, -0.0592,  0.1011],\n",
      "        [-0.0285, -0.0530,  0.0815]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.3266, grad_fn=<StdBackward0>) tensor(0.3156, requires_grad=True) tensor(0.2916, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0158, -0.1008], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 7.21E+08, mean_loss=7.22E+08;\n",
      " logitstar = tensor([[-0.0038, -0.1052,  0.1090],\n",
      "        [-0.0291, -0.1055,  0.1347],\n",
      "        [-0.0145, -0.0916,  0.1061]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.3312, grad_fn=<StdBackward0>) tensor(0.3163, requires_grad=True) tensor(0.2894, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0020, -0.1131], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 6.55E+08, mean_loss=7.22E+08;\n",
      " logitstar = tensor([[ 0.0079, -0.1263,  0.1184],\n",
      "        [ 0.0077, -0.1156,  0.1079],\n",
      "        [-0.0215, -0.0973,  0.1188]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.3438, grad_fn=<StdBackward0>) tensor(0.3291, requires_grad=True) tensor(0.2935, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0217, -0.0905], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 6.88E+08, mean_loss=7.19E+08;\n",
      " logitstar = tensor([[ 0.0216, -0.1129,  0.0913],\n",
      "        [ 0.0225, -0.0798,  0.0573],\n",
      "        [ 0.0211, -0.0786,  0.0576]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.3260, grad_fn=<StdBackward0>) tensor(0.3150, requires_grad=True) tensor(0.2911, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0392, -0.0812], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.64E+08, mean_loss=7.17E+08;\n",
      " logitstar = tensor([[ 0.0557, -0.1007,  0.0449],\n",
      "        [ 0.0260, -0.0678,  0.0418],\n",
      "        [ 0.0359, -0.0752,  0.0393]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3147, grad_fn=<StdBackward0>) tensor(0.3037, requires_grad=True) tensor(0.2749, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0351, -0.0992], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 7.00E+08, mean_loss=7.15E+08;\n",
      " logitstar = tensor([[ 0.0530, -0.1272,  0.0743],\n",
      "        [ 0.0108, -0.0889,  0.0781],\n",
      "        [ 0.0414, -0.0815,  0.0401]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.3261, grad_fn=<StdBackward0>) tensor(0.3176, requires_grad=True) tensor(0.2873, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0283, -0.1161], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 7.50E+08, mean_loss=7.15E+08;\n",
      " logitstar = tensor([[ 0.0429, -0.1440,  0.1011],\n",
      "        [ 0.0228, -0.0982,  0.0753],\n",
      "        [ 0.0192, -0.1061,  0.0870]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2796, grad_fn=<StdBackward0>) tensor(0.2643, requires_grad=True) tensor(0.2442, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0390, -0.1003], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 6.53E+08, mean_loss=7.14E+08;\n",
      " logitstar = tensor([[ 0.0523, -0.1186,  0.0664],\n",
      "        [ 0.0231, -0.0838,  0.0608],\n",
      "        [ 0.0418, -0.0985,  0.0567]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.2944, grad_fn=<StdBackward0>) tensor(0.2801, requires_grad=True) tensor(0.2478, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0572, -0.1004], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 6.69E+08, mean_loss=7.13E+08;\n",
      " logitstar = tensor([[ 0.0735, -0.1256,  0.0522],\n",
      "        [ 0.0405, -0.0773,  0.0368],\n",
      "        [ 0.0575, -0.0983,  0.0408]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3083, grad_fn=<StdBackward0>) tensor(0.2961, requires_grad=True) tensor(0.2692, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0537, -0.1167], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 6.76E+08, mean_loss=7.12E+08;\n",
      " logitstar = tensor([[ 0.0752, -0.1502,  0.0750],\n",
      "        [ 0.0414, -0.1013,  0.0599],\n",
      "        [ 0.0444, -0.0987,  0.0543]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds: tensor(0.2813, grad_fn=<StdBackward0>) tensor(0.2614, requires_grad=True) tensor(0.2425, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0542, -0.1246], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 6.48E+08, mean_loss=7.12E+08;\n",
      " logitstar = tensor([[ 0.0677, -0.1603,  0.0926],\n",
      "        [ 0.0442, -0.1035,  0.0593],\n",
      "        [ 0.0508, -0.1101,  0.0593]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3458, grad_fn=<StdBackward0>) tensor(0.3323, requires_grad=True) tensor(0.3079, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0619, -0.1187], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 7.24E+08, mean_loss=7.10E+08;\n",
      " logitstar = tensor([[ 0.0843, -0.1462,  0.0619],\n",
      "        [ 0.0454, -0.1009,  0.0554],\n",
      "        [ 0.0560, -0.1091,  0.0531]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.2762, grad_fn=<StdBackward0>) tensor(0.2671, requires_grad=True) tensor(0.2485, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0586, -0.1151], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 7.20E+08, mean_loss=7.12E+08;\n",
      " logitstar = tensor([[ 0.0757, -0.1449,  0.0691],\n",
      "        [ 0.0558, -0.1004,  0.0446],\n",
      "        [ 0.0442, -0.1000,  0.0558]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2812, grad_fn=<StdBackward0>) tensor(0.2667, requires_grad=True) tensor(0.2450, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0436, -0.1086], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 7.11E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0570, -0.1238,  0.0669],\n",
      "        [ 0.0351, -0.0938,  0.0587],\n",
      "        [ 0.0387, -0.1082,  0.0696]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3235, grad_fn=<StdBackward0>) tensor(0.3155, requires_grad=True) tensor(0.2925, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0333, -0.1135], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 8.80E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0441, -0.1354,  0.0913],\n",
      "        [ 0.0146, -0.0977,  0.0830],\n",
      "        [ 0.0412, -0.1073,  0.0661]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2960, grad_fn=<StdBackward0>) tensor(0.2826, requires_grad=True) tensor(0.2604, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0471, -0.1085], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 7.72E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0625, -0.1358,  0.0733],\n",
      "        [ 0.0318, -0.0812,  0.0493],\n",
      "        [ 0.0470, -0.1086,  0.0616]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.3028, grad_fn=<StdBackward0>) tensor(0.2864, requires_grad=True) tensor(0.2643, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0467, -0.1104], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 6.92E+08, mean_loss=7.10E+08;\n",
      " logitstar = tensor([[ 0.0595, -0.1317,  0.0722],\n",
      "        [ 0.0332, -0.0878,  0.0547],\n",
      "        [ 0.0475, -0.1117,  0.0643]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3219, grad_fn=<StdBackward0>) tensor(0.3083, requires_grad=True) tensor(0.2756, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0599, -0.1013], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 6.58E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0710, -0.1178,  0.0468],\n",
      "        [ 0.0507, -0.0864,  0.0358],\n",
      "        [ 0.0581, -0.0996,  0.0415]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3149, grad_fn=<StdBackward0>) tensor(0.2992, requires_grad=True) tensor(0.2650, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0562, -0.1034], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 6.47E+08, mean_loss=7.08E+08;\n",
      " logitstar = tensor([[ 0.0727, -0.1293,  0.0566],\n",
      "        [ 0.0398, -0.0892,  0.0494],\n",
      "        [ 0.0560, -0.0918,  0.0358]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2841, grad_fn=<StdBackward0>) tensor(0.2726, requires_grad=True) tensor(0.2540, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0366, -0.1095], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 6.96E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0490, -0.1391,  0.0901],\n",
      "        [ 0.0329, -0.0869,  0.0540],\n",
      "        [ 0.0280, -0.1026,  0.0746]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3307, grad_fn=<StdBackward0>) tensor(0.3171, requires_grad=True) tensor(0.2886, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0302, -0.1008], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 7.86E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0485, -0.1225,  0.0740],\n",
      "        [ 0.0083, -0.0855,  0.0772],\n",
      "        [ 0.0339, -0.0945,  0.0606]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3227, grad_fn=<StdBackward0>) tensor(0.3114, requires_grad=True) tensor(0.2820, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0415, -0.0955], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 7.14E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0529, -0.1202,  0.0672],\n",
      "        [ 0.0289, -0.0707,  0.0418],\n",
      "        [ 0.0428, -0.0956,  0.0528]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3349, grad_fn=<StdBackward0>) tensor(0.3209, requires_grad=True) tensor(0.2892, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0478, -0.0967], grad_fn=<SliceBackward>)\n",
      "epoch 230 loss = 6.93E+08, mean_loss=7.07E+08;\n",
      " logitstar = tensor([[ 0.0623, -0.1230,  0.0607],\n",
      "        [ 0.0293, -0.0757,  0.0464],\n",
      "        [ 0.0518, -0.0915,  0.0397]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3032, grad_fn=<StdBackward0>) tensor(0.2882, requires_grad=True) tensor(0.2635, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0479, -0.1041], grad_fn=<SliceBackward>)\n",
      "epoch 240 loss = 6.00E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0680, -0.1363,  0.0683],\n",
      "        [ 0.0345, -0.0719,  0.0374],\n",
      "        [ 0.0412, -0.1040,  0.0627]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2951, grad_fn=<StdBackward0>) tensor(0.2835, requires_grad=True) tensor(0.2611, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0453, -0.1068], grad_fn=<SliceBackward>)\n",
      "epoch 250 loss = 7.01E+08, mean_loss=7.11E+08;\n",
      " logitstar = tensor([[ 0.0598, -0.1458,  0.0861],\n",
      "        [ 0.0221, -0.0674,  0.0453],\n",
      "        [ 0.0540, -0.1073,  0.0532]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 256\n",
      "guide:begin line 51 256\n",
      "lp:  line 51 256\n",
      "guide:end line 51 256\n",
      "model:end line 51 512\n",
      "sds: tensor(0.3172, grad_fn=<StdBackward0>) tensor(0.3038, requires_grad=True) tensor(0.2819, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0377, -0.1027], grad_fn=<SliceBackward>)\n",
      "epoch 260 loss = 7.73E+08, mean_loss=7.08E+08;\n",
      " logitstar = tensor([[ 0.0510, -0.1406,  0.0897],\n",
      "        [ 0.0153, -0.0681,  0.0529],\n",
      "        [ 0.0468, -0.0994,  0.0525]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2986, grad_fn=<StdBackward0>) tensor(0.2888, requires_grad=True) tensor(0.2574, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0482, -0.0930], grad_fn=<SliceBackward>)\n",
      "epoch 270 loss = 6.95E+08, mean_loss=7.09E+08;\n",
      " logitstar = tensor([[ 0.0665, -0.1235,  0.0571],\n",
      "        [ 0.0247, -0.0633,  0.0386],\n",
      "        [ 0.0535, -0.0921,  0.0386]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2920, grad_fn=<StdBackward0>) tensor(0.2776, requires_grad=True) tensor(0.2547, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0451, -0.0988], grad_fn=<SliceBackward>)\n",
      "epoch 280 loss = 7.76E+08, mean_loss=7.10E+08;\n",
      " logitstar = tensor([[ 0.0616, -0.1321,  0.0705],\n",
      "        [ 0.0294, -0.0675,  0.0381],\n",
      "        [ 0.0443, -0.0967,  0.0524]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 51 1 :\n",
      "     710097478.3820825\n",
      "     708110060.1482035\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.0451, -0.0988],\n",
      "        [ 0.0165, -0.0333],\n",
      "        [-0.0157,  0.0313]], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "jsonizing 2\n",
      "np complete? line 1311 1 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 1 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 2 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 2 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 3 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 3 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 4 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 4 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 5 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 5 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 6 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 6 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 7 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 7 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 8 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 8 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 9 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 9 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 10 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 10 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 16\n",
      "sampleYs line 1433 16\n",
      "np complete? line 1311 32\n",
      "sampleYs line 1433 32\n",
      "np complete? line 1311 64\n",
      "sampleYs line 1433 64\n",
      "np complete? line 1311 128\n",
      "sampleYs line 1433 128\n",
      "np complete? line 1311 256\n",
      "sampleYs line 1433 256\n",
      "np complete? line 1311 512\n",
      "sampleYs line 1433 512\n",
      "denses line 1447 1 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "BAsize torch.Size([7, 7])\n",
      "Inner comparing mean diagonals: gg_cov tensor(2.9226e-06) tensor(0.0013)\n",
      "np complete? line 1311 1024\n",
      "sampleYs line 1433 1024\n",
      "denses line 1447 2 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.9226e-06) tensor(0.0013) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 694 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 1 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 2048\n",
      "sampleYs line 1433 2048\n",
      "denses line 1447 3 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 2 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 4 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.8088e-06) tensor(0.0012) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 1388 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 3 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 5 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 4 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 4096\n",
      "sampleYs line 1433 4096\n",
      "denses line 1447 6 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.9116e-06) tensor(0.0013) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 2082 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 5 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 7 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 6 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 8 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.8398e-06) tensor(0.0013) ei_post_results_MSEbiasterm/\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "ei_post_results_MSEbiasterm/scenario_SIG0.1_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.2489, grad_fn=<StdBackward0>) tensor(0.2360, requires_grad=True) tensor(0.2093, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-42551104.2824, grad_fn=<AddBackward0>)\n",
      "     tensor(-2699.9526, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 6.63E+08, mean_loss=6.63E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-49775471.9892, grad_fn=<AddBackward0>)\n",
      "     tensor(-2043.1948, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-41634538.3905, grad_fn=<AddBackward0>)\n",
      "     tensor(-1878.8064, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-42285104.1600, grad_fn=<AddBackward0>)\n",
      "     tensor(-1896.4924, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-49577247.9400, grad_fn=<AddBackward0>)\n",
      "     tensor(-2050.1829, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-46169471.4243, grad_fn=<AddBackward0>)\n",
      "     tensor(-2124.6508, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n",
      "     tensor(-41502723.4081, grad_fn=<AddBackward0>)\n",
      "     tensor(-2069.9607, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-40250403.0581, grad_fn=<AddBackward0>)\n",
      "     tensor(-1918.9824, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-47582456.0373, grad_fn=<AddBackward0>)\n",
      "     tensor(-1857.1300, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-39400795.4655, grad_fn=<AddBackward0>)\n",
      "     tensor(-1841.3667, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.2373, grad_fn=<StdBackward0>) tensor(0.2289, requires_grad=True) tensor(0.1958, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0326, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 6.99E+08, mean_loss=6.66E+08;\n",
      " logitstar = tensor([[-0.0220, -0.0710,  0.0930],\n",
      "        [-0.0403, -0.0514,  0.0917],\n",
      "        [-0.0355, -0.0426,  0.0781]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.2813, grad_fn=<StdBackward0>) tensor(0.2676, requires_grad=True) tensor(0.2260, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0272, -0.0885], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 5.73E+08, mean_loss=6.69E+08;\n",
      " logitstar = tensor([[-0.0078, -0.1314,  0.1392],\n",
      "        [-0.0383, -0.0602,  0.0984],\n",
      "        [-0.0357, -0.0738,  0.1095]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.2845, grad_fn=<StdBackward0>) tensor(0.2767, requires_grad=True) tensor(0.2415, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0058, -0.0812], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 7.04E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0453, -0.1564,  0.1111],\n",
      "        [-0.0140, -0.0445,  0.0585],\n",
      "        [-0.0138, -0.0428,  0.0566]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.2664, grad_fn=<StdBackward0>) tensor(0.2562, requires_grad=True) tensor(0.2173, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0180, -0.0896], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 6.92E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[ 0.0531, -0.1945,  0.1414],\n",
      "        [-0.0080, -0.0364,  0.0444],\n",
      "        [ 0.0089, -0.0378,  0.0289]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.2356, grad_fn=<StdBackward0>) tensor(0.2329, requires_grad=True) tensor(0.2035, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0254, -0.0839], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.91E+08, mean_loss=6.80E+08;\n",
      " logitstar = tensor([[ 0.0405, -0.2291,  0.1886],\n",
      "        [ 0.0106, -0.0027, -0.0079],\n",
      "        [ 0.0250, -0.0198, -0.0052]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2105, grad_fn=<StdBackward0>) tensor(0.2016, requires_grad=True) tensor(0.1690, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0432, -0.0540], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 6.44E+08, mean_loss=6.80E+08;\n",
      " logitstar = tensor([[ 0.0265, -0.2386,  0.2121],\n",
      "        [ 0.0311,  0.0561, -0.0872],\n",
      "        [ 0.0721,  0.0207, -0.0928]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.2138, grad_fn=<StdBackward0>) tensor(0.2090, requires_grad=True) tensor(0.1674, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0682, -0.0189], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 7.04E+08, mean_loss=6.81E+08;\n",
      " logitstar = tensor([[ 0.0149, -0.2426,  0.2277],\n",
      "        [ 0.0593,  0.1287, -0.1881],\n",
      "        [ 0.1303,  0.0572, -0.1876]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1861, grad_fn=<StdBackward0>) tensor(0.1831, requires_grad=True) tensor(0.1458, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1072, 0.0255], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 7.01E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[ 0.0145, -0.2420,  0.2275],\n",
      "        [ 0.1133,  0.2188, -0.3322],\n",
      "        [ 0.1939,  0.0997, -0.2936]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.1802, grad_fn=<StdBackward0>) tensor(0.1685, requires_grad=True) tensor(0.1291, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1346, 0.0572], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 6.68E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[ 0.0033, -0.2535,  0.2503],\n",
      "        [ 0.1640,  0.2990, -0.4630],\n",
      "        [ 0.2364,  0.1261, -0.3625]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1632, grad_fn=<StdBackward0>) tensor(0.1412, requires_grad=True) tensor(0.1051, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1629, 0.0846], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 6.83E+08, mean_loss=6.81E+08;\n",
      " logitstar = tensor([[-0.0019, -0.2719,  0.2737],\n",
      "        [ 0.2331,  0.3759, -0.6090],\n",
      "        [ 0.2576,  0.1498, -0.4074]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1552, grad_fn=<StdBackward0>) tensor(0.1309, requires_grad=True) tensor(0.0937, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1860, 0.1207], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 7.05E+08, mean_loss=6.83E+08;\n",
      " logitstar = tensor([[-0.0077, -0.2782,  0.2858],\n",
      "        [ 0.3029,  0.4618, -0.7648],\n",
      "        [ 0.2628,  0.1785, -0.4413]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1445, grad_fn=<StdBackward0>) tensor(0.1185, requires_grad=True) tensor(0.0765, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2116, 0.1480], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 6.85E+08, mean_loss=6.83E+08;\n",
      " logitstar = tensor([[-0.0139, -0.2935,  0.3074],\n",
      "        [ 0.3773,  0.5390, -0.9163],\n",
      "        [ 0.2713,  0.1983, -0.4696]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.1566, grad_fn=<StdBackward0>) tensor(0.1232, requires_grad=True) tensor(0.0699, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2322, 0.1832], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 7.27E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[-0.0150, -0.2970,  0.3120],\n",
      "        [ 0.4475,  0.6242, -1.0718],\n",
      "        [ 0.2639,  0.2224, -0.4863]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1191, grad_fn=<StdBackward0>) tensor(0.1056, requires_grad=True) tensor(0.0584, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2329, 0.2099], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 7.38E+08, mean_loss=6.84E+08;\n",
      " logitstar = tensor([[-0.0360, -0.3127,  0.3487],\n",
      "        [ 0.4929,  0.7010, -1.1938],\n",
      "        [ 0.2417,  0.2415, -0.4832]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds: tensor(0.1853, grad_fn=<StdBackward0>) tensor(0.1418, requires_grad=True) tensor(0.0696, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2417, 0.2251], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 7.06E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[-0.0182, -0.3243,  0.3425],\n",
      "        [ 0.5420,  0.7661, -1.3081],\n",
      "        [ 0.2012,  0.2335, -0.4347]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1675, grad_fn=<StdBackward0>) tensor(0.1370, requires_grad=True) tensor(0.0613, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2419, 0.2177], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 7.34E+08, mean_loss=6.80E+08;\n",
      " logitstar = tensor([[-0.0036, -0.3567,  0.3604],\n",
      "        [ 0.5677,  0.8087, -1.3764],\n",
      "        [ 0.1615,  0.2011, -0.3625]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.1402, grad_fn=<StdBackward0>) tensor(0.1129, requires_grad=True) tensor(0.0545, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2368, 0.2199], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 6.33E+08, mean_loss=6.81E+08;\n",
      " logitstar = tensor([[ 0.0054, -0.3553,  0.3499],\n",
      "        [ 0.5713,  0.8609, -1.4322],\n",
      "        [ 0.1336,  0.1541, -0.2877]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1697, grad_fn=<StdBackward0>) tensor(0.1385, requires_grad=True) tensor(0.0596, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2269, 0.2254], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 6.51E+08, mean_loss=6.79E+08;\n",
      " logitstar = tensor([[-3.6402e-04, -3.4438e-01,  3.4474e-01],\n",
      "        [ 5.6058e-01,  9.0274e-01, -1.4633e+00],\n",
      "        [ 1.2034e-01,  1.1781e-01, -2.3815e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2029, grad_fn=<StdBackward0>) tensor(0.1648, requires_grad=True) tensor(0.0707, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2247, 0.2173], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 6.58E+08, mean_loss=6.80E+08;\n",
      " logitstar = tensor([[ 0.0020, -0.3551,  0.3532],\n",
      "        [ 0.5692,  0.9089, -1.4781],\n",
      "        [ 0.1028,  0.0980, -0.2008]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1733, grad_fn=<StdBackward0>) tensor(0.1471, requires_grad=True) tensor(0.0611, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2263, 0.2194], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 6.96E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[ 6.9328e-04, -3.4894e-01,  3.4825e-01],\n",
      "        [ 5.7741e-01,  9.2085e-01, -1.4983e+00],\n",
      "        [ 1.0093e-01,  8.6317e-02, -1.8725e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2037, grad_fn=<StdBackward0>) tensor(0.1672, requires_grad=True) tensor(0.0648, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2232, 0.2168], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 6.48E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 5.4057e-04, -3.4879e-01,  3.4825e-01],\n",
      "        [ 5.7085e-01,  9.2438e-01, -1.4952e+00],\n",
      "        [ 9.8145e-02,  7.4832e-02, -1.7298e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1964, grad_fn=<StdBackward0>) tensor(0.1584, requires_grad=True) tensor(0.0625, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2292, 0.2074], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 7.37E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[ 0.0144, -0.3552,  0.3408],\n",
      "        [ 0.5755,  0.9168, -1.4923],\n",
      "        [ 0.0978,  0.0607, -0.1585]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1759, grad_fn=<StdBackward0>) tensor(0.1381, requires_grad=True) tensor(0.0563, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2306, 0.2042], grad_fn=<SliceBackward>)\n",
      "epoch 230 loss = 6.91E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0101, -0.3503,  0.3401],\n",
      "        [ 0.5705,  0.9205, -1.4910],\n",
      "        [ 0.1110,  0.0422, -0.1533]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2288, grad_fn=<StdBackward0>) tensor(0.1819, requires_grad=True) tensor(0.0648, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2304, 0.2024], grad_fn=<SliceBackward>)\n",
      "epoch 240 loss = 6.67E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 0.0015, -0.3507,  0.3491],\n",
      "        [ 0.5631,  0.9125, -1.4756],\n",
      "        [ 0.1266,  0.0454, -0.1720]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1935, grad_fn=<StdBackward0>) tensor(0.1544, requires_grad=True) tensor(0.0658, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2321, 0.2044], grad_fn=<SliceBackward>)\n",
      "epoch 250 loss = 6.64E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[ 1.6757e-04, -3.4104e-01,  3.4088e-01],\n",
      "        [ 5.5461e-01,  9.0243e-01, -1.4570e+00],\n",
      "        [ 1.4162e-01,  5.1714e-02, -1.9333e-01]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 256\n",
      "guide:begin line 51 256\n",
      "lp:  line 51 256\n",
      "guide:end line 51 256\n",
      "model:end line 51 512\n",
      "sds: tensor(0.1842, grad_fn=<StdBackward0>) tensor(0.1413, requires_grad=True) tensor(0.0604, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2376, 0.2026], grad_fn=<SliceBackward>)\n",
      "epoch 260 loss = 6.16E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0052, -0.3427,  0.3479],\n",
      "        [ 0.5576,  0.9033, -1.4609],\n",
      "        [ 0.1603,  0.0470, -0.2073]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2021, grad_fn=<StdBackward0>) tensor(0.1724, requires_grad=True) tensor(0.0653, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2363, 0.1988], grad_fn=<SliceBackward>)\n",
      "epoch 270 loss = 7.00E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0104, -0.3383,  0.3486],\n",
      "        [ 0.5557,  0.9054, -1.4611],\n",
      "        [ 0.1636,  0.0291, -0.1927]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1951, grad_fn=<StdBackward0>) tensor(0.1576, requires_grad=True) tensor(0.0669, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2335, 0.1969], grad_fn=<SliceBackward>)\n",
      "epoch 280 loss = 6.03E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0165, -0.3426,  0.3591],\n",
      "        [ 0.5660,  0.9185, -1.4846],\n",
      "        [ 0.1509,  0.0148, -0.1657]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2113, grad_fn=<StdBackward0>) tensor(0.1761, requires_grad=True) tensor(0.0646, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2415, 0.1982], grad_fn=<SliceBackward>)\n",
      "epoch 290 loss = 6.38E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-6.0839e-04, -3.3493e-01,  3.3554e-01],\n",
      "        [ 5.9412e-01,  9.2117e-01, -1.5153e+00],\n",
      "        [ 1.3106e-01,  8.4612e-03, -1.3952e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2143, grad_fn=<StdBackward0>) tensor(0.1726, requires_grad=True) tensor(0.0701, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2371, 0.1920], grad_fn=<SliceBackward>)\n",
      "epoch 300 loss = 6.32E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[ 6.9931e-04, -3.4440e-01,  3.4370e-01],\n",
      "        [ 5.8316e-01,  8.9489e-01, -1.4780e+00],\n",
      "        [ 1.2743e-01,  2.5444e-02, -1.5288e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1635, grad_fn=<StdBackward0>) tensor(0.1342, requires_grad=True) tensor(0.0602, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2350, 0.1976], grad_fn=<SliceBackward>)\n",
      "epoch 310 loss = 7.26E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[ 0.0089, -0.3381,  0.3292],\n",
      "        [ 0.5647,  0.9056, -1.4703],\n",
      "        [ 0.1313,  0.0254, -0.1567]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1605, grad_fn=<StdBackward0>) tensor(0.1285, requires_grad=True) tensor(0.0565, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2265, 0.1938], grad_fn=<SliceBackward>)\n",
      "epoch 320 loss = 7.56E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0106, -0.3545,  0.3651],\n",
      "        [ 0.5459,  0.9075, -1.4534],\n",
      "        [ 0.1443,  0.0284, -0.1727]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1783, grad_fn=<StdBackward0>) tensor(0.1476, requires_grad=True) tensor(0.0634, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2405, 0.1981], grad_fn=<SliceBackward>)\n",
      "epoch 330 loss = 6.97E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0107, -0.3490,  0.3382],\n",
      "        [ 0.5658,  0.9142, -1.4800],\n",
      "        [ 0.1449,  0.0290, -0.1739]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1820, grad_fn=<StdBackward0>) tensor(0.1472, requires_grad=True) tensor(0.0613, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2372, 0.1961], grad_fn=<SliceBackward>)\n",
      "epoch 340 loss = 6.80E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 0.0018, -0.3541,  0.3523],\n",
      "        [ 0.5574,  0.9201, -1.4775],\n",
      "        [ 0.1522,  0.0221, -0.1744]], grad_fn=<AddBackward0>)\n",
      "types? line 100 1024\n",
      "sds: tensor(0.1783, grad_fn=<StdBackward0>) tensor(0.1447, requires_grad=True) tensor(0.0658, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2377, 0.1980], grad_fn=<SliceBackward>)\n",
      "epoch 350 loss = 6.00E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0021, -0.3505,  0.3484],\n",
      "        [ 0.5645,  0.9228, -1.4874],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 0.1465,  0.0218, -0.1682]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1446, grad_fn=<StdBackward0>) tensor(0.1162, requires_grad=True) tensor(0.0585, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2403, 0.1940], grad_fn=<SliceBackward>)\n",
      "epoch 360 loss = 7.03E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 0.0097, -0.3469,  0.3372],\n",
      "        [ 0.5722,  0.9118, -1.4840],\n",
      "        [ 0.1390,  0.0171, -0.1561]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1677, grad_fn=<StdBackward0>) tensor(0.1380, requires_grad=True) tensor(0.0577, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2287, 0.1937], grad_fn=<SliceBackward>)\n",
      "epoch 370 loss = 7.31E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0089, -0.3421,  0.3511],\n",
      "        [ 0.5707,  0.9248, -1.4955],\n",
      "        [ 0.1242, -0.0015, -0.1227]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 51 1 :\n",
      "     676261966.0460861\n",
      "     676245120.927931\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.2287,  0.1937],\n",
      "        [-0.2376, -0.5359],\n",
      "        [ 0.3420,  0.7311]], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "jsonizing 2\n",
      "np complete? line 1311 1 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 1 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 2 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 2 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 3 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 3 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 4 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 4 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 5 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 5 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 6 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 6 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 7 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 7 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 8 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 8 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 9 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 9 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 10 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 10 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 16\n",
      "sampleYs line 1433 16\n",
      "np complete? line 1311 32\n",
      "sampleYs line 1433 32\n",
      "np complete? line 1311 64\n",
      "sampleYs line 1433 64\n",
      "np complete? line 1311 128\n",
      "sampleYs line 1433 128\n",
      "np complete? line 1311 256\n",
      "sampleYs line 1433 256\n",
      "np complete? line 1311 512\n",
      "sampleYs line 1433 512\n",
      "denses line 1447 1 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "BAsize torch.Size([7, 7])\n",
      "Inner comparing mean diagonals: gg_cov tensor(8.5449e-06) tensor(0.7947)\n",
      "np complete? line 1311 1024\n",
      "sampleYs line 1433 1024\n",
      "denses line 1447 2 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(8.5449e-06) tensor(0.7947) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 694 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 1 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 2048\n",
      "sampleYs line 1433 2048\n",
      "denses line 1447 3 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 2 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 4 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(8.6600e-06) tensor(0.7540) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 1388 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 3 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 5 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 4 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 4096\n",
      "sampleYs line 1433 4096\n",
      "denses line 1447 6 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(8.1579e-06) tensor(0.7205) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 2082 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 5 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 7 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 6 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 8 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(8.5957e-06) tensor(0.9045) ei_post_results_MSEbiasterm/\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "ei_post_results_MSEbiasterm/scenario_SIG0.02_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.2493, grad_fn=<StdBackward0>) tensor(0.2394, requires_grad=True) tensor(0.2112, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-47870009.8058, grad_fn=<AddBackward0>)\n",
      "     tensor(-2866.2239, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 7.44E+08, mean_loss=7.44E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-42964416.6790, grad_fn=<AddBackward0>)\n",
      "     tensor(-1929.8896, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-43777279.3215, grad_fn=<AddBackward0>)\n",
      "     tensor(-1877.4360, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-45609939.4220, grad_fn=<AddBackward0>)\n",
      "     tensor(-1849.2356, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-49213355.4726, grad_fn=<AddBackward0>)\n",
      "     tensor(-1844.9896, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-41085782.0838, grad_fn=<AddBackward0>)\n",
      "     tensor(-1776.2670, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n",
      "     tensor(-45976981.8341, grad_fn=<AddBackward0>)\n",
      "     tensor(-1847.6171, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-38059334.1599, grad_fn=<AddBackward0>)\n",
      "     tensor(-1920.6674, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-45027536.4062, grad_fn=<AddBackward0>)\n",
      "     tensor(-1768.8320, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-45404129.0232, grad_fn=<AddBackward0>)\n",
      "     tensor(-1662.1832, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.2292, grad_fn=<StdBackward0>) tensor(0.2174, requires_grad=True) tensor(0.1876, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0480, -0.0495], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 7.29E+08, mean_loss=7.37E+08;\n",
      " logitstar = tensor([[-0.0474, -0.0766,  0.1240],\n",
      "        [-0.0444, -0.0459,  0.0903],\n",
      "        [-0.0522, -0.0259,  0.0781]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.2696, grad_fn=<StdBackward0>) tensor(0.2540, requires_grad=True) tensor(0.2227, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0358, -0.0827], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 6.42E+08, mean_loss=7.32E+08;\n",
      " logitstar = tensor([[-0.0160, -0.1499,  0.1659],\n",
      "        [-0.0370, -0.0615,  0.0985],\n",
      "        [-0.0544, -0.0367,  0.0911]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.2603, grad_fn=<StdBackward0>) tensor(0.2578, requires_grad=True) tensor(0.2272, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0029, -0.0927], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 7.02E+08, mean_loss=7.26E+08;\n",
      " logitstar = tensor([[ 0.0254, -0.2070,  0.1816],\n",
      "        [ 0.0066, -0.0517,  0.0451],\n",
      "        [-0.0233, -0.0194,  0.0428]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.2338, grad_fn=<StdBackward0>) tensor(0.2263, requires_grad=True) tensor(0.1946, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0254, -0.0745], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 7.02E+08, mean_loss=7.21E+08;\n",
      " logitstar = tensor([[ 0.0244, -0.2368,  0.2124],\n",
      "        [ 0.0378, -0.0098, -0.0280],\n",
      "        [ 0.0139,  0.0231, -0.0370]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.1764, grad_fn=<StdBackward0>) tensor(0.1739, requires_grad=True) tensor(0.1384, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0518, -0.0381], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.29E+08, mean_loss=7.17E+08;\n",
      " logitstar = tensor([[ 0.0234, -0.2441,  0.2207],\n",
      "        [ 0.0790,  0.0676, -0.1466],\n",
      "        [ 0.0531,  0.0623, -0.1154]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1904, grad_fn=<StdBackward0>) tensor(0.1849, requires_grad=True) tensor(0.1398, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.0832, 0.0072], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 6.67E+08, mean_loss=7.14E+08;\n",
      " logitstar = tensor([[ 0.0167, -0.2426,  0.2259],\n",
      "        [ 0.1181,  0.1597, -0.2779],\n",
      "        [ 0.1149,  0.1044, -0.2193]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.1553, grad_fn=<StdBackward0>) tensor(0.1398, requires_grad=True) tensor(0.1050, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1101, 0.0537], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 6.44E+08, mean_loss=7.10E+08;\n",
      " logitstar = tensor([[ 0.0011, -0.2415,  0.2404],\n",
      "        [ 0.1492,  0.2551, -0.4043],\n",
      "        [ 0.1800,  0.1473, -0.3273]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1350, grad_fn=<StdBackward0>) tensor(0.1283, requires_grad=True) tensor(0.0820, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1445, 0.0978], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 7.20E+08, mean_loss=7.07E+08;\n",
      " logitstar = tensor([[-0.0063, -0.2457,  0.2521],\n",
      "        [ 0.2008,  0.3489, -0.5497],\n",
      "        [ 0.2390,  0.1903, -0.4293]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.1345, grad_fn=<StdBackward0>) tensor(0.1053, requires_grad=True) tensor(0.0639, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1740, 0.1278], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 6.12E+08, mean_loss=7.06E+08;\n",
      " logitstar = tensor([[-0.0184, -0.2651,  0.2835],\n",
      "        [ 0.2667,  0.4288, -0.6955],\n",
      "        [ 0.2736,  0.2199, -0.4935]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sds: tensor(0.1161, grad_fn=<StdBackward0>) tensor(0.0924, requires_grad=True) tensor(0.0450, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1974, 0.1617], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 6.98E+08, mean_loss=7.02E+08;\n",
      " logitstar = tensor([[-0.0045, -0.2810,  0.2855],\n",
      "        [ 0.3354,  0.5126, -0.8481],\n",
      "        [ 0.2614,  0.2536, -0.5150]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1385, grad_fn=<StdBackward0>) tensor(0.1002, requires_grad=True) tensor(0.0482, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2081, 0.1893], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 6.45E+08, mean_loss=6.96E+08;\n",
      " logitstar = tensor([[-0.0182, -0.3000,  0.3182],\n",
      "        [ 0.3945,  0.5902, -0.9846],\n",
      "        [ 0.2480,  0.2777, -0.5257]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1272, grad_fn=<StdBackward0>) tensor(0.1008, requires_grad=True) tensor(0.0393, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2190, 0.2124], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 7.02E+08, mean_loss=6.92E+08;\n",
      " logitstar = tensor([[-0.0177, -0.3226,  0.3403],\n",
      "        [ 0.4547,  0.6633, -1.1180],\n",
      "        [ 0.2199,  0.2965, -0.5164]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.1411, grad_fn=<StdBackward0>) tensor(0.1130, requires_grad=True) tensor(0.0372, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2265, 0.2265], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 6.65E+08, mean_loss=6.89E+08;\n",
      " logitstar = tensor([[-0.0104, -0.3362,  0.3466],\n",
      "        [ 0.4931,  0.7274, -1.2205],\n",
      "        [ 0.1969,  0.2884, -0.4853]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1579, grad_fn=<StdBackward0>) tensor(0.1271, requires_grad=True) tensor(0.0319, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2284, 0.2318], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 7.11E+08, mean_loss=6.87E+08;\n",
      " logitstar = tensor([[-0.0036, -0.3481,  0.3517],\n",
      "        [ 0.5081,  0.7826, -1.2908],\n",
      "        [ 0.1806,  0.2608, -0.4414]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1177, grad_fn=<StdBackward0>) tensor(0.1009, requires_grad=True) tensor(0.0284, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2285, 0.2343], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 6.99E+08, mean_loss=6.87E+08;\n",
      " logitstar = tensor([[ 0.0016, -0.3544,  0.3528],\n",
      "        [ 0.5203,  0.8351, -1.3555],\n",
      "        [ 0.1637,  0.2220, -0.3858]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1828, grad_fn=<StdBackward0>) tensor(0.1426, requires_grad=True) tensor(0.0325, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2323, 0.2331], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 6.17E+08, mean_loss=6.85E+08;\n",
      " logitstar = tensor([[ 0.0159, -0.3544,  0.3384],\n",
      "        [ 0.5155,  0.8783, -1.3938],\n",
      "        [ 0.1653,  0.1754, -0.3407]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.1857, grad_fn=<StdBackward0>) tensor(0.1473, requires_grad=True) tensor(0.0362, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2266, 0.2257], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 7.36E+08, mean_loss=6.84E+08;\n",
      " logitstar = tensor([[ 0.0083, -0.3670,  0.3587],\n",
      "        [ 0.4994,  0.8967, -1.3961],\n",
      "        [ 0.1721,  0.1475, -0.3196]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1485, grad_fn=<StdBackward0>) tensor(0.1240, requires_grad=True) tensor(0.0295, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2326, 0.2250], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 6.66E+08, mean_loss=6.82E+08;\n",
      " logitstar = tensor([[ 0.0141, -0.3667,  0.3526],\n",
      "        [ 0.5162,  0.9121, -1.4283],\n",
      "        [ 0.1676,  0.1297, -0.2972]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1746, grad_fn=<StdBackward0>) tensor(0.1395, requires_grad=True) tensor(0.0328, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2357, 0.2218], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 6.72E+08, mean_loss=6.79E+08;\n",
      " logitstar = tensor([[ 0.0127, -0.3558,  0.3431],\n",
      "        [ 0.5204,  0.9112, -1.4316],\n",
      "        [ 0.1741,  0.1101, -0.2842]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1481, grad_fn=<StdBackward0>) tensor(0.1193, requires_grad=True) tensor(0.0298, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2301, 0.2200], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 6.73E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0054, -0.3516,  0.3570],\n",
      "        [ 0.5131,  0.8976, -1.4107],\n",
      "        [ 0.1825,  0.1140, -0.2965]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1847, grad_fn=<StdBackward0>) tensor(0.1470, requires_grad=True) tensor(0.0316, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2350, 0.2202], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 6.23E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-2.6256e-04, -3.4750e-01,  3.4776e-01],\n",
      "        [ 5.1684e-01,  8.8598e-01, -1.4028e+00],\n",
      "        [ 1.8855e-01,  1.2199e-01, -3.1054e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1964, grad_fn=<StdBackward0>) tensor(0.1588, requires_grad=True) tensor(0.0370, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2383, 0.2159], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 5.95E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 0.0045, -0.3493,  0.3448],\n",
      "        [ 0.5250,  0.8879, -1.4128],\n",
      "        [ 0.1853,  0.1090, -0.2943]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1448, grad_fn=<StdBackward0>) tensor(0.1154, requires_grad=True) tensor(0.0298, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2409, 0.2143], grad_fn=<SliceBackward>)\n",
      "epoch 230 loss = 6.55E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[ 0.0035, -0.3474,  0.3439],\n",
      "        [ 0.5199,  0.8974, -1.4173],\n",
      "        [ 0.1993,  0.0928, -0.2921]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1409, grad_fn=<StdBackward0>) tensor(0.1130, requires_grad=True) tensor(0.0283, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2454, 0.2048], grad_fn=<SliceBackward>)\n",
      "epoch 240 loss = 7.23E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 2.5589e-04, -3.6064e-01,  3.6039e-01],\n",
      "        [ 5.1374e-01,  9.0061e-01, -1.4144e+00],\n",
      "        [ 2.2230e-01,  7.4570e-02, -2.9687e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1234, grad_fn=<StdBackward0>) tensor(0.1050, requires_grad=True) tensor(0.0267, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2560, 0.2081], grad_fn=<SliceBackward>)\n",
      "epoch 250 loss = 7.53E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 0.0046, -0.3522,  0.3476],\n",
      "        [ 0.5178,  0.9040, -1.4218],\n",
      "        [ 0.2454,  0.0725, -0.3179]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 256\n",
      "guide:begin line 51 256\n",
      "lp:  line 51 256\n",
      "guide:end line 51 256\n",
      "model:end line 51 512\n",
      "sds: tensor(0.2059, grad_fn=<StdBackward0>) tensor(0.1617, requires_grad=True) tensor(0.0351, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2517, 0.2067], grad_fn=<SliceBackward>)\n",
      "epoch 260 loss = 6.42E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0114, -0.3492,  0.3605],\n",
      "        [ 0.5191,  0.9024, -1.4215],\n",
      "        [ 0.2474,  0.0668, -0.3141]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1504, grad_fn=<StdBackward0>) tensor(0.1185, requires_grad=True) tensor(0.0274, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2497, 0.2007], grad_fn=<SliceBackward>)\n",
      "epoch 270 loss = 7.33E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0085, -0.3521,  0.3606],\n",
      "        [ 0.5155,  0.8965, -1.4120],\n",
      "        [ 0.2421,  0.0576, -0.2997]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1698, grad_fn=<StdBackward0>) tensor(0.1329, requires_grad=True) tensor(0.0312, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2532, 0.2005], grad_fn=<SliceBackward>)\n",
      "epoch 280 loss = 5.92E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[ 0.0017, -0.3467,  0.3449],\n",
      "        [ 0.5056,  0.9060, -1.4116],\n",
      "        [ 0.2522,  0.0420, -0.2942]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1852, grad_fn=<StdBackward0>) tensor(0.1505, requires_grad=True) tensor(0.0358, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2594, 0.1951], grad_fn=<SliceBackward>)\n",
      "epoch 290 loss = 6.81E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[ 0.0015, -0.3560,  0.3545],\n",
      "        [ 0.5061,  0.9025, -1.4087],\n",
      "        [ 0.2706,  0.0388, -0.3094]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1639, grad_fn=<StdBackward0>) tensor(0.1362, requires_grad=True) tensor(0.0291, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2658, 0.1968], grad_fn=<SliceBackward>)\n",
      "epoch 300 loss = 6.81E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[-0.0033, -0.3599,  0.3632],\n",
      "        [ 0.5043,  0.9055, -1.4098],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 0.2964,  0.0447, -0.3411]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1984, grad_fn=<StdBackward0>) tensor(0.1572, requires_grad=True) tensor(0.0319, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2675, 0.2103], grad_fn=<SliceBackward>)\n",
      "epoch 310 loss = 6.78E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-0.0117, -0.3354,  0.3470],\n",
      "        [ 0.5070,  0.9201, -1.4271],\n",
      "        [ 0.3071,  0.0462, -0.3533]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1681, grad_fn=<StdBackward0>) tensor(0.1362, requires_grad=True) tensor(0.0302, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2653, 0.2051], grad_fn=<SliceBackward>)\n",
      "epoch 320 loss = 6.30E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0130, -0.3447,  0.3577],\n",
      "        [ 0.5251,  0.9057, -1.4308],\n",
      "        [ 0.2838,  0.0544, -0.3382]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1311, grad_fn=<StdBackward0>) tensor(0.1139, requires_grad=True) tensor(0.0248, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2607, 0.1968], grad_fn=<SliceBackward>)\n",
      "epoch 330 loss = 6.47E+08, mean_loss=6.69E+08;\n",
      " logitstar = tensor([[-0.0117, -0.3477,  0.3595],\n",
      "        [ 0.5136,  0.8915, -1.4051],\n",
      "        [ 0.2803,  0.0466, -0.3270]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1445, grad_fn=<StdBackward0>) tensor(0.1272, requires_grad=True) tensor(0.0312, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2560, 0.1927], grad_fn=<SliceBackward>)\n",
      "epoch 340 loss = 6.78E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0097, -0.3525,  0.3622],\n",
      "        [ 0.5044,  0.9048, -1.4091],\n",
      "        [ 0.2735,  0.0259, -0.2993]], grad_fn=<AddBackward0>)\n",
      "types? line 100 1024\n",
      "sds: tensor(0.1734, grad_fn=<StdBackward0>) tensor(0.1378, requires_grad=True) tensor(0.0277, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2600, 0.1936], grad_fn=<SliceBackward>)\n",
      "epoch 350 loss = 6.66E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-1.2127e-03, -3.5038e-01,  3.5159e-01],\n",
      "        [ 5.1721e-01,  9.1980e-01, -1.4370e+00],\n",
      "        [ 2.6402e-01,  1.1340e-02, -2.7536e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1126, grad_fn=<StdBackward0>) tensor(0.0946, requires_grad=True) tensor(0.0251, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2592, 0.1940], grad_fn=<SliceBackward>)\n",
      "epoch 360 loss = 6.78E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-1.1676e-03, -3.4949e-01,  3.5065e-01],\n",
      "        [ 5.0877e-01,  9.2138e-01, -1.4301e+00],\n",
      "        [ 2.6992e-01,  1.0012e-02, -2.7993e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2153, grad_fn=<StdBackward0>) tensor(0.1721, requires_grad=True) tensor(0.0365, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2616, 0.1921], grad_fn=<SliceBackward>)\n",
      "epoch 370 loss = 5.68E+08, mean_loss=6.69E+08;\n",
      " logitstar = tensor([[-0.0051, -0.3471,  0.3522],\n",
      "        [ 0.4966,  0.9136, -1.4102],\n",
      "        [ 0.2932,  0.0096, -0.3029]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1815, grad_fn=<StdBackward0>) tensor(0.1373, requires_grad=True) tensor(0.0327, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2620, 0.1882], grad_fn=<SliceBackward>)\n",
      "epoch 380 loss = 5.47E+08, mean_loss=6.68E+08;\n",
      " logitstar = tensor([[-0.0055, -0.3458,  0.3513],\n",
      "        [ 0.5040,  0.8977, -1.4017],\n",
      "        [ 0.2873,  0.0127, -0.3000]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1191, grad_fn=<StdBackward0>) tensor(0.1067, requires_grad=True) tensor(0.0231, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2681, 0.1882], grad_fn=<SliceBackward>)\n",
      "epoch 390 loss = 7.19E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0034, -0.3426,  0.3460],\n",
      "        [ 0.4994,  0.9012, -1.4005],\n",
      "        [ 0.3083,  0.0061, -0.3144]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1518, grad_fn=<StdBackward0>) tensor(0.1226, requires_grad=True) tensor(0.0287, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2679, 0.1868], grad_fn=<SliceBackward>)\n",
      "epoch 400 loss = 6.64E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0050, -0.3501,  0.3550],\n",
      "        [ 0.5006,  0.9011, -1.4017],\n",
      "        [ 0.3080,  0.0094, -0.3174]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1189, grad_fn=<StdBackward0>) tensor(0.0964, requires_grad=True) tensor(0.0257, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2628, 0.1916], grad_fn=<SliceBackward>)\n",
      "epoch 410 loss = 6.72E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0096, -0.3429,  0.3525],\n",
      "        [ 0.5198,  0.9153, -1.4351],\n",
      "        [ 0.2781,  0.0023, -0.2804]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1358, grad_fn=<StdBackward0>) tensor(0.1130, requires_grad=True) tensor(0.0272, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2667, 0.1928], grad_fn=<SliceBackward>)\n",
      "epoch 420 loss = 6.74E+08, mean_loss=6.69E+08;\n",
      " logitstar = tensor([[-0.0031, -0.3413,  0.3444],\n",
      "        [ 0.5212,  0.9153, -1.4365],\n",
      "        [ 0.2819,  0.0044, -0.2863]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1480, grad_fn=<StdBackward0>) tensor(0.1179, requires_grad=True) tensor(0.0294, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2623, 0.1890], grad_fn=<SliceBackward>)\n",
      "epoch 430 loss = 6.36E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[-0.0103, -0.3440,  0.3543],\n",
      "        [ 0.5081,  0.9089, -1.4170],\n",
      "        [ 0.2892,  0.0020, -0.2912]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1572, grad_fn=<StdBackward0>) tensor(0.1297, requires_grad=True) tensor(0.0301, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2634, 0.1868], grad_fn=<SliceBackward>)\n",
      "epoch 440 loss = 6.55E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0069, -0.3454,  0.3523],\n",
      "        [ 0.5070,  0.8977, -1.4048],\n",
      "        [ 0.2899,  0.0081, -0.2980]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1543, grad_fn=<StdBackward0>) tensor(0.1199, requires_grad=True) tensor(0.0276, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2633, 0.1926], grad_fn=<SliceBackward>)\n",
      "epoch 450 loss = 6.13E+08, mean_loss=6.70E+08;\n",
      " logitstar = tensor([[-0.0175, -0.3407,  0.3582],\n",
      "        [ 0.5143,  0.9133, -1.4276],\n",
      "        [ 0.2930,  0.0051, -0.2981]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1682, grad_fn=<StdBackward0>) tensor(0.1270, requires_grad=True) tensor(0.0294, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2710, 0.1887], grad_fn=<SliceBackward>)\n",
      "epoch 460 loss = 6.17E+08, mean_loss=6.71E+08;\n",
      " logitstar = tensor([[-0.0077, -0.3464,  0.3541],\n",
      "        [ 0.5140,  0.9083, -1.4223],\n",
      "        [ 0.3069,  0.0042, -0.3111]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1597, grad_fn=<StdBackward0>) tensor(0.1260, requires_grad=True) tensor(0.0285, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2742, 0.1857], grad_fn=<SliceBackward>)\n",
      "epoch 470 loss = 6.77E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[-3.4978e-03, -3.4824e-01,  3.5174e-01],\n",
      "        [ 5.0624e-01,  9.0616e-01, -1.4124e+00],\n",
      "        [ 3.1976e-01, -8.9279e-04, -3.1886e-01]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 51 1 :\n",
      "     673740365.6967701\n",
      "     669173001.4961851\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.2742,  0.1857],\n",
      "        [-0.2777, -0.5339],\n",
      "        [ 0.2321,  0.7205]], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "jsonizing 2\n",
      "np complete? line 1311 1 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 1 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 2 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 2 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 3 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 3 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 4 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 4 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 5 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 5 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 6 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 6 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 7 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 7 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 8 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 8 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 9 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 9 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 10 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 10 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 16\n",
      "sampleYs line 1433 16\n",
      "np complete? line 1311 32\n",
      "sampleYs line 1433 32\n",
      "np complete? line 1311 64\n",
      "sampleYs line 1433 64\n",
      "np complete? line 1311 128\n",
      "sampleYs line 1433 128\n",
      "np complete? line 1311 256\n",
      "sampleYs line 1433 256\n",
      "np complete? line 1311 512\n",
      "sampleYs line 1433 512\n",
      "denses line 1447 1 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "BAsize torch.Size([7, 7])\n",
      "Inner comparing mean diagonals: gg_cov tensor(2.3389e-05) tensor(14.0194)\n",
      "np complete? line 1311 1024\n",
      "sampleYs line 1433 1024\n",
      "denses line 1447 2 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.3389e-05) tensor(14.0194) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 694 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 1 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 2048\n",
      "sampleYs line 1433 2048\n",
      "denses line 1447 3 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 2 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 4 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.2542e-05) tensor(12.6481) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 1388 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 3 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 5 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 4 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 4096\n",
      "sampleYs line 1433 4096\n",
      "denses line 1447 6 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(1.6430e-05) tensor(8.5126) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 2082 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 5 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 7 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 6 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 8 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.2630e-05) tensor(12.8008) ei_post_results_MSEbiasterm/\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "ei_post_results_MSEbiasterm/scenario_SIG0.3_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.3187, grad_fn=<StdBackward0>) tensor(0.3039, requires_grad=True) tensor(0.2746, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-38325128.0516, grad_fn=<AddBackward0>)\n",
      "     tensor(-2466.5428, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 6.05E+08, mean_loss=6.05E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-44716771.3876, grad_fn=<AddBackward0>)\n",
      "     tensor(-1990.1902, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-43114246.1878, grad_fn=<AddBackward0>)\n",
      "     tensor(-1894.2786, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-42425487.1629, grad_fn=<AddBackward0>)\n",
      "     tensor(-1942.4637, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-44299912.9923, grad_fn=<AddBackward0>)\n",
      "     tensor(-1996.3285, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-43341516.3880, grad_fn=<AddBackward0>)\n",
      "     tensor(-2009.2110, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n",
      "     tensor(-50486714.6855, grad_fn=<AddBackward0>)\n",
      "     tensor(-2084.3703, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-42829614.5493, grad_fn=<AddBackward0>)\n",
      "     tensor(-2069.4875, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-44789902.8024, grad_fn=<AddBackward0>)\n",
      "     tensor(-1969.8330, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-44354893.3945, grad_fn=<AddBackward0>)\n",
      "     tensor(-1932.3914, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.3123, grad_fn=<StdBackward0>) tensor(0.3019, requires_grad=True) tensor(0.2762, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0227, -0.0550], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 7.55E+08, mean_loss=6.18E+08;\n",
      " logitstar = tensor([[-0.0121, -0.0584,  0.0705],\n",
      "        [-0.0373, -0.0471,  0.0844],\n",
      "        [-0.0187, -0.0595,  0.0781]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.3488, grad_fn=<StdBackward0>) tensor(0.3386, requires_grad=True) tensor(0.3132, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 4.4891e-05, -1.0388e-01], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 6.50E+08, mean_loss=6.27E+08;\n",
      " logitstar = tensor([[ 0.0198, -0.1240,  0.1041],\n",
      "        [-0.0204, -0.1084,  0.1289],\n",
      "        [ 0.0007, -0.0792,  0.0785]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.3494, grad_fn=<StdBackward0>) tensor(0.3402, requires_grad=True) tensor(0.3213, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0056, -0.1368], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 7.09E+08, mean_loss=6.38E+08;\n",
      " logitstar = tensor([[ 0.0180, -0.1604,  0.1424],\n",
      "        [-0.0193, -0.1349,  0.1542],\n",
      "        [-0.0154, -0.1150,  0.1304]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.2935, grad_fn=<StdBackward0>) tensor(0.2773, requires_grad=True) tensor(0.2525, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0137, -0.1226], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 7.49E+08, mean_loss=6.49E+08;\n",
      " logitstar = tensor([[ 0.0311, -0.1566,  0.1254],\n",
      "        [-0.0043, -0.0989,  0.1032],\n",
      "        [ 0.0142, -0.1124,  0.0982]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.3539, grad_fn=<StdBackward0>) tensor(0.3420, requires_grad=True) tensor(0.3155, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0402, -0.1092], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.31E+08, mean_loss=6.55E+08;\n",
      " logitstar = tensor([[ 0.0585, -0.1418,  0.0833],\n",
      "        [ 0.0198, -0.0763,  0.0565],\n",
      "        [ 0.0424, -0.1094,  0.0670]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2705, grad_fn=<StdBackward0>) tensor(0.2529, requires_grad=True) tensor(0.2326, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0598, -0.0987], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 6.59E+08, mean_loss=6.60E+08;\n",
      " logitstar = tensor([[ 0.0712, -0.1345,  0.0632],\n",
      "        [ 0.0368, -0.0577,  0.0209],\n",
      "        [ 0.0713, -0.1039,  0.0326]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.2892, grad_fn=<StdBackward0>) tensor(0.2750, requires_grad=True) tensor(0.2521, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0556, -0.1064], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 6.88E+08, mean_loss=6.65E+08;\n",
      " logitstar = tensor([[ 0.0686, -0.1459,  0.0773],\n",
      "        [ 0.0308, -0.0646,  0.0338],\n",
      "        [ 0.0676, -0.1087,  0.0411]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3071, grad_fn=<StdBackward0>) tensor(0.2942, requires_grad=True) tensor(0.2666, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0506, -0.1132], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 7.57E+08, mean_loss=6.72E+08;\n",
      " logitstar = tensor([[ 0.0692, -0.1479,  0.0788],\n",
      "        [ 0.0242, -0.0717,  0.0475],\n",
      "        [ 0.0584, -0.1201,  0.0617]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.3340, grad_fn=<StdBackward0>) tensor(0.3228, requires_grad=True) tensor(0.2971, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0580, -0.1141], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 7.67E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[ 0.0807, -0.1540,  0.0733],\n",
      "        [ 0.0329, -0.0673,  0.0344],\n",
      "        [ 0.0604, -0.1209,  0.0606]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3081, grad_fn=<StdBackward0>) tensor(0.2919, requires_grad=True) tensor(0.2717, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0619, -0.1145], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 6.77E+08, mean_loss=6.81E+08;\n",
      " logitstar = tensor([[ 0.0803, -0.1664,  0.0861],\n",
      "        [ 0.0325, -0.0643,  0.0318],\n",
      "        [ 0.0727, -0.1129,  0.0402]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2745, grad_fn=<StdBackward0>) tensor(0.2600, requires_grad=True) tensor(0.2443, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0476, -0.1085], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 8.12E+08, mean_loss=6.86E+08;\n",
      " logitstar = tensor([[ 0.0685, -0.1560,  0.0875],\n",
      "        [ 0.0251, -0.0687,  0.0435],\n",
      "        [ 0.0492, -0.1007,  0.0515]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3084, grad_fn=<StdBackward0>) tensor(0.2964, requires_grad=True) tensor(0.2677, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0494, -0.1018], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 7.00E+08, mean_loss=6.89E+08;\n",
      " logitstar = tensor([[ 0.0686, -0.1354,  0.0667],\n",
      "        [ 0.0374, -0.0824,  0.0450],\n",
      "        [ 0.0422, -0.0875,  0.0453]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.2790, grad_fn=<StdBackward0>) tensor(0.2633, requires_grad=True) tensor(0.2404, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0542, -0.0870], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 7.23E+08, mean_loss=6.88E+08;\n",
      " logitstar = tensor([[ 0.0686, -0.1138,  0.0452],\n",
      "        [ 0.0444, -0.0638,  0.0194],\n",
      "        [ 0.0495, -0.0834,  0.0339]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2995, grad_fn=<StdBackward0>) tensor(0.2870, requires_grad=True) tensor(0.2655, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0287, -0.0992], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 7.10E+08, mean_loss=6.94E+08;\n",
      " logitstar = tensor([[ 0.0388, -0.1159,  0.0771],\n",
      "        [ 0.0196, -0.0818,  0.0622],\n",
      "        [ 0.0276, -0.0998,  0.0722]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3022, grad_fn=<StdBackward0>) tensor(0.2919, requires_grad=True) tensor(0.2696, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0275, -0.1056], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 7.82E+08, mean_loss=6.95E+08;\n",
      " logitstar = tensor([[ 0.0437, -0.1246,  0.0810],\n",
      "        [ 0.0143, -0.0897,  0.0754],\n",
      "        [ 0.0245, -0.1025,  0.0780]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3534, grad_fn=<StdBackward0>) tensor(0.3424, requires_grad=True) tensor(0.3108, grad_fn=<StdBackward0>)\n",
      "ps2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ecstar = tensor([ 0.0435, -0.1048], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 6.57E+08, mean_loss=6.95E+08;\n",
      " logitstar = tensor([[ 0.0615, -0.1367,  0.0752],\n",
      "        [ 0.0273, -0.0912,  0.0638],\n",
      "        [ 0.0417, -0.0865,  0.0448]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.3123, grad_fn=<StdBackward0>) tensor(0.2980, requires_grad=True) tensor(0.2653, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0564, -0.1116], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 6.84E+08, mean_loss=6.95E+08;\n",
      " logitstar = tensor([[ 0.0744, -0.1484,  0.0740],\n",
      "        [ 0.0445, -0.0884,  0.0439],\n",
      "        [ 0.0502, -0.0981,  0.0480]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3228, grad_fn=<StdBackward0>) tensor(0.3109, requires_grad=True) tensor(0.2894, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0561, -0.1129], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 7.55E+08, mean_loss=6.97E+08;\n",
      " logitstar = tensor([[ 0.0754, -0.1474,  0.0719],\n",
      "        [ 0.0440, -0.0935,  0.0495],\n",
      "        [ 0.0488, -0.0978,  0.0490]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.3037, grad_fn=<StdBackward0>) tensor(0.2910, requires_grad=True) tensor(0.2734, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0561, -0.1134], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 7.38E+08, mean_loss=6.99E+08;\n",
      " logitstar = tensor([[ 0.0703, -0.1421,  0.0718],\n",
      "        [ 0.0431, -0.0840,  0.0409],\n",
      "        [ 0.0549, -0.1140,  0.0591]], grad_fn=<AddBackward0>)\n",
      "Cutoff reached line 51 1 :\n",
      "     698911587.9560229\n",
      "     654230896.5196248\n",
      "trainGuide post..................................................\n",
      ",,\n",
      ",,\n",
      ",,\n",
      "ec_then_erc_star:\n",
      "tensor([[ 0.0561, -0.1134],\n",
      "        [ 0.0142, -0.0287],\n",
      "        [-0.0130,  0.0293]], grad_fn=<SliceBackward>) (10 elems)\n",
      "::\n",
      "::\n",
      "rerunGuide 2774 0 None 694\n",
      "    rerunGuide 2774 0 None 694\n",
      "jsonizing 2\n",
      "np complete? line 1311 1 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 1 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 2 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 2 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 3 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 3 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 4 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 4 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 5 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 5 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 6 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 6 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 7 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 7 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 8 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 8 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 9 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 9 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 10 :\n",
      "     \n",
      "    Size 0: [400]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 9]; noNAN\n",
      "    Size 3: [400, 3, 3]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400, 9]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "sampleYs line 1433 10 :\n",
      "     \n",
      "    Size 0: [400, 13]; noNAN\n",
      "    Size 1: [400, 1, 13]; noNAN\n",
      "    Size 2: [13]; noNAN\n",
      "    Size 3: [694, 13, 13]; noNAN\n",
      "    Size 4: [400, 7]; noNAN\n",
      "    Size 5: [400, 3, 3]; noNAN\n",
      "    Size 6: [400, 1]; noNAN\n",
      "np complete? line 1311 16\n",
      "sampleYs line 1433 16\n",
      "np complete? line 1311 32\n",
      "sampleYs line 1433 32\n",
      "np complete? line 1311 64\n",
      "sampleYs line 1433 64\n",
      "np complete? line 1311 128\n",
      "sampleYs line 1433 128\n",
      "np complete? line 1311 256\n",
      "sampleYs line 1433 256\n",
      "np complete? line 1311 512\n",
      "sampleYs line 1433 512\n",
      "denses line 1447 1 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "BAsize torch.Size([7, 7])\n",
      "Inner comparing mean diagonals: gg_cov tensor(2.9533e-06) tensor(0.0011)\n",
      "np complete? line 1311 1024\n",
      "sampleYs line 1433 1024\n",
      "denses line 1447 2 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.9533e-06) tensor(0.0011) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 694 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 1 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 2048\n",
      "sampleYs line 1433 2048\n",
      "denses line 1447 3 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 2 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 4 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.9555e-06) tensor(0.0011) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 1388 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 3 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 5 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 4 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Size 6: [400]; noNAN\n",
      "np complete? line 1311 4096\n",
      "sampleYs line 1433 4096\n",
      "denses line 1447 6 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.8974e-06) tensor(0.0013) ei_post_results_MSEbiasterm/\n",
      "    rerunGuide 2774 2082 None 694\n",
      "jsonizing 2\n",
      "sampleYs0 line 1395 5 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 7 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "sampleYs0 line 1395 6 :\n",
      "     \n",
      "    Size 0: [400, 7]; noNAN\n",
      "    Size 1: [400, 3, 3]; noNAN\n",
      "    Size 2: [400, 4]; noNAN\n",
      "    Size 3: [400]; noNAN\n",
      "    Size 4: [400]; noNAN\n",
      "    Size 5: [400]; noNAN\n",
      "    Size 6: [400]; noNAN\n",
      "denses line 1447 8 :\n",
      "     \n",
      "    Size 0: [400, 4]; noNAN\n",
      "Comparing mean diagonals: gg_cov tensor(2.8488e-06) tensor(0.0012) ei_post_results_MSEbiasterm/\n",
      "Done trainGuide..................................................\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "ei_post_results_MSEbiasterm/scenario_SIG0.1_0_N2774.csv from file\n",
      "svi.step(... line 51 1 :\n",
      "     0\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 1 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 1 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 2 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 3 :\n",
      "     [torch.float64, torch.float64]\n",
      "sds: tensor(0.2382, grad_fn=<StdBackward0>) tensor(0.2266, requires_grad=True) tensor(0.1945, grad_fn=<StdBackward0>)\n",
      "model:end line 51 1 :\n",
      "lp:  line 51 1 :\n",
      "     tensor(-44882446.5678, grad_fn=<AddBackward0>)\n",
      "     tensor(-2783.1748, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "ps2\n",
      "guide:end line 51 1 :\n",
      "model:end line 51 2 :\n",
      " ecstar = tensor([-0.0050, -0.0050], grad_fn=<SliceBackward>)\n",
      "epoch 0 loss = 6.96E+08, mean_loss=6.96E+08;\n",
      " logitstar = tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.0150, -0.0150,  0.0300]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 2 :\n",
      "     1\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 2 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 4 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 5 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 6 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 3 :\n",
      "lp:  line 51 2 :\n",
      "     tensor(-45626403.2935, grad_fn=<AddBackward0>)\n",
      "     tensor(-2029.2002, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 2 :\n",
      "model:end line 51 4 :\n",
      "svi.step(... line 51 3 :\n",
      "     2\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 3 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 7 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 8 :\n",
      "     [torch.float64, torch.float64]\n",
      "types? line 100 9 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 5 :\n",
      "lp:  line 51 3 :\n",
      "     tensor(-45035998.4196, grad_fn=<AddBackward0>)\n",
      "     tensor(-1870.4201, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 3 :\n",
      "model:end line 51 6 :\n",
      "svi.step(... line 51 4 :\n",
      "     3\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 4 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 10 :\n",
      "     [torch.float64, torch.float64]\n",
      "model:end line 51 7 :\n",
      "lp:  line 51 4 :\n",
      "     tensor(-44061332.1707, grad_fn=<AddBackward0>)\n",
      "     tensor(-1690.4635, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 4 :\n",
      "model:end line 51 8 :\n",
      "svi.step(... line 51 5 :\n",
      "     4\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 5 :\n",
      "     27.74\n",
      "     True\n",
      "model:end line 51 9 :\n",
      "lp:  line 51 5 :\n",
      "     tensor(-43654825.3986, grad_fn=<AddBackward0>)\n",
      "     tensor(-1642.9284, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 5 :\n",
      "model:end line 51 10 :\n",
      "svi.step(... line 51 6 :\n",
      "     5\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 6 :\n",
      "     27.74\n",
      "     True\n",
      "types? line 100 16\n",
      "lp:  line 51 6 :\n",
      "     tensor(-47125709.8701, grad_fn=<AddBackward0>)\n",
      "     tensor(-1693.7549, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 6 :\n",
      "svi.step(... line 51 7 :\n",
      "     6\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 7 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 7 :\n",
      "     tensor(-43038109.3642, grad_fn=<AddBackward0>)\n",
      "     tensor(-1678.6519, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 7 :\n",
      "svi.step(... line 51 8 :\n",
      "     7\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 8 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 8 :\n",
      "     tensor(-47901609.3365, grad_fn=<AddBackward0>)\n",
      "     tensor(-1677.4694, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 8 :\n",
      "model:end line 51 16\n",
      "svi.step(... line 51 9 :\n",
      "     8\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 9 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 9 :\n",
      "     tensor(-43671900.6090, grad_fn=<AddBackward0>)\n",
      "     tensor(-1659.4011, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 9 :\n",
      "svi.step(... line 51 10 :\n",
      "     9\n",
      "     27.74\n",
      "     torch.Size([100, 9])\n",
      "guide:begin line 51 10 :\n",
      "     27.74\n",
      "     True\n",
      "lp:  line 51 10 :\n",
      "     tensor(-39670459.2069, grad_fn=<AddBackward0>)\n",
      "     tensor(-1636.2449, grad_fn=<AddBackward0>)\n",
      "     806\n",
      "guide:end line 51 10 :\n",
      "types? line 100 32\n",
      "sds: tensor(0.2900, grad_fn=<StdBackward0>) tensor(0.2813, requires_grad=True) tensor(0.2458, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0410, -0.0535], grad_fn=<SliceBackward>)\n",
      "epoch 10 loss = 6.34E+08, mean_loss=6.96E+08;\n",
      " logitstar = tensor([[-0.0469, -0.0807,  0.1276],\n",
      "        [-0.0202, -0.0647,  0.0849],\n",
      "        [-0.0558, -0.0153,  0.0711]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 16\n",
      "guide:begin line 51 16\n",
      "lp:  line 51 16\n",
      "guide:end line 51 16\n",
      "model:end line 51 32\n",
      "sds: tensor(0.2422, grad_fn=<StdBackward0>) tensor(0.2380, requires_grad=True) tensor(0.2118, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([-0.0193, -0.0929], grad_fn=<SliceBackward>)\n",
      "epoch 20 loss = 7.05E+08, mean_loss=6.96E+08;\n",
      " logitstar = tensor([[-0.0178, -0.1277,  0.1455],\n",
      "        [-0.0055, -0.0863,  0.0918],\n",
      "        [-0.0345, -0.0648,  0.0993]], grad_fn=<AddBackward0>)\n",
      "types? line 100 64\n",
      "sds: tensor(0.2047, grad_fn=<StdBackward0>) tensor(0.1978, requires_grad=True) tensor(0.1725, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0117, -0.1002], grad_fn=<SliceBackward>)\n",
      "epoch 30 loss = 6.57E+08, mean_loss=6.95E+08;\n",
      " logitstar = tensor([[ 0.0249, -0.1571,  0.1321],\n",
      "        [ 0.0066, -0.0711,  0.0645],\n",
      "        [ 0.0035, -0.0724,  0.0689]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 32\n",
      "guide:begin line 51 32\n",
      "lp:  line 51 32\n",
      "guide:end line 51 32\n",
      "model:end line 51 64\n",
      "sds: tensor(0.1884, grad_fn=<StdBackward0>) tensor(0.1810, requires_grad=True) tensor(0.1479, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0235, -0.1039], grad_fn=<SliceBackward>)\n",
      "epoch 40 loss = 6.48E+08, mean_loss=6.95E+08;\n",
      " logitstar = tensor([[ 0.0404, -0.1968,  0.1564],\n",
      "        [ 0.0093, -0.0533,  0.0440],\n",
      "        [ 0.0208, -0.0616,  0.0408]], grad_fn=<AddBackward0>)\n",
      "types? line 100 128\n",
      "sds: tensor(0.2775, grad_fn=<StdBackward0>) tensor(0.2742, requires_grad=True) tensor(0.2491, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0327, -0.0827], grad_fn=<SliceBackward>)\n",
      "epoch 50 loss = 7.76E+08, mean_loss=6.97E+08;\n",
      " logitstar = tensor([[ 0.0250, -0.2181,  0.1931],\n",
      "        [ 0.0192,  0.0009, -0.0201],\n",
      "        [ 0.0538, -0.0310, -0.0228]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2418, grad_fn=<StdBackward0>) tensor(0.2353, requires_grad=True) tensor(0.1989, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0502, -0.0479], grad_fn=<SliceBackward>)\n",
      "epoch 60 loss = 7.00E+08, mean_loss=6.96E+08;\n",
      " logitstar = tensor([[ 0.0159, -0.2250,  0.2091],\n",
      "        [ 0.0371,  0.0722, -0.1093],\n",
      "        [ 0.0977,  0.0089, -0.1066]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 64\n",
      "guide:begin line 51 64\n",
      "lp:  line 51 64\n",
      "guide:end line 51 64\n",
      "model:end line 51 128\n",
      "sds: tensor(0.2132, grad_fn=<StdBackward0>) tensor(0.1984, requires_grad=True) tensor(0.1586, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([ 0.0843, -0.0090], grad_fn=<SliceBackward>)\n",
      "epoch 70 loss = 6.50E+08, mean_loss=6.95E+08;\n",
      " logitstar = tensor([[ 0.0170, -0.2285,  0.2115],\n",
      "        [ 0.0810,  0.1557, -0.2367],\n",
      "        [ 0.1550,  0.0459, -0.2008]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1834, grad_fn=<StdBackward0>) tensor(0.1770, requires_grad=True) tensor(0.1403, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1102, 0.0202], grad_fn=<SliceBackward>)\n",
      "epoch 80 loss = 6.98E+08, mean_loss=6.95E+08;\n",
      " logitstar = tensor([[ 0.0032, -0.2467,  0.2435],\n",
      "        [ 0.1264,  0.2329, -0.3593],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 0.2010,  0.0743, -0.2753]], grad_fn=<AddBackward0>)\n",
      "types? line 100 256\n",
      "sds: tensor(0.1605, grad_fn=<StdBackward0>) tensor(0.1475, requires_grad=True) tensor(0.1110, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1406, 0.0583], grad_fn=<SliceBackward>)\n",
      "epoch 90 loss = 6.64E+08, mean_loss=6.94E+08;\n",
      " logitstar = tensor([[ 0.0064, -0.2536,  0.2471],\n",
      "        [ 0.1920,  0.3204, -0.5123],\n",
      "        [ 0.2235,  0.1081, -0.3316]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1562, grad_fn=<StdBackward0>) tensor(0.1427, requires_grad=True) tensor(0.1052, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1605, 0.1000], grad_fn=<SliceBackward>)\n",
      "epoch 100 loss = 7.45E+08, mean_loss=6.96E+08;\n",
      " logitstar = tensor([[-5.3999e-05, -2.5766e-01,  2.5772e-01],\n",
      "        [ 2.5669e-01,  4.1189e-01, -6.6857e-01],\n",
      "        [ 2.2501e-01,  1.4592e-01, -3.7092e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1345, grad_fn=<StdBackward0>) tensor(0.1138, requires_grad=True) tensor(0.0779, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.1768, 0.1276], grad_fn=<SliceBackward>)\n",
      "epoch 110 loss = 6.82E+08, mean_loss=6.91E+08;\n",
      " logitstar = tensor([[-0.0164, -0.2758,  0.2922],\n",
      "        [ 0.3211,  0.4893, -0.8104],\n",
      "        [ 0.2256,  0.1692, -0.3947]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1372, grad_fn=<StdBackward0>) tensor(0.1133, requires_grad=True) tensor(0.0700, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2020, 0.1590], grad_fn=<SliceBackward>)\n",
      "epoch 120 loss = 6.44E+08, mean_loss=6.90E+08;\n",
      " logitstar = tensor([[-0.0114, -0.2827,  0.2941],\n",
      "        [ 0.3957,  0.5707, -0.9664],\n",
      "        [ 0.2216,  0.1890, -0.4105]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 128\n",
      "guide:begin line 51 128\n",
      "lp:  line 51 128\n",
      "guide:end line 51 128\n",
      "model:end line 51 256\n",
      "sds: tensor(0.1430, grad_fn=<StdBackward0>) tensor(0.1125, requires_grad=True) tensor(0.0594, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2160, 0.1808], grad_fn=<SliceBackward>)\n",
      "epoch 130 loss = 8.04E+08, mean_loss=6.90E+08;\n",
      " logitstar = tensor([[-0.0193, -0.3058,  0.3252],\n",
      "        [ 0.4595,  0.6425, -1.1021],\n",
      "        [ 0.2079,  0.2058, -0.4137]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1625, grad_fn=<StdBackward0>) tensor(0.1172, requires_grad=True) tensor(0.0648, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2281, 0.1986], grad_fn=<SliceBackward>)\n",
      "epoch 140 loss = 6.55E+08, mean_loss=6.89E+08;\n",
      " logitstar = tensor([[-0.0203, -0.3133,  0.3336],\n",
      "        [ 0.5186,  0.7104, -1.2290],\n",
      "        [ 0.1860,  0.1989, -0.3849]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1726, grad_fn=<StdBackward0>) tensor(0.1331, requires_grad=True) tensor(0.0662, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2374, 0.2055], grad_fn=<SliceBackward>)\n",
      "epoch 150 loss = 6.60E+08, mean_loss=6.86E+08;\n",
      " logitstar = tensor([[-0.0160, -0.3269,  0.3429],\n",
      "        [ 0.5553,  0.7672, -1.3225],\n",
      "        [ 0.1729,  0.1762, -0.3492]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1822, grad_fn=<StdBackward0>) tensor(0.1456, requires_grad=True) tensor(0.0669, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2423, 0.2063], grad_fn=<SliceBackward>)\n",
      "epoch 160 loss = 6.47E+08, mean_loss=6.83E+08;\n",
      " logitstar = tensor([[-0.0050, -0.3433,  0.3483],\n",
      "        [ 0.5716,  0.8180, -1.3896],\n",
      "        [ 0.1605,  0.1441, -0.3046]], grad_fn=<AddBackward0>)\n",
      "types? line 100 512\n",
      "sds: tensor(0.1824, grad_fn=<StdBackward0>) tensor(0.1504, requires_grad=True) tensor(0.0637, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2349, 0.2118], grad_fn=<SliceBackward>)\n",
      "epoch 170 loss = 6.63E+08, mean_loss=6.83E+08;\n",
      " logitstar = tensor([[-0.0075, -0.3435,  0.3510],\n",
      "        [ 0.5617,  0.8725, -1.4342],\n",
      "        [ 0.1505,  0.1065, -0.2569]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1850, grad_fn=<StdBackward0>) tensor(0.1489, requires_grad=True) tensor(0.0599, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2257, 0.2138], grad_fn=<SliceBackward>)\n",
      "epoch 180 loss = 6.16E+08, mean_loss=6.81E+08;\n",
      " logitstar = tensor([[-0.0071, -0.3333,  0.3404],\n",
      "        [ 0.5585,  0.9142, -1.4726],\n",
      "        [ 0.1258,  0.0604, -0.1862]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1554, grad_fn=<StdBackward0>) tensor(0.1252, requires_grad=True) tensor(0.0602, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2291, 0.1967], grad_fn=<SliceBackward>)\n",
      "epoch 190 loss = 6.83E+08, mean_loss=6.79E+08;\n",
      " logitstar = tensor([[ 1.1780e-03, -3.5773e-01,  3.5655e-01],\n",
      "        [ 5.7961e-01,  9.1292e-01, -1.4925e+00],\n",
      "        [ 1.0663e-01,  3.5005e-02, -1.4164e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1830, grad_fn=<StdBackward0>) tensor(0.1495, requires_grad=True) tensor(0.0643, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2354, 0.1960], grad_fn=<SliceBackward>)\n",
      "epoch 200 loss = 6.46E+08, mean_loss=6.79E+08;\n",
      " logitstar = tensor([[ 0.0062, -0.3495,  0.3433],\n",
      "        [ 0.5846,  0.9186, -1.5032],\n",
      "        [ 0.1153,  0.0190, -0.1343]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2016, grad_fn=<StdBackward0>) tensor(0.1680, requires_grad=True) tensor(0.0625, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2297, 0.1996], grad_fn=<SliceBackward>)\n",
      "epoch 210 loss = 6.28E+08, mean_loss=6.79E+08;\n",
      " logitstar = tensor([[-0.0077, -0.3356,  0.3433],\n",
      "        [ 0.5819,  0.9193, -1.5012],\n",
      "        [ 0.1149,  0.0151, -0.1300]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1809, grad_fn=<StdBackward0>) tensor(0.1431, requires_grad=True) tensor(0.0625, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2292, 0.1956], grad_fn=<SliceBackward>)\n",
      "epoch 220 loss = 6.02E+08, mean_loss=6.78E+08;\n",
      " logitstar = tensor([[-2.0332e-03, -3.3470e-01,  3.3673e-01],\n",
      "        [ 5.8237e-01,  9.2068e-01, -1.5031e+00],\n",
      "        [ 1.0734e-01,  7.7528e-04, -1.0812e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1594, grad_fn=<StdBackward0>) tensor(0.1243, requires_grad=True) tensor(0.0542, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2328, 0.1896], grad_fn=<SliceBackward>)\n",
      "epoch 230 loss = 6.33E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[ 0.0029, -0.3446,  0.3417],\n",
      "        [ 0.5813,  0.9070, -1.4884],\n",
      "        [ 0.1140,  0.0064, -0.1204]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1908, grad_fn=<StdBackward0>) tensor(0.1496, requires_grad=True) tensor(0.0585, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2259, 0.1934], grad_fn=<SliceBackward>)\n",
      "epoch 240 loss = 6.59E+08, mean_loss=6.77E+08;\n",
      " logitstar = tensor([[-0.0104, -0.3393,  0.3497],\n",
      "        [ 0.5590,  0.9029, -1.4619],\n",
      "        [ 0.1291,  0.0166, -0.1458]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2124, grad_fn=<StdBackward0>) tensor(0.1702, requires_grad=True) tensor(0.0652, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2255, 0.2023], grad_fn=<SliceBackward>)\n",
      "epoch 250 loss = 6.46E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0087, -0.3268,  0.3355],\n",
      "        [ 0.5569,  0.9057, -1.4626],\n",
      "        [ 0.1284,  0.0280, -0.1564]], grad_fn=<AddBackward0>)\n",
      "svi.step(... line 51 256\n",
      "guide:begin line 51 256\n",
      "lp:  line 51 256\n",
      "guide:end line 51 256\n",
      "model:end line 51 512\n",
      "sds: tensor(0.1635, grad_fn=<StdBackward0>) tensor(0.1316, requires_grad=True) tensor(0.0574, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2244, 0.1986], grad_fn=<SliceBackward>)\n",
      "epoch 260 loss = 6.88E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[-0.0102, -0.3398,  0.3500],\n",
      "        [ 0.5700,  0.8986, -1.4686],\n",
      "        [ 0.1133,  0.0372, -0.1505]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2125, grad_fn=<StdBackward0>) tensor(0.1776, requires_grad=True) tensor(0.0671, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2335, 0.1984], grad_fn=<SliceBackward>)\n",
      "epoch 270 loss = 6.54E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 0.0068, -0.3464,  0.3396],\n",
      "        [ 0.5864,  0.9053, -1.4917],\n",
      "        [ 0.1073,  0.0363, -0.1436]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1740, grad_fn=<StdBackward0>) tensor(0.1397, requires_grad=True) tensor(0.0580, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2272, 0.1942], grad_fn=<SliceBackward>)\n",
      "epoch 280 loss = 6.65E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0072, -0.3535,  0.3607],\n",
      "        [ 0.5703,  0.8999, -1.4702],\n",
      "        [ 0.1184,  0.0361, -0.1545]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1739, grad_fn=<StdBackward0>) tensor(0.1357, requires_grad=True) tensor(0.0558, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2345, 0.1999], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 290 loss = 6.57E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[ 0.0094, -0.3410,  0.3316],\n",
      "        [ 0.5783,  0.9129, -1.4912],\n",
      "        [ 0.1158,  0.0278, -0.1436]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1906, grad_fn=<StdBackward0>) tensor(0.1574, requires_grad=True) tensor(0.0625, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2285, 0.1975], grad_fn=<SliceBackward>)\n",
      "epoch 300 loss = 6.22E+08, mean_loss=6.75E+08;\n",
      " logitstar = tensor([[-0.0018, -0.3553,  0.3571],\n",
      "        [ 0.5663,  0.9230, -1.4893],\n",
      "        [ 0.1211,  0.0249, -0.1460]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1773, grad_fn=<StdBackward0>) tensor(0.1427, requires_grad=True) tensor(0.0661, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2311, 0.1989], grad_fn=<SliceBackward>)\n",
      "epoch 310 loss = 6.90E+08, mean_loss=6.73E+08;\n",
      " logitstar = tensor([[ 0.0039, -0.3552,  0.3513],\n",
      "        [ 0.5604,  0.9262, -1.4866],\n",
      "        [ 0.1290,  0.0259, -0.1549]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.2339, grad_fn=<StdBackward0>) tensor(0.1881, requires_grad=True) tensor(0.0684, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2402, 0.1987], grad_fn=<SliceBackward>)\n",
      "epoch 320 loss = 6.50E+08, mean_loss=6.74E+08;\n",
      " logitstar = tensor([[ 0.0155, -0.3480,  0.3325],\n",
      "        [ 0.5549,  0.9279, -1.4828],\n",
      "        [ 0.1503,  0.0161, -0.1664]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1935, grad_fn=<StdBackward0>) tensor(0.1559, requires_grad=True) tensor(0.0696, grad_fn=<StdBackward0>)\n",
      "ps2\n",
      " ecstar = tensor([0.2306, 0.1958], grad_fn=<SliceBackward>)\n",
      "epoch 330 loss = 5.96E+08, mean_loss=6.76E+08;\n",
      " logitstar = tensor([[ 3.6896e-04, -3.4857e-01,  3.4821e-01],\n",
      "        [ 5.5497e-01,  9.2100e-01, -1.4760e+00],\n",
      "        [ 1.3634e-01,  1.4951e-02, -1.5129e-01]], grad_fn=<AddBackward0>)\n",
      "sds: tensor(0.1458, grad_fn=<StdBackward0>) tensor(0.1182, requires_grad=True) tensor(0.0539, grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-54314cdba83b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msigma_nu\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;36m.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m.02\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#.02,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m#%prun result = trainGuide(nsamps=nsamps,subsample_n=subn)#inits = inits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mtrainGuide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsamps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnsamps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubsample_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigmanu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma_nu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_full\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#,inits = inits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;31m#modelQvar(sigmanu=sigma_nu)#,samps=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\ei_multisampleQ.py\u001b[0m in \u001b[0;36mtrainGuide\u001b[1;34m(subsample_n, filebase, nsteps, sigmanu, dummydata, nsamps, dversion, inits, num_y_samps, force_full)\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[0mddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"svi.step(...\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindeps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1599\u001b[0m         loss = svi.step(subset,scale,True,do_print=(i % 10 == 0),nsamps=nsamps,\n\u001b[1;32m-> 1600\u001b[1;33m                 inits=inits)\n\u001b[0m\u001b[0;32m   1601\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetachRecursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#I hate memory leaks!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# get loss and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m# grab a trace from the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \"\"\"\n\u001b[0;32m     51\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[1;32m---> 52\u001b[1;33m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[1;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \"\"\"\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mguide_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[0;32m     45\u001b[0m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\ei_multisampleQ.py\u001b[0m in \u001b[0;36mguide\u001b[1;34m(data, scale, include_nuisance, do_print, inits, nsamps, icky_sigma, *args, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m                     \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma_star_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#tensors, not elements=gamma_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[0mtensors_per_unit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                     return_grad=True)\n\u001b[0m\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\utilities\\myhessian.py\u001b[0m in \u001b[0;36marrowhead_hessian_precision\u001b[1;34m(output_raw, inputs, headsize, blocksize, allow_unused, create_graph, return_grad)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                     \u001b[1;31m#print(f\"arrow {i},{maxi},{headsize},{blocksize}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                     \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                     \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hessian-0.0.0-py3.7.egg\\hessian\\gradient.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     20\u001b[0m                                 \u001b[0mallow_unused\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                                 create_graph=create_graph)\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei_multisampleQ #import *\n",
    "reload(ei_multisampleQ)\n",
    "from ei_multisampleQ import *\n",
    "import cProfile as profile\n",
    "\n",
    "#ec,erc = legible_values(3,3)\n",
    "#print(ec,\"\\n\",erc,\"\\n\",ec+erc)\n",
    "#inits = good_inits(1.)\n",
    "#del inits[\"ercstar_raw\"]\n",
    "for (nsamps,subn) in [(15,100)]:#[(2,60),(5,60),(2,30),(20,30),(40,5)]:\n",
    "    \n",
    "    for i in range(1,3):\n",
    "        for sigma_nu in [ .3,.1,  .02,]: #.02, \n",
    "            #%prun result = trainGuide(nsamps=nsamps,subsample_n=subn)#inits = inits)\n",
    "            trainGuide(nsamps=nsamps,subsample_n=subn,sigmanu=sigma_nu,dversion=i, force_full=True)#,inits = inits)\n",
    "            #modelQvar(sigmanu=sigma_nu)#,samps=5)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base:Yes, I will run. line 5 3 :\n",
      "Reloading polytopize.\n",
      "tensor([[ 0.0500, -0.9100,  1.2200],\n",
      "        [ 0.2100,  0.0100, -0.9500],\n",
      "        [ 0.3400, -0.5400,  0.5800]])\n",
      "0.15\n",
      "0.15\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import ei_multisample #import *\n",
    "reload(ei_multisample)\n",
    "from ei_multisample import *\n",
    "import cProfile as profile\n",
    "\n",
    "inits = dict() #good_inits()\n",
    "#del inits[\"ercstar_raw\"]\n",
    "#%prun result = trainGuide(inits = inits)\n",
    "\n",
    "NCparams = EIData.load(\"NC_Data/NC_2016_statewide_alpha_and_beta.csv\")\n",
    "print(NCparams.alpha + NCparams.beta)\n",
    "#print(\"components\")\n",
    "#print(NCparams.alpha)\n",
    "#\n",
    "#print(NCparams.beta)\n",
    "print(SIM_SIGMA_NU)\n",
    "SIM_SIGMA_NU = 0.001\n",
    "print(ei_multisample.SIM_SIGMA_NU)\n",
    "ei_multisample.SIM_SIGMA_NU = .0001\n",
    "print(ei_multisample.SIM_SIGMA_NU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing hessian transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hess tensor([[6., 0., 0., 0.],\n",
      "        [0., 6., 0., 0.],\n",
      "        [0., 0., 6., 0.],\n",
      "        [0., 0., 0., 6.]], grad_fn=<CopySlices>)\n",
      "d  tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "d  tensor(12., grad_fn=<SumBackward0>)\n",
      "ddd  (tensor([[6., 6.],\n",
      "        [6., 6.]]),)\n",
      "(tensor([[72., 72.],\n",
      "        [72., 72.]]),)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ts = torch.tensor\n",
    "os = torch.ones\n",
    "zs = torch.zeros\n",
    "from importlib import reload\n",
    "import myhessian\n",
    "reload(myhessian)\n",
    "\n",
    "t1 = os(2,2,requires_grad=True)\n",
    "r = torch.sum(t1 * t1 * t1)\n",
    "\n",
    "h = myhessian.hessian(r,t1)\n",
    "print(\"hess\",h)\n",
    "r2 = torch.sum(h * h)\n",
    "[r3] = torch.autograd.grad(r,t1,create_graph=True,retain_graph=True)\n",
    "print(\"d \",r3)\n",
    "print(\"d \",torch.sum(r3))\n",
    "[r4] = torch.autograd.grad(torch.sum(r3),t1,create_graph=True,retain_graph=True)\n",
    "print(\"ddd \",torch.autograd.grad(torch.sum(r4),t1,create_graph=True,retain_graph=True))\n",
    "print(torch.autograd.grad(r2,t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I will run.\n",
      "Yes, I will run.\n",
      "ge fail\n",
      "loc tensor([[ 0.3147],\n",
      "        [ 2.4440],\n",
      "        [-4.0535],\n",
      "        [ 2.2007]])\n",
      "polytopedLoc tensor([[ 2.1063e-01,  2.1136e-02],\n",
      "        [ 2.8514e-01, -1.8626e-09],\n",
      "        [ 3.4959e-01,  9.9957e-02],\n",
      "        [ 3.5462e-01,  1.1892e-02],\n",
      "        [ 2.5462e+00,  3.2228e-01]])\n",
      "ge fail\n",
      "loc tensor([[-5.8855],\n",
      "        [-5.2805],\n",
      "        [ 5.4654],\n",
      "        [ 0.1889]])\n",
      "polytopedLoc tensor([[ 2.8885e-01,  1.1871e+00],\n",
      "        [ 8.5629e-01,  2.0505e+00],\n",
      "        [ 3.9984e-01, -1.4901e-08],\n",
      "        [ 9.5542e-01,  1.5538e+00],\n",
      "        [ 1.0063e+00,  9.9522e-01]])\n",
      "Reloading cmult...\n",
      "callable? <bound method TorchDistributionMixin.__call__ of Multinomial()>\n",
      "callable? <bound method TorchDistributionMixin.__call__ of TorchCMult()>\n",
      "Sampling multinomial: tensor([1., 2.])\n",
      "Sampling cm2: tensor([0., 3.])\n",
      "tensor(5.6022, grad_fn=<NegBackward>) tensor([[112.2500]])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import hessian\n",
    "\n",
    "from importlib import reload\n",
    "import polytopize #import *\n",
    "reload(polytopize)\n",
    "from polytopize import *\n",
    "\n",
    "import tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test rank1torch (to get yhat from pi,n,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing optimize_Q (50 tests): \n",
      "R=3, C=5, tolerance=0.001\n",
      "==================================================\n",
      "Oh no! In test 3, Q has some negative entries:\n",
      "\t trueQ[2][4]=0.00010659269901225343, \n",
      "\t     Q[2][4]=-0.00021605131041724235\n",
      "Oh no! In test 5, Q has some negative entries:\n",
      "\t trueQ[1][4]=0.00011974151857430115, \n",
      "\t     Q[1][4]=-1.1631345842033625e-06\n",
      "Oh no! In test 8, Q has some negative entries:\n",
      "\t trueQ[0][1]=2.882161788875237e-05, \n",
      "\t     Q[0][1]=-0.0004783869662787765\n",
      "Oh no! In test 15, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.0007846675580367446, \n",
      "\t     Q[2][3]=-6.166117964312434e-05\n",
      "Oh no! In test 28, Q has some negative entries:\n",
      "\t trueQ[0][4]=8.13114020274952e-05, \n",
      "\t     Q[0][4]=-0.00018321917741559446\n",
      "Oh no! In test 40, Q has some negative entries:\n",
      "\t trueQ[2][3]=0.00032634526723995805, \n",
      "\t     Q[2][3]=-0.000617634505033493\n",
      "Oh no! In test 47, Q has some negative entries:\n",
      "\t trueQ[2][1]=0.00017936740186996758, \n",
      "\t     Q[2][1]=-0.00041433278238400817\n",
      "Oh no! In test 48, Q has some negative entries:\n",
      "\t trueQ[0][0]=4.524858377408236e-05, \n",
      "\t     Q[0][0]=-0.0006647921400144696\n",
      "\n",
      "Cumulative results for the 50 tests \n",
      "(R=3, C=5, tolerance=0.001):\n",
      "-------------------------------------------\n",
      "Worst error in entry of Q: 0.0019194334745407104\n",
      "\n",
      "To get within tolerance, it took us:\n",
      "002 iterations: ***** 5.0 times\n",
      "003 iterations: ********** 10.0 times\n",
      "004 iterations: *********** 11.0 times\n",
      "005 iterations: ****** 6.0 times\n",
      "006 iterations: **** 4.0 times\n",
      "007 iterations: **** 4.0 times\n",
      "008 iterations: ****** 6.0 times\n",
      "010 iterations: *** 3.0 times\n",
      "013 iterations: * 1.0 times\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import rank1torch #import *\n",
    "reload(rank1torch)\n",
    "from rank1torch import *\n",
    "\n",
    "test_solver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Most SVI problems in pyro are coded as a model, a generic guide (such as: multivariate Gaussian in all parameters), and specific observations/data (passed as arguments to svi.step). For EI, that's going to be different; the observations are going to be built into the guide function, leaving nothing to include in the \"data\" argument to svi.step.\n",
    "\n",
    "That means there is a lot of work for the guide to do. As usual, it must establish reasonable distributional families for the posterior of each of the hyperparameters. But for the latent parameters, the job of the guide is to take a \"relative strength\" number for each race/candidate/precinct combo, and turn that into a number of votes for each combo, such that those numbers obey all the constraints set by observations. This means that for each precinct (considered separately), the latent guide must:\n",
    "\n",
    "-Find the \"center point\" where candidate preference is independent of race.\n",
    "\n",
    "-Find the \"basis vectors\" (actually, there are more than enough of them to form a basis) which determine the directions to move in the space.\n",
    "\n",
    "-For any given set of \"relative strengths\" which is a distance $d$ in a direction $\\theta$, find the first constraint violated when moving in that direction, and the distance $r$ between the origin and that constraint.\n",
    "\n",
    "-Project the \"relative strengths\" onto the numbers of votes, by moving $r(1-e^{-d})$ in direction $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a = zs(2,2,2,2)\n",
    "a[0,1,1,1] = 2\n",
    "print(a[1,1])\n",
    "print(a[0,1])\n",
    "print(torch.max(a))\n",
    "print(torch.distributions.exponential.Exponential(ts([1])).sample(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
