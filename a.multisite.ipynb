{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "1\n",
      "exception: [Errno 2] No such file or directory: 'testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv'\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv created\n",
      "44\n",
      "tensor([-3.1530,  2.8530,  7.0121, -1.9480])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 265.7834322452545;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "complaint 9 assert approx_eq( tensor([-2.7901e+01,  2.5214e+01,  3.5639e+02, -6.2773e+00,  7.8169e-08,\n",
      "         4.3887e+02, -3.0162e+01,  2.3478e+01, -1.5303e+02, -1.5692e+03,\n",
      "         1.7010e+02,  3.7738e+03, -3.1116e+01, -2.9878e+01,  3.0790e+01,\n",
      "        -3.6496e+02,  8.6667e+01, -1.1278e+00,  1.4731e+03,  2.5302e+01,\n",
      "         4.1634e+00,  3.4109e+02, -6.2827e-03, -4.5942e-03,  2.0862e+02,\n",
      "         1.0490e+04,  2.1211e+03,  2.8949e-01, -7.2642e+02, -1.1324e+01,\n",
      "         6.0602e+01, -6.3807e+01,  2.1726e+01, -4.0522e+02, -1.9944e+02,\n",
      "        -4.6461e+00, -4.2444e+03, -1.4130e+04,  2.5262e+03, -1.5545e+01,\n",
      "        -8.7570e+02,  1.8663e+01,  9.5685e-03, -3.2433e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 2.8120e+01, -2.5360e+01, -3.5731e+02,  6.3015e+00, -7.8507e-08,\n",
      "        -4.3916e+02,  3.0274e+01, -2.3552e+01,  1.5316e+02,  1.5699e+03,\n",
      "        -1.7071e+02, -3.7768e+03,  3.1326e+01,  3.0379e+01, -3.1065e+01,\n",
      "         3.6554e+02, -8.6985e+01,  1.1404e+00, -1.4756e+03, -2.5376e+01,\n",
      "        -4.2289e+00, -3.4140e+02,  6.6436e-03,  4.6688e-03, -2.0866e+02,\n",
      "        -1.0491e+04, -2.1230e+03, -3.0342e-01,  7.2654e+02,  1.1659e+01,\n",
      "        -6.1180e+01,  6.3818e+01, -2.2164e+01,  4.0549e+02,  1.9956e+02,\n",
      "         4.6565e+00,  4.2446e+03,  1.4131e+04, -2.5265e+03,  1.5866e+01,\n",
      "         8.7826e+02, -1.8932e+01, -9.6133e-03,  3.2479e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([-1.5616e+01,  1.5000e+01,  3.6726e+01, -9.3517e+00,  2.1630e-02,\n",
      "         3.8594e+01, -1.5849e+01,  1.4543e+01, -2.7095e+01, -5.9252e+01,\n",
      "         2.8622e+01,  8.1468e+01, -1.6160e+01, -1.6393e+01,  1.6203e+01,\n",
      "        -3.6633e+01,  2.2691e+01, -5.3141e+00,  5.9916e+01,  1.4904e+01,\n",
      "         8.2960e+00,  3.5533e+01, -9.8319e-01, -8.5101e-01,  2.9928e+01,\n",
      "         1.1108e+02,  6.6671e+01,  3.5063e+00, -4.5406e+01, -1.1981e+01,\n",
      "         2.0478e+01, -2.0144e+01,  1.4777e+01, -3.7565e+01, -2.9563e+01,\n",
      "        -8.4340e+00, -8.1801e+01, -1.2268e+02,  6.8893e+01, -1.3151e+01,\n",
      "        -5.0889e+01,  1.3823e+01,  1.0744e+00, -1.6132e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ 1.5397e+01, -1.4855e+01, -3.5804e+01,  9.3275e+00, -2.1630e-02,\n",
      "        -3.8303e+01,  1.5737e+01, -1.4468e+01,  2.6965e+01,  5.8558e+01,\n",
      "        -2.8009e+01, -7.8482e+01,  1.5950e+01,  1.5892e+01, -1.5928e+01,\n",
      "         3.6053e+01, -2.2372e+01,  5.3015e+00, -5.7409e+01, -1.4830e+01,\n",
      "        -8.2306e+00, -3.5225e+01,  9.8283e-01,  8.5094e-01, -2.9880e+01,\n",
      "        -1.1027e+02, -6.4776e+01, -3.4924e+00,  4.5287e+01,  1.1646e+01,\n",
      "        -1.9973e+01,  2.0131e+01, -1.4338e+01,  3.7298e+01,  2.9446e+01,\n",
      "         8.4237e+00,  8.1558e+01,  1.2178e+02, -6.8608e+01,  1.2830e+01,\n",
      "         4.8331e+01, -1.3554e+01, -1.0744e+00,  1.6086e+01],\n",
      "       grad_fn=<MulBackward0>)\n",
      "complaint 8 assert2 approx_eq( tensor([-7.6294e-06, -5.7220e-06, -3.8147e-06, -9.5367e-07,  2.7940e-08,\n",
      "         2.2888e-05,  1.2398e-05,  7.6294e-06, -1.3351e-05, -6.4850e-05,\n",
      "         3.8147e-06,  3.0518e-05, -1.5259e-05, -9.5367e-07,  8.5831e-06,\n",
      "        -2.6703e-05,  5.9128e-05, -4.7684e-07,  8.3923e-05, -7.6294e-06,\n",
      "         9.5367e-07,  2.2888e-05, -2.3842e-07,  2.9802e-07,  1.9073e-05,\n",
      "         5.5695e-04,  6.8665e-05,  0.0000e+00, -6.4850e-05,  1.9073e-06,\n",
      "        -7.2773e-02, -1.0738e-03, -3.8147e-06, -1.9073e-05,  3.4332e-05,\n",
      "        -1.9073e-06,  1.2970e-04, -9.9182e-04, -1.5259e-04, -1.9073e-06,\n",
      "         3.0518e-05,  2.8610e-06,  1.1921e-07,  1.5259e-05],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 7 dm.grad\n",
      "complaint 6 dtr.grad\n",
      "complaint 5 ddfr.grad\n",
      "complaint 4 dm.grad\n",
      "complaint 3 dtr.grad\n",
      "complaint 2 ddfr.grad\n",
      "complaint 1 assert approx_eq( tensor([-2.7902e+01,  2.5222e+01,  3.5642e+02, -6.2764e+00,  8.7907e-08,\n",
      "         4.3890e+02, -3.0160e+01,  2.3484e+01, -1.5302e+02, -1.5691e+03,\n",
      "         1.7012e+02,  3.7739e+03, -3.1115e+01, -2.9884e+01,  3.0801e+01,\n",
      "        -3.6494e+02,  8.6682e+01, -1.1278e+00,  1.4731e+03,  2.5308e+01,\n",
      "         4.1671e+00,  3.4112e+02, -6.2836e-03, -4.5840e-03,  2.0864e+02,\n",
      "         1.0490e+04,  2.1212e+03,  2.9035e-01, -7.2638e+02, -1.1331e+01,\n",
      "         6.1068e+01, -6.3805e+01,  2.1740e+01, -4.0520e+02, -1.9943e+02,\n",
      "        -4.6451e+00, -4.2443e+03, -1.4130e+04,  2.5263e+03, -1.5551e+01,\n",
      "        -8.7568e+02,  1.8673e+01,  9.5939e-03, -3.2429e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 2.8119e+01, -2.5366e+01, -3.5734e+02,  6.3003e+00, -8.8282e-08,\n",
      "        -4.3919e+02,  3.0271e+01, -2.3557e+01,  1.5315e+02,  1.5698e+03,\n",
      "        -1.7073e+02, -3.7769e+03,  3.1324e+01,  3.0382e+01, -3.1074e+01,\n",
      "         3.6552e+02, -8.6999e+01,  1.1402e+00, -1.4756e+03, -2.5381e+01,\n",
      "        -4.2318e+00, -3.4142e+02,  6.6384e-03,  4.6571e-03, -2.0868e+02,\n",
      "        -1.0491e+04, -2.1231e+03, -3.0409e-01,  7.2650e+02,  1.1663e+01,\n",
      "        -6.1495e+01,  6.3814e+01, -2.2175e+01,  4.0546e+02,  1.9954e+02,\n",
      "         4.6553e+00,  4.2445e+03,  1.4130e+04, -2.5266e+03,  1.5868e+01,\n",
      "         8.7823e+02, -1.8941e+01, -9.6380e-03,  3.2474e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([-1.5847e+01,  1.5226e+01,  3.7268e+01, -9.4924e+00,  2.2834e-02,\n",
      "         3.9176e+01, -1.6087e+01,  1.4763e+01, -2.7504e+01, -6.0140e+01,\n",
      "         2.9046e+01,  8.2655e+01, -1.6400e+01, -1.6630e+01,  1.6444e+01,\n",
      "        -3.7178e+01,  2.3030e+01, -5.3936e+00,  6.0783e+01,  1.5130e+01,\n",
      "         8.4213e+00,  3.6069e+01, -9.9725e-01, -8.6307e-01,  3.0383e+01,\n",
      "         1.1276e+02,  6.7652e+01,  3.5601e+00, -4.6093e+01, -1.2154e+01,\n",
      "         2.0830e+01, -2.0449e+01,  1.4992e+01, -3.8130e+01, -3.0009e+01,\n",
      "        -8.5611e+00, -8.3040e+01, -1.2453e+02,  6.9937e+01, -1.3342e+01,\n",
      "        -5.1615e+01,  1.4028e+01,  1.0916e+00, -1.6375e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ 1.5630e+01, -1.5082e+01, -3.6349e+01,  9.4685e+00, -2.2834e-02,\n",
      "        -3.8887e+01,  1.5976e+01, -1.4689e+01,  2.7374e+01,  5.9448e+01,\n",
      "        -2.8436e+01, -7.9677e+01,  1.6191e+01,  1.6133e+01, -1.6171e+01,\n",
      "         3.6600e+01, -2.2713e+01,  5.3812e+00, -5.8283e+01, -1.5057e+01,\n",
      "        -8.3566e+00, -3.5762e+01,  9.9690e-01,  8.6300e-01, -3.0336e+01,\n",
      "        -1.1195e+02, -6.5762e+01, -3.5463e+00,  4.5974e+01,  1.1822e+01,\n",
      "        -2.0278e+01,  2.0436e+01, -1.4557e+01,  3.7864e+01,  2.9893e+01,\n",
      "         8.5509e+00,  8.2797e+01,  1.2363e+02, -6.9653e+01,  1.3024e+01,\n",
      "         4.9065e+01, -1.3761e+01, -1.0916e+00,  1.6330e+01],\n",
      "       grad_fn=<MulBackward0>)\n",
      "complaint 0 assert2 approx_eq( tensor([-3.8147e-06,  7.6294e-06, -3.8147e-06,  9.5367e-07, -3.7253e-07,\n",
      "         2.6703e-05,  0.0000e+00,  1.0490e-05, -2.4796e-05,  3.8147e-06,\n",
      "        -3.8147e-06,  2.4414e-04, -9.5367e-06, -5.7220e-06, -3.8147e-06,\n",
      "         1.9073e-05,  5.9128e-05,  0.0000e+00,  1.1826e-04, -2.8610e-06,\n",
      "        -9.5367e-07,  1.9073e-05, -2.9802e-07,  5.9605e-08,  7.6294e-06,\n",
      "         6.4087e-04,  2.2888e-05,  0.0000e+00, -5.7220e-05, -9.5367e-07,\n",
      "         1.2514e-01, -3.5324e-03,  0.0000e+00, -4.1962e-05,  1.5259e-05,\n",
      "         0.0000e+00,  2.5177e-04, -8.6212e-04,  9.9182e-05,  2.8610e-06,\n",
      "        -6.4850e-05,  0.0000e+00, -4.7684e-07, -5.7220e-06],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 0\n",
      "yay -140\n",
      "complaint -20\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 266.07786750793457;\n",
      "mode_hat tensor(-0.1965, requires_grad=True)\n",
      "ltscale_hat tensor(0.5017, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4943, requires_grad=True)\n",
      "yay -320\n",
      "complaint -40\n",
      "complaint -60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay -380\n",
      "complaint -80\n",
      "yay -440\n",
      "complaint -100\n",
      "yay -500\n",
      "complaint -120\n",
      "epoch 200 loss = 186.60689616203308;\n",
      "mode_hat tensor(-0.1895, requires_grad=True)\n",
      "ltscale_hat tensor(0.9778, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9168, requires_grad=True)\n",
      "complaint -140\n",
      "yay -560\n",
      "yay -620\n",
      "complaint -160\n",
      "complaint -180\n",
      "yay -680\n",
      "complaint -200\n",
      "yay -740\n",
      "epoch 300 loss = 206.8032693862915;\n",
      "mode_hat tensor(-0.1821, requires_grad=True)\n",
      "ltscale_hat tensor(1.3578, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.2166, requires_grad=True)\n",
      "yay -800\n",
      "yay -860\n",
      "complaint -220\n",
      "complaint -240\n",
      "complaint -260\n",
      "yay -920\n",
      "yay -980\n",
      "complaint -280\n",
      "yay -1040\n",
      "complaint -300\n",
      "epoch 400 loss = 183.98835253715515;\n",
      "mode_hat tensor(-0.1126, requires_grad=True)\n",
      "ltscale_hat tensor(1.5761, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.3365, requires_grad=True)\n",
      "complaint -320\n",
      "yay -1100\n",
      "complaint -340\n",
      "complaint -360\n",
      "yay -1160\n",
      "complaint -380\n",
      "complaint -400\n",
      "complaint -420\n",
      "complaint -440\n",
      "complaint -460\n",
      "complaint -480\n",
      "complaint -500\n",
      "complaint -520\n",
      "complaint -540\n",
      "complaint -560\n",
      "yay -1220\n",
      "complaint -580\n",
      "complaint -600\n",
      "complaint -620\n",
      "epoch 500 loss = 195.43048977851868;\n",
      "mode_hat tensor(-0.1532, requires_grad=True)\n",
      "ltscale_hat tensor(1.6309, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.2925, requires_grad=True)\n",
      "complaint -640\n",
      "complaint -660\n",
      "complaint -680\n",
      "complaint -700\n",
      "complaint -720\n",
      "complaint -740\n",
      "yay -1280\n",
      "complaint -760\n",
      "complaint -780\n",
      "yay -1340\n",
      "complaint -800\n",
      "complaint -820\n",
      "yay -1400\n",
      "complaint -840\n",
      "yay -1460\n",
      "epoch 600 loss = 192.3054916858673;\n",
      "mode_hat tensor(-0.0985, requires_grad=True)\n",
      "ltscale_hat tensor(1.5874, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.2038, requires_grad=True)\n",
      "complaint -860\n",
      "complaint -880\n",
      "yay -1520\n",
      "complaint -900\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "complaint -920\n",
      "epoch 700 loss = 176.03254055976868;\n",
      "mode_hat tensor(-0.0515, requires_grad=True)\n",
      "ltscale_hat tensor(1.6326, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.1467, requires_grad=True)\n",
      "yay -1760\n",
      "complaint -940\n",
      "yay -1820\n",
      "complaint -960\n",
      "yay -1880\n",
      "complaint -980\n",
      "complaint -1000\n",
      "complaint -1020\n",
      "yay -1940\n",
      "complaint -1040\n",
      "complaint -1060\n",
      "yay -2000\n",
      "complaint -1080\n",
      "epoch 800 loss = 171.55048859119415;\n",
      "mode_hat tensor(0.0035, requires_grad=True)\n",
      "ltscale_hat tensor(1.5892, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0509, requires_grad=True)\n",
      "complaint -1100\n",
      "complaint -1120\n",
      "complaint -1140\n",
      "yay -2060\n",
      "complaint -1160\n",
      "complaint -1180\n",
      "yay -2120\n",
      "complaint -1200\n",
      "complaint -1220\n",
      "yay -2180\n",
      "complaint -1240\n",
      "yay -2240\n",
      "complaint -1260\n",
      "yay -2300\n",
      "epoch 900 loss = 182.15159225463867;\n",
      "mode_hat tensor(-0.0436, requires_grad=True)\n",
      "ltscale_hat tensor(1.6529, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0112, requires_grad=True)\n",
      "yay -2360\n",
      "yay -2420\n",
      "Final mean_losses: 187.85366518933046\n",
      "save_data {'modal_effect': tensor(-0.0400, requires_grad=True), 't_scale_raw': tensor(1.6424, requires_grad=True), 't_part': tensor([-3.2487,  2.6294, -7.2089,  7.5463, 21.8349,  4.3816, -1.1075, 12.7966],\n",
      "       grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(8.9790, grad_fn=<AddBackward0>), 'hessian': tensor([[ 8.2652e+03,  0.0000e+00,  9.8211e+02,  1.2095e+02,  2.3662e+02,\n",
      "          5.0746e+02,  5.6202e+02,  2.3332e+02,  3.0898e+02,  1.3878e+02],\n",
      "        [ 0.0000e+00,  8.1788e+00,  2.3849e-01, -2.1250e-01,  2.2500e-01,\n",
      "         -2.1699e-01, -3.2642e-02, -2.6041e-01,  1.0503e-01, -1.0620e-01],\n",
      "        [ 9.8211e+02,  2.3849e-01,  9.8214e+02,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2095e+02, -2.1250e-01,  0.0000e+00,  1.2099e+02,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3662e+02,  2.2500e-01,  0.0000e+00,  0.0000e+00,  2.3662e+02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.0746e+02, -2.1699e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          5.0746e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.6202e+02, -3.2642e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  5.6202e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3332e+02, -2.6041e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.3335e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.0898e+02,  1.0503e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.0903e+02,  0.0000e+00],\n",
      "        [ 1.3878e+02, -1.0620e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3878e+02]],\n",
      "       grad_fn=<MulBackward0>), 'raw_hessian_upper': tensor([[-3.0902e+03,  0.0000e+00, -9.8211e+02],\n",
      "        [ 0.0000e+00, -8.1788e+00, -2.3849e-01],\n",
      "        [-9.8211e+02, -2.3849e-01, -9.8214e+02]], grad_fn=<SliceBackward>), 'grad': tensor([ 2.3158,  1.4271, -0.6377,  0.5416, -0.9228,  0.9271,  0.6112,  0.7738,\n",
      "        -0.2470,  0.8492], grad_fn=<CatBackward>), 'df': tensor(2.3859, grad_fn=<AddBackward0>), 'thetapsi': tensor([-9.1466, -4.6052, -4.6986], requires_grad=True), 'latentpsi': tensor([-4.8788], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46]) torch.Size([46])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "latentpsi:\n",
      "tensor([-4.8788], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.952200174331665\n",
      "ltscale_hat:\n",
      "1.6423808336257935\n",
      "mode_hat:\n",
      "-0.0400131456553936\n",
      "thetapsi:\n",
      "tensor([-9.1466, -4.6052, -4.6986], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-3.1530,  2.8530,  7.0121, -1.9480])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 86279.78473573923;\n",
      "epoch 100 loss = 191104.1846178174;\n",
      "epoch 200 loss = 177597.92614471912;\n",
      "epoch 300 loss = 160779.73208145425;\n",
      "epoch 400 loss = 79316.42716794461;\n",
      "epoch 500 loss = 38373.49503985047;\n",
      "Final mean_losses: 142201.51815554657\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "auto_loc:\n",
      "tensor([-0.5275, -0.1043,  0.8641, -0.7912,  0.8185,  0.7408, -0.6020,  0.1536,\n",
      "         0.9030, -0.7616,  0.6087, -0.7752, -0.7896,  0.7793,  0.6839, -0.7623,\n",
      "        -0.8615,  0.6788, -0.7028,  0.8052, -0.2982,  0.8357,  0.6974,  0.6213,\n",
      "         0.7026, -0.0243,  0.0624,  0.8336,  0.8503,  0.7502,  0.4326, -0.8551,\n",
      "        -0.6618,  0.7885, -0.6545,  0.7812, -0.7814, -0.6651, -0.5563, -0.8411,\n",
      "        -0.7603,  0.7790, -0.6799, -0.8617,  0.6724,  0.1930, -0.6546],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.5990, 0.2255, 1.2320, 0.9337, 1.0564, 1.0715, 0.8446, 0.6990, 1.0363,\n",
      "        0.9752, 1.1232, 1.0627, 0.9189, 1.0448, 1.1438, 0.9765, 1.1781, 1.1220,\n",
      "        1.0142, 0.9725, 0.8370, 1.1147, 1.0341, 0.9889, 1.0750, 0.7245, 0.7193,\n",
      "        1.1337, 1.2668, 0.9802, 0.8516, 1.0575, 0.9560, 1.2015, 1.1372, 1.1326,\n",
      "        1.0829, 1.2403, 0.8150, 1.0270, 1.2288, 0.9738, 1.0784, 1.1847, 1.0388,\n",
      "        0.6153, 1.0550], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "exception: [Errno 2] No such file or directory: 'testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv'\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv created\n",
      "44\n",
      "tensor([-0.1451,  0.3999,  0.4944,  0.6045])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 102.442387342453;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay -2480\n",
      "yay -2540\n",
      "yay -2600\n",
      "yay -2660\n",
      "yay -2720\n",
      "epoch 100 loss = 74.81326758861542;\n",
      "mode_hat tensor(0.3864, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4267, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3708, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay -2780\n",
      "yay -2840\n",
      "yay -2900\n",
      "yay -2960\n",
      "yay -3020\n",
      "epoch 200 loss = 68.92836332321167;\n",
      "mode_hat tensor(0.5965, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8787, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5063, requires_grad=True)\n",
      "yay -3080\n",
      "complaint -1280\n",
      "complaint -1300\n",
      "yay -3140\n",
      "yay -3200\n",
      "yay -3260\n",
      "epoch 300 loss = 76.20874953269958;\n",
      "mode_hat tensor(0.6002, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1497, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4290, requires_grad=True)\n",
      "yay -3320\n",
      "yay -3380\n",
      "complaint -1320\n",
      "yay -3440\n",
      "yay -3500\n",
      "yay -3560\n",
      "epoch 400 loss = 77.6132915019989;\n",
      "mode_hat tensor(0.6056, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2332, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1791, requires_grad=True)\n",
      "yay -3620\n",
      "yay -3680\n",
      "yay -3740\n",
      "yay -3800\n",
      "yay -3860\n",
      "epoch 500 loss = 88.68690943717957;\n",
      "mode_hat tensor(0.5913, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3241, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0272, requires_grad=True)\n",
      "yay -3920\n",
      "yay -3980\n",
      "yay -4040\n",
      "yay -4100\n",
      "yay -4160\n",
      "epoch 600 loss = 68.23833680152893;\n",
      "mode_hat tensor(0.5961, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3638, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2464, requires_grad=True)\n",
      "yay -4220\n",
      "yay -4280\n",
      "yay -4340\n",
      "yay -4400\n",
      "yay -4460\n",
      "epoch 700 loss = 83.79162240028381;\n",
      "mode_hat tensor(0.5980, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4249, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4276, requires_grad=True)\n",
      "yay -4520\n",
      "yay -4580\n",
      "yay -4640\n",
      "yay -4700\n",
      "yay -4760\n",
      "epoch 800 loss = 75.28764963150024;\n",
      "mode_hat tensor(0.5812, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4044, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6232, requires_grad=True)\n",
      "yay -4820\n",
      "yay -4880\n",
      "yay -4940\n",
      "yay -5000\n",
      "yay -5060\n",
      "epoch 900 loss = 59.889779806137085;\n",
      "mode_hat tensor(0.5975, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4875, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7769, requires_grad=True)\n",
      "yay -5120\n",
      "yay -5180\n",
      "yay -5240\n",
      "yay -5300\n",
      "complaint -1340\n",
      "complaint -1360\n",
      "epoch 1000 loss = 83.01701641082764;\n",
      "mode_hat tensor(0.5846, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5658, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8969, requires_grad=True)\n",
      "yay -5360\n",
      "yay -5420\n",
      "complaint -1380\n",
      "Final mean_losses: 74.4814045258897\n",
      "save_data {'modal_effect': tensor(0.6039, requires_grad=True), 't_scale_raw': tensor(-1.5984, requires_grad=True), 't_part': tensor([ 0.9387,  0.2541, -0.0640,  3.9992, -0.3165,  0.1945, -0.3635, -1.8551],\n",
      "       grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(31.9758, grad_fn=<AddBackward0>), 'hessian': tensor([[ 2.1084e+04,  0.0000e+00,  2.3045e+03,  5.0495e+02,  4.3333e+02,\n",
      "          1.7594e+02,  2.3662e+02,  5.2989e+03,  3.0898e+02,  7.0713e+01],\n",
      "        [ 0.0000e+00,  1.2894e+00, -7.7774e-01, -2.4098e+00,  8.9444e-01,\n",
      "         -1.6820e-02,  2.4631e+00, -2.1702e+00,  2.4053e+00,  1.4932e-01],\n",
      "        [ 2.3045e+03, -7.7774e-01,  2.3030e+03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.0495e+02, -2.4098e+00,  0.0000e+00,  5.1110e+02,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.3333e+02,  8.9444e-01,  0.0000e+00,  0.0000e+00,  4.4497e+02,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7594e+02, -1.6820e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          1.7574e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3662e+02,  2.4631e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  2.4082e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2989e+03, -2.1702e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  5.3071e+03,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.0898e+02,  2.4053e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1192e+02,  0.0000e+00],\n",
      "        [ 7.0713e+01,  1.4932e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.9939e+01]],\n",
      "       grad_fn=<MulBackward0>), 'raw_hessian_upper': tensor([[-9.3340e+03,  0.0000e+00, -2.3045e+03],\n",
      "        [ 0.0000e+00, -1.2894e+00,  7.7774e-01],\n",
      "        [-2.3045e+03,  7.7774e-01, -2.3030e+03]], grad_fn=<SliceBackward>), 'grad': tensor([ -0.7249,   2.4085,  12.2628,  11.2889,  -3.4507,   3.7417, -12.7377,\n",
      "          9.3737, -13.4893,  -7.5930], grad_fn=<CatBackward>), 'df': tensor(2.3831, grad_fn=<AddBackward0>), 'thetapsi': tensor([-9.5875, -4.5899, -4.7603], requires_grad=True), 'latentpsi': tensor([-4.9188], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46]) torch.Size([46])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "latentpsi:\n",
      "tensor([-4.9188], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.9624338746070862\n",
      "ltscale_hat:\n",
      "-1.5984398126602173\n",
      "mode_hat:\n",
      "0.6039386987686157\n",
      "thetapsi:\n",
      "tensor([-9.5875, -4.5899, -4.7603], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-0.1451,  0.3999,  0.4944,  0.6045])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 7114.1819954924285;\n",
      "epoch 100 loss = 7358.354495383799;\n",
      "epoch 200 loss = 1427.812389716506;\n",
      "epoch 300 loss = 786.2298147678375;\n",
      "epoch 400 loss = 1186.8518577218056;\n",
      "epoch 500 loss = 1337.875171765685;\n",
      "epoch 600 loss = 1327.0562991201878;\n",
      "epoch 700 loss = 231.5855268239975;\n",
      "epoch 800 loss = 920.7755283713341;\n",
      "epoch 900 loss = 44.808976113796234;\n",
      "epoch 1000 loss = 479.7775378227234;\n",
      "epoch 1100 loss = 407.5046511888504;\n",
      "epoch 1200 loss = 427.0961824655533;\n",
      "epoch 1300 loss = 688.1865749359131;\n",
      "epoch 1400 loss = 1139.796975016594;\n",
      "epoch 1500 loss = 454.92001080513;\n",
      "Final mean_losses: 651.4214705476886\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "auto_loc:\n",
      "tensor([ 0.7746, -1.5526,  2.0055, -0.3679, -0.2285, -0.0290, -0.1300, -0.1003,\n",
      "        -0.1389,  0.1644,  0.0536, -0.2016, -0.2668,  0.0697, -0.2353, -0.1883,\n",
      "         0.1117, -0.5612, -0.2602, -0.1015, -0.2444,  0.0483,  0.1944,  0.6653,\n",
      "        -0.0185, -0.0410, -0.0556,  0.2269,  0.0281, -0.2030, -0.0883,  0.2816,\n",
      "        -0.4693,  0.1182, -0.0260, -0.1736, -0.0423, -0.0325,  0.1804, -0.1147,\n",
      "        -0.4255,  0.1566,  0.0037, -0.0854, -0.2369, -0.0711,  0.2635],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0593, 0.1886, 0.8894, 0.4181, 0.2658, 0.2994, 0.2343, 0.2053, 0.2843,\n",
      "        0.3016, 0.2454, 0.3844, 0.3752, 0.2570, 0.3238, 0.3378, 0.2990, 0.5735,\n",
      "        0.3080, 0.2748, 0.3585, 0.2941, 0.3490, 0.6304, 0.2861, 0.3042, 0.2701,\n",
      "        0.3877, 0.2481, 0.3418, 0.3267, 0.3302, 0.5522, 0.3092, 0.2083, 0.3223,\n",
      "        0.2408, 0.2207, 0.2994, 0.2531, 0.4623, 0.2686, 0.2738, 0.3528, 0.3465,\n",
      "        0.2534, 0.3193], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "1\n",
      "exception: [Errno 2] No such file or directory: 'testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv'\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv created\n",
      "44\n",
      "tensor([ 1.0065, -0.0191, 10.7015, -3.8023])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 287.939457654953;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "yay -5480\n",
      "complaint -1400\n",
      "complaint -1420\n",
      "complaint -1440\n",
      "yay -5540\n",
      "yay -5600\n",
      "complaint -1460\n",
      "yay -5660\n",
      "complaint -1480\n",
      "epoch 100 loss = 217.96019661426544;\n",
      "mode_hat tensor(0.1087, requires_grad=True)\n",
      "ltscale_hat tensor(0.4842, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5025, requires_grad=True)\n",
      "complaint -1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay -5720\n",
      "complaint -1520\n",
      "yay -5780\n",
      "complaint -1540\n",
      "complaint -1560\n",
      "yay -5840\n",
      "yay -5900\n",
      "complaint -1580\n",
      "epoch 200 loss = 212.27053356170654;\n",
      "mode_hat tensor(0.1972, requires_grad=True)\n",
      "ltscale_hat tensor(0.9757, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9320, requires_grad=True)\n",
      "complaint -1600\n",
      "yay -5960\n",
      "complaint -1620\n",
      "yay -6020\n",
      "complaint -1640\n",
      "yay -6080\n",
      "yay -6140\n",
      "complaint -1660\n",
      "complaint -1680\n",
      "complaint -1700\n",
      "epoch 300 loss = 191.32716608047485;\n",
      "mode_hat tensor(0.2418, requires_grad=True)\n",
      "ltscale_hat tensor(1.4374, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.2837, requires_grad=True)\n",
      "yay -6200\n",
      "complaint -1720\n",
      "complaint -1740\n",
      "complaint -1760\n",
      "yay -6260\n",
      "complaint -1780\n",
      "complaint -1800\n",
      "complaint -1820\n",
      "complaint -1840\n",
      "yay -6320\n",
      "complaint -1860\n",
      "complaint -1880\n",
      "complaint -1900\n",
      "yay -6380\n",
      "complaint -1920\n",
      "epoch 400 loss = 178.26808309555054;\n",
      "mode_hat tensor(0.2231, requires_grad=True)\n",
      "ltscale_hat tensor(1.6887, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.2388, requires_grad=True)\n",
      "yay -6440\n",
      "complaint -1940\n",
      "complaint -1960\n",
      "yay -6500\n",
      "complaint -1980\n",
      "yay -6560\n",
      "complaint -2000\n",
      "complaint -2020\n",
      "complaint -2040\n",
      "yay -6620\n",
      "yay -6680\n",
      "epoch 500 loss = 182.42481350898743;\n",
      "mode_hat tensor(0.3890, requires_grad=True)\n",
      "ltscale_hat tensor(1.7400, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0308, requires_grad=True)\n",
      "yay -6740\n",
      "yay -6800\n",
      "yay -6860\n",
      "yay -6920\n",
      "yay -6980\n",
      "epoch 600 loss = 195.6709132194519;\n",
      "mode_hat tensor(0.5796, requires_grad=True)\n",
      "ltscale_hat tensor(1.7693, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7519, requires_grad=True)\n",
      "yay -7040\n",
      "yay -7100\n",
      "yay -7160\n",
      "yay -7220\n",
      "yay -7280\n",
      "epoch 700 loss = 182.72732257843018;\n",
      "mode_hat tensor(0.6551, requires_grad=True)\n",
      "ltscale_hat tensor(1.8199, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5131, requires_grad=True)\n",
      "yay -7340\n",
      "yay -7400\n",
      "yay -7460\n",
      "yay -7520\n",
      "yay -7580\n",
      "epoch 800 loss = 195.04407405853271;\n",
      "mode_hat tensor(0.6606, requires_grad=True)\n",
      "ltscale_hat tensor(1.8273, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2489, requires_grad=True)\n",
      "yay -7640\n",
      "complaint -2060\n",
      "yay -7700\n",
      "complaint -2080\n",
      "complaint -2100\n",
      "yay -7760\n",
      "complaint -2120\n",
      "complaint -2140\n",
      "complaint -2160\n",
      "complaint -2180\n",
      "complaint -2200\n",
      "complaint -2220\n",
      "complaint -2240\n",
      "complaint -2260\n",
      "complaint -2280\n",
      "yay -7820\n",
      "complaint -2300\n",
      "epoch 900 loss = 193.04121255874634;\n",
      "mode_hat tensor(0.7629, requires_grad=True)\n",
      "ltscale_hat tensor(1.8314, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0103, requires_grad=True)\n",
      "complaint -2320\n",
      "Final mean_losses: 192.0018380655475\n",
      "save_data {'modal_effect': tensor(0.7649, requires_grad=True), 't_scale_raw': tensor(1.8188, requires_grad=True), 't_part': tensor([-6.9041, -6.4935, 19.3240, -1.8793,  2.9929, -5.0515, -5.4889, -5.6290],\n",
      "       grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(13.2870, grad_fn=<AddBackward0>), 'hessian': tensor([[ 1.9273e+04,  0.0000e+00,  2.3045e+03,  9.0839e+01,  7.0713e+01,\n",
      "          1.5915e+02,  4.3333e+02,  5.0495e+02,  8.1558e+01,  5.2989e+03],\n",
      "        [ 0.0000e+00,  9.3912e+00,  2.3131e-01,  2.3248e-01, -7.5235e-02,\n",
      "          1.1559e-01, -1.6901e-01,  2.2435e-01,  2.2911e-01,  2.3018e-01],\n",
      "        [ 2.3045e+03,  2.3131e-01,  2.3045e+03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 9.0839e+01,  2.3248e-01,  0.0000e+00,  9.0851e+01,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.0713e+01, -7.5235e-02,  0.0000e+00,  0.0000e+00,  7.0708e+01,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5915e+02,  1.1559e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          1.5918e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.3333e+02, -1.6901e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  4.3336e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.0495e+02,  2.2435e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  5.0496e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.1558e+01,  2.2911e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  8.1574e+01,  0.0000e+00],\n",
      "        [ 5.2989e+03,  2.3018e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  5.2989e+03]],\n",
      "       grad_fn=<MulBackward0>), 'raw_hessian_upper': tensor([[-8.9440e+03,  0.0000e+00, -2.3045e+03],\n",
      "        [ 0.0000e+00, -9.3912e+00, -2.3131e-01],\n",
      "        [-2.3045e+03, -2.3131e-01, -2.3045e+03]], grad_fn=<SliceBackward>), 'grad': tensor([-3.0166, -0.6630, -0.7417, -0.7215,  0.8283, -0.2737,  0.4174, -0.6251,\n",
      "        -0.6585, -0.6701], grad_fn=<CatBackward>), 'df': tensor(3.0246, grad_fn=<AddBackward0>), 'thetapsi': tensor([-9.0011, -4.6052, -4.6585], requires_grad=True), 'latentpsi': tensor([-4.8633], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46]) torch.Size([46])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "latentpsi:\n",
      "tensor([-4.8633], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.028381505981087685\n",
      "ltscale_hat:\n",
      "1.8187572956085205\n",
      "mode_hat:\n",
      "0.7648642659187317\n",
      "thetapsi:\n",
      "tensor([-9.0011, -4.6052, -4.6585], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 1.0065, -0.0191, 10.7015, -3.8023])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 109420.2143600611;\n",
      "epoch 100 loss = 54853.493791759014;\n",
      "epoch 200 loss = 177164.3913615942;\n",
      "epoch 300 loss = 280234.02305129915;\n",
      "epoch 400 loss = 233147.75677743554;\n",
      "epoch 500 loss = 83985.61865900457;\n",
      "Final mean_losses: 146847.64227777993\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "auto_loc:\n",
      "tensor([-0.1550, -0.1037,  0.9615,  0.2775, -0.0342,  0.8265, -0.7223,  0.7267,\n",
      "         0.7747, -0.4504, -0.6479,  0.5623, -0.8566, -0.8725, -0.6705, -0.1135,\n",
      "         0.7879, -0.2688,  0.7807,  0.7904,  0.7522, -0.6581,  0.7580,  0.7670,\n",
      "         0.8147, -0.8123,  0.8638, -0.7204, -0.7282,  0.5539, -0.3563, -0.7789,\n",
      "         0.7151,  0.2925, -0.7827, -0.7579, -0.7799,  0.7415, -0.8137, -0.7403,\n",
      "         0.7299,  0.7123, -0.8451,  0.7133,  0.0830,  0.7487,  0.8979],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.6476, 0.2429, 1.2210, 0.8566, 0.7438, 1.2709, 1.1157, 1.0607, 1.1452,\n",
      "        0.8900, 1.2498, 1.0187, 1.0913, 1.1513, 0.9655, 0.6711, 1.2260, 0.8133,\n",
      "        0.9970, 1.1338, 1.1579, 1.0866, 1.0778, 1.0277, 0.9774, 0.9245, 1.1086,\n",
      "        1.1106, 1.0864, 0.9227, 0.7232, 1.2425, 1.0074, 0.7000, 1.1591, 1.1583,\n",
      "        0.9288, 1.0732, 1.0956, 0.9869, 1.0757, 1.1034, 1.0555, 1.0660, 0.7831,\n",
      "        1.0227, 1.0379], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "exception: [Errno 2] No such file or directory: 'testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv'\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv created\n",
      "44\n",
      "tensor([0.2674, 0.4915, 0.0769, 0.7012])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 75.51871478557587;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay -7880\n",
      "yay -7940\n",
      "yay -8000\n",
      "yay -8060\n",
      "yay -8120\n",
      "epoch 100 loss = 51.232035756111145;\n",
      "mode_hat tensor(0.2973, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4921, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5025, requires_grad=True)\n",
      "yay -8180\n",
      "yay -8240\n",
      "yay -8300\n",
      "yay -8360\n",
      "yay -8420\n",
      "epoch 200 loss = 69.83525896072388;\n",
      "mode_hat tensor(0.4757, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9846, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9982, requires_grad=True)\n",
      "yay -8480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay -8540\n",
      "yay -8600\n",
      "yay -8660\n",
      "yay -8720\n",
      "epoch 300 loss = 15.483309507369995;\n",
      "mode_hat tensor(0.4895, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4735, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4817, requires_grad=True)\n",
      "yay -8780\n",
      "yay -8840\n",
      "yay -8900\n",
      "yay -8960\n",
      "yay -9020\n",
      "epoch 400 loss = 59.9900438785553;\n",
      "mode_hat tensor(0.4898, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9328, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8717, requires_grad=True)\n",
      "yay -9080\n",
      "yay -9140\n",
      "yay -9200\n",
      "yay -9260\n",
      "yay -9320\n",
      "epoch 500 loss = 48.14955258369446;\n",
      "mode_hat tensor(0.4932, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2988, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0049, requires_grad=True)\n",
      "yay -9380\n",
      "yay -9440\n",
      "yay -9500\n",
      "yay -9560\n",
      "yay -9620\n",
      "epoch 600 loss = 24.34367048740387;\n",
      "mode_hat tensor(0.4977, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5583, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9724, requires_grad=True)\n",
      "yay -9680\n",
      "yay -9740\n",
      "yay -9800\n",
      "yay -9860\n",
      "yay -9920\n",
      "epoch 700 loss = 23.58233094215393;\n",
      "mode_hat tensor(0.4842, requires_grad=True)\n",
      "ltscale_hat tensor(-2.7351, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9818, requires_grad=True)\n",
      "yay -9980\n",
      "yay -10040\n",
      "yay -10100\n",
      "yay -10160\n",
      "yay -10220\n",
      "epoch 800 loss = 34.85998296737671;\n",
      "mode_hat tensor(0.4881, requires_grad=True)\n",
      "ltscale_hat tensor(-2.8037, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9166, requires_grad=True)\n",
      "yay -10280\n",
      "yay -10340\n",
      "yay -10400\n",
      "yay -10460\n",
      "yay -10520\n",
      "epoch 900 loss = 54.54590129852295;\n",
      "mode_hat tensor(0.4870, requires_grad=True)\n",
      "ltscale_hat tensor(-2.8802, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8464, requires_grad=True)\n",
      "yay -10580\n",
      "yay -10640\n",
      "yay -10700\n",
      "yay -10760\n",
      "yay -10820\n",
      "epoch 1000 loss = 36.646745800971985;\n",
      "mode_hat tensor(0.4993, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9633, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8015, requires_grad=True)\n",
      "Final mean_losses: 39.71121672838018\n",
      "save_data {'modal_effect': tensor(0.4993, requires_grad=True), 't_scale_raw': tensor(-2.9633, requires_grad=True), 't_part': tensor([ 0.1972, -0.0803,  0.1568, -0.2325, -0.6577,  0.0781,  0.2863,  0.1459],\n",
      "       grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(38.7949, grad_fn=<AddBackward0>), 'hessian': tensor([[ 2.6158e+04,  0.0000e+00,  2.3045e+03,  1.3760e+03,  5.2989e+03,\n",
      "          7.0713e+01,  9.8133e+02,  3.0898e+02,  7.3532e+02,  8.0109e+01],\n",
      "        [ 0.0000e+00,  5.4080e-01, -2.5594e+00,  1.2793e+00, -2.2211e+00,\n",
      "          2.7602e+00,  1.7924e+00, -1.2467e+00, -2.9128e+00, -2.1106e+00],\n",
      "        [ 2.3045e+03, -2.5594e+00,  2.3254e+03,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3760e+03,  1.2793e+00,  0.0000e+00,  1.4049e+03,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2989e+03, -2.2211e+00,  0.0000e+00,  0.0000e+00,  5.3230e+03,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.0713e+01,  2.7602e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          8.8651e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 9.8133e+02,  1.7924e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  9.7896e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.0898e+02, -1.2467e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.3794e+02,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.3532e+02, -2.9128e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  7.4891e+02,  0.0000e+00],\n",
      "        [ 8.0109e+01, -2.1106e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0496e+02]],\n",
      "       grad_fn=<MulBackward0>), 'raw_hessian_upper': tensor([[-1.1156e+04,  0.0000e+00, -2.3045e+03],\n",
      "        [ 0.0000e+00, -3.9516e-01,  2.5594e+00],\n",
      "        [-2.3045e+03,  2.5594e+00, -2.3254e+03]], grad_fn=<SliceBackward>), 'grad': tensor([ 36.2742,   0.9458,  24.1491, -10.8943,  20.0558, -27.2303, -36.9024,\n",
      "         10.6048,  31.0362,  18.8609], grad_fn=<CatBackward>), 'df': tensor(8.0608, grad_fn=<AddBackward0>), 'thetapsi': tensor([-9.0051, -3.9830, -4.6966], requires_grad=True), 'latentpsi': tensor([-4.9349], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46]) torch.Size([46])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "latentpsi:\n",
      "tensor([-4.9349], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.8015203475952148\n",
      "ltscale_hat:\n",
      "-2.9632999897003174\n",
      "mode_hat:\n",
      "0.4993329346179962\n",
      "thetapsi:\n",
      "tensor([-9.0051, -3.9830, -4.6966], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([0.2674, 0.4915, 0.0769, 0.7012])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 2331.7503435201943;\n",
      "epoch 100 loss = 5157.467307090759;\n",
      "epoch 200 loss = 2670.6880809664726;\n",
      "epoch 300 loss = 1013.8338739573956;\n",
      "epoch 400 loss = 257.40138697624207;\n",
      "epoch 500 loss = 430.9424585700035;\n",
      "epoch 600 loss = 442.4435772895813;\n",
      "epoch 700 loss = 379.09192872047424;\n",
      "epoch 800 loss = 895.2948834300041;\n",
      "epoch 900 loss = 37.50565958023071;\n",
      "epoch 1000 loss = 411.8952008485794;\n",
      "epoch 1100 loss = 484.82714200019836;\n",
      "epoch 1200 loss = 279.3519477844238;\n",
      "epoch 1300 loss = 84.88309562206268;\n",
      "epoch 1400 loss = 36.32856488227844;\n",
      "epoch 1500 loss = 35.85241615772247;\n",
      "epoch 1600 loss = 60.79362678527832;\n",
      "epoch 1700 loss = 73.20705860853195;\n",
      "epoch 1800 loss = 87.70547783374786;\n",
      "Final mean_losses: 217.3614766308217\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "auto_loc:\n",
      "tensor([ 0.4955, -2.6240,  2.3653, -0.1153,  0.0092, -0.0748,  0.0849, -0.0644,\n",
      "         0.0201, -0.0831, -0.0889,  0.1585, -0.0685, -0.0379,  0.0627, -0.0073,\n",
      "        -0.0684, -0.0911, -0.0225, -0.0192,  0.0342,  0.0575,  0.0210, -0.0698,\n",
      "        -0.1176, -0.0564, -0.0305,  0.0590,  0.1459,  0.1229,  0.0750,  0.0549,\n",
      "        -0.1437,  0.0123,  0.0686,  0.1181,  0.0592, -0.0766,  0.0844, -0.0678,\n",
      "        -0.0231, -0.1510, -0.0093, -0.1052,  0.0494, -0.0830,  0.0113],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0391, 0.3084, 0.8583, 0.1910, 0.1869, 0.2403, 0.1988, 0.1753, 0.1781,\n",
      "        0.1806, 0.2037, 0.2117, 0.2159, 0.2071, 0.2087, 0.1876, 0.2037, 0.1818,\n",
      "        0.1970, 0.2039, 0.2023, 0.2545, 0.1563, 0.1946, 0.1950, 0.2155, 0.1872,\n",
      "        0.1791, 0.2255, 0.2663, 0.2228, 0.1520, 0.2561, 0.2217, 0.1608, 0.2160,\n",
      "        0.2038, 0.2180, 0.1623, 0.1507, 0.1597, 0.2414, 0.2196, 0.2941, 0.1921,\n",
      "        0.2293, 0.1352], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxcVZnw8d9TS+/pJUln3yEmBGQJkUUEGZiBgCi4IDgqERkZfdEZX31VHPUl6qjwuqC4oCgIuAyCwpDRIIaoIEIgCUvCmnT2ztqd7vS+VdXz/nFPd1d3V1dXdd+q6uX5fj71qVvnnnvPqdvJfeos915RVYwxxhg/BXJdAWOMMeOPBRdjjDG+s+BijDHGdxZcjDHG+M6CizHGGN+Fcl2B0WLq1Km6YMGCXFfDGGPGlM2bN9eqamX/dAsuzoIFC9i0aVOuq2GMMWOKiOxJlG7dYsYYY3xnwcUYY4zvMhpcRKRcRH4rIq+JyKsicraITBaRdSKy3b1XuLwiIreJSJWIbBGR5XH7WeXybxeRVXHpp4vIVrfNbSIiLj1hGcYYY7Ij0y2X7wF/VNWlwCnAq8CNwHpVXQysd58BLgEWu9f1wO3gBQrgJuBM4AzgprhgcbvL273dSpc+WBnGGGOyIGPBRURKgfOAOwFUtVNVjwGXA/e4bPcAV7jly4F71bMBKBeRmcDFwDpVrVPVemAdsNKtK1XVp9W7Qdq9/faVqAxjjDFZkMmWyyKgBvi5iDwvIj8TkWJguqoeBHDv01z+2cC+uO2rXVqy9OoE6SQpow8RuV5ENonIppqamuF/U2OMMX1kMriEgOXA7ap6GtBC8u4pSZCmw0hPmareoaorVHVFZeWAadrGGGOGKZPBpRqoVtVn3Off4gWbw65LC/d+JC7/3Ljt5wAHhkifkyCdJGWYTNn9dzjyWq5rYYwZJTIWXFT1ELBPRJa4pAuBV4A1QPeMr1XAw255DXCNmzV2FtDgurQeBS4SkQo3kH8R8Khb1yQiZ7lZYtf021eiMkym3H0p/OjMXNfCGDNKZPoK/U8AvxKRPGAncC1eQLtfRK4D9gJXurxrgUuBKqDV5UVV60Tkq8BGl+8rqlrnlj8G3A0UAo+4F8DNg5RhjDEmCzIaXFT1BWBFglUXJsirwA2D7Ocu4K4E6ZuAkxKkH01UhjHGmOywK/SNMcb4zoKLMcYY31lwMcYY4zsLLsYYY3xnwcUYY4zvLLgYY4zxnQUXY4wxvrPgYowxxncWXIwxxvjOgosxxhjfWXAxxhjjOwsuxhhjfGfBxRhjjO8suBhjjPGdBRdjjDG+s+BijDHGdxZcjDHG+M6CizHGGN9ZcDHGGOM7Cy7GGGN8Z8HFGGOM7yy4GGOM8Z0FF2OMMb6z4OKHbY/C4ZcTr1vzCVhdlt36GGNMjoVyXYFx4dfv9d5XNwxc99y92a2LMcaMAhltuYjIbhHZKiIviMgmlzZZRNaJyHb3XuHSRURuE5EqEdkiIsvj9rPK5d8uIqvi0k93+69y20qyMowxxmRHNrrF/kFVT1XVFe7zjcB6VV0MrHefAS4BFrvX9cDt4AUK4CbgTOAM4Ka4YHG7y9u93cohyjDGGJMFuRhzuRy4xy3fA1wRl36vejYA5SIyE7gYWKeqdapaD6wDVrp1par6tKoqcG+/fSUqwxhjTBZkOrgo8CcR2Swi17u06ap6EMC9T3Pps4F9cdtWu7Rk6dUJ0pOV0YeIXC8im0RkU01NzTC/ojHGmP4yPaB/jqoeEJFpwDoReS1JXkmQpsNIT5mq3gHcAbBixYq0tjXGGDO4jLZcVPWAez8CPIQ3ZnLYdWnh3o+47NXA3LjN5wAHhkifkyCdJGUYY4zJgowFFxEpFpFJ3cvARcBLwBqge8bXKuBht7wGuMbNGjsLaHBdWo8CF4lIhRvIvwh41K1rEpGz3Cyxa/rtK1EZxhhjsiCT3WLTgYfc7OAQ8GtV/aOIbATuF5HrgL3AlS7/WuBSoApoBa4FUNU6EfkqsNHl+4qq1rnljwF3A4XAI+4FcPMgZRhjjMmCjAUXVd0JnJIg/ShwYYJ0BW4YZF93AXclSN8EnJRqGcYYY7LDbv9ijDHGdxZcjDHG+M6CizHGGN9ZcDHGGOM7Cy7GGGN8Z8HFGGOM7yy4GGOM8Z0FF2OMMb6z4GKMMcZ3FlyMMcb4zoKL8d+W++Gp7+e6FsaYHLLgMgHt2Pwsv/rCp4jFopkp4MGPwJ++mJl9G2PGhEw/LMyMQmu//y0621rpam8nv6g419UxxoxD1nKZwDTSlesqGGPGKQsuE8ErD0PV+p6PojFv4a8356hCxpjxzrrFJoL7r/HeVze4BBdcal/LSXWMMeOftVwmMs11BYwx45UFF2OMMb6z4JJrHU0Q6Rw637F90FCd+n7r98Ad50PL0d60+1elXT1jjBkOCy659o05cM/bh8733ZPg1hNT3+9Tt8GB5+HlB3vTXvlvtyCA9YoZYzLHgovfol2ptUTi7duQmboA6MAQIpK54owxBiy4+O/Wk+A/K3NdC7pbJ8YYkwsWXPzWfCjXNejHOr+MMdlnwWW86u77StAtZq0aY0ymZTy4iEhQRJ4Xkd+7zwtF5BkR2S4ivxGRPJee7z5XufUL4vbxeZf+uohcHJe+0qVViciNcekJy5gIfvyvH+Sez3wcCyDGmFzKRsvl34FX4z7fAtyqqouBeuA6l34dUK+qxwO3unyIyDLgauBEYCXwIxewgsAPgUuAZcD7XN5kZYwuCVsVI9NyrJ7avbvjCxm8eN9LN8YYT0aDi4jMAd4G/Mx9FuAC4Lcuyz3AFW75cvcZt/5Cl/9y4D5V7VDVXUAVcIZ7VanqTlXtBO4DLh+ijNHlyVszt28RjrQXc/RoU4J1mSvWGGMg8y2X7wKfpedmVkwBjqlqxH2uBma75dnAPgC3vsHl70nvt81g6cnK6ENErheRTSKyqaamZrjfcfhe+l1Gd/+LXcu5+94nMlqGMcYkkrHgIiKXAUdUdXN8coKsOsQ6v9IHJqreoaorVHVFZeVomD6cZWpNGGNMZmSy5XIO8A4R2Y3XZXUBXkumXES678Y8BzjglquBuQBufRlQF5/eb5vB0muTlJEVrzRU8tAtXx46YwbGXHoNHjjE+sWMMRmWseCiqp9X1TmqugBvQP7Pqvp+4C/Ae1y2VcDDbnmN+4xb/2dVVZd+tZtNthBYDDwLbAQWu5lhea6MNW6bwcrIikcOLGXncxuzWaQxxowqubjO5XPAp0SkCm985E6XficwxaV/CrgRQFVfBu4HXgH+CNygqlE3pvJx4FG82Wj3u7zJypg47B4vxpgcysrDwlT1r8Bf3fJOvJle/fO0A1cOsv3XgK8lSF8LrE2QnrCM8WDH5mdZf9ftfPi7dxAKh5PkTBJcLO4YYzLMrtD305PfzXgRf/75T2iqraG57ujQmY0xJkcsuPjpsZtyXYNe/brFnq2dw6G2kj5pdhGlMSZTLLjkVPZO73+rWcivdp8G9Jst9vfvwcEXs1YPY8zEkJUxF4M37diHQXZfx+kVWPd/veXVDT7u2Bgz0VnLxSddsQDffvVcnqmdO3RmP4zoGhnrEDPGZJYFF590RIMAPFc3K7MF+dh0sRBjjMkUCy4+GfKcn9Gr8RNIVqFk6x6+AX7wJv/rY4yZUGzMZYzS/u2O5hooib8/2jBbOM//cth1AmB12ci2N8aMC9ZyGWMS3hfslTXwreNh95Np7Svbjak+nvo+fGsJVK2HtZ/JYUWMMZlgLZes8flMHh8Z9j7tvcdPKU7S9TUqLtD/0xe991++y3u/9Ju5q4sxxnfWcvFZWiGkf9PhwPPpNyfaG2HDj9LbJpHmIyPfhzHGOBZcfCIJll77++P8T/VS78NQQePlh+CO82Hrb5Pn66/mtfTyx+lTo28tHvZ+hqOmvYj7dp9MV8z+CRozHtn/7Az6w23fZFtTig8hq63y3o+8nDxfyn1aw5wtliV/OXwc+9vKONg2KddVMcZkgAWX0SLg/hRP3jr8fTz6H/7UxRhjRsiCS9YM0S0WSG9uxZBDM0laJy1NLSlVyRhjhsuCi8/SOV9HY3FBQoIpbSMDgsZgQSRxev3B/T3LoyG26OiYu2aM8ZkFF98Mfqre25L4wsLvPjmVh/ad6H0IpBZciMWGLC+ZhhqbFWaMyTwLLj5J9vv7kQNLBu3H2tUy2e0gxeBSvzO9ivWT8CLMfrbUz2D7xqdHVI4xZmKz4OK3BDEkpil0/aQ5g0uHGnRJYX+D7WLdocWs+daAp0oP6b7dJ/P9189OKa91hhkzvtkV+n5JcrZMaVxBlb8cXsTW+hn8mw/V6YpEB1nR6sPeE9vfZvcVM8Z4LLj4JUlDQhV46HpYdD6c/iF4bS1ov5O/xniubvbAjb82E06/dkByz8D+IC2Ujs5YwnTuex/wxsErmzWjYTqBMSZTLLj4LNEpM4bw4CPb6Izt4Oq7P+RO8ADnxm04SDDoaoUNPxxYzhDdYgNnlbn0uBrq3qcgL+lujDFmWGzMxSfJTvWKN3CftNuoNMMPGcuFtmPe3Y+TBMKc3pnZGJMxKQUXEfl3ESkVz50i8pyIXJTpyo1NA1sMmsqAfl5xesUMOZ7f+6ftjKY4E81vf/iUd/fjXU8MXGcj+saMa6m2XD6sqo3ARUAlcC1wc7INRKRARJ4VkRdF5GUR+bJLXygiz4jIdhH5jYjkufR897nKrV8Qt6/Pu/TXReTiuPSVLq1KRG6MS09YRjYkOuenOqCfiuGck7+/7c1D5nlg70l8+6rLhrH3JNqOee/RTn/3a4wZ9VINLt3ntEuBn6vqiwx9nusALlDVU4BTgZUichZwC3Crqi4G6oHrXP7rgHpVPR641eVDRJYBVwMnAiuBH4lIUESCwA+BS4BlwPtcXpKUkUGDH46UpiKnPcA9vP6k+JrEt6j2tlQMa3/GGJNIqsFls4j8CS+4PCoik4BBRqA96ml2H8PupcAFQPd95e8BrnDLl7vPuPUXijcqfTlwn6p2qOouoAo4w72qVHWnqnYC9wGXu20GKyMnUmq5+DxFWAI+9Dt1tcOxvSPfjzFmwkk1uFwH3Ai8SVVb8QLFwPmx/bgWxgvAEWAdsAM4pqoRl6Ua6J5/OxvYB+DWNwBT4tP7bTNY+pQkZYxeD3worez33fQ5t5TmxZfpZP7ddfDdN0JskGtmRsCGXIwZ31INLmcDr6vqMRH5APBFvJN/UqoaVdVTgTl4LY0TEmVz74nON+pj+gAicr2IbBKRTTU1NYmyjFrtzU1J18cP6Md7unZ+z/KQgWbbH733WBT2b4Ztf0qjhsaYiSzV4HI70CoipwCfBfYA96ZaiKoeA/4KnAWUi0j39TVzgANuuRqYC+DWlwF18en9thksvTZJGf3rdYeqrlDVFZWVKT7UawjDGQlpi4Q42lE0rPLaWls51lkwcMUg17nsby1Nfec9AUrhpxfAr6/su75qPawug8aEhzd+R6mXaYwZF1INLhH1rtq7HPieqn4PSPoIQRGpFJFyt1wI/CPwKvAX4D0u2yrgYbe8xn3Grf+zK3MNcLWbTbYQWAw8C2wEFruZYXl4g/5r3DaDlZExI7lc4xe7TuPunacPa9uf3/ID7tzxpoH1GWT2maRVUxcUBrvAc9Nd3vv+zWns0xgzEaQaXJpE5PPAB4E/uJla4SG2mQn8RUS24AWCdar6e+BzwKdEpApvfOROl/9OYIpL/xTeGA+q+jJwP/AK8EfgBtfdFgE+DjyKF7Tud3lJUkbmpTQzrK+mSL+WxyteLGxtbKC2X4umf3Boa25Jq6xYnz/5EHWNdnjvSaZJP1c3i7/+8alB1g4dyOx5LsaMT6ne/uUq4J/xrnc5JCLzgG8m20BVtwCnJUjfiTf+0j+9Hbiyf7pb9zVgwG16VXUtsDbVMsaM19bC2s9w92vLaWs6nU+f8LeMFJPo1N8VS/R7Y/Ag8ZfDx8HhrZyfaDTNGDNhpdRyUdVDwK+AMhG5DGhX1ZTHXEyattzHi/uEtqbmgevifujHbuq9ncyOpsl8+9VzE2dMw7bGqQMT+3eLtR2DaGTQFs3PqlbwyIE3wO4nh1UHY8zYl+rtX96LN85xJfBe4BkReU/yrSYmv26V9dihxUPmib8486WG6f3qkcpdAVKsTHxwUYVb5sPDNwyavaGrkFcapvdemZ+gKumN/RhjxppUx1y+gHeNyypVvQavy+lLmavW2JOLGzBGtffPN5x2SuJb1SRK9IJLY1c+D3/7617X2Zb7hlGiMWaiSDW4BFQ1/uHrR9PY1vgoPohsqJ2XnUJd5Hz88EKqNj7Nzmbv0cy7j0SSbTXQgRfsNsjGTBCpBog/isijIvIhEfkQ8AcSDKRPbJmd9dQaCfNKw7Q+aZvq5mS0zB51u4DeS2e670m2tyaN4LLzcbjjrbT+5Taa644OXL/77yOtpTFmFElptpiqfkZE3g2cg3cWvUNVH8pozUwf/7N/KdWt5eQFUjyhp9BASHka8M8uAHrHSRQ40DaJjbvTuNtxg3enntt/sg5Yx4LiftW8+1I4//NQsQBOuTr1/RpjRqWUn0Spqr8DfpfBupgkWiLeUwMiCacKZ2eAvDsUKbB2/5L0Ng70/aeWMKz99RveuwUXY8a8pMFFRJpI/BtY8G58nMa9RMa3TJ/a2yJhV05qrY1M1EfEtVxUaOgqTG/jQGiQa2iMMeNR0uCiqklv8WIGysQV56rQHksvuKS034SpvfuvaprM8ZPqBqwZVuAKhOiM5eiJmMaYrLOfkmNAruZXPVx9IlEV2qNB7tpxes+taNIPcAKBUOKHptnkMWPGJQsuIxSNRGhP4xn1+197hViaJ9RUTuaD3AR5qB2nZG9LOfWdRRxu9xqyac8mfulBCIYTBhe7t5gx45MFlxFa852v88MUnlHf7b6bPsu+1vKkefqfvFN7THJfP/vlMynl29VcQSSWfP8D16ZZnxd+CYFgn4s+d7V418q0RVOeU2KMGUMsuIzQzs3PAun17jR35WWgJn1rEIkkfQo1AAfbSnlw30k8cWThCEpK0SDdYo8eTHPWmTFmTLDg4rNUuoyG6sLa39Z3Et5wWi6paI16kwTqO9Ob+VXTXpxW/r0tZcSiUaLWBWbMhGHBJSeSR6Df7DkljdyeYQ25uKCVbNxDEzw4+sVjs1IuY3dzOQ/sPZmNTzzTU54xZvyz4OKT3e5+W6lI9xSbqZNyd8fZnpaKpPlSuUBzS/2MhOndF39uevK5tOpmjBnbLLj4ZJ27RX5GrnNJYZ/pdm2lut9UrRvkEQEBd+Fle2v7oNse6yxge+MU3+pijMk9Cy5jQCpXtndPE05H4qnB/T/LsEPQt189l8PtJYPuu9s9O5ezZv+yYZZijBmNLLj4LBMtl4auAt/3mS0vH4t/iFniYxNRu3LfmPHGgksOpHsblKBk5jL2TM1CiycZqrsxZnSz4JIDqTzCOF6mTtCptrJGcsfl+MBoYcaYicOCyxiQqYc3Jmq5/L1mft+yYUTPQWuO5A9/Y2PMmGXBZQzI1P23EgWXlv7BQIWoX7fKt6aLMROG3dhpDMjUdS4vNSS+NiXeX48sZOuxmb6UZ7HFmInDWi5jwP17T85Z2X4FFmPMxJKx4CIic0XkLyLyqoi8LCL/7tIni8g6Ednu3itcuojIbSJSJSJbRGR53L5WufzbRWRVXPrpIrLVbXObiHfXrsHKMLlmt38xZqLIZMslAnxaVU8AzgJuEJFlwI3AelVdDKx3nwEuARa71/XA7eAFCuAm4EzgDOCmuGBxu8vbvd1Klz5YGSaHrFvMmIkjY8FFVQ+q6nNuuQl4FZgNXA7c47LdA1zhli8H7lXPBqBcRGYCFwPrVLVOVeuBdcBKt65UVZ9WVQXu7bevRGWMGr/edcrQmYwxZozKypiLiCwATgOeAaar6kHwAhAwzWWbDeyL26zapSVLr06QTpIy+tfrehHZJCKbampqhvv1huVge+nQmSaYmvaiXFfBGOOTjAcXESkBfgd8UlUbk2VNkJbghu9DpqdMVe9Q1RWquqKysjKdTU0G3Lvr9FxXwRjjk4wGFxEJ4wWWX6nqgy75sOvSwr0fcenVwNy4zecAB4ZIn5MgPVkZZpRrt8ceGzMuZHK2mAB3Aq+q6nfiVq0Bumd8rQIejku/xs0aOwtocF1ajwIXiUiFG8i/CHjUrWsSkbNcWdf021eiMkwOpXK9TmOXXdFvzHiQyZ+J5wAfBLaKyAsu7T+Am4H7ReQ6YC9wpVu3FrgUqAJagWsBVLVORL4KbHT5vqKqdW75Y8DdQCHwiHuRpAwzyj2470Q+mutKGGNGLGPBRVWfZPALGy5MkF+BGwbZ113AXQnSNwEnJUg/mqgMM/oNuP2MMWZMsiv0TdbYdS7GTBwWXIwxxvjOgovJmkzd3dkYM/pYcDFZk6nn0hhjRh8LLsYYY3xnwcVkTVcsmOsqGGOyxIKLyZo1+5flugrGmCyx4GKMMcZ3FlyMMcb4zoKLMcYY31lwMcYY4zsLLsYYY3xnwcUYY4zvLLgYY4zxnQUXY4wxvrPgYowxxncWXIwxxvjOgosxxhjfWXAxxhjjOwsuxhhjfGfBxRhjjO8suBhjjPGdBRdjjDG+s+Ayyp1cfjDXVTDGmLRlLLiIyF0ickREXopLmywi60Rku3uvcOkiIreJSJWIbBGR5XHbrHL5t4vIqrj000Vkq9vmNhGRZGUYY4zJnky2XO4GVvZLuxFYr6qLgfXuM8AlwGL3uh64HbxAAdwEnAmcAdwUFyxud3m7t1s5RBkZcU7l7kzuHsno3o0xJjMyFlxU9Qmgrl/y5cA9bvke4Iq49HvVswEoF5GZwMXAOlWtU9V6YB2w0q0rVdWnVVWBe/vtK1EZGZEXiGZy9xNOQbAr11Uwxvgg22Mu01X1IIB7n+bSZwP74vJVu7Rk6dUJ0pOVMYCIXC8im0RkU01NzbC/VGZpritgjDFpGy0D+ol6f3QY6WlR1TtUdYWqrqisrEx3cwAk0yf/idYvZrHUmHEh28HlsOvSwr0fcenVwNy4fHOAA0Okz0mQnqyMjNAMn/27976guH8P4/iU6eNpjMmObAeXNUD3jK9VwMNx6de4WWNnAQ2uS+tR4CIRqXAD+RcBj7p1TSJylpsldk2/fSUqY0yryGvLdRUGmF3Y4Ps+reFizPgQytSOReS/gPOBqSJSjTfr62bgfhG5DtgLXOmyrwUuBaqAVuBaAFWtE5GvAhtdvq+oavdP+I/hzUgrBB5xL5KUkRGZ7hbLeLebMcZkQMaCi6q+b5BVFybIq8ANg+znLuCuBOmbgJMSpB9NVMZo8a4LZvLgn8fHhZGSgR4sVesWM2Y8yFhwmTAKJ6eVPRQaLXMohu9ts16jKZLHzub0vnsq3lhxyPd9GmOyz4JLlokE08ufoXqMxNIyb9r2Lp+DS0mog3+YvtPXfRpjcmPs/4weYySYXnAZzfwOfDa6ZMz4YcEly0S8Qy4oi0qOppDfO+WOzim6Fg6MMYlZcMkyCXqHfGp+S1qD1+rDebwgPPJ99OF702U0BlBjzHBYcBmpIaZMhSVKgFjP50Cgt1ssWbyYkt/CmVP2xuXNzon3X457NuW8FgqMMYOx4JJhBcEuKgtaej6LCy6KJA0Y51bu5i3T9vR8jvnwq372lKHHe4JiXV3GmJGz4JJl3WMuKed3736c8uP38e65WxOXl0Zw8fsCTwtrxowfFlyyraflknwcpf+Je7jdYuFAJH4nPeYW+3/rlv5Wznx9YMHGmAnBgks25Jf1LHZ3i6FDBIyeVW62WNz5+QMLn+O987akVHT8pIH48gZrdaQTwpLlXVZ2mPK89jT2Bv80c3ta+Y0xo5ddROmTWChM5+Tp5B+pHnjSjU9wEwC03+m9KNhJazSvN0H7ZO8JDFPzW5geN4aTrg8seJ5QIDZoYAhIbJA1nnnlnT3LybrQJoU60upiu3r+i8wuakw5vzFmdLOWywjNK/XuVtw+ayFdU2YQLSwZkGf5ot6gIYH4QfXeU3wo0Pek3r9V0z2gn8o4xyeW/J1Tyg8M2I8iTC9sZkp+66CT3EKDBJeLzlvI++a/wBUnDt2ddtnsVzm7cm/cJARhUih5K8Y6zowZXyy4jNCU4iifPuFvSackL5sXd4GJG9DvP+YSGDDG4rJ3J1QuBSA4RMsCIC8Q44yp+5hT1MCS0t4nbKZyrcxgXyMcDjKrqIlwCjcYWFJaS1C0z3e67vhNzChoGnpjY8y4YMFlxPqejQuDkUHyudyB3kPefeo9teJAki4kL71ywSLOmLKPt895Len+u0/gpeFOrpq/hYL4Af0UZqoN2TJK42rOWUW9wSQoSigQTXlbY8zYZsHFLz1NjSFOvt0tF+29zmVpac2AMZDugfgKNyheVj6Jc2dUUxruSLr7paV9H7ypfZbjSrnwJlYt3NynZQPpDuin15mVdN9T3pDWvowxo5sFl2yYcnzPYt8xF5eGcnJ532e8dJ+2Tyw7zFXzX2TpScfBfxyA//1KT56LZ27jtIr9A8srm5ewGrMr83s/BEJMLWglL5C8pZVMfMskFbOLkozXvP17w66HMWb0seDiM431/X2uxZWw4trehLhBje4eJvnIepZPPkBlfnPvOvc7XwTmFDV6rYRQPpTNhtXeSfqk8sOcUNa35dG9df/9nLby7Zz1xor4irr6Te+zZToPAHvT5Go+tGhTn7T+Y0JvqdzFO2Z7AfHsqXsH5O+tpw3pGzOeWHAZqRn9H4bZ7+6QoXy6Dtf2fMzL92aOVRa09HZTycCTenu0d5a4An/eWk1Dw8Bf/v1PyYFBuuXKZ8wiEIybed7RlHD7wSTKJwJT8tv65uuX8cwfvMzi0qOubgPzd6uYOTvFmhhjxgILLiN10dfcgjurJuj22vn+j/UsF5cUcdX8F1k56/XeDNFYd0Oix5zuLqRwMYeZyhOv1fLAAw/0Zrj46/C278C7vSdAT81v4awpezl5kCc5igAXfCmuTG/sZunM3N5+sqBkEp/+ze8pqZgMF94E7/tNTutjjPGHBZeRCnnjGNMC3i/y/HB+n9UNJZP5r3e8nVn1bnwiEGROUSN5gVjPoBpjBbMAABSaSURBVP2+j3yE7f89vacl88GFz/X+wj/lKmLuzxSJxI2PnH0DvOk6KPfGV8IS5Zxpe7wbTxb2dn/1tCREoHgKhAq9zxEvuCyoFD69+l/71PnTJ/xtwNecv2CmtzB9WdLDcXbl3qTrkzr3U7Bk5fC3N8aMGhZcRswLCEHXcplWXNpnbWuR9/mUvUf41NK/gQR6Wind5/1YUxPRzmDvGAzKVpawlTdAqKC3pFQHRFZ+I0Et3bbdJ++Iu6hRAlAyI+FuAnFPzSyaeRy85+dw0X/Cig8nzP/pE/7GWVP3pVZHY8y4ZsFlpIJujEW8E/G8iqlUTCojFgyRF8jrk7Xr5PfzP0/VsvXBeXQ0hlhUUgdAfpd3/UdEe1scv+NSfsfboHByT4vm4MG+M8o8LiIF48pa8JaexeJQFwAFkyb1zRft6v089019d1k0lX/44LV88ObvUVFe5KWVzYWT3gVlc+DSb/fJ/tHLJvORH9zVm3DcBfCJ5+D/uHuFzXhj77qSvhMI0ppBYIwZM+zeYiNVNBne9VNi/7MNuiI0rnsMmVlG66JltIR7T/gqwqbp/8zmrY/RdsJS5ncI53znKSLX/SshFx9i7R0QlL7Xg5zzb9z/dCu0DzH0PvMUuPYrEOztlotF4fTpjZRd/WmWnH2ulzhlsfd+wjugaAq8+RMAVM5fyPLOP3rrjr+Q5Ze9mz179rDiY//BCeVdMC8uAAUC8N5fwNM/hH0bKC4IQOU0OPGd8PJDXnCbclxv/lW/h4bq3skPV12W4sE1xoxVFlx80Ln0Cg48+HUAnjj/reQ1N6Lhvq2WaDDIkR/+CJa8gVggQEfp2bRE4K+LFzNp2nTe8vcnkUiMaElpnxlfnQeP0BAXWKLNzcRaWglPnzawIvPf3OfjnvVTaa/L44QvvpW2zZspWrGCtrJ/Qs6ppGDJJbD00p6819xyG3y53PsQ88Z2fv7znwOwevXqAUXp8Suhsw3Zt4GeyyOvvNsLVjNP65u5sNx7GWMmDOsWG6Gu2loOPruxT1pnSemAfLsXLiDW5g3SH542naMPPcHu/3UDAE1lpTxy6aXsP/VMWhecQOueop7tdvzTRX32s+PCf6TqrW9FYzF2/OxO7vvpnagEmLXkhL4FXvMw7XVegNtx18/5++du5Ohjj7H76vex6xO3DOiO6qyuRo93ZXV3mTl/Xb+e1atX07nfu2Bz165dvHLKqez+6v2w5G10nfpvHFy9mraXX4bZp3stmzjRpiZaN26kbYv3mIAz3/nehMcyHbGODiL19YOub378cba/9Xxi7end9t8Y4w/RNO4VNZaIyErge0AQ+Jmq3pws/4oVK3TTpsQX+CXz4Cc+wZYpU1LKO/3QIQ7P8AbPC9raaC8sHHKbix/5I49e0juD6synNxAJhThw3rkcdMGqsqaG8zY8w1MrVnD+m8+m7vVtBE9+I2tfe403vPY625Yu6dn+3Q/8lrrJk2lfvpzFIhTMm0fVzBnkf+dW5v/jmdQ/9BgAtWeewfqFC/vU5QM1tZR86Yv8+Mc/ZvHr21j+/PPMffopdp57Hnvnz0NFOPvHPyESCjJ9+nSi0SiPr1vH1M9+jlAkwgNXvZdly5bxnne9i298/WsUxrp417vezYKT+7V04jQ2NlJXV8fMmTPZs307s1tbCc+axf4vfYkjL73Mm/72BIGCggHb7Vh5CZ27dzP3jp9Qct55ABw7doxf/OIXXHnllcyY0XcSg0YiaGcnHbt2EaqspOWppyi/4gq0sxNCoZ57wkWPHYNQiGDJwLtf99e+bRuBomLy5ozNa3i6Dh8mVFnZ5354xvQnIptVdcWA9PEYXEQkCGwD/gmoBjYC71PVVwbbZrjB5Zb//E/aIsO/hUquTWpspKm0b0tr4Y6d7Dpu0ZDbhjs76crLS7iuoq6O+smTE5YzufYodVO9gHxmezt506eje/ayr6mJQzNnEOzqYu7uPVQtXULUtbDy29vpKCjoKXPBrl3sXriQhTt30pGfT0lzM8dV7aDiQx+iIBplx4O/Y9OKFczdu49pb34z5a+8zNb2dnYt6v1ex9XWEpQADV2dLHvlFZomTWLLySfzpmc3MuvAAfJ/8mNev/lm5u7dh6gSikbpCoU4NGMGkz77GWZveIbw1KkULlrEod/+lvZnnyWUl4e0tFD6vz9J3fd/wN758zjuwx+m5MUtBN92KV0/up3mZ5+lecYMdh63iLnnnMPxJ59MtLiY4oOHCDQ2QCBIwdIlhGbMoOqnP6WwtJSiKVNoKiujWGHK2WcRqa2l/ukNNP33fzP1mg9SfOppHHvxBdi7l8AFF9Dx3HNMmj+fUEEBocpK9h86RFFzMyWTJ9MJHD1yhLVr17Lyne9k3uTJHFr9ZSq/9U3am5tpve8+ii+8kP0f/RiVV72X8iuvpGnDBtoOHqTyssto27GDl9avZ8ahwyz47q107d1L66ZNFJ56KoGyMp5du5YDkydzyYIF5M+eTd2Tfyf2/HOUXfZ2tLMDwmG2tbXxhqVL0YMHKXrDG4h1dtIWixHavZuCZcuI1NcTnjaNYHk5qkrjH9bSuXcPUz/yEaSggLbnn4dgkGBJCZ179tDy1NN07t1LYPo0okdqCJ90IhUrV5K/YIE3G/PYMfKXLCFy5AgSCtH02GMc+PJXmP2Nr5N3xhnU/2kdU996Ho2PPEJtewfBZ55hxkf+BVSJqaL1x5BQiFhHOwWLF1Nw0klE6+tBhLbnnyc8Zw75xx9Px44daFcXgaIioo2N1D7yCOELLmDmW96CiKCqqc/6BOLPz4m2i8VixGIxAoEAgUCAjo4O8vLyevJ2r1NVVLVnORqNIiJ0dHQQCoXIG+T/cSomWnA5G1itqhe7z58HUNWBc3Sd4QaX73/pexwNDt49Y8aPsAbpkpHd2TmoAaJJHpsQUCFIYMTlpCO/vZ1oMEgkHB6wLtTVRTAapcO1Doubm2mJa7UFol49g9Eookpnfv6AfXSX0ZmXhwYCSCyGxreGVHu6afPb2wlGo8QCAaLBIDGXLxCLEQmFCHd1kdfZiXY/dE+ESChEZ34+gWiUWDDY8w5eD4G4c5yKEAsEUBHvO+Xnk9/R0dOD0P0DplteR0fP/otaW4mEQn3KFVVCkUjPcrxoMNjzfbsVFxfT0tJCcXEx0WiUQleuqtLU5F0HV1BQgIgQDofp6uqira2NWCyGiBCLxSgsLCQUCtHa2oqI9Ln2rbS0lMbGRkSEkpISotFoT768vDwikQgFBQV0dHT0vWYO+OhHPzqgNZ+qwYLLeB3Qnw3EX3BRDZzZP5OIXA9cDzBvXuKbPQ5lRsl8pjdOJl/DlETyOBZqhUCQPA2THw1REFGaaaUzL0hYA4Q7IxwI19MVhM5AF3Nis2iVNjq1k4rYJA4EDxPWMFNiFRyRIxwNNVMRncTcyFQOhY4xu20SB/LqaQl2EJI8pneV0SERZndNpipcDRKgNtxMlCjzOqeSHwvTGYzSQRd5GuJwXgMhDVIaLUSA+kATTcF2JkULKIp6/xmmt+bTEo7SHlYOB+upjJQhGqM6v57SSCFlkULaQhGiGiWk0BqK0hJoZ1bXZMq7itmbfwRRIUSQ+lALZZEiKiLF1IabaAm0UxTLp7yrgA6JoAGhLtRMWaSQY+GBt4YJxwJ0BWJUdpYQ1ABtgU4iEiOsAdoDEfI1TFugi8ldxagoh/Ma3XZBugJR8mIhOgMRSiL5NId67yhdHMmjJJLH4QLvfm5TO4ppD3ahwIyucjoCXVTn1zOro5yAQjgmiAoHCppoD3aRHw1RGAtzLNxGYSwPVOmSKEXRMIWxMIfzm6nsKKYmv4XSSCGgRFEqosXUB5vpDEQRoDiaBwptwS7agxHmtJWBCF0SIRJQavKamdWWR3FnjO1lEUq6hPJImGAwSBOdtAViBBVKNEQrEUpjIfbnd5EfCzA5GiJ0aBfBaDs1lZVMamwmFg7QkZ9Ha2Exoc4I0xsbCOYXoMXFdIrQFI1SWlvL/qlTiQYCLDh0CJk8hbraWlqLipjW3Ex7ezsHp05lak0NBcEgsdY2CmJRIqq0FBfTFQ7TWFbG9EOHCEUiHJ4+nTmHDxOLRunMyyNcUsKesjLKjh0jr7OT/HCYWGsrR6dNY9rhw0hMCcaiBKNRCubNo0OV6P79BGIxusJhwscdT7S2Fm1vRyNdBGJKRzBIfmcH9RUVlLe20Vo6icKWFsKlpXQdOYKoUrBoEV1HjtARjZIXidAWCBCKRDgyaxbt4TCzOzoItbayvaKCKbW1FLa10RUK0zyphKmNjcTyCyAaJdzeTmfpJGJt7YTb2wnk5yElJRAIEK2tJTxrFtLWRsehQxyYM4eCllaKjj+OmbNno6oEg0EikUhP0BARWlpaKIkL2vHrgsFgnwAD9LREAPbt20dJSQlTpkxh27ZtzJo1i9LSUkSEmpoaCgsL6ejooKOjg5kzZxIKeaf9hoYGqqurAZiSYtd+OsZrcEnU7hzQRFPVO4A7wGu5DKegKz93xXA2y4jzcl0BY4xxxutIXTUwN+7zHOBAjupijDETzngNLhuBxSKyUETygKuBNTmukzHGTBjjsltMVSMi8nHgUbypyHep6ss5rpYxxkwY4zK4AKjqWmBtruthjDET0XjtFjPGGJNDFlyMMcb4zoKLMcYY31lwMcYY47txefuX4RCRGmDPMDefCtT6WJ1MGQv1HAt1hLFRz7FQR7B6+ikXdZyvqpX9Ey24+EBENiW6t85oMxbqORbqCGOjnmOhjmD19NNoqqN1ixljjPGdBRdjjDG+s+DijztyXYEUjYV6joU6wtio51ioI1g9/TRq6mhjLsYYY3xnLRdjjDG+s+BijDHGdxZcRkhEVorI6yJSJSI35rAec0XkLyLyqoi8LCL/7tJXi8h+EXnBvS6N2+bzrt6vi8jFWazrbhHZ6uqzyaVNFpF1IrLdvVe4dBGR21w9t4jI8izUb0nc8XpBRBpF5JOj4ViKyF0ickREXopLS/vYicgql3+7iKzKQh2/KSKvuXo8JCLlLn2BiLTFHdMfx21zuvt3UuW+R+oPnx9+PdP+G2f6HDBIPX8TV8fdIvKCS8/Z8Ryg+3GZ9kr/hXc7/x3AIiAPeBFYlqO6zASWu+VJwDZgGbAa+D8J8i9z9c0HFrrvEcxSXXcDU/ul/T/gRrd8I3CLW74UeATv6aJnAc/k4G98CJg/Go4l3gNHlwMvDffYAZOBne69wi1XZLiOFwEht3xLXB0XxOfrt59ngbNd/R8BLsnCsUzrb5yNc0CievZb/23g/+b6ePZ/WctlZM4AqlR1p6p2AvcBl+eiIqp6UFWfc8tNwKvA7CSbXA7cp6odqroLqML7PrlyOXCPW74HuCIu/V71bADKRWRmFut1IbBDVZPdvSFrx1JVnwDqEpSfzrG7GFinqnWqWg+sA1Zmso6q+idVjbiPG/CeDjsoV89SVX1avTPjvXHfK2P1TGKwv3HGzwHJ6ulaH+8F/ivZPrJxPPuz4DIys4F9cZ+rSX5CzwoRWQCcBjzjkj7uuiPu6u4yIbd1V+BPIrJZRK53adNV9SB4gRKYNgrqCd5TTOP/4462YwnpH7tc1/fDeL+cuy0UkedF5HEROdelzXb16pbNOqbzN871sTwXOKyq2+PSRsXxtOAyMon6LHM6t1tESoDfAZ9U1UbgduA44FTgIF4TGnJb93NUdTlwCXCDiJyXJG/O6ineI7LfATzgkkbjsUxmsHrl8ph+AYgAv3JJB4F5qnoa8Cng1yJSmsM6pvs3zvXf/n30/fEzao6nBZeRqQbmxn2eAxzIUV0QkTBeYPmVqj4IoKqHVTWqqjHgp/R21+Ss7qp6wL0fAR5ydTrc3d3l3o/kup54we85VT3s6jvqjqWT7rHLSX3dxIHLgPe7rhlcN9NRt7wZb/ziDa6O8V1nWanjMP7GOfvbi0gIeBfwm+600XQ8LbiMzEZgsYgsdL9yrwbW5KIiru/1TuBVVf1OXHr8+MQ7ge4ZJ2uAq0UkX0QWAovxBvwyXc9iEZnUvYw30PuSq0/3rKVVwMNx9bzGzXw6C2jo7gLKgj6/CkfbsYyT7rF7FLhIRCpct89FLi1jRGQl8DngHaraGpdeKSJBt7wI79jtdPVsEpGz3L/ta+K+Vybrme7fOJfngH8EXlPVnu6uUXU8MzlbYCK88GbkbMP7hfCFHNbjLXjN3C3AC+51KfALYKtLXwPMjNvmC67er5PhmSNxZS7Cm1HzIvBy9zEDpgDrge3ufbJLF+CHrp5bgRVZqmcRcBQoi0vL+bHEC3YHgS68X6PXDefY4Y17VLnXtVmoYxXe2ET3v80fu7zvdv8OXgSeA94et58VeCf3HcAPcHcUyXA90/4bZ/ockKieLv1u4KP98ubsePZ/2e1fjDHG+M66xYwxxvjOgosxxhjfWXAxxhjjOwsuxhhjfGfBxRhjjO8suBgzDojI+SLy+1zXw5huFlyMMcb4zoKLMVkkIh8QkWfdszZ+IiJBEWkWkW+LyHMisl5EKl3eU0Vkg/Q+A6X7OS3Hi8hjIvKi2+Y4t/sSEfmteM9N+VXGn9dhTBIWXIzJEhE5AbgK78adpwJR4P1AMd49zJYDjwM3uU3uBT6nqifjXTXenf4r4IeqegrwZryrt8G7E/Yn8Z49sgg4J+NfyphBhHJdAWMmkAuB04GNrlFRiHeTyRi9Nx/8JfCgiJQB5ar6uEu/B3jA3Zdttqo+BKCq7QBuf8+qu8+UeE8mXAA8mfmvZcxAFlyMyR4B7lHVz/dJFPlSv3zJ7smUrKurI245iv3/Njlk3WLGZM964D0iMg1ARCaLyHy8/4fvcXn+GXhSVRuA+riHPX0QeFy9Z/RUi8gVbh/5IlKU1W9hTArsl40xWaKqr4jIF/GewhnAu8vtDUALcKKIbAYa8MZlwLt9/o9d8NgJXOvSPwj8RES+4vZxZRa/hjEpsbsiG5NjItKsqiW5rocxfrJuMWOMMb6zlosxxhjfWcvFGGOM7yy4GGOM8Z0FF2OMMb6z4GKMMcZ3FlyMMcb47v8DOluIngHqTOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [tdom_fat_params,ndom_fat_params,tdom_norm_params,ndom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,filename=\"testresults/demoT_2.csv\")\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
