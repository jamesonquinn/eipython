{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: [Errno 2] No such file or directory: 'testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv'\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1125.0234968662262;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 881.7810064554214;\n",
      "mode_hat tensor(0.2974, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4898, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5040, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 998.8655805587769;\n",
      "mode_hat tensor(0.4645, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9900, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9999, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 772.5725042819977;\n",
      "mode_hat tensor(0.5638, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4430, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4322, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 708.0967376232147;\n",
      "mode_hat tensor(0.5238, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8317, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8228, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 942.3891944885254;\n",
      "mode_hat tensor(0.5747, requires_grad=True)\n",
      "ltscale_hat tensor(-2.1674, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1262, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "Final mean_losses: 987.1326825514539\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.4126, -4.3435], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.3064026832580566\n",
      "ltscale_hat:\n",
      "-2.4277000427246094\n",
      "mode_hat:\n",
      "0.5791259407997131\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 1286.6930704116821;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 862.2821502685547;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4858, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5028, requires_grad=True)\n",
      "epoch 200 loss = 1070.9503083229065;\n",
      "mode_hat tensor(0.5732, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9024, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9770, requires_grad=True)\n",
      "epoch 300 loss = 956.8327114582062;\n",
      "mode_hat tensor(0.5717, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1907, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3556, requires_grad=True)\n",
      "epoch 400 loss = 754.4600331783295;\n",
      "mode_hat tensor(0.5659, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4777, requires_grad=True)\n",
      "ldfraw_hat tensor(1.6696, requires_grad=True)\n",
      "epoch 500 loss = 866.2187206745148;\n",
      "mode_hat tensor(0.5653, requires_grad=True)\n",
      "ltscale_hat tensor(-1.6745, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8557, requires_grad=True)\n",
      "epoch 600 loss = 932.982700586319;\n",
      "mode_hat tensor(0.5690, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9035, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9875, requires_grad=True)\n",
      "Final mean_losses: 1040.9998566508732\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-1.5144, -0.3795,  1.3290, -2.0341,  0.2317,  0.4471,  0.0957,  0.2383,\n",
      "         0.5340, -0.4329], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.3089, -4.2224], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.018993616104126\n",
      "ltscale_hat:\n",
      "-1.944521427154541\n",
      "mode_hat:\n",
      "0.5649628043174744\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 14835.870676517487;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1640.11048412323;\n",
      "mode_hat tensor(0.1723, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4931, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4772, requires_grad=True)\n",
      "epoch 200 loss = 1502.472872376442;\n",
      "mode_hat tensor(0.3281, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9515, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9407, requires_grad=True)\n",
      "epoch 300 loss = 1777.2125344276428;\n",
      "mode_hat tensor(0.3946, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4098, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4229, requires_grad=True)\n",
      "epoch 400 loss = 1890.0197078585625;\n",
      "mode_hat tensor(0.4557, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8744, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8583, requires_grad=True)\n",
      "epoch 500 loss = 1375.8268373012543;\n",
      "mode_hat tensor(0.4679, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2633, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2069, requires_grad=True)\n",
      "epoch 600 loss = 1081.1094653606415;\n",
      "mode_hat tensor(0.5160, requires_grad=True)\n",
      "ltscale_hat tensor(-2.6268, requires_grad=True)\n",
      "ldfraw_hat tensor(2.5394, requires_grad=True)\n",
      "epoch 700 loss = 1550.9627926945686;\n",
      "mode_hat tensor(0.4840, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9028, requires_grad=True)\n",
      "ldfraw_hat tensor(2.7377, requires_grad=True)\n",
      "Final mean_losses: 8278.4594077939\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.860539197921753\n",
      "ldfraw_sigma:\n",
      "0.6379201412200928\n",
      "ltscale_hat:\n",
      "-3.080940008163452\n",
      "ltscale_sigma:\n",
      "0.7833869457244873\n",
      "mode_hat:\n",
      "0.5215353965759277\n",
      "mode_sigma:\n",
      "0.3083323538303375\n",
      "t_part_hat:\n",
      "tensor([-0.3489,  0.0498,  0.3499, -0.2676,  0.0524,  0.3404,  0.1429,  0.0481,\n",
      "         0.2287, -0.0776], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([1.0825, 0.9528, 0.9526, 0.9023, 1.0000, 1.0109, 0.9492, 1.2435, 1.0409,\n",
      "        0.9476], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: [Errno 2] No such file or directory: 'testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv'\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 980.0103516578674;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1177.125830411911;\n",
      "mode_hat tensor(0.3103, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4275, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3404, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 1250.3508446216583;\n",
      "mode_hat tensor(0.5085, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7903, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5995, requires_grad=True)\n",
      "yay -620\n",
      "complaint 9 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-169.9698]], grad_fn=<IndexBackward>) tensor([[182.9657]], grad_fn=<IndexBackward>) tensor([[-66.7950]], grad_fn=<IndexBackward>) tensor([[53.7464]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0528]], grad_fn=<IndexBackward>)\n",
      "complaint 8 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-168.3613]], grad_fn=<IndexBackward>) tensor([[181.4645]], grad_fn=<IndexBackward>) tensor([[-66.1707]], grad_fn=<IndexBackward>) tensor([[53.1179]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0504]], grad_fn=<IndexBackward>)\n",
      "yay -680\n",
      "complaint 7 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-167.7399]], grad_fn=<IndexBackward>) tensor([[180.9522]], grad_fn=<IndexBackward>) tensor([[-65.9066]], grad_fn=<IndexBackward>) tensor([[52.7448]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0505]], grad_fn=<IndexBackward>)\n",
      "complaint 6 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-169.4030]], grad_fn=<IndexBackward>) tensor([[182.3819]], grad_fn=<IndexBackward>) tensor([[-66.0207]], grad_fn=<IndexBackward>) tensor([[52.5958]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.4461]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-168.9741]], grad_fn=<IndexBackward>) tensor([[182.1607]], grad_fn=<IndexBackward>) tensor([[-65.8462]], grad_fn=<IndexBackward>) tensor([[52.4925]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1671]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-168.9947]], grad_fn=<IndexBackward>) tensor([[182.2764]], grad_fn=<IndexBackward>) tensor([[-65.7545]], grad_fn=<IndexBackward>) tensor([[52.4126]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0602]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-169.4534]], grad_fn=<IndexBackward>) tensor([[182.7184]], grad_fn=<IndexBackward>) tensor([[-65.7388]], grad_fn=<IndexBackward>) tensor([[52.3511]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1227]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-168.9619]], grad_fn=<IndexBackward>) tensor([[182.4227]], grad_fn=<IndexBackward>) tensor([[-65.5585]], grad_fn=<IndexBackward>) tensor([[52.2385]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.1408]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-169.3275]], grad_fn=<IndexBackward>) tensor([[182.7633]], grad_fn=<IndexBackward>) tensor([[-65.5128]], grad_fn=<IndexBackward>) tensor([[52.1510]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0741]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[83]]) \n",
      "              1.. tensor([[-168.9530]], grad_fn=<IndexBackward>) tensor([[182.5870]], grad_fn=<IndexBackward>) tensor([[-65.3889]], grad_fn=<IndexBackward>) tensor([[52.0820]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.3271]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1005.9716408252716;\n",
      "mode_hat tensor(0.5758, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1026, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7326, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 835.7458202838898;\n",
      "mode_hat tensor(0.5996, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4170, requires_grad=True)\n",
      "ldfraw_hat tensor(0.8317, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 893.4733929634094;\n",
      "mode_hat tensor(0.6561, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7250, requires_grad=True)\n",
      "ldfraw_hat tensor(0.8825, requires_grad=True)\n",
      "Final mean_losses: 1101.2785406242738\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.2759, -4.2333], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.8824966549873352\n",
      "ltscale_hat:\n",
      "-1.7249844074249268\n",
      "mode_hat:\n",
      "0.6560949087142944\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 1496.6925435066223;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1097.8265762329102;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3942, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2641, requires_grad=True)\n",
      "epoch 200 loss = 883.436249256134;\n",
      "mode_hat tensor(0.5595, requires_grad=True)\n",
      "ltscale_hat tensor(-0.6571, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4622, requires_grad=True)\n",
      "epoch 300 loss = 1148.4762508869171;\n",
      "mode_hat tensor(0.5599, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8864, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6115, requires_grad=True)\n",
      "epoch 400 loss = 828.8775160312653;\n",
      "mode_hat tensor(0.5630, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0460, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7090, requires_grad=True)\n",
      "epoch 500 loss = 2834.931601047516;\n",
      "mode_hat tensor(0.5714, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2523, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7688, requires_grad=True)\n",
      "epoch 600 loss = 871.0768887996674;\n",
      "mode_hat tensor(0.5601, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4146, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7896, requires_grad=True)\n",
      "Final mean_losses: 1181.3931965854008\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-0.2278, -0.2793, -0.0858,  1.4519, -0.9536,  1.8905, -0.7732,  0.9154,\n",
      "        -2.1953,  3.0422], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.2438, -4.1546], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.8141106367111206\n",
      "ltscale_hat:\n",
      "-1.4676077365875244\n",
      "mode_hat:\n",
      "0.5633018016815186\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 117623.31003004313;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 4859.848524212837;\n",
      "mode_hat tensor(0.0903, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5013, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4879, requires_grad=True)\n",
      "epoch 200 loss = 845.5728847980499;\n",
      "mode_hat tensor(0.1643, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9742, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9421, requires_grad=True)\n",
      "epoch 300 loss = 39427.787880420685;\n",
      "mode_hat tensor(0.2608, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4110, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3903, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400 loss = 3211.697224199772;\n",
      "mode_hat tensor(0.3792, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8429, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8349, requires_grad=True)\n",
      "epoch 500 loss = 6171.574309468269;\n",
      "mode_hat tensor(0.4527, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2473, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1769, requires_grad=True)\n",
      "epoch 600 loss = 10106.563112080097;\n",
      "mode_hat tensor(0.5323, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5956, requires_grad=True)\n",
      "ldfraw_hat tensor(2.4634, requires_grad=True)\n",
      "epoch 700 loss = 3270.7181154489517;\n",
      "mode_hat tensor(0.4423, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9371, requires_grad=True)\n",
      "ldfraw_hat tensor(2.7516, requires_grad=True)\n",
      "epoch 800 loss = 1597.721910059452;\n",
      "mode_hat tensor(0.5015, requires_grad=True)\n",
      "ltscale_hat tensor(-3.2011, requires_grad=True)\n",
      "ldfraw_hat tensor(2.8893, requires_grad=True)\n",
      "epoch 900 loss = 2717.022665977478;\n",
      "mode_hat tensor(0.5488, requires_grad=True)\n",
      "ltscale_hat tensor(-3.4175, requires_grad=True)\n",
      "ldfraw_hat tensor(2.9758, requires_grad=True)\n",
      "epoch 1000 loss = 146792.79597890377;\n",
      "mode_hat tensor(0.5379, requires_grad=True)\n",
      "ltscale_hat tensor(-3.6500, requires_grad=True)\n",
      "ldfraw_hat tensor(3.0673, requires_grad=True)\n",
      "Final mean_losses: 12526.393282276049\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "3.0644891262054443\n",
      "ldfraw_sigma:\n",
      "0.6445980668067932\n",
      "ltscale_hat:\n",
      "-3.7159271240234375\n",
      "ltscale_sigma:\n",
      "0.7506757378578186\n",
      "mode_hat:\n",
      "0.5578150153160095\n",
      "mode_sigma:\n",
      "0.24338093400001526\n",
      "t_part_hat:\n",
      "tensor([-0.0600,  0.0119, -0.0392,  0.3045, -0.1868,  0.3951, -0.0918,  0.2695,\n",
      "        -0.5813,  0.4003], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.8381, 0.9779, 0.7825, 0.8240, 1.0419, 1.0589, 1.1482, 0.9008, 1.0580,\n",
      "        1.1068], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 958.2064621448517;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 885.8118772506714;\n",
      "mode_hat tensor(0.3799, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5045, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 767.7631573677063;\n",
      "mode_hat tensor(0.5475, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0036, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9992, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 750.1600143909454;\n",
      "mode_hat tensor(0.5733, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4569, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4565, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 843.0838751792908;\n",
      "mode_hat tensor(0.6005, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8756, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7998, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 743.9722228050232;\n",
      "mode_hat tensor(0.6355, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2463, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0541, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 877.3233795166016;\n",
      "mode_hat tensor(0.6149, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5219, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1969, requires_grad=True)\n",
      "yay -1820\n",
      "yay -1880\n",
      "yay -1940\n",
      "yay -2000\n",
      "yay -2060\n",
      "epoch 700 loss = 837.6484117507935;\n",
      "mode_hat tensor(0.6357, requires_grad=True)\n",
      "ltscale_hat tensor(-2.7793, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1790, requires_grad=True)\n",
      "yay -2120\n",
      "Final mean_losses: 864.5853724981499\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.3559, -4.1898], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.165966272354126\n",
      "ltscale_hat:\n",
      "-2.807084798812866\n",
      "mode_hat:\n",
      "0.6261124014854431\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 2429.86824631691;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 946.5649036169052;\n",
      "mode_hat tensor(0.5048, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5050, requires_grad=True)\n",
      "epoch 200 loss = 835.8800106048584;\n",
      "mode_hat tensor(0.5281, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9506, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9912, requires_grad=True)\n",
      "epoch 300 loss = 880.2029531002045;\n",
      "mode_hat tensor(0.5252, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2799, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4306, requires_grad=True)\n",
      "epoch 400 loss = 910.4906907081604;\n",
      "mode_hat tensor(0.5404, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5000, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7029, requires_grad=True)\n",
      "epoch 500 loss = 884.2164754867554;\n",
      "mode_hat tensor(0.5244, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7431, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8741, requires_grad=True)\n",
      "epoch 600 loss = 938.1449444293976;\n",
      "mode_hat tensor(0.5383, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9516, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9607, requires_grad=True)\n",
      "Final mean_losses: 1600.7071440390332\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-1.6869, -0.2379,  1.2276, -2.2277,  0.3204,  0.4632,  0.1172,  0.3466,\n",
      "         0.6309, -0.4440], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.3043, -4.2136], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.9004276990890503\n",
      "ltscale_hat:\n",
      "-2.0264599323272705\n",
      "mode_hat:\n",
      "0.542144238948822\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 15194.057995676994;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 6812.117061972618;\n",
      "mode_hat tensor(0.1618, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5021, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4878, requires_grad=True)\n",
      "epoch 200 loss = 2300.9530250430107;\n",
      "mode_hat tensor(0.2674, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9962, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9652, requires_grad=True)\n",
      "epoch 300 loss = 3223.428772866726;\n",
      "mode_hat tensor(0.4375, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4697, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4181, requires_grad=True)\n",
      "epoch 400 loss = 1981.3090561628342;\n",
      "mode_hat tensor(0.4517, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9098, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8508, requires_grad=True)\n",
      "epoch 500 loss = 2516.74364811182;\n",
      "mode_hat tensor(0.4940, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3251, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2024, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600 loss = 1588.5726612210274;\n",
      "mode_hat tensor(0.4729, requires_grad=True)\n",
      "ltscale_hat tensor(-2.7184, requires_grad=True)\n",
      "ldfraw_hat tensor(2.5367, requires_grad=True)\n",
      "epoch 700 loss = 1329.2007588148117;\n",
      "mode_hat tensor(0.4862, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9751, requires_grad=True)\n",
      "ldfraw_hat tensor(2.6938, requires_grad=True)\n",
      "epoch 800 loss = 1343.55820530653;\n",
      "mode_hat tensor(0.4905, requires_grad=True)\n",
      "ltscale_hat tensor(-3.2683, requires_grad=True)\n",
      "ldfraw_hat tensor(2.8657, requires_grad=True)\n",
      "Final mean_losses: 4802.075557782001\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.856783866882324\n",
      "ldfraw_sigma:\n",
      "0.662932276725769\n",
      "ltscale_hat:\n",
      "-3.440983533859253\n",
      "ltscale_sigma:\n",
      "0.7450007796287537\n",
      "mode_hat:\n",
      "0.4966871440410614\n",
      "mode_sigma:\n",
      "0.2537615895271301\n",
      "t_part_hat:\n",
      "tensor([-0.4534, -0.0138,  0.3771, -0.6700,  0.2132,  0.2029,  0.1627,  0.2300,\n",
      "         0.4192,  0.0195], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.9456, 1.0178, 1.1198, 0.9618, 1.0174, 0.9555, 0.7523, 0.9795, 0.8632,\n",
      "        0.7327], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1086.332978963852;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "complaint 9 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[277.1982]], grad_fn=<IndexBackward>) tensor([[-300.5785]], grad_fn=<IndexBackward>) tensor([[110.3607]], grad_fn=<IndexBackward>) tensor([[-86.9125]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0678]], grad_fn=<IndexBackward>)\n",
      "complaint 8 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[275.8923]], grad_fn=<IndexBackward>) tensor([[-299.2653]], grad_fn=<IndexBackward>) tensor([[109.6326]], grad_fn=<IndexBackward>) tensor([[-86.1616]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0980]], grad_fn=<IndexBackward>)\n",
      "complaint 7 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[272.6795]], grad_fn=<IndexBackward>) tensor([[-296.1422]], grad_fn=<IndexBackward>) tensor([[108.3864]], grad_fn=<IndexBackward>) tensor([[-84.9771]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0535]], grad_fn=<IndexBackward>)\n",
      "complaint 6 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[271.8889]], grad_fn=<IndexBackward>) tensor([[-295.3640]], grad_fn=<IndexBackward>) tensor([[108.1043]], grad_fn=<IndexBackward>) tensor([[-84.6998]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0706]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[271.0582]], grad_fn=<IndexBackward>) tensor([[-294.5554]], grad_fn=<IndexBackward>) tensor([[107.7912]], grad_fn=<IndexBackward>) tensor([[-84.3974]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1034]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[270.3871]], grad_fn=<IndexBackward>) tensor([[-293.8615]], grad_fn=<IndexBackward>) tensor([[107.5704]], grad_fn=<IndexBackward>) tensor([[-84.1868]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0907]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[271.5360]], grad_fn=<IndexBackward>) tensor([[-294.5703]], grad_fn=<IndexBackward>) tensor([[107.5730]], grad_fn=<IndexBackward>) tensor([[-83.9767]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.5620]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[269.1605]], grad_fn=<IndexBackward>) tensor([[-292.7095]], grad_fn=<IndexBackward>) tensor([[107.0317]], grad_fn=<IndexBackward>) tensor([[-83.6899]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.2072]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[268.4511]], grad_fn=<IndexBackward>) tensor([[-292.0408]], grad_fn=<IndexBackward>) tensor([[106.7261]], grad_fn=<IndexBackward>) tensor([[-83.4061]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.2696]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[389]]) \n",
      "              1.. tensor([[269.9147]], grad_fn=<IndexBackward>) tensor([[-292.9353]], grad_fn=<IndexBackward>) tensor([[106.6943]], grad_fn=<IndexBackward>) tensor([[-83.1035]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.5702]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1219.3412063121796;\n",
      "mode_hat tensor(0.4319, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4702, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2352, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 931.5634976625443;\n",
      "mode_hat tensor(0.5319, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8513, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2715, requires_grad=True)\n",
      "complaint -20\n",
      "yay -620\n",
      "yay -680\n",
      "complaint -40\n",
      "yay -740\n",
      "yay -800\n",
      "complaint -60\n",
      "yay -860\n",
      "epoch 300 loss = 932.8462264537811;\n",
      "mode_hat tensor(0.5399, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1937, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2922, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "complaint -80\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 883.9109748601913;\n",
      "mode_hat tensor(0.5777, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5781, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3353, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "complaint -100\n",
      "yay -1460\n",
      "epoch 500 loss = 948.8990608453751;\n",
      "mode_hat tensor(0.6048, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9064, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2870, requires_grad=True)\n",
      "yay -1520\n",
      "complaint -120\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 820.7557413578033;\n",
      "mode_hat tensor(0.5611, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2071, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1197, requires_grad=True)\n",
      "complaint -140\n",
      "yay -1820\n",
      "yay -1880\n",
      "yay -1940\n",
      "yay -2000\n",
      "yay -2060\n",
      "epoch 700 loss = 1046.8736106157303;\n",
      "mode_hat tensor(0.5897, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4932, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0486, requires_grad=True)\n",
      "yay -2120\n",
      "complaint -160\n",
      "yay -2180\n",
      "yay -2240\n",
      "Final mean_losses: 1046.188468498429\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.3330, -4.0740], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.08789720386266708\n",
      "ltscale_hat:\n",
      "-2.627011775970459\n",
      "mode_hat:\n",
      "0.5813127756118774\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 1479.2464859485626;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1051.1160072088242;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4201, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2747, requires_grad=True)\n",
      "epoch 200 loss = 1038.6972568035126;\n",
      "mode_hat tensor(0.5245, requires_grad=True)\n",
      "ltscale_hat tensor(-0.6867, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3859, requires_grad=True)\n",
      "epoch 300 loss = 833.9274837970734;\n",
      "mode_hat tensor(0.5586, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9223, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4051, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400 loss = 1070.7785416841507;\n",
      "mode_hat tensor(0.5547, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1079, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3677, requires_grad=True)\n",
      "epoch 500 loss = 1158.1947757005692;\n",
      "mode_hat tensor(0.5417, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3527, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3345, requires_grad=True)\n",
      "epoch 600 loss = 1007.2528648376465;\n",
      "mode_hat tensor(0.5494, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5421, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1967, requires_grad=True)\n",
      "epoch 700 loss = 897.8960349559784;\n",
      "mode_hat tensor(0.5416, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7844, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0761, requires_grad=True)\n",
      "Final mean_losses: 1045.9119034489543\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-0.1865, -0.2216, -0.0960,  1.4738, -1.1256,  1.4334, -0.6134,  1.0464,\n",
      "        -2.1629,  2.9300], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.3923, -4.2484], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.03161434456706047\n",
      "ltscale_hat:\n",
      "-1.8750267028808594\n",
      "mode_hat:\n",
      "0.5447664260864258\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 5544.319856584072;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 5582.08510440588;\n",
      "mode_hat tensor(0.1600, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5044, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4890, requires_grad=True)\n",
      "epoch 200 loss = 10430.667927920818;\n",
      "mode_hat tensor(0.3959, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9901, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9606, requires_grad=True)\n",
      "epoch 300 loss = 3285.0207889676094;\n",
      "mode_hat tensor(0.4439, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4731, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4173, requires_grad=True)\n",
      "epoch 400 loss = 11517.232592463493;\n",
      "mode_hat tensor(0.5025, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9267, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8573, requires_grad=True)\n",
      "epoch 500 loss = 2805.198852777481;\n",
      "mode_hat tensor(0.5305, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3721, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2419, requires_grad=True)\n",
      "Final mean_losses: 7850.688708270309\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.2418508529663086\n",
      "ldfraw_sigma:\n",
      "0.9680710434913635\n",
      "ltscale_hat:\n",
      "-2.3721096515655518\n",
      "ltscale_sigma:\n",
      "0.8843944072723389\n",
      "mode_hat:\n",
      "0.5305085778236389\n",
      "mode_sigma:\n",
      "0.39373573660850525\n",
      "t_part_hat:\n",
      "tensor([-0.0946, -0.0602,  0.0501,  0.3591, -0.2779,  0.4754, -0.2033,  0.3090,\n",
      "        -0.3509,  0.4944], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.9616, 0.8295, 0.9009, 0.7875, 0.9163, 1.0566, 0.9656, 0.8353, 1.0936,\n",
      "        1.0114], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1011.0253973007202;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 948.3020322322845;\n",
      "mode_hat tensor(0.4468, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5050, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 927.7715742588043;\n",
      "mode_hat tensor(0.5483, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(1.0025, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1008.8783192634583;\n",
      "mode_hat tensor(0.5839, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4898, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4737, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 889.0162343978882;\n",
      "mode_hat tensor(0.6012, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9425, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8696, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 897.8101146221161;\n",
      "mode_hat tensor(0.6220, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3687, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0724, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 869.1616818904877;\n",
      "mode_hat tensor(0.6201, requires_grad=True)\n",
      "ltscale_hat tensor(-2.6950, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1375, requires_grad=True)\n",
      "yay -1820\n",
      "yay -1880\n",
      "yay -1940\n",
      "yay -2000\n",
      "yay -2060\n",
      "epoch 700 loss = 920.953357219696;\n",
      "mode_hat tensor(0.6267, requires_grad=True)\n",
      "ltscale_hat tensor(-3.0352, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1892, requires_grad=True)\n",
      "yay -2120\n",
      "yay -2180\n",
      "yay -2240\n",
      "Final mean_losses: 906.7843431146948\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.5654, -4.3686], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.2089757919311523\n",
      "ltscale_hat:\n",
      "-3.1229708194732666\n",
      "mode_hat:\n",
      "0.6465418934822083\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 1374.6987636089325;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 929.7676976919174;\n",
      "mode_hat tensor(0.4971, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5045, requires_grad=True)\n",
      "epoch 200 loss = 889.8545072078705;\n",
      "mode_hat tensor(0.5004, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9891, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9976, requires_grad=True)\n",
      "epoch 300 loss = 864.2875406742096;\n",
      "mode_hat tensor(0.5037, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4162, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4547, requires_grad=True)\n",
      "epoch 400 loss = 879.9525756835938;\n",
      "mode_hat tensor(0.5234, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7560, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7835, requires_grad=True)\n",
      "epoch 500 loss = 862.0447292327881;\n",
      "mode_hat tensor(0.5125, requires_grad=True)\n",
      "ltscale_hat tensor(-2.0181, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9610, requires_grad=True)\n",
      "epoch 600 loss = 888.742404460907;\n",
      "mode_hat tensor(0.5298, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2475, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9583, requires_grad=True)\n",
      "Final mean_losses: 1481.0659474876122\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-1.0389, -0.3036,  1.2846, -1.6054,  0.2902,  0.4597,  0.1164,  0.2175,\n",
      "         0.4527, -0.3415], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.5850, -4.5212], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.9840425252914429\n",
      "ltscale_hat:\n",
      "-2.300445318222046\n",
      "mode_hat:\n",
      "0.5288234353065491\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.1585,  0.1837,  2.1454, -1.7191])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 2875.3215783834457;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 loss = 2995.4192737340927;\n",
      "mode_hat tensor(0.2356, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5013, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4842, requires_grad=True)\n",
      "epoch 200 loss = 3299.8778267502785;\n",
      "mode_hat tensor(0.3760, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9961, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9578, requires_grad=True)\n",
      "epoch 300 loss = 1999.5401501655579;\n",
      "mode_hat tensor(0.5316, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4872, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4166, requires_grad=True)\n",
      "epoch 400 loss = 1575.7583575844765;\n",
      "mode_hat tensor(0.5991, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9497, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8260, requires_grad=True)\n",
      "epoch 500 loss = 13730.682535409927;\n",
      "mode_hat tensor(0.5474, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3841, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2061, requires_grad=True)\n",
      "Final mean_losses: 3342.3376135520944\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.206073760986328\n",
      "ldfraw_sigma:\n",
      "0.932204008102417\n",
      "ltscale_hat:\n",
      "-2.384106397628784\n",
      "ltscale_sigma:\n",
      "0.8568403124809265\n",
      "mode_hat:\n",
      "0.5474441051483154\n",
      "mode_sigma:\n",
      "0.27455955743789673\n",
      "t_part_hat:\n",
      "tensor([-0.5586, -0.1153,  0.5362, -0.5919,  0.1903,  0.2315,  0.0765,  0.2370,\n",
      "         0.2439, -0.1005], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.8480, 0.7440, 0.9847, 1.0391, 0.8230, 0.7764, 0.9969, 0.8674, 0.9539,\n",
      "        0.8452], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 958.5982863903046;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1056.4202246665955;\n",
      "mode_hat tensor(0.4435, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4968, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2161, requires_grad=True)\n",
      "yay -320\n",
      "complaint 9 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-134.9539],\n",
      "        [-149.5218]], grad_fn=<IndexBackward>) tensor([[135.1072],\n",
      "        [153.9404]], grad_fn=<IndexBackward>) tensor([[-46.2445],\n",
      "        [-53.4331]], grad_fn=<IndexBackward>) tensor([[46.1147],\n",
      "        [49.0720]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0236],\n",
      "        [0.0576]], grad_fn=<IndexBackward>)\n",
      "yay -380\n",
      "complaint 8 assert approx_eq: tensor([[255]]) \n",
      "              1.. tensor([[-149.3455]], grad_fn=<IndexBackward>) tensor([[153.8207]], grad_fn=<IndexBackward>) tensor([[-53.3065]], grad_fn=<IndexBackward>) tensor([[48.9585]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.1271]], grad_fn=<IndexBackward>)\n",
      "complaint 7 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-134.8989],\n",
      "        [-150.2848]], grad_fn=<IndexBackward>) tensor([[135.0454],\n",
      "        [154.4366]], grad_fn=<IndexBackward>) tensor([[-45.9885],\n",
      "        [-53.2713]], grad_fn=<IndexBackward>) tensor([[45.8559],\n",
      "        [48.7972]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0139],\n",
      "        [-0.3224]], grad_fn=<IndexBackward>)\n",
      "complaint 6 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-134.7228],\n",
      "        [-149.5326]], grad_fn=<IndexBackward>) tensor([[134.8759],\n",
      "        [153.8652]], grad_fn=<IndexBackward>) tensor([[-45.8001],\n",
      "        [-53.0069]], grad_fn=<IndexBackward>) tensor([[45.6698],\n",
      "        [48.6002]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0228],\n",
      "        [-0.0741]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[185]]) \n",
      "              1.. tensor([[-135.6757]], grad_fn=<IndexBackward>) tensor([[135.5235]], grad_fn=<IndexBackward>) tensor([[-45.5884]], grad_fn=<IndexBackward>) tensor([[45.3548]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.3858]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-135.0992],\n",
      "        [-148.7768]], grad_fn=<IndexBackward>) tensor([[135.1272],\n",
      "        [153.3464]], grad_fn=<IndexBackward>) tensor([[-45.3829],\n",
      "        [-52.4430]], grad_fn=<IndexBackward>) tensor([[45.2098],\n",
      "        [48.1108]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1451],\n",
      "        [ 0.2374]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-134.8963],\n",
      "        [-148.5536]], grad_fn=<IndexBackward>) tensor([[135.0116],\n",
      "        [153.2141]], grad_fn=<IndexBackward>) tensor([[-45.1985],\n",
      "        [-52.2490]], grad_fn=<IndexBackward>) tensor([[45.0547],\n",
      "        [47.9453]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0286],\n",
      "        [ 0.3567]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-135.1070],\n",
      "        [-149.6359]], grad_fn=<IndexBackward>) tensor([[135.1967],\n",
      "        [154.0051]], grad_fn=<IndexBackward>) tensor([[-45.0765],\n",
      "        [-52.2257]], grad_fn=<IndexBackward>) tensor([[44.9239],\n",
      "        [47.8051]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0629],\n",
      "        [-0.0513]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-134.9983],\n",
      "        [-149.5129]], grad_fn=<IndexBackward>) tensor([[135.1882],\n",
      "        [153.9891]], grad_fn=<IndexBackward>) tensor([[-44.9072],\n",
      "        [-52.0480]], grad_fn=<IndexBackward>) tensor([[44.7878],\n",
      "        [47.6589]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0704],\n",
      "        [0.0871]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[185],\n",
      "        [255]]) \n",
      "              1.. tensor([[-134.9309],\n",
      "        [-150.0501]], grad_fn=<IndexBackward>) tensor([[135.2218],\n",
      "        [154.4423]], grad_fn=<IndexBackward>) tensor([[-44.7505],\n",
      "        [-51.9558]], grad_fn=<IndexBackward>) tensor([[44.6643],\n",
      "        [47.5259]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.2047],\n",
      "        [-0.0377]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 966.5940917730331;\n",
      "mode_hat tensor(0.6025, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9680, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3132, requires_grad=True)\n",
      "yay -620\n",
      "complaint -20\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 922.1700910329819;\n",
      "mode_hat tensor(0.6101, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3811, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2160, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "complaint -40\n",
      "yay -1040\n",
      "yay -1100\n",
      "complaint -60\n",
      "yay -1160\n",
      "epoch 400 loss = 873.4568823575974;\n",
      "mode_hat tensor(0.6036, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7297, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0694, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 857.0665171146393;\n",
      "mode_hat tensor(0.5953, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9950, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1631, requires_grad=True)\n",
      "Final mean_losses: 987.5347520534523\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.5681, -4.4784], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.16308172047138214\n",
      "ltscale_hat:\n",
      "-1.9949918985366821\n",
      "mode_hat:\n",
      "0.5953049063682556\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss = 1407.2159523963928;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 902.394047498703;\n",
      "mode_hat tensor(0.4981, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5031, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2408, requires_grad=True)\n",
      "epoch 200 loss = 1032.1620995998383;\n",
      "mode_hat tensor(0.5068, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8385, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2092, requires_grad=True)\n",
      "epoch 300 loss = 920.6856588125229;\n",
      "mode_hat tensor(0.5169, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1147, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0705, requires_grad=True)\n",
      "epoch 400 loss = 1034.8199476003647;\n",
      "mode_hat tensor(0.5199, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3933, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0229, requires_grad=True)\n",
      "epoch 500 loss = 952.6954329013824;\n",
      "mode_hat tensor(0.5226, requires_grad=True)\n",
      "ltscale_hat tensor(-1.6526, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1687, requires_grad=True)\n",
      "epoch 600 loss = 1021.7812711000443;\n",
      "mode_hat tensor(0.5341, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9218, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3922, requires_grad=True)\n",
      "epoch 700 loss = 1038.7126650810242;\n",
      "mode_hat tensor(0.5413, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2040, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5880, requires_grad=True)\n",
      "epoch 800 loss = 1010.9669536352158;\n",
      "mode_hat tensor(0.5536, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5168, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8015, requires_grad=True)\n",
      "Final mean_losses: 1012.601831359586\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-0.1086, -0.2109, -0.1351,  1.5823, -0.5711,  1.8398, -0.9180,  1.0315,\n",
      "        -2.2361,  3.1109], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.5808, -4.3712], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.8158876299858093\n",
      "ltscale_hat:\n",
      "-2.540142059326172\n",
      "mode_hat:\n",
      "0.5326717495918274\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([0.3062, 0.2151, 0.4296, 2.1763])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 22127.009661614895;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 5310.729051947594;\n",
      "mode_hat tensor(0.0988, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4870, requires_grad=True)\n",
      "epoch 200 loss = 4157.453716993332;\n",
      "mode_hat tensor(0.2287, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0026, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9675, requires_grad=True)\n",
      "epoch 300 loss = 3731.9559269547462;\n",
      "mode_hat tensor(0.3784, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4882, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4397, requires_grad=True)\n",
      "epoch 400 loss = 10521.834514558315;\n",
      "mode_hat tensor(0.4287, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9496, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8689, requires_grad=True)\n",
      "epoch 500 loss = 1542.0195673704147;\n",
      "mode_hat tensor(0.3783, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3693, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2082, requires_grad=True)\n",
      "epoch 600 loss = 4349.536128103733;\n",
      "mode_hat tensor(0.4340, requires_grad=True)\n",
      "ltscale_hat tensor(-2.7382, requires_grad=True)\n",
      "ldfraw_hat tensor(2.4548, requires_grad=True)\n",
      "epoch 700 loss = 6494.273156166077;\n",
      "mode_hat tensor(0.5274, requires_grad=True)\n",
      "ltscale_hat tensor(-3.0022, requires_grad=True)\n",
      "ldfraw_hat tensor(2.5163, requires_grad=True)\n",
      "epoch 800 loss = 4759.86824464798;\n",
      "mode_hat tensor(0.5529, requires_grad=True)\n",
      "ltscale_hat tensor(-3.1542, requires_grad=True)\n",
      "ldfraw_hat tensor(2.4555, requires_grad=True)\n",
      "epoch 900 loss = 7090.218062996864;\n",
      "mode_hat tensor(0.5655, requires_grad=True)\n",
      "ltscale_hat tensor(-3.1824, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3325, requires_grad=True)\n",
      "epoch 1000 loss = 1804.948120713234;\n",
      "mode_hat tensor(0.5064, requires_grad=True)\n",
      "ltscale_hat tensor(-3.2738, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2630, requires_grad=True)\n",
      "epoch 1100 loss = 6348.3945345282555;\n",
      "mode_hat tensor(0.5265, requires_grad=True)\n",
      "ltscale_hat tensor(-3.3115, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1299, requires_grad=True)\n",
      "epoch 1200 loss = 1715.9366073012352;\n",
      "mode_hat tensor(0.5489, requires_grad=True)\n",
      "ltscale_hat tensor(-3.3378, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9502, requires_grad=True)\n",
      "epoch 1300 loss = 1801.4014860391617;\n",
      "mode_hat tensor(0.5633, requires_grad=True)\n",
      "ltscale_hat tensor(-3.3147, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7340, requires_grad=True)\n",
      "epoch 1400 loss = 1460.5858777165413;\n",
      "mode_hat tensor(0.5715, requires_grad=True)\n",
      "ltscale_hat tensor(-3.2784, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5344, requires_grad=True)\n",
      "epoch 1500 loss = 836.4957004785538;\n",
      "mode_hat tensor(0.5707, requires_grad=True)\n",
      "ltscale_hat tensor(-3.2242, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3809, requires_grad=True)\n",
      "epoch 1600 loss = 5721.563866615295;\n",
      "mode_hat tensor(0.5856, requires_grad=True)\n",
      "ltscale_hat tensor(-3.2304, requires_grad=True)\n",
      "ldfraw_hat tensor(1.2520, requires_grad=True)\n",
      "epoch 1700 loss = 1344.9728680849075;\n",
      "mode_hat tensor(0.6051, requires_grad=True)\n",
      "ltscale_hat tensor(-3.1388, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1029, requires_grad=True)\n",
      "Final mean_losses: 3556.655550687828\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "1.0834015607833862\n",
      "ldfraw_sigma:\n",
      "0.4342521131038666\n",
      "ltscale_hat:\n",
      "-3.1343722343444824\n",
      "ltscale_sigma:\n",
      "1.3646599054336548\n",
      "mode_hat:\n",
      "0.605413019657135\n",
      "mode_sigma:\n",
      "0.07752630859613419\n",
      "t_part_hat:\n",
      "tensor([-0.1792, -0.0813, -0.1157,  0.7701, -0.7236,  1.4614, -0.8681,  0.7972,\n",
      "        -1.9345,  1.4407], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.6784, 0.8809, 0.7025, 1.0883, 0.7050, 0.7343, 0.3389, 0.7491, 0.6707,\n",
      "        1.4050], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEGCAYAAAC6i5gfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3xdVZ3//9fnnFx6v9H0QltogXIpd6hQ74xVKMjPMiMqqFAVB0dxRr/OBfg6I+rMfAUVURxFQRiLMgKCDBWBWqCICLRNL7T0Aknv6SVJ07TNPTnnfH5/nJX0JDlJk5DsE+j7+XjkkXM+e+291tlp9+fstdbe29wdERGRKMVy3QARETn6KPmIiEjklHxERCRySj4iIhI5JR8REYlcXq4bMNiNHz/ep0+fnutmiIi8paxcuXKfuxd1tVzJ5wimT59OcXFxrpshIvKWYmbbu1uubjcREYmcko+IiEROyUdERCKn5CMiIpFT8hERkcgp+YiISOSUfEREJHJKPjny4q4X2VW7K9fNEBHJCV1kmiNffOaLFMYLKf60LmAVkaOPznxyqCnZlOsmiIjkhJKPiIhETslHREQip+QjIiKRU/IREZHIKfmIiEjklHxERCRySj4iIhK5AUs+ZnafmVWY2WsZse+Z2SYzW2tmj5nZmIxlN5tZqZm9bmaXZMTnhVipmd2UEZ9hZsvMrMTMHjKzghAvDO9Lw/LpR6pDRESiNZBnPr8E5nWILQHOcPezgDeAmwHMbBZwFXB6WOenZhY3szjwE+BSYBZwdSgLcBtwh7vPBKqB60L8OqDa3U8C7gjluqyjvz+0iIgc2YAlH3d/AdjfIfZHd0+Et68AU8Pr+cCD7t7k7luBUuCC8FPq7lvcvRl4EJhvZgZ8AHgkrL8QuCJjWwvD60eAuaF8V3WIiEjEcjnm8zngqfB6CrAzY1lZiHUVPwY4kJHIWuPtthWWHwzlu9qWiIhELCfJx8y+DiSAB1pDWYp5H+J92Va29l1vZsVmVlxZWZmtiIiIvAmRJx8zWwBcDnzK3VsP/mXAtIxiU4Hd3cT3AWPMLK9DvN22wvLRpLv/utpWJ+5+t7vPdvfZRUVFffmYIiLSjUiTj5nNA24EPuLu9RmLFgFXhZlqM4CZwHJgBTAzzGwrID1hYFFIWkuBK8P6C4DHM7a1ILy+EngulO+qDhERidiAPc/HzH4DXASMN7My4BbSs9sKgSXpOQC84u5/5+7rzexhYAPp7rgb3D0ZtvNlYDEQB+5z9/WhihuBB83sP4DVwL0hfi/wKzMrJX3GcxVAd3WIiEi07HDPl2Qze/ZsLy7u/we+nbnwTADWLVjX79sWEck1M1vp7rO7Wq47HIiISOSUfEREJHJKPiIiEjklHxERiZySj4iIRE7JR0REIqfkIyIikVPyERGRyCn5iIhI5JR8REQkcko+IiISOSUfERGJnJKPiIhETslHREQip+QjIiKRU/IREZHIKfmIiEjklHxERCRySj4iIhI5JR8REYmcko+IiEROyUdERCI3YMnHzO4zswozey0jNs7MlphZSfg9NsTNzO40s1IzW2tm52WssyCULzGzBRnx881sXVjnTjOzvtYhIiLRGsgzn18C8zrEbgKedfeZwLPhPcClwMzwcz1wF6QTCXALcCFwAXBLazIJZa7PWG9eX+oQEZHoDVjycfcXgP0dwvOBheH1QuCKjPj9nvYKMMbMJgOXAEvcfb+7VwNLgHlh2Sh3f9ndHbi/w7Z6U4eIiEQs6jGfie6+ByD8nhDiU4CdGeXKQqy7eFmWeF/q6MTMrjezYjMrrqys7NUHFBGRIxssEw4sS8z7EO9LHZ2D7ne7+2x3n11UVHSEzYqISG9FnXzKW7u6wu+KEC8DpmWUmwrsPkJ8apZ4X+oQEZGIRZ18FgGtM9YWAI9nxK8NM9LmAAdDl9li4GIzGxsmGlwMLA7LasxsTpjldm2HbfWmDhERiVjeQG3YzH4DXASMN7My0rPWbgUeNrPrgB3Ax0LxJ4HLgFKgHvgsgLvvN7N/B1aEct9299ZJDF8kPaNuKPBU+KG3dYiISPQGLPm4+9VdLJqbpawDN3SxnfuA+7LEi4EzssSreluHiIhEa7BMOBARkaOIko+IiEROyUdERCKn5CMiIpFT8hERkcgp+YiISOSUfEREJHJKPiIiEjklHxERiZySj4iIRE7JR0REIqfkIyIikVPyERGRyCn5iIhI5JR8REQkcko+IiISOSUfERGJnJJPDqQfqioicvRS8hERkcgp+YiISOSUfEREJHJKPjngaMxHRI5uOUk+ZvZ/zGy9mb1mZr8xsyFmNsPMlplZiZk9ZGYFoWxheF8alk/P2M7NIf66mV2SEZ8XYqVmdlNGPGsdIiISrciTj5lNAf4BmO3uZwBx4CrgNuAOd58JVAPXhVWuA6rd/STgjlAOM5sV1jsdmAf81MziZhYHfgJcCswCrg5l6aYOERGJUK663fKAoWaWBwwD9gAfAB4JyxcCV4TX88N7wvK5ZmYh/qC7N7n7VqAUuCD8lLr7FndvBh4E5od1uqpDREQiFHnycfddwPeBHaSTzkFgJXDA3ROhWBkwJbyeAuwM6yZC+WMy4x3W6Sp+TDd1tGNm15tZsZkVV1ZW9v3DdkHX+YjI0S4X3W5jSZ+1zACOBYaT7iLrqPUIbV0s669456D73e4+291nFxUVZSsiIiJvQi663T4IbHX3SndvAX4HvAsYE7rhAKYCu8PrMmAaQFg+GtifGe+wTlfxfd3UISIiEcpF8tkBzDGzYWEcZi6wAVgKXBnKLAAeD68XhfeE5c95ut9qEXBVmA03A5gJLAdWADPDzLYC0pMSFoV1uqpDREQilIsxn2WkB/1XAetCG+4GbgS+ZmalpMdn7g2r3AscE+JfA24K21kPPEw6cT0N3ODuyTCm82VgMbAReDiUpZs6REQkQqbB7+7Nnj3bi4uL+3WbiVSCc391LgDrFqzr122LiAwGZrbS3Wd3tVx3OBARkcgp+YiISOSUfEREJHJKPjmgG4uKyNFOyUdERCKn5CMiIpFT8hERkcgp+YiISOSUfHJB8w1E5Cin5CMiIpFT8hERkcgp+YiISOSUfHJAF5mKyNGuR8nHzL5iZqMs7V4zW2VmFw9040RE5O2pp2c+n3P3Q8DFQBHwWeDWAWuViIi8rfU0+Vj4fRnw3+7+akZMRESkV3qafFaa2R9JJ5/FZjYSSA1cs97eNOYjIke7vB6Wuw44B9ji7vVmNo5015uIiEiv9fTM553A6+5+wMw+DfwrcHDgmiUiIm9nPU0+dwH1ZnY28C/AduD+AWuViIi8rfU0+STc3YH5wI/c/UfAyIFrloiIvJ31dMynxsxuBq4B3mtmcSB/4Jr19pbO4yIiR6+envl8Amgifb3PXmAK8L2+VmpmY8zsETPbZGYbzeydZjbOzJaYWUn4PTaUNTO708xKzWytmZ2XsZ0FoXyJmS3IiJ9vZuvCOneamYV41jpERCRaPUo+IeE8AIw2s8uBRnd/M2M+PwKedvdTgbOBjcBNwLPuPhN4NrwHuBSYGX6uJz3+RJhxdwtwIXABcEtGMrkrlG1db16Id1WHiIhEqKe31/k4sBz4GPBxYJmZXdmXCs1sFPA+4F4Ad2929wOkx5MWhmILgSvC6/nA/Z72CjDGzCYDlwBL3H2/u1cDS4B5Ydkod385jFPd32Fb2eoQEZEI9XTM5+vAO9y9AsDMioBngEf6UOcJQCXw32H23ErgK8BEd98D4O57zGxCKD8F2JmxflmIdRcvyxKnmzraMbPrSZ85cdxxx/XhI3ZPF5mKyNGup2M+sdbEE1T1Yt2O8oDzgLvc/Vygju67v7Ldxsf7EO8xd7/b3We7++yioqLerCoiIj3Q0wTytJktNrPPmNlngD8AT/axzjKgzN2XhfePkE5G5aHLjPC7IqP8tIz1pwK7jxCfmiVON3WIiEiEejrh4J+Bu4GzSE8QuNvdb+xLhWHywk4zOyWE5gIbgEVA64y1BcDj4fUi4Now620OcDB0nS0GLjazsWGiwcXA4rCsxszmhFlu13bYVrY6REQkQj0d88HdHwUe7ad6/x54wMwKgC2k7xMXAx42s+uAHaQnN0D6DOsyoBSoD2Vx9/1m9u/AilDu2+6+P7z+IvBLYCjwVPiB9GMgstURKV3nIyJHu26Tj5nVkH28xAB391F9qdTd1wCzsyyam6WsAzd0sZ37gPuyxIuBM7LEq7LVISIi0eo2+bi7bqEjIiL9rq8z1kRERPpMyUdERCKn5CMiIpFT8hERkcgp+YiISOSUfEREJHJKPjmgG4uKyNFOyUdERCKn5CMiIpFT8hERkcgp+YiISOSUfHJAd7UWkaOdko+IiEROyUdERCKn5CMiIpFT8skBXWQqIkc7JR8REYmcko+IiEROyUdERCKn5JMDGvMRkaOdko+IiEQuZ8nHzOJmttrMngjvZ5jZMjMrMbOHzKwgxAvD+9KwfHrGNm4O8dfN7JKM+LwQKzWzmzLiWesQEZFo5fLM5yvAxoz3twF3uPtMoBq4LsSvA6rd/STgjlAOM5sFXAWcDswDfhoSWhz4CXApMAu4OpTtrg4REYlQTpKPmU0FPgz8Irw34APAI6HIQuCK8Hp+eE9YPjeUnw886O5N7r4VKAUuCD+l7r7F3ZuBB4H5R6hDREQilKsznx8C/wKkwvtjgAPungjvy4Ap4fUUYCdAWH4wlG+Ld1inq3h3dbRjZtebWbGZFVdWVvb1M3ZJNxYVkaNd5MnHzC4HKtx9ZWY4S1E/wrL+incOut/t7rPdfXZRUVG2IiIi8ibk5aDOdwMfMbPLgCHAKNJnQmPMLC+cmUwFdofyZcA0oMzM8oDRwP6MeKvMdbLF93VTh4iIRCjyMx93v9ndp7r7dNITBp5z908BS4ErQ7EFwOPh9aLwnrD8OU/3Wy0Crgqz4WYAM4HlwApgZpjZVhDqWBTW6aoOERGJ0GC6zudG4GtmVkp6fObeEL8XOCbEvwbcBODu64GHgQ3A08AN7p4MZzVfBhaTnk33cCjbXR0iIhKhXHS7tXH354Hnw+stpGeqdSzTCHysi/X/E/jPLPEngSezxLPWISIi0RpMZz4iInKUUPIREZHIKfmIiEjklHxyQBeZisjRTslHREQip+QjIiKRU/IREZHIKfnkgJ5kKiJHOyUfERGJnJKPiIhETslHREQip+STAxrzEZGjnZKPiIhETslHREQip+QjIiKRU/IR6Scv7XqJpmRTrpsh8pag5JMDurHo28/r+1/nC898gVuX35rrpoi8JSj5iPSDg00HAdh+aHuOWyLy1qDkIyIikVPyERGRyCn55IAuMhWRo52Sj4iIRC7y5GNm08xsqZltNLP1ZvaVEB9nZkvMrCT8HhviZmZ3mlmpma01s/MytrUglC8xswUZ8fPNbF1Y504zs+7qEBGRaOXizCcB/KO7nwbMAW4ws1nATcCz7j4TeDa8B7gUmBl+rgfugnQiAW4BLgQuAG7JSCZ3hbKt680L8a7qEBGRCEWefNx9j7uvCq9rgI3AFGA+sDAUWwhcEV7PB+73tFeAMWY2GbgEWOLu+929GlgCzAvLRrn7y56+oOb+DtvKVoeIiEQop2M+ZjYdOBdYBkx09z2QTlDAhFBsCrAzY7WyEOsuXpYlTjd1dGzX9WZWbGbFlZWVff14IiLShZwlHzMbATwKfNXdD3VXNEvM+xDvMXe/291nu/vsoqKi3qw6KKQ8xf3r76ch0ZDrpoiIZJWT5GNm+aQTzwPu/rsQLg9dZoTfFSFeBkzLWH0qsPsI8alZ4t3V8bayeNtivlf8PX68+se5bspRZ8XeFew4tCPXzRAZ9HIx282Ae4GN7v6DjEWLgNYZawuAxzPi14ZZb3OAg6HLbDFwsZmNDRMNLgYWh2U1ZjYn1HVth21lq+NtpfWMp7a5NsctiVYylWR/4/5cN4PHN78t/1mJ9KtcnPm8G7gG+ICZrQk/lwG3Ah8ysxLgQ+E9wJPAFqAUuAf4EoC77wf+HVgRfr4dYgBfBH4R1tkMPBXiXdURqd7eWPRg00F+uPKHJFKJAWrRW0vl9q288cqLneLfL/4+73/o/Rxq7q4XV0QGg7yoK3T3F8k+LgMwN0t5B27oYlv3AfdliRcDZ2SJV2WrY7C7dfmtPLHlCc4YfwYfPP6DuW5Ozt3/L38PwD8+9ES7+LM7ngXSZ3yjCkZF3i4R6Tnd4eAtoPUZMUlPvqntfPC3H+SHK3/YH00SEXlTlHyOIuX15dz72r19Xv/XN3+Vlx/9TT+2qH/pnnn9p7mxgS2rV+S6GfI2puSTAwN9kByoh9WVbynlpYcf6PV6h/ZVviUfoHewopzbP3E55VtKc92UyP3x5z/msVu/xf7dZUcuLNIHSj5vQ55IcsH6sVjj4QkKG/68lGnlQ/u3Hve2pLLhz0vZtWlDpzJ7S9/gnhs+y7pnF/dr3dlYl0OJfdP6zX/d0iX9ut23guo9uwBoaWzMcUvk7UrJ521ozy+eZNb2URS+tLst9tR/3c7clVlv6JBV2ab17NvZ/VM5f33zV7njk/Pbtv/gLf/SqUzrN+eyTet7XLcMbqnkmxt7FAEln0Ft1VOLqNy+NeuyZ+/7GUt/eXen+MGKvTTv2geApfre1fXQLTey8J+yTjLkJ5+7ihWLHqVi62Y8lepzHf1NYz4DY//uXTzzi5+QSiUp27SeOz45n50b1uW6WfIWp+QzQEqWv8SPP/NxqnbtPHLhLiz95d1t04o7WrP4CVY9tahTvDffSg/t69t96xrrannhgf/uUdmuxnreqH6Dx0oe61P9Eq0n7vgOry55iqqdO9j52loAlj32cI5bJW91Sj4DxFMpmhvqsyaDqAff61rqOsV2vPYq99zwWTa99EJb7PZPXM6LD94/IG3oOBrz0UUf5RsvfaOf60jX8lY7A0omEln/TTzyn//G/Tf+Q5+2uWXVin4br2lrmVlbO7evXd0v25ajl5LPALFYetf2pFvq4dcf5syFZ2ZNEv3hjpV3dIq1duftKXkdONzOt9I32qUL7+Hhb//fTvGOB/KG2hqSiQTP7niWMxeeyd66vbg7NVX73nQbXl3yFLd/4nJa6g/fxLU3Ex9amhr54aeu4KXf/k+nZdvXrqZy25Yu163atZMfXfNRDlaUt4vv27GNx277Fs/c+9Met6Pn3lqJXQYvJZ8BYtY++bg7xXuLs5ZduD79iKHK+sPdYL05O3JPkWhpYfcbm9rF4/EEiURNj243kxpEYzc9terJx9m5fm3b+9Yzno777qfXXc2T/3V7Wzffpv2bWPnEY9z9pc/0qFt0x7o1XS5bszh9l4XmA4f3cW/OvJrq6wFY+8xTRyjZ2WtLl5Bobup0q6HWbR7Yu6fX2xSJipLPAGk78wkHwt9s+g2fXfxZlu5Y2rmsdf6m3NOB/KamCp5bOpO/PPlP/Obf/om9GdeknP+uV3jhz7NpaEl/Kx9z4iEm52ff7lvxOpyuZB78Wz/XGy//uV2Z7a+9CsChDmcN2bROOx4I2f72g5UBb6N/JpJjSj4DxGJh/CEkkW2HtgGwu253j74Zu6fXKxzddHibWbpzGhrSt+9vii0H4MDe3e2Wuyd4vux5AKZ/cBc3Tso+DuCpt8/02ZQfTrDuA3dGt6ZiDSXVJb1fb/EfWPXU7zvFU6kkT9/1Q6rKejZJJTdfGJR9pH8o+QyQWOh262l31gm7htNUc/gRCJ5yxpx4kNOu2kKRp7+dZ0taZul7w8ZCsmtu6PwAufevHt/ufXND/eE34QCWqynT/XkAHbXfGFOTT4qM5DMAn6vuQDUtzU08seWJIxfO4tn77mLpL38OtP/8f/z5j1n//DM88H//T+82OIBnT+6u0x0ZEEo+A8RicaD7b96GU1e3hcI6eN+r41n288P3XfNUiqHj02cpYw90PTDeNrYUDriJ5uZOZWbsGd7ufbaLR/szCbQ0NbL+T8+232Y4QG5euTw9SSAs6upmqZ5KsXV1ca/a9a5nC7jiz8e2Wydb8n+zn/VnX7iG32aZ6NBbVWU72h3YS5b9BUjvv1zrsjtQiUj6iZLPAOnY7dZpucPn6/J5ZdmHOMbSXWv1Bw60Lc9MWsM3HmJ0TX7W7VTvSQ8qN9Yd6rK+glHNHKm75EhnaN0dsDOnawM8v/AXPP3TOyjLvBAxrL/o9v9k5/q1xLz9dre9uorbP3E5hyrTD5dd9dTv+d2t3+Tef/g8t3/icm7/xOXdti/Tmgceapvinrk/ejMLre5ANeuff6bL5W2zBMMm+zK9u7mxYdBN9KjYtqXLv7XSjvQnJZ8Bcniqdfb/ssMb8pg2PH2AHJHX0ml5KpVq15tSkIhlPXi2NKUTV2vZbMln1tWbGXfKwU7xgpHNpI67jcrKZ47YPdXdGdwffvTddu9r9qfP1JqzXGfSemCzcNROepJkooVH/1/6mp/dJZuorSvhQGV63KPjNOKe2PbCS52mkEPPE0Qy2cjj3/+PHt1Q1FqTaB8OzYYNqjtEbF2zkl/d+A+8lnkvu8xE5K4TH+k3Sj4DpLXbovXg0jlxHP5fbJ1etD/T8LbfWf7ntx7Mw6lEV9+kW7vwMisaVpSO7d37v0dOPr25VU9rm7oZi2g9aKc81S5JpbyBZcvmwTFP9ry+bmTbH921q6ZmPc//6XRSQ9/oXT2e+fc0nt72NNsPde7eXFORMW3b2iefKA7sdQeqs3bNAlSH+/Bl3tKpcxemso/0DyWfAdI25hNmkXV1DUqmgpF1bcvb3RnBYUxt+263gliCy47dhDWGrrpuznxat9HWth5M7S6IJXhv0VZINB+x3V3KrCbU2Vp3LJX+nfJU21F3yLhGCvc8QDyRwofs6LS5leUrqa/fStFZVT1ugqdSjD35QOh6PLJDh9LXDQ2ftP8IJdur3baLUbXpyR+O889/+mf+5vG/6VTumqeuOVxX/YskEocTb6/PgjL+JjU1G3n9jW8d8e/0sy9cw2Pf/Xb2hdn+XWSe8WbcxVzkzVLyGSCxDtf5TKrazRkHMw8umac5MHxyPcfPXcmuXekr3RPJ9l1x7153DF9/4R9Zsys9DnHmmL2cNrqScSXpGVdmrWc+nQfwRx1q4Zz6yq6/Wpt1OkN4z8RtXDC+DF57JHyOnh8YM2vpeLBqfd865tOSbGTXnl+BOed9uIQTX3ucWa/Xtvt2PmxCA9Pet5t/vf/vWP7Kx5nyzgpi+T2bGp5KJjn+r/Zw8t9sZSgNxPAOZ5XeofyRzgDbL28d89ny2yf5u5pChsccT6U4bu9QmpPtE15TYwMfWp6+s/iIY+vYWfkf7K78ebu2jp5xiHhhot16m1564YgH/dVrrqWs7H5aWo6cmLu7aLYjTx3eX6lUUhMOpN8o+QwQ8xTvHL+dVEM1AJ9b/it+s78Mb04fWGIpwJ3Zqw9w9oEDFI5uYlh9gnGPfYtEeSkrfvEMQ1ry2m3z28NriD93HStWrGDvyKmkAG8J1wGFg+DI5l2cOqqi3XrnrjvEqU0HiCfTB46OB0VIt2XoMY2MnFZL2cbXKDohnFE1h1v+hG63T05fw9xJ3YyFvPoQpySWc8KIquwD/OZMvqCC83cNZ2JVIbvKfsn2sh9w0ke2p/cJMLSxfWJ53+zXOXlCJZesHU9TY3rsKtbhYtnHbvtWu/dN9XVsW7OSZHgEeV5hinn2PH8bh6qVh5879Nit32pL2NuXLKb0S98jXg6tKbRl1Diax01sK98uuWcciIdNbODYCyq5alwzyZe28IFVE5hacfj5Scv2LGPTqpeYsi8dixemt1NXe7hrLl7YxIyLdzH9Q7s4WLG3Lf6HH32XzcXLOu/LLnT1RSHbF5Ps62depJs5bf2tdtc8GcyUfAZIfNdLbC06l1/98S/UVO6ijiGUt5zE9BdfJvm99/Gz6t14Io+GmjFcs3creeactKWeIVUVbHjk97y+ZSLH7H0XeXuG4imIkeKydQfYtvl8/vCHP7Bp2Gxe41TGbf8TuLed+bz30L2kpkxl7MxjsJST35wiLySdghZneMkI/nfxF9KNtPRjF/IOVpNoOMgpV25l+iW7+Z9b/514XjjoPPlPVL32Alb8CwAmD63hnLHZb9vy+ROXw2PXc0byJf562gby6sshHLxKlr+MuzNich0Tz63i4uPqWNCcR/nOuwA4yaq5cFU64VldAYcOHX720Olbazhn/SGGjG0ib0j6ADppdvvp51tWtX/k82O3fYtHv3MLlXvbP4nzxNEtbH/wqXZpsfzAHn7/g+/w/B23Mam0iXjN4aWNU06gaeK0tvftukNTnh5rMycWD12H5qSq0wl7dF36y8PzT36X7z1xPQ9s7PwU2N1vbGx7bfH0tgtHNbPhz0tDLMUJl+3gUM3aduutXr2A1Jj0A/q2r13dliQ2r36l04P7aqr2sfzxR0gmDp9RpVLJbh6L0PkOEZA+6xtMEyTkrS3vyEWkL0rKD1DCCQDc/pN7gC8yvuq91Ddt59kRk3lv8wrWlr2DtcBpqe1sjh3P01Uns9mmk1+xn2TRKzwXHwklVzKEet5z/D5ebriUN4ZObatjF5NYwnu55s+PsvI8JxXPI0GMlZwFeXDiyzt5T3IlazmFlziffSuOIUEec3mRgoM/5JqC9ex/cQz3cjxf4gOkJh7Hzv0nUz/jeCoqtjOZ9IFx6KK/xZrLmTTrUso9vY2CcSMY0nCAXdPnAHA1/8s6zuQ9HL5/3bQln8SGXwgUEGuuYe/vv09+LMEpJbU01TWRPDZF4ZYUpScMZ9LrcRzYwRT+h/k0vV7ICIqZUHj4wtup797D8DXHMHbIPjbVns/QwjIammIU//53bWU8XPdkniIxdAS/fuQPnHracRQVpceQWpqH0jymiJqMY+itL/8/jlu2gwkp59DIkSTzq2luGdLujKdVoiWBE040U85fXbWF6s0jqdowFoD82mEk6hPkx5wLN49m+fLl1PkDfPHEWn6xdicTKWzbVjKZRyKZHsurP3iAglGtS6ztPn2Fo5oZObWOqsR9wPUAvPDCCzz33AwunPMwcALb165m+Fl1VFSfxvoXfkxLmJbf2nX51H/dziUOkesAAA/LSURBVM4N65hyyiw8FodUihWPP8qLD97Plf/6H0w97QzieXmA0TR+MuU19W0z/TInmrinSDQfvuPGQEkmk6xatYrzzjuPeDzeZbmKigpefPFF5s+f31bu6aefZty4cVxwwQXd1lFVVcW4ceO6nXxSXV3Nli1bOP/88/v2QTpoffJva5f8YJGrdtnROIBoZvOAHwFx4BfufmtXZWfPnu3FxdlvCNqd5359NS+UntL3RvbSqSPWs6n29D6vP7mljj35wzvFj09WUO3j+Ov4Yyy0jx1xO3/PfzOERoo5mwRxmmvPYK2dwuVD72Fp7AKu5VFWczpnpkq4M/YZ3s0K/sI7sm5rzPByZtRW0GSFnMxWykaMpLj2Xe3KTBy7ldrlh2gZU8TQsXUczJsJnsISCTy/AICxY3cxanQFMUtRVjaLlpZ019dJU/9E/SbnQNlwEsdMZlhhnAOjJndoRZKTTlrO+973t/zpjzvZXHaQ/NoqaEnSOGUE7zlnEVu3nsfePSd3av/5sx9nZXH6Sa+TJ7/OlkNDGLsNaE7SfOxUUpZu34jXV5MsHEre2BinfHAD9QdGsHPlOdSMGs/Qpj1MOGUv27edy7BYFcefuo6NGy5qV89IdjLmuGp27jiLAjtEoiEPS7QwLtXMpHd/gA2rV5LMK2grH6uvZeTuLSTCWUxi5Fi+fNsP+O13vsmOoekkGq+vYejOEk796DUUv7aewt3bKDi4j8TwUcTra6k76UwKR4zkhhtuoKmpiVGjRrF8+XLMjOeee45kMsnZZ5/N9OnTOffcc0kmk7S0tDBkyBBSqRSJRIKCggK2b99OaWkpF110UVsCefnll1m8eDEf/vCHOfvss9m3bx8TJkxg06ZNuDunn346sViMn/70p1RUVHDKKaewb98+Zs+ezeLFh8/6Pv3pTzN58mSGDh2KuxOPx6mtreXJJ59kw4YNnH322Vx00UVs3LiROXPmtDv4plIp7rnnHvbs2cOsWbOYOnUqZ511FiNGjGD58uUMHz6cVCrFvn37OOWUUzj22GMBaGlpobi4mAkTJlBSUkJ9fT1r165l7ty57N69m40bN/L1r3+deDxOLBYjmUyybds2ioqKuPPOO3nHO97B3Llz+ctf/sI73/lOCgrSfzd3J5VKUV1dza5du5g1axaVlZVMmjSJuro6SkpKOOOMM4jH410m7PLycsyMCRPSvQrV1dVUVFSwdu1a1q9fT35+Pi0tLXzjG9/AzFi/fj0nn3xyWxt6y8xWuvvsLpcfbcnHzOLAG8CHgDJgBXC1u2/IVr6vyWf1I5/h8demv4mWShRGj95LY+MImppG5Lopb1vTp09n27Zt/ba91oNkb33oQx9iyZIl3Zb5/Oc/z6ZNm3jxxRezLi8sLKSpqeuzv1GjRnHo0JHvIg9QVFTElClTWLOm6wkgU6dO5T3veQ/l5eUsXdr5psTZ5OXlcdZZZ7Fq1aqsyydNmsQFF1zAokWdH0YJMGPGDLZuTU+3v/DCC7n00kt7VG9HSj4dmNk7gW+6+yXh/c0A7v6dbOX7mnwe/tJ3mDDmJJ4vWN/nts5pOpFXCjf3eX0RkTfjvPPO4yMf+Uif1j1S8jkax3ymAJm3DS4DLswsYGbXEzrYjzvuuD5VcmiMM+bAbs6OD2FkIg/HgBaazIhjJGL5DEumqI87hV5AQSpBizlJcwqTMSw+BmjmrziWxlgLsVSSg/nNDE8OZUjSMZIYMVLEOFDQzJBkjBj5pDxBYzxJYzzJuJZhFKbiOElSJElZjEP5LTTEncmNhSSskaYY5HkByViMIYkERj618WbyyKMpluBAfjNjW4ZTH2+hMd7C5MYRxJMtHCxIMSKRT1M8wfjmIYDTYE0cKDTq4k2MbxpCfsrACihIJWmOpbdtxEgaVOfVMbI5BbGhjEgaewsbqclrYkxLIYWpfMa0FFCb10JNXpKGeAsTm/KBfJriKcyTTLRx7CjYT3NLDQUpZ3xtgrJRcca3xGmIQcWQBMMTxrT6PJpjMQ7mJ0jE0nfAy3OjJj9JQcpojjmOUZg0Yg5xi7N3dBx3SJJkSKyQlDtmSfLCeE2zt9DiLcQwGlNNDIsNIeFJYhanwPJI4TSlmkl4eoB/eHwotck68mMw3AwnxvRhheR5HdUtcUbE8tmfcgq8hWaH/BhYyzCOH+VUj9pC2cECho7ezjFj91C+51gSqZHE4gliVkBLIsWoUeUkaobQmBxOzf5pTDjmWOp376Apv5CmeD4NbuTh5O3ayoRJk9ibMFKJZkYXTWT4iBGUl5eTcmiJxRmZaCQ+dBgHWlIMjxvJpiaS9bXYqLGQaGFofpxRo8ewv6GJ0ceMJy8vjxEjRuDujBs3jo0bNzJjxgwOHDjAvn37OP/88zl06BC7d++mqamJqqoqxowZQ0NDAyNHjuSMM85g3LhxLF68mFgsRmNjIyeffDKbNm1i8uTJVFVV0dDQwJgxYygoKKCiooJZs2ZRUlLCWWedhbuTSCTYsGEDp556Ks3NzZSXl3POOedQVVVFfX09ZsbmzZuZMWMGU6ZMYfTo0axdu5aRI0cyceJEDh48SCKRYN++fRx//PG0tLRQUVFBLBajtraWffv2cfLJJ7N161YKCgqoq0tPKJkzZw5VVVU0NTWxY0d6TPG0006jtraWwsJCysvLqampwcITYMeNG8f+/ft5//vfz9atW9mxYwfTpk3j4MGDTJs2jYaGhrbtNYYLrydNmkReXh7jx4+ntLSU4447jpEjR7JsWXr248SJ6XHJ0aNHE4/HqampoaysjKKiIiorK5k6dSplZelJN5dddhl79+6ltLSUoUOH0tzcTHV1ejbumDFjyM/P58CBA4wcOZJkMsmwYcOYOXNmn45/PXE0nvl8DLjE3T8f3l8DXODuf5+tfF/PfEREjmZHOvMZXNMuolEGTMt4PxXY3UVZEREZAEdj8lkBzDSzGWZWAFwFZB95ExGRAXHUjfm4e8LMvgwsJj3V+j537/usABER6bWjLvkAuPuTQP/cNllERHrtaOx2ExGRHFPyERGRyCn5iIhI5JR8REQkckfdRaa9ZWaVQOfnIffMeGDfEUsNHmrvwFJ7B5baO7B6297j3b2oq4VKPgPIzIq7u8J3sFF7B5baO7DU3oHV3+1Vt5uIiEROyUdERCKn5DOw7s51A3pJ7R1Yau/AUnsHVr+2V2M+IiISOZ35iIhI5JR8REQkcko+A8TM5pnZ62ZWamY35bo9AGY2zcyWmtlGM1tvZl8J8W+a2S4zWxN+LstY5+bwGV43s0ty0OZtZrYutKs4xMaZ2RIzKwm/x4a4mdmdob1rzey8iNt6SsY+XGNmh8zsq4Np/5rZfWZWYWavZcR6vT/NbEEoX2JmCyJu7/fMbFNo02NmNibEp5tZQ8Z+/lnGOueHf0el4TNZhO3t9d8/quNHF+19KKOt28xsTYj37/51d/308w/pRzVsBk4ACoBXgVmDoF2TgfPC65HAG8As4JvAP2UpPyu0vRCYET5TPOI2bwPGd4h9F7gpvL4JuC28vgx4CjBgDrAsx/8G9gLHD6b9C7wPOA94ra/7ExgHbAm/x4bXYyNs78VAXnh9W0Z7p2eW67Cd5cA7w2d5Crg0wvb26u8f5fEjW3s7LL8d+MZA7F+d+QyMC4BSd9/i7s3Ag8D8HLcJd9/j7qvC6xpgIzClm1XmAw+6e5O7bwVKSX+2XJsPLAyvFwJXZMTv97RXgDFmNjkXDQTmApvdvbu7Y0S+f939BWB/lnb0Zn9eAixx9/3uXg0sAeZF1V53/6O7J8LbV0g/jbhLoc2j3P1lTx8p7+fwZxzw9najq79/ZMeP7tobzl4+Dvymu230df8q+QyMKcDOjPdldH+Qj5yZTQfOBZaF0JdDN8Z9rd0uDI7P4cAfzWylmV0fYhPdfQ+kEyowIcQHQ3tbXUX7/7SDdf9C7/fnYGk3wOdIf9NuNcPMVpvZn8zsvSE2hXQbW+Wivb35+w+W/fteoNzdSzJi/bZ/lXwGRrb+zkEzp93MRgCPAl9190PAXcCJwDnAHtKn2jA4Pse73f084FLgBjN7XzdlB0N7sfTj2T8C/DaEBvP+7U5X7RsU7TazrwMJ4IEQ2gMc5+7nAl8D/sfMRpH79vb275/r9ra6mvZfoPp1/yr5DIwyYFrG+6nA7hy1pR0zyyedeB5w998BuHu5uyfdPQXcw+Gun5x/DnffHX5XAI+FtpW3dqeF3xWheM7bG1wKrHL3chjc+zfo7f7MebvDJIfLgU+Frh5C91VVeL2S9LjJyaG9mV1zkba3D3//wbB/84C/AR5qjfX3/lXyGRgrgJlmNiN8C74KWJTjNrX24d4LbHT3H2TEM8dF/hponfmyCLjKzArNbAYwk/TAYlTtHW5mI1tfkx5ofi20q3WG1QLg8Yz2Xhtmac0BDrZ2J0Ws3TfGwbp/M/R2fy4GLjazsaEL6eIQi4SZzQNuBD7i7vUZ8SIzi4fXJ5Den1tCm2vMbE74P3BtxmeMor29/fsPhuPHB4FN7t7Wndbv+3cgZlDop22m0Bukvx18PdftCW16D+nT4bXAmvBzGfArYF2ILwImZ6zz9fAZXmeAZgh1094TSM/0eRVY37ofgWOAZ4GS8HtciBvwk9DedcDsHOzjYUAVMDojNmj2L+mkuAdoIf2N9bq+7E/SYy2l4eezEbe3lPSYSOu/4Z+Fsh8N/05eBVYB/1/GdmaTPuhvBv6LcHeXiNrb679/VMePbO0N8V8Cf9ehbL/uX91eR0REIqduNxERiZySj4iIRE7JR0REIqfkIyIikVPyERGRyCn5iLyNmdlFZvZErtsh0pGSj4iIRE7JR2QQMLNPm9ny8JyUn5tZ3Mxqzex2M1tlZs+aWVEoe46ZvWKHn2fT+vydk8zsGTN7NaxzYtj8CDN7xNLPwHmgR89aERlgSj4iOWZmpwGfIH0T1XOAJPApYDjpe8SdB/wJuCWscj9wo7ufRfrK+db4A8BP3P1s4F2kr1yH9N3Lv0r6+TEnAO8e8A8lcgR5uW6AiDAXOB9YEU5KhpK+uWeKwzd2/DXwOzMbDYxx9z+F+ELgt+EeeFPc/TEAd28ECNtb7uEeXZZ+KuV04MWB/1giXVPyEck9Axa6+83tgmb/1qFcd/fC6q4rrSnjdRL9v5dBQN1uIrn3LHClmU0AMLNxZnY86f+fV4YynwRedPeDQHXGg7yuAf7k6ecylZnZFWEbhWY2LNJPIdIL+gYkkmPuvsHM/pX0E1tjpO8wfANQB5xuZiuBg6THhSD92IOfheSyBfhsiF8D/NzMvh228bEIP4ZIr+iu1iKDlJnVuvuIXLdDZCCo201ERCKnMx8REYmcznxERCRySj4iIhI5JR8REYmcko+IiEROyUdERCL3/wMas+Y7AQVl4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "  for nsamps in [12,25,50]:#,150,400]:\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [ndom_norm_params,ndom_fat_params,]:#tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,\n",
    "                                        filename=\"testresults/demoT_2.csv\",\n",
    "                                      \n",
    "                                        subsample_N = nsamps)\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
