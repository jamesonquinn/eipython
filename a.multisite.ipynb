{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 ['amortized_laplace', 'meanfield', 'unamortized_laplace'] [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "1\n",
      "testresults/scenario_N400_mu1.0_sigma2.0_nu30.0.csv from file\n",
      "400\n",
      "tensor([ 4.2983,  5.0246, -0.0529,  2.4836])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "sourceparams [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1016.3002998630205; mean_loss= 1016.3002998630205; ()\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 989.5257201592128; mean_loss= 1020.4372519515316; ()\n",
      "mode_hat tensor(0.3680, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5052, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 954.1049318710964; mean_loss= 988.2963391767169; ()\n",
      "mode_hat tensor(0.6812, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0044, requires_grad=True)\n",
      "ldfraw_hat tensor(1.0043, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 968.4459052681923; mean_loss= 967.0109413871501; ()\n",
      "mode_hat tensor(0.8599, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4992, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4973, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 933.0005173484485; mean_loss= 953.9185986332225; ()\n",
      "mode_hat tensor(1.0370, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9670, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9671, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 902.0455419222515; mean_loss= 953.7136943537829; ()\n",
      "mode_hat tensor(1.0659, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3669, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3621, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 960.9518428643544; mean_loss= 951.4137255219794; ()\n",
      "mode_hat tensor(1.0836, requires_grad=True)\n",
      "ltscale_hat tensor(-2.6736, requires_grad=True)\n",
      "ldfraw_hat tensor(2.6647, requires_grad=True)\n",
      "yay -1820\n",
      "yay -1880\n",
      "yay -1940\n",
      "yay -2000\n",
      "Final mean_losses: 1021.752240930821\n",
      "file exists: testresults/fit_amortized_laplace_0_parts3_N400_S50_mu1.0_sigma2.0_nu30.0.csv\n",
      "file exists: testresults/fit_amortized_laplace_1_parts3_N400_S50_mu1.0_sigma2.0_nu30.0.csv\n",
      "guidename amortized_laplace\n",
      "sourceparams [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "globalpsi:\n",
      "tensor([-4.5887, -4.3700], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.78271484375\n",
      "ltscale_hat:\n",
      "-2.8588144779205322\n",
      "mode_hat:\n",
      "1.0923864841461182\n",
      "0 3 ['amortized_laplace', 'meanfield', 'unamortized_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 3 ['amortized_laplace', 'meanfield', 'unamortized_laplace'] [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "1\n",
      "testresults/scenario_N400_mu1.0_sigma2.0_nu30.0.csv from file\n",
      "400\n",
      "tensor([ 4.2983,  5.0246, -0.0529,  2.4836])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "sourceparams [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 8399.221264580885; mean_loss= 8399.221264580885; ()\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 9968.052617470423; mean_loss= 11658.794933625355; ()\n",
      "mode_hat tensor(0.3823, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4967, requires_grad=True)\n",
      "epoch 200 loss = 10552.654392739138; mean_loss= 9800.205157419301; ()\n",
      "mode_hat tensor(0.7090, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9837, requires_grad=True)\n",
      "epoch 300 loss = 9179.054051140944; mean_loss= 7881.078146385257; ()\n",
      "mode_hat tensor(0.8563, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4679, requires_grad=True)\n",
      "epoch 400 loss = 6632.698568582535; mean_loss= 6483.447828191442; ()\n",
      "mode_hat tensor(0.8554, requires_grad=True)\n",
      "ltscale_hat tensor(-2.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9536, requires_grad=True)\n",
      "epoch 500 loss = 5326.974462270737; mean_loss= 5534.129024394653; ()\n",
      "mode_hat tensor(0.8477, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(2.4354, requires_grad=True)\n",
      "epoch 600 loss = 4819.342683752378; mean_loss= 4769.990421589035; ()\n",
      "mode_hat tensor(0.9442, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9990, requires_grad=True)\n",
      "ldfraw_hat tensor(2.8868, requires_grad=True)\n",
      "epoch 700 loss = 3264.6525174578032; mean_loss= 4108.606580045537; ()\n",
      "mode_hat tensor(0.9476, requires_grad=True)\n",
      "ltscale_hat tensor(-3.4801, requires_grad=True)\n",
      "ldfraw_hat tensor(3.3272, requires_grad=True)\n",
      "epoch 800 loss = 2516.9955222407975; mean_loss= 3389.6282105537907; ()\n",
      "mode_hat tensor(0.9568, requires_grad=True)\n",
      "ltscale_hat tensor(-3.9613, requires_grad=True)\n",
      "ldfraw_hat tensor(3.7353, requires_grad=True)\n",
      "epoch 900 loss = 2357.6383152802787; mean_loss= 2987.6337814160383; ()\n",
      "mode_hat tensor(0.9401, requires_grad=True)\n",
      "ltscale_hat tensor(-4.4401, requires_grad=True)\n",
      "ldfraw_hat tensor(3.9904, requires_grad=True)\n",
      "epoch 1000 loss = 1785.4569546282291; mean_loss= 2599.696196525771; ()\n",
      "mode_hat tensor(0.9251, requires_grad=True)\n",
      "ltscale_hat tensor(-4.9175, requires_grad=True)\n",
      "ldfraw_hat tensor(4.0983, requires_grad=True)\n",
      "epoch 1100 loss = 2572.2923956712084; mean_loss= 2250.3795715435895; ()\n",
      "mode_hat tensor(0.9430, requires_grad=True)\n",
      "ltscale_hat tensor(-5.3960, requires_grad=True)\n",
      "ldfraw_hat tensor(4.1137, requires_grad=True)\n",
      "epoch 1200 loss = 1981.0638427933059; mean_loss= 2030.3153959587369; ()\n",
      "mode_hat tensor(0.9615, requires_grad=True)\n",
      "ltscale_hat tensor(-5.8650, requires_grad=True)\n",
      "ldfraw_hat tensor(4.1451, requires_grad=True)\n",
      "epoch 1300 loss = 1003.7252220312755; mean_loss= 1745.2608551451274; ()\n",
      "mode_hat tensor(0.9803, requires_grad=True)\n",
      "ltscale_hat tensor(-6.3488, requires_grad=True)\n",
      "ldfraw_hat tensor(4.1139, requires_grad=True)\n",
      "epoch 1400 loss = 1269.990249713262; mean_loss= 1600.0397435345142; ()\n",
      "mode_hat tensor(0.9656, requires_grad=True)\n",
      "ltscale_hat tensor(-6.8204, requires_grad=True)\n",
      "ldfraw_hat tensor(4.0568, requires_grad=True)\n",
      "epoch 1500 loss = 1526.6435836354892; mean_loss= 1447.3423516797866; ()\n",
      "mode_hat tensor(0.9792, requires_grad=True)\n",
      "ltscale_hat tensor(-7.3074, requires_grad=True)\n",
      "ldfraw_hat tensor(4.0271, requires_grad=True)\n",
      "epoch 1600 loss = 1890.4518507520356; mean_loss= 1342.2263692708611; ()\n",
      "mode_hat tensor(0.9975, requires_grad=True)\n",
      "ltscale_hat tensor(-7.7392, requires_grad=True)\n",
      "ldfraw_hat tensor(4.0343, requires_grad=True)\n",
      "epoch 1700 loss = 981.7249567111332; mean_loss= 1229.6072413668662; ()\n",
      "mode_hat tensor(1.0093, requires_grad=True)\n",
      "ltscale_hat tensor(-8.1778, requires_grad=True)\n",
      "ldfraw_hat tensor(3.9582, requires_grad=True)\n",
      "epoch 1800 loss = 979.6058186292648; mean_loss= 1154.4425828575418; ()\n",
      "mode_hat tensor(1.0106, requires_grad=True)\n",
      "ltscale_hat tensor(-8.6169, requires_grad=True)\n",
      "ldfraw_hat tensor(3.9008, requires_grad=True)\n",
      "epoch 1900 loss = 1120.024128337701; mean_loss= 1084.9491184142455; ()\n",
      "mode_hat tensor(1.0384, requires_grad=True)\n",
      "ltscale_hat tensor(-9.0764, requires_grad=True)\n",
      "ldfraw_hat tensor(3.8797, requires_grad=True)\n",
      "epoch 2000 loss = 1389.781247496605; mean_loss= 1048.2945642680104; ()\n",
      "mode_hat tensor(1.0458, requires_grad=True)\n",
      "ltscale_hat tensor(-9.5504, requires_grad=True)\n",
      "ldfraw_hat tensor(3.7819, requires_grad=True)\n",
      "Final mean_losses: 1048.2945642680104\n",
      "file exists: testresults/fit_meanfield_0_parts3_N400_S50_mu1.0_sigma2.0_nu30.0.csv\n",
      "file exists: testresults/fit_meanfield_1_parts3_N400_S50_mu1.0_sigma2.0_nu30.0.csv\n",
      "guidename meanfield\n",
      "sourceparams [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "ldfraw_hat:\n",
      "3.7818593978881836\n",
      "ldfraw_sigma:\n",
      "0.6980547308921814\n",
      "ltscale_hat:\n",
      "-9.550430297851562\n",
      "ltscale_sigma:\n",
      "3.044301748275757\n",
      "mode_hat:\n",
      "1.0457875728607178\n",
      "mode_sigma:\n",
      "0.016162030398845673\n",
      "t_part_hat:\n",
      "tensor([ 2.8940,  3.3476, -0.9479,  1.3169,  2.8350,  1.6921,  0.0257,  1.8883,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        -1.6729,  0.8486], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.6671, 0.4984, 0.6368, 0.7200, 0.8624, 0.1450, 0.7211, 0.3115, 0.5455,\n",
      "        0.3219], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 3 ['amortized_laplace', 'meanfield', 'unamortized_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 3 ['amortized_laplace', 'meanfield', 'unamortized_laplace'] [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "1\n",
      "testresults/scenario_N400_mu1.0_sigma2.0_nu30.0.csv from file\n",
      "400\n",
      "tensor([ 4.2983,  5.0246, -0.0529,  2.4836])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "sourceparams [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 3983.9284252723055; mean_loss= 3983.9284252723055; ()\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1289.903274277846; mean_loss= 2158.12052723951; ()\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5050, requires_grad=True)\n",
      "epoch 200 loss = 1037.6794958313308; mean_loss= 1158.0322574458578; ()\n",
      "mode_hat tensor(0.8115, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0012, requires_grad=True)\n",
      "ldfraw_hat tensor(1.0035, requires_grad=True)\n",
      "epoch 300 loss = 959.3173337976139; mean_loss= 982.4921001344718; ()\n",
      "mode_hat tensor(0.8224, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4902, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4938, requires_grad=True)\n",
      "epoch 400 loss = 920.5025153557458; mean_loss= 952.1353711851282; ()\n",
      "mode_hat tensor(0.8408, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9293, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9348, requires_grad=True)\n",
      "epoch 500 loss = 923.4808091918628; mean_loss= 945.027828827414; ()\n",
      "mode_hat tensor(0.8461, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3077, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3053, requires_grad=True)\n",
      "epoch 600 loss = 1003.5219959616661; mean_loss= 966.2793833849323; ()\n",
      "mode_hat tensor(0.8501, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5779, requires_grad=True)\n",
      "ldfraw_hat tensor(2.5160, requires_grad=True)\n",
      "epoch 700 loss = 964.3554736375809; mean_loss= 976.9084511254255; ()\n",
      "mode_hat tensor(0.8727, requires_grad=True)\n",
      "ltscale_hat tensor(-2.7883, requires_grad=True)\n",
      "ldfraw_hat tensor(2.6135, requires_grad=True)\n",
      "epoch 800 loss = 899.0138995846112; mean_loss= 984.9793113522257; ()\n",
      "mode_hat tensor(0.8654, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9172, requires_grad=True)\n",
      "ldfraw_hat tensor(2.7064, requires_grad=True)\n",
      "Final mean_losses: 984.9793113522257\n",
      "file exists: testresults/fit_unamortized_laplace_0_parts3_N400_S50_mu1.0_sigma2.0_nu30.0.csv\n",
      "guidename unamortized_laplace\n",
      "sourceparams [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "full_tmode:\n",
      "tensor([ 3.3050,  4.0948, -0.8772,  1.3935,  3.2665,  1.7867,  0.1708,  1.9216,\n",
      "        -1.6383,  1.0114], grad_fn=<SliceBackward>) (10 elems)\n",
      "globalpsi:\n",
      "tensor([-4.5448, -4.1820], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.7064313888549805\n",
      "ltscale_hat:\n",
      "-2.9171793460845947\n",
      "mode_hat:\n",
      "0.8653900623321533\n",
      "0 3 ['amortized_laplace', 'meanfield', 'unamortized_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield', 'unamortized_laplace'] [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "1\n",
      "testresults/scenario_N400_mu1.0_sigma2.0_nu30.0.csv from file\n",
      "400\n",
      "tensor([ 4.2983,  5.0246, -0.0529,  2.4836])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "sourceparams [{'modal_effect': 1.0, 'df': 30.0, 't_scale': 2.0}]\n",
      "sizes torch.Size([400]) 400 100 4.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1016.6898382902145; mean_loss= 1016.6898382902145; ()\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1010.5056411623955; mean_loss= 1026.0086243232436; ()\n",
      "mode_hat tensor(0.5013, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5051, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 972.258185505867; mean_loss= 995.1580348770591; ()\n",
      "mode_hat tensor(0.9240, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(1.0048, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 990.5293079018593; mean_loss= 975.9741099053256; ()\n",
      "mode_hat tensor(1.0533, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5026, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4983, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 988.967580974102; mean_loss= 966.0056271306981; ()\n",
      "mode_hat tensor(1.0597, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9806, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9790, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 978.6888266205788; mean_loss= 960.2828042916789; ()\n",
      "mode_hat tensor(1.0741, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4153, requires_grad=True)\n",
      "ldfraw_hat tensor(2.4215, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jameson\\Anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_struct.py:231: UserWarning: Encountered NaN: log_prob_sum at site 't_scale_raw'\n",
      "  warn_if_nan(site[\"log_prob_sum\"], \"log_prob_sum at site '{}'\".format(name))\n",
      "C:\\Users\\jameson\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py:138: UserWarning: Encountered NaN: loss\n",
      "  warn_if_nan(loss, \"loss\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint 9 ldfraw_hat.grad\n",
      "> c:\\users\\jameson\\dropbox\\eipython\\eipython\\multisitet.py(628)fix_df_grad()\n",
      "-> if torch.any(torch.isnan(ddfr.grad)):\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"meanfield\",\"unamortized_laplace\"]#,\"unamortized_laplace\",\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "    for aniter in range(10):\n",
    "        for trueparams in [ndom_norm_params,ndom_fat_params,]:#,tdom_fat_params,tdom_norm_params,]:\n",
    "            for nsamps,nparticles in [(50,3),(100,1),(50,5),(50,1),]:#(10,1),(10,3),(50,1),(50,3),(100,1),(400,1)]:#(44,5)]:#]:#,\n",
    "                    for guidename in guidenames:\n",
    "                        #\n",
    "\n",
    "                        print(aniter,nparticles,guidenames,trueparams)\n",
    "                        result = trainGuide(guidename,nparticles,trueparams,\n",
    "                                            filename=\"testresults/demoT_2.csv\",\n",
    "\n",
    "                                            subsample_N = nsamps,\n",
    "                                           name_offset=0)\n",
    "                        print(aniter,nparticles,guidenames)\n",
    "                        for line in range(10):\n",
    "                            print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "MCMC, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
