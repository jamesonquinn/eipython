{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "complaint 9 assert approx_eq( tensor([-8.2267e+01,  1.0443e+01,  2.7109e+00,  1.0697e+00,  1.9967e-02,\n",
      "        -8.8542e+01,  2.5713e-01, -1.4608e+00,  3.0260e+02,  8.5227e-02],\n",
      "       grad_fn=<SliceBackward>) tensor([ 9.5398e+01, -1.0671e+01, -2.7259e+00, -1.0727e+00, -2.0224e-02,\n",
      "         8.9496e+01, -2.5961e-01,  1.7317e+00, -3.0406e+02, -9.1723e-02],\n",
      "       grad_fn=<SliceBackward>) tensor([-101.9181,   39.5448,   24.6985,   18.0587,    4.8378,  -80.2647,\n",
      "          11.3054,  -23.9506,  120.2219,    8.3443], grad_fn=<SliceBackward>) tensor([  88.7867,  -39.3176,  -24.6834,  -18.0557,   -4.8375,   79.3103,\n",
      "         -11.3029,   23.6796, -118.7607,   -8.3378], grad_fn=<SliceBackward>)\n",
      "complaint 8 assert2 approx_eq( tensor([-1.5259e-05, -3.8147e-06,  1.9073e-06,  0.0000e+00,  1.9073e-06,\n",
      "        -1.5259e-05,  0.0000e+00, -3.8147e-06,  7.2479e-04, -2.8610e-06],\n",
      "       grad_fn=<SliceBackward>)\n",
      "complaint 7 dm.grad\n",
      "complaint 6 dtr.grad\n",
      "complaint 5 ddfr.grad\n",
      "epoch 0 loss = 1322.5984432697296;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint 4 assert approx_eq( tensor([-8.2450e+01,  1.0371e+01,  2.6818e+00,  1.0541e+00,  1.8894e-02,\n",
      "        -8.8833e+01,  2.5113e-01, -1.4747e+00,  3.0192e+02,  8.2479e-02],\n",
      "       grad_fn=<SliceBackward>) tensor([ 9.5635e+01, -1.0597e+01, -2.6967e+00, -1.0571e+00, -1.9138e-02,\n",
      "         8.9792e+01, -2.5357e-01,  1.7492e+00, -3.0338e+02, -8.8794e-02],\n",
      "       grad_fn=<SliceBackward>) tensor([-101.7909,   39.3379,   24.5361,   17.9165,    4.7354,  -80.1176,\n",
      "          11.1835,  -23.9704,  119.7769,    8.2312], grad_fn=<SliceBackward>) tensor([  88.6066,  -39.1112,  -24.5211,  -17.9135,   -4.7351,   79.1588,\n",
      "         -11.1811,   23.6959, -118.3147,   -8.2249], grad_fn=<SliceBackward>)\n",
      "complaint 3 assert2 approx_eq( tensor([ 7.6294e-06,  0.0000e+00,  3.8147e-06,  5.7220e-06,  1.9073e-06,\n",
      "        -2.2888e-05,  2.8610e-06, -1.9073e-06,  6.8665e-04, -2.8610e-06],\n",
      "       grad_fn=<SliceBackward>)\n",
      "complaint 2 dm.grad\n",
      "complaint 1 dtr.grad\n",
      "complaint 0 ddfr.grad\n",
      "complaint 0\n",
      "Final mean_losses: 1332.72508714612\n",
      "complaint -20\n",
      "file exists: testresults/fit_amortized_laplace_0_N400_S12_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "file exists: testresults/fit_amortized_laplace_1_N400_S12_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "file exists: testresults/fit_amortized_laplace_2_N400_S12_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.019292674958705902\n",
      "ltscale_hat:\n",
      "-0.024948468431830406\n",
      "mode_hat:\n",
      "0.022025225684046745\n",
      "thetapsi:\n",
      "tensor([-4.5995, -4.5995], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 5161.56213593483;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 4978.695254802773\n",
      "file exists: testresults/fit_unamortized_laplace_0_N400_S12_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "file exists: testresults/fit_unamortized_laplace_1_N400_S12_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "file exists: testresults/fit_unamortized_laplace_2_N400_S12_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-5.6415e+00,  1.6460e+00,  8.1803e-01,  4.2753e-01, -3.2331e-01,\n",
      "        -5.1032e+00,  4.3945e-02, -1.9432e+00,  6.1479e+00, -1.1632e-01,\n",
      "         3.8252e-01,  4.6221e+00,  1.2439e+00, -7.7668e-01,  3.7946e+00,\n",
      "         1.2160e-01, -2.5535e-01,  2.0956e-01,  1.0776e+00,  5.4347e+00,\n",
      "        -1.7954e+00, -4.4658e-01,  3.8380e+00,  1.1113e+00, -2.2398e+00,\n",
      "         5.7211e+00, -2.4164e+00,  1.6446e+00, -6.1994e-01, -4.8976e-01,\n",
      "        -5.0947e+00, -6.6662e+00, -8.7926e-02,  2.5378e+00,  3.5191e-01,\n",
      "        -2.5506e+00,  9.3364e-01,  2.4169e+00, -5.2299e-02,  4.0263e-01,\n",
      "        -3.7006e-01, -3.7350e-01,  2.1183e-01, -1.5591e+00, -8.7995e-01,\n",
      "        -9.9503e-02,  5.3109e-01, -7.4613e-01,  1.3398e+00,  8.0819e+00,\n",
      "         5.8504e-01,  3.4499e-01, -1.5751e+00, -2.3097e+00, -3.0212e-01,\n",
      "         1.5565e-01, -1.4124e+00,  3.8216e+00, -2.9179e+00, -1.1364e+00,\n",
      "         2.4224e+00,  1.6383e+00, -5.7559e+00, -8.3826e-01,  8.2490e-02,\n",
      "        -4.6748e-01, -2.7269e+00, -1.7350e+00,  1.6716e+00, -8.2522e-01,\n",
      "        -1.2285e+00,  3.0565e+00, -1.1439e+00,  1.2036e+00, -1.8064e+00,\n",
      "         3.1142e+00, -3.0841e+00,  7.6394e-01,  3.0904e-02,  6.1732e-01,\n",
      "         2.4467e-01, -2.1868e+00, -4.6683e-01, -6.8200e-01, -4.0885e-01,\n",
      "        -1.9147e+00, -6.7976e-01, -5.0070e+00,  1.1975e-01, -2.8084e+00,\n",
      "        -2.5953e+00, -2.8459e+00,  9.2368e-01, -3.0948e+00,  9.8439e-01,\n",
      "        -4.2444e+00, -1.2162e+00, -1.7805e+00, -2.7029e-01,  2.0171e+00,\n",
      "        -4.8271e-01,  1.5847e+00, -2.2279e+00, -7.2269e-01, -5.4547e-01,\n",
      "         4.0774e-01, -6.2872e-01, -8.1439e-02,  2.7656e-01,  1.6353e+00,\n",
      "        -1.6375e+00,  3.3370e-01,  5.7575e-01, -4.5341e+00,  1.9685e+00,\n",
      "        -1.5103e+00,  6.1619e-01,  4.9793e+00,  6.9780e-01, -2.6279e+00,\n",
      "         1.0448e+00, -1.4842e+00, -1.1525e+00,  2.1921e-01, -2.6205e+00,\n",
      "        -2.1202e+00,  8.7117e+00,  1.5045e+00,  6.2288e-01,  4.2116e+00,\n",
      "         5.5343e+00,  4.8469e-01, -2.1237e+00,  1.2242e+00, -1.5611e+00,\n",
      "         1.4491e+01, -4.1368e-01, -9.3553e-02,  7.3996e+00,  7.4849e-01,\n",
      "         1.2483e+00, -5.3522e+00,  8.3338e+00, -2.3636e+00,  2.4829e-01,\n",
      "         3.4973e-01,  1.2845e+01, -2.5079e+00, -6.5657e-01,  1.4360e+00,\n",
      "        -1.3976e+00, -1.3060e-01, -6.9080e+00,  1.4570e+01,  3.0474e-01,\n",
      "        -2.4577e+00,  2.6426e+00,  3.0920e+00, -1.5446e+00,  3.0408e+00,\n",
      "        -2.0127e+00,  2.2213e+00, -9.7450e-01,  1.5781e-02, -1.1882e-01,\n",
      "         1.1998e+00,  2.4433e+00,  6.1352e+00,  3.5445e+00, -1.1191e-01,\n",
      "         1.6962e-01, -2.6865e+00, -1.3579e+00,  3.1241e+00,  4.2097e-01,\n",
      "         4.4461e-01,  1.6482e+00,  2.6394e+00,  4.3510e-01, -8.0111e-02,\n",
      "        -1.0483e+00, -3.2779e+00, -1.5061e+00, -1.0000e+00,  6.5111e+00,\n",
      "        -1.5054e+00,  3.6129e+00,  6.9942e-01,  8.4187e+00, -2.5880e+00,\n",
      "        -3.3617e+00, -1.5140e+00,  1.1677e+00,  4.7231e-01, -8.2901e-01,\n",
      "         4.5510e-01, -9.6925e-01, -1.9278e+00,  7.0519e-01, -2.0131e+00,\n",
      "         1.8695e+00,  1.1764e+00,  5.5833e-01,  3.5832e+00,  3.0505e-01,\n",
      "        -2.5038e+00,  1.5821e+00, -9.7251e-01,  1.3660e+00,  1.2255e-02,\n",
      "        -1.0848e+00,  9.3236e-01,  1.9684e+00,  6.0035e-01,  1.4725e+00,\n",
      "         2.6838e+00, -1.4452e+00,  3.1280e+00, -1.3093e+00,  7.3893e-02,\n",
      "        -1.2727e+00, -4.4914e-01,  1.0062e+00,  1.5540e+00,  3.2049e-01,\n",
      "        -3.8081e-01,  1.6945e-01, -2.5317e+00, -7.1156e-01, -8.5860e-01,\n",
      "        -9.8188e-01,  3.2457e-01,  8.9659e-01, -2.3212e+00,  3.9436e+00,\n",
      "         1.0025e+00, -1.1148e+00,  1.4608e+00,  4.0912e+00,  1.2943e+00,\n",
      "        -6.2587e-01,  4.4920e-01, -2.4699e+00, -7.8309e+00,  1.9683e+00,\n",
      "        -1.1353e+00,  2.1048e-01, -5.2847e+00, -2.3613e-01,  6.5458e+00,\n",
      "         8.9519e-01, -5.8918e-01,  1.0714e+00, -2.4681e+00,  5.9522e-01,\n",
      "        -7.1862e-01, -8.5109e+00,  4.1761e-01, -5.2520e-01,  1.8189e+00,\n",
      "        -1.1152e+00, -1.4080e-01, -1.6928e+00,  4.8480e+00, -3.8675e+00,\n",
      "         3.0852e+00,  4.3233e+00,  1.3878e+00,  1.1150e+00, -7.2922e+00,\n",
      "        -4.7941e-01,  1.6097e+00,  1.0194e-01,  2.4631e+00, -1.1362e+00,\n",
      "        -1.2298e+00, -3.2841e+00, -4.6385e+00,  9.2727e-01, -1.2749e+00,\n",
      "         1.3336e+00, -1.5701e+00,  1.7512e+00, -2.6622e+00, -9.3865e-01,\n",
      "        -5.7482e+00, -6.4080e+00, -4.0823e-02, -1.4711e+00,  5.2905e+00,\n",
      "         1.8294e-01,  7.8267e-01, -8.5804e+00,  1.5034e-01, -1.0280e+00,\n",
      "         7.5744e-02, -4.5037e-01,  1.1268e-01,  5.4580e-01, -1.6620e+00,\n",
      "        -4.8050e+00, -5.2320e-01, -6.4527e-01,  1.2043e+00,  2.7006e-01,\n",
      "        -6.4339e-01,  1.8681e+00, -1.0747e+01,  2.6266e+00,  3.6049e+00,\n",
      "        -2.5718e+00, -8.0985e-01, -5.3677e-01, -1.2150e-01, -2.3956e-01,\n",
      "        -4.0766e+00,  1.3443e+00, -1.4394e+00,  5.8780e-01,  4.8767e-01,\n",
      "        -6.4095e-02, -1.0848e+00, -2.8426e+00, -1.5442e-01,  4.0436e-01,\n",
      "        -2.6814e+00,  6.8003e-01,  6.4855e-01, -8.5480e-01,  1.1096e-01,\n",
      "        -1.5387e+00, -2.3467e+00,  2.8151e+00, -6.3640e-01,  1.7897e+00,\n",
      "         3.2136e+00,  5.2929e-01, -9.2443e-01, -3.9022e+00,  1.2445e+01,\n",
      "        -2.9088e+00, -6.0897e+00, -4.1451e-01, -4.8297e+00, -1.9267e-01,\n",
      "         7.3278e-01,  1.7536e+00,  1.3691e+00, -2.7435e+00,  2.3816e+00,\n",
      "         2.4702e+00, -1.2687e-01, -8.1038e-01,  4.2829e+00, -4.2863e+00,\n",
      "        -1.4102e+00,  1.2358e+00, -6.6752e-01, -3.4299e+00, -9.8693e-01,\n",
      "        -1.6730e+00,  4.2223e+00,  2.3754e+00,  8.2222e+00, -2.2296e-01,\n",
      "         5.1595e-01, -1.0676e+00, -1.9448e+00, -3.6679e+00, -1.4253e+00,\n",
      "         3.5412e-01,  8.4462e-01,  6.5691e-01,  1.6800e+00, -4.4666e-01,\n",
      "        -5.1956e-02,  7.2615e-01,  5.4399e-01,  4.3249e+00, -3.6420e+00,\n",
      "        -7.2455e-01,  5.9262e-01, -8.3236e-01,  1.8336e+00,  2.5228e+00,\n",
      "        -1.0354e+01,  6.5895e-01,  3.2782e-01, -3.3943e+00, -5.5059e+00,\n",
      "        -1.5545e-01,  1.0995e+00, -4.7929e-01, -1.6185e-01, -1.0629e+00,\n",
      "        -7.8924e-01,  3.3197e+00, -8.1913e-01,  2.2374e-01, -2.1979e+00],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.011724702082574368\n",
      "ltscale_hat:\n",
      "-0.013315988704562187\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 118213.9912994504;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 114222.85135057493\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "0.023582404479384422\n",
      "ldfraw_sigma:\n",
      "0.9926800727844238\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "ltscale_sigma:\n",
      "0.9876028299331665\n",
      "mode_hat:\n",
      "-0.002004945417866111\n",
      "mode_sigma:\n",
      "0.9867752194404602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_part_hat:\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0140,  0.0000, -0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0082,  0.0000,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0030,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0030,  0.0000,  0.0030,  0.0000,  0.0082,  0.0000,\n",
      "        -0.0107,  0.0000,  0.0000,  0.0000, -0.0172,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0030,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0082,  0.0000,  0.0000,  0.0000, -0.0057,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0082,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0057,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0057,  0.0000,  0.0000,  0.0000,  0.0000,  0.0030,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0057,\n",
      "         0.0000,  0.0000,  0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0082,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0140, -0.0140,  0.0000,\n",
      "         0.0000,  0.0140,  0.0000,  0.0000,  0.0000,  0.0000, -0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0107,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,\n",
      "        -0.0030,  0.0140,  0.0000,  0.0107,  0.0000, -0.0082,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0107,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0030,  0.0000,\n",
      "         0.0000, -0.0008,  0.0140,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0030,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0140,  0.0000,  0.0082,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0082, -0.0057,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0030, -0.0057,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0082,  0.0000, -0.0057, -0.0107,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "       requires_grad=True)\n",
      "t_part_sigma:\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 1.0141, 1.0000, 1.0000, 1.0000,\n",
      "        0.9919, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000, 0.9970, 1.0000,\n",
      "        0.9970, 1.0000, 1.0082, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000, 0.9915,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0082, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9943, 1.0000, 0.9919, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9970, 1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000,\n",
      "        0.9943, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0141, 0.9861, 1.0000, 1.0000, 0.9861, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9919, 0.9970, 1.0141, 1.0000, 1.0108, 1.0000, 0.9919,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 0.9992, 1.0141,\n",
      "        1.0000, 1.0000, 0.9861, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0030, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9861, 1.0000, 1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0082, 1.0057,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0030, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0082, 1.0000, 0.9943, 0.9893, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1477.8225829601288;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay 1 fix_m_grad\n",
      "Final mean_losses: 1464.3861169525596\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.024664469063282013\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 2056.65966629982;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 2190.5570474900715\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-2.5405, -0.2396, -2.7810,  1.4479,  1.2068,  1.8429, -2.1058, -1.7662,\n",
      "         0.9705,  0.2193, -1.7468, -1.8253, -1.3015, -0.8762, -1.7528, -1.3457,\n",
      "        -1.8002,  0.2313, -0.4036, -1.5680, -0.4028, -1.2178,  2.1218, -0.9210,\n",
      "        -1.0343,  0.4334, -1.3057,  1.4636,  2.9016,  3.0387, -1.6347,  1.5272,\n",
      "         1.6347,  1.7460,  1.5338, -2.9760, -0.8630, -0.5539, -1.2114,  0.3437,\n",
      "        -0.0704, -0.0468, -0.6720,  0.4061,  0.7152, -0.4148, -0.4183,  2.0267,\n",
      "        -0.5117, -0.8107, -2.7882,  0.4663, -1.5968, -2.3694, -1.2219,  1.2727,\n",
      "        -0.3019,  0.6703,  3.1520,  1.8499,  1.9365,  3.0840,  1.1658,  1.1217,\n",
      "         1.3961, -2.0124, -0.8981, -2.1887, -1.7900, -0.5446,  0.2111, -2.5049,\n",
      "         0.9596, -3.5912,  1.0975,  0.5665,  0.2291,  2.2406,  4.1565,  1.9954,\n",
      "        -0.3724, -1.5611, -1.3620, -1.7499,  0.2263,  1.1862, -2.9601, -0.3540,\n",
      "        -0.7300, -0.4786,  0.0948,  0.5454,  2.9797, -1.2123, -0.2799,  1.8564,\n",
      "         1.1179,  1.4029,  0.3435,  0.8043, -0.1577, -3.2785, -0.1123,  1.2440,\n",
      "        -0.3239,  0.0180,  1.2483, -1.4350, -2.1021,  0.5023, -3.3919,  1.4645,\n",
      "        -0.8728,  0.1655, -1.4133,  1.2043,  2.2518,  1.0570, -0.2071, -0.5539,\n",
      "        -2.3828, -1.3041, -1.6707,  0.0379, -1.5769, -0.1738,  0.3633,  0.9327,\n",
      "         0.1933,  0.3416, -2.4654, -1.3627, -0.7408,  2.1973,  1.4076, -1.9239,\n",
      "        -0.4363,  1.3049, -1.8730, -1.3697,  1.6861,  1.6500,  3.0549,  2.5941,\n",
      "        -2.6505,  5.3004,  2.3355, -0.6995,  1.0308,  0.0890, -0.5937,  0.0733,\n",
      "         0.6974, -0.2624,  1.0112,  2.4254, -0.1833, -0.5163,  0.8456, -0.7254,\n",
      "         0.4403,  1.9660, -3.1765, -0.4469,  2.1711,  0.8714,  1.0516,  2.6546,\n",
      "         0.6330, -1.9191,  1.8782,  0.3012, -0.2563,  0.1790, -0.5953, -0.4902,\n",
      "         0.5505,  0.4781,  0.1404,  2.8865,  2.4708,  0.2202, -1.2706, -1.2874,\n",
      "         1.4338,  1.4566,  2.1212,  2.3147,  0.9758,  0.4796,  1.4660,  3.3162,\n",
      "         1.2441, -0.8202, -1.4335, -0.6330,  0.5990,  0.5291,  0.1734, -0.6267,\n",
      "        -2.3801, -1.9496,  0.8346, -0.3365,  1.5136, -2.3413, -2.5927, -0.0191,\n",
      "         1.6221, -0.3778,  1.5132,  2.1334,  1.0283,  0.3523, -2.5051, -0.4767,\n",
      "        -2.4117, -0.1402,  0.3064, -0.5425,  0.6427, -0.2575,  1.1922, -0.3753,\n",
      "         0.9917,  0.1610, -2.5751, -3.1843, -3.6448,  0.0697,  0.6253,  1.0547,\n",
      "         5.0899, -0.8915,  1.4350,  1.9191,  0.0269, -2.2051, -1.3137, -1.5121,\n",
      "         0.4717,  0.4678, -0.1734,  0.0694,  2.1080, -1.0055, -0.2372, -0.1337,\n",
      "        -0.4504, -1.1974,  2.1359, -0.4895,  1.6951,  2.2858,  1.3677, -0.6463,\n",
      "        -0.2802,  0.0921, -2.2939, -1.2648, -2.1787,  0.2038,  1.3826,  0.7465,\n",
      "         0.8256, -2.3603,  0.9817, -0.1072,  1.1293, -0.5727, -0.4999,  2.0823,\n",
      "        -0.6936, -0.6315,  1.7530, -0.3424, -0.5840, -0.1468, -0.2618, -1.5098,\n",
      "         0.0533,  1.5790, -2.1363, -0.7814,  1.9028, -0.8809,  0.1788, -1.5558,\n",
      "        -2.7942,  1.8579, -1.1265,  1.6268,  1.4386, -0.0804,  1.2665, -2.2487,\n",
      "         3.0570, -0.3410,  1.2860, -0.8341, -1.1315, -0.3334, -0.0659,  1.4550,\n",
      "        -2.3427, -1.4036,  0.0181,  2.1167, -1.2364, -1.1025,  1.1859, -0.7041,\n",
      "         0.1843,  1.4363, -1.9977,  0.7012,  0.8122,  0.3155, -0.7840,  0.1999,\n",
      "         0.7951, -2.8989, -1.2246, -1.3364, -1.0562, -1.4751,  2.1432,  0.9923,\n",
      "         1.6283,  1.3102,  0.3285, -0.2174, -0.1223, -1.4417,  1.8311, -0.5624,\n",
      "        -2.3174,  0.7211,  2.1172, -0.9534,  1.7786,  1.6542, -1.6193, -1.4285,\n",
      "        -1.4460, -0.1606, -0.3058, -0.6933, -0.1177,  1.9429,  0.7875, -0.5768,\n",
      "        -1.7328,  0.7727,  0.8313,  0.1143, -0.6881, -0.0886,  3.1646,  0.4200,\n",
      "         2.6301, -2.7181,  2.6395,  1.1513, -1.3645, -0.8440, -0.0689, -1.7304,\n",
      "         1.9026, -0.3537,  0.2446,  1.8909, -1.8001,  0.4503, -2.4024, -0.5686,\n",
      "         0.2894, -0.8197,  0.9691, -0.3209, -0.1832, -0.5834,  0.6757, -0.5481,\n",
      "         1.8705, -1.5886, -0.4374, -2.1008, -1.2829, -0.6303, -4.6421, -0.9668,\n",
      "         0.3665, -1.7617,  0.5942,  0.6804,  0.3957, -2.8706,  4.5349, -0.0701],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.025008928030729294\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 53661.19209712744;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean_losses: 52268.79078857651\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "0.02500000037252903\n",
      "ldfraw_sigma:\n",
      "1.0225712060928345\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "ltscale_sigma:\n",
      "1.017053484916687\n",
      "mode_hat:\n",
      "0.019232647493481636\n",
      "mode_sigma:\n",
      "0.9809511303901672\n",
      "t_part_hat:\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0140,  0.0000,  0.0000,  0.0000, -0.0057,\n",
      "         0.0000,  0.0000, -0.0108,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0140,  0.0000,\n",
      "         0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0082,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0140,  0.0000,  0.0000, -0.0107,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,  0.0000, -0.0057,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0057,  0.0000,  0.0082,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0057,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0030,  0.0000,\n",
      "         0.0057,  0.0000,  0.0000,  0.0000,  0.0082,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0057,  0.0000,  0.0000,  0.0030,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0140,  0.0000,\n",
      "         0.0140,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,\n",
      "         0.0000,  0.0000,  0.0000,  0.0030,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0082,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0140,  0.0000,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0057,  0.0000,  0.0000,\n",
      "         0.0000,  0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0107, -0.0030,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0057,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0027,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0030,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0107,  0.0000,  0.0000,  0.0082,  0.0030,  0.0000,\n",
      "         0.0000,  0.0000,  0.0082,  0.0000,  0.0107,  0.0000, -0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0097,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0082,  0.0000,  0.0000,  0.0000,  0.0000,  0.0140,  0.0000,  0.0030,\n",
      "         0.0000,  0.0000,  0.0140,  0.0000,  0.0000,  0.0000,  0.0057,  0.0000],\n",
      "       requires_grad=True)\n",
      "t_part_sigma:\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000,\n",
      "        1.0000, 0.9975, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9893, 1.0141, 1.0000, 1.0030, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0108, 0.9919, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 1.0000, 1.0108,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000, 0.9943,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0082, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9943, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9970, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000,\n",
      "        0.9919, 1.0141, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0057, 1.0000, 1.0000, 0.9970,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000, 1.0141,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0030, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000, 1.0000, 1.0000,\n",
      "        1.0030, 1.0000, 1.0000, 1.0000, 1.0000, 1.0082, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9861, 1.0000, 1.0000, 0.9919, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0057, 1.0000, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0108, 1.0030,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0057, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9930,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9861, 1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000,\n",
      "        0.9919, 0.9970, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000, 1.0108, 1.0000,\n",
      "        0.9893, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9904, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9861, 1.0000, 1.0030, 1.0000, 1.0000, 1.0141, 1.0000,\n",
      "        1.0000, 1.0000, 0.9943, 1.0000], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "complaint 9 assert approx_eq( tensor([-1.2330e+02,  1.1137e+01,  2.6641e+00,  8.7169e-01,  1.5588e-02,\n",
      "        -8.9295e+01,  2.5657e-01, -1.0310e+00,  3.0634e+02,  1.0347e-01],\n",
      "       grad_fn=<SliceBackward>) tensor([ 1.2494e+02, -1.1138e+01, -2.6945e+00, -9.3590e-01, -1.7147e-02,\n",
      "         9.0003e+01, -2.5924e-01,  1.3728e+00, -3.0656e+02, -1.0438e-01],\n",
      "       grad_fn=<SliceBackward>) tensor([-61.4194,  26.4740,  16.6501,  12.2214,   3.2587, -54.1087,   7.6131,\n",
      "        -16.2856,  80.1841,   5.6149], grad_fn=<SliceBackward>) tensor([ 59.7813, -26.4731, -16.6196, -12.1571,  -3.2572,  53.4007,  -7.6104,\n",
      "         15.9438, -79.9632,  -5.6140], grad_fn=<SliceBackward>)\n",
      "complaint 8 assert2 approx_eq( tensor([-6.4850e-05,  0.0000e+00,  3.8147e-06,  9.5367e-07, -1.9073e-06,\n",
      "         7.6294e-06,  9.5367e-07, -2.8610e-06,  2.0599e-04, -1.9073e-06],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1303.76616024971;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint 7 assert approx_eq( tensor([-1.2294e+02,  1.1212e+01,  2.6932e+00,  8.8552e-01,  1.6478e-02,\n",
      "        -8.9001e+01,  2.6266e-01, -1.0229e+00,  3.0703e+02,  1.0680e-01],\n",
      "       grad_fn=<SliceBackward>) tensor([ 1.2457e+02, -1.1213e+01, -2.7238e+00, -9.5039e-01, -1.8117e-02,\n",
      "         8.9705e+01, -2.6538e-01,  1.3605e+00, -3.0725e+02, -1.0774e-01],\n",
      "       grad_fn=<SliceBackward>) tensor([-61.5938,  26.6400,  16.7766,  12.3304,   3.3314, -54.2608,   7.7032,\n",
      "        -16.2860,  80.5650,   5.6970], grad_fn=<SliceBackward>) tensor([ 59.9623, -26.6391, -16.7460, -12.2655,  -3.3298,  53.5560,  -7.7005,\n",
      "         15.9484, -80.3444,  -5.6960], grad_fn=<SliceBackward>)\n",
      "complaint 6 assert2 approx_eq( tensor([-1.1444e-04,  1.9073e-06,  1.9073e-06,  9.5367e-07,  1.6689e-06,\n",
      "        -1.9073e-05, -1.4305e-06,  0.0000e+00,  4.1199e-04, -4.7684e-07],\n",
      "       grad_fn=<SliceBackward>)\n",
      "complaint 5 dtr.grad\n",
      "complaint 4 dm.grad\n",
      "complaint 3 ddfr.grad\n",
      "complaint 2 assert approx_eq( tensor([-1.2258e+02,  1.1287e+01,  2.7224e+00,  8.9938e-01,  1.7399e-02,\n",
      "        -8.8704e+01,  2.6883e-01, -1.0144e+00,  3.0771e+02,  1.1019e-01],\n",
      "       grad_fn=<SliceBackward>) tensor([ 1.2420e+02, -1.1288e+01, -2.7532e+00, -9.6493e-01, -1.9122e-02,\n",
      "         8.9407e+01, -2.7160e-01,  1.3479e+00, -3.0793e+02, -1.1115e-01],\n",
      "       grad_fn=<SliceBackward>) tensor([-61.8613,  26.8471,  16.9291,  12.4587,   3.4097, -54.4949,   7.8056,\n",
      "        -16.3103,  81.0692,   5.7883], grad_fn=<SliceBackward>) tensor([ 60.2341, -26.8461, -16.8984, -12.3931,  -3.4079,  53.7924,  -7.8029,\n",
      "         15.9769, -80.8484,  -5.7873], grad_fn=<SliceBackward>)\n",
      "complaint 1 assert2 approx_eq( tensor([ 1.5259e-05,  0.0000e+00,  1.9073e-06,  9.5367e-07,  4.7684e-07,\n",
      "        -3.8147e-06,  0.0000e+00, -4.7684e-06,  2.2888e-04, -4.7684e-07],\n",
      "       grad_fn=<SliceBackward>)\n",
      "complaint 0 dtr.grad\n",
      "complaint 0\n",
      "Final mean_losses: 1304.708848578003\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.007004368584603071\n",
      "ltscale_hat:\n",
      "0.01594109646975994\n",
      "mode_hat:\n",
      "-0.015113143250346184\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 44955.480207920074;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 42055.59591750756\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-5.6415e+00,  1.6212e+00,  8.0400e-01,  4.2753e-01, -3.2331e-01,\n",
      "        -5.0925e+00,  4.6955e-02, -1.9432e+00,  6.1479e+00, -1.2448e-01,\n",
      "         3.9323e-01,  4.6080e+00,  1.2439e+00, -7.7668e-01,  3.7946e+00,\n",
      "         1.2160e-01, -2.5535e-01,  2.0956e-01,  1.0776e+00,  5.4347e+00,\n",
      "        -1.7954e+00, -4.4658e-01,  3.8380e+00,  1.1113e+00, -2.2291e+00,\n",
      "         5.7211e+00, -2.4164e+00,  1.6446e+00, -6.0923e-01, -4.7873e-01,\n",
      "        -5.0978e+00, -6.6662e+00, -8.7926e-02,  2.5434e+00,  3.5191e-01,\n",
      "        -2.5365e+00,  9.3364e-01,  2.4226e+00, -5.2299e-02,  4.0263e-01,\n",
      "        -3.7006e-01, -3.7350e-01,  2.1183e-01, -1.5591e+00, -8.7995e-01,\n",
      "        -9.1340e-02,  5.3109e-01, -7.4613e-01,  1.3398e+00,  8.0789e+00,\n",
      "         5.8504e-01,  3.5067e-01, -1.5669e+00, -2.3097e+00, -3.0212e-01,\n",
      "         1.5565e-01, -1.4124e+00,  3.8297e+00, -2.9039e+00, -1.1334e+00,\n",
      "         2.4224e+00,  1.6383e+00, -5.7559e+00, -8.2589e-01,  8.2490e-02,\n",
      "        -4.6748e-01, -2.7269e+00, -1.7350e+00,  1.6716e+00, -8.1119e-01,\n",
      "        -1.2285e+00,  3.0507e+00, -1.1439e+00,  1.2036e+00, -1.8187e+00,\n",
      "         3.1142e+00, -3.0841e+00,  7.6394e-01,  2.5225e-02,  6.1732e-01,\n",
      "         2.4467e-01, -2.1918e+00, -4.4645e-01, -6.9272e-01, -4.0885e-01,\n",
      "        -1.9090e+00, -6.6077e-01, -5.0014e+00,  1.2791e-01, -2.8111e+00,\n",
      "        -2.5953e+00, -2.8459e+00,  9.2368e-01, -3.0870e+00,  9.8439e-01,\n",
      "        -4.2444e+00, -1.2162e+00, -1.7805e+00, -2.7845e-01,  2.0171e+00,\n",
      "        -4.8271e-01,  1.5847e+00, -2.2223e+00, -7.2269e-01, -5.3731e-01,\n",
      "         4.0774e-01, -6.2304e-01, -7.5760e-02,  2.7656e-01,  1.6409e+00,\n",
      "        -1.6375e+00,  3.3370e-01,  5.7575e-01, -4.5423e+00,  1.9792e+00,\n",
      "        -1.5103e+00,  6.1619e-01,  4.9793e+00,  6.9780e-01, -2.6279e+00,\n",
      "         1.0307e+00, -1.4842e+00, -1.1525e+00,  2.1921e-01, -2.6205e+00,\n",
      "        -2.1202e+00,  8.7117e+00,  1.5326e+00,  6.2288e-01,  4.1975e+00,\n",
      "         5.5424e+00,  4.8469e-01, -2.1237e+00,  1.2242e+00, -1.5611e+00,\n",
      "         1.4491e+01, -4.1368e-01, -9.3553e-02,  7.3996e+00,  7.4849e-01,\n",
      "         1.2539e+00, -5.3522e+00,  8.3338e+00, -2.3636e+00,  2.4829e-01,\n",
      "         3.4973e-01,  1.2845e+01, -2.5079e+00, -6.6474e-01,  1.4441e+00,\n",
      "        -1.3976e+00, -1.3060e-01, -6.9162e+00,  1.4575e+01,  3.0474e-01,\n",
      "        -2.4577e+00,  2.6426e+00,  3.0920e+00, -1.5446e+00,  3.0505e+00,\n",
      "        -2.0238e+00,  2.2358e+00, -9.7450e-01,  1.2771e-02, -1.1882e-01,\n",
      "         1.2106e+00,  2.4433e+00,  6.1352e+00,  3.5527e+00, -1.1191e-01,\n",
      "         1.6962e-01, -2.6865e+00, -1.3579e+00,  3.1241e+00,  4.2097e-01,\n",
      "         4.6041e-01,  1.6482e+00,  2.6394e+00,  4.3209e-01, -8.0111e-02,\n",
      "        -1.0483e+00, -3.2655e+00, -1.5061e+00, -1.0000e+00,  6.5111e+00,\n",
      "        -1.5054e+00,  3.6129e+00,  6.9942e-01,  8.4187e+00, -2.5880e+00,\n",
      "        -3.3617e+00, -1.5280e+00,  1.1677e+00,  4.7231e-01, -8.2085e-01,\n",
      "         4.7226e-01, -9.6925e-01, -1.9170e+00,  7.0519e-01, -2.0049e+00,\n",
      "         1.8695e+00,  1.1764e+00,  5.5833e-01,  3.5862e+00,  3.0505e-01,\n",
      "        -2.4981e+00,  1.5764e+00, -9.7251e-01,  1.3660e+00,  1.2255e-02,\n",
      "        -1.0848e+00,  9.3236e-01,  1.9741e+00,  6.0851e-01,  1.4832e+00,\n",
      "         2.6838e+00, -1.4452e+00,  3.1199e+00, -1.3093e+00,  7.3893e-02,\n",
      "        -1.2727e+00, -4.3510e-01,  1.0119e+00,  1.5540e+00,  3.2049e-01,\n",
      "        -3.6678e-01,  1.6945e-01, -2.5317e+00, -7.1156e-01, -8.5292e-01,\n",
      "        -9.8188e-01,  3.2156e-01,  8.9659e-01, -2.3212e+00,  3.9577e+00,\n",
      "         1.0025e+00, -1.1118e+00,  1.4715e+00,  4.0968e+00,  1.2943e+00,\n",
      "        -6.2587e-01,  4.4920e-01, -2.4592e+00, -7.8366e+00,  1.9683e+00,\n",
      "        -1.1323e+00,  2.1048e-01, -5.2847e+00, -2.3613e-01,  6.5515e+00,\n",
      "         8.9519e-01, -5.8918e-01,  1.0714e+00, -2.4681e+00,  5.8451e-01,\n",
      "        -7.1862e-01, -8.5109e+00,  4.3342e-01, -5.2520e-01,  1.8107e+00,\n",
      "        -1.1152e+00, -1.4080e-01, -1.6928e+00,  4.8480e+00, -3.8846e+00,\n",
      "         3.0852e+00,  4.3233e+00,  1.3878e+00,  1.1150e+00, -7.2922e+00,\n",
      "        -4.9344e-01,  1.6097e+00,  1.0194e-01,  2.4631e+00, -1.1265e+00,\n",
      "        -1.2298e+00, -3.2841e+00, -4.6278e+00,  9.2727e-01, -1.2749e+00,\n",
      "         1.3254e+00, -1.5701e+00,  1.7512e+00, -2.6622e+00, -9.3297e-01,\n",
      "        -5.7482e+00, -6.4080e+00, -4.0823e-02, -1.4711e+00,  5.2935e+00,\n",
      "         1.8294e-01,  7.8267e-01, -8.5697e+00,  1.5034e-01, -1.0310e+00,\n",
      "         7.5744e-02, -4.4534e-01,  1.1268e-01,  5.3509e-01, -1.6727e+00,\n",
      "        -4.8050e+00, -5.2320e-01, -6.4527e-01,  1.2184e+00,  2.8409e-01,\n",
      "        -6.2936e-01,  1.8711e+00, -1.0756e+01,  2.6266e+00,  3.6049e+00,\n",
      "        -2.5800e+00, -8.0985e-01, -5.3677e-01, -1.1443e-01, -2.3655e-01,\n",
      "        -4.0766e+00,  1.3413e+00, -1.4364e+00,  5.8780e-01,  4.8200e-01,\n",
      "        -5.5286e-02, -1.0848e+00, -2.8285e+00, -1.5442e-01,  4.0436e-01,\n",
      "        -2.6814e+00,  6.6932e-01,  6.4567e-01, -8.5480e-01,  1.2065e-01,\n",
      "        -1.5387e+00, -2.3386e+00,  2.8151e+00, -6.2236e-01,  1.7897e+00,\n",
      "         3.2166e+00,  5.2222e-01, -9.2443e-01, -3.9022e+00,  1.2445e+01,\n",
      "        -2.8948e+00, -6.0897e+00, -4.1451e-01, -4.8157e+00, -1.9267e-01,\n",
      "         7.3278e-01,  1.7536e+00,  1.3691e+00, -2.7328e+00,  2.3816e+00,\n",
      "         2.4702e+00, -1.2687e-01, -8.1038e-01,  4.2829e+00, -4.2863e+00,\n",
      "        -1.4102e+00,  1.2358e+00, -6.6451e-01, -3.4406e+00, -9.8693e-01,\n",
      "        -1.6730e+00,  4.2223e+00,  2.3836e+00,  8.2222e+00, -2.1728e-01,\n",
      "         5.2666e-01, -1.0651e+00, -1.9448e+00, -3.6649e+00, -1.4223e+00,\n",
      "         3.5412e-01,  8.5865e-01,  6.4619e-01,  1.6907e+00, -4.3849e-01,\n",
      "        -3.7922e-02,  7.3687e-01,  5.4399e-01,  4.3280e+00, -3.6420e+00,\n",
      "        -7.1639e-01,  5.9262e-01, -8.3236e-01,  1.8191e+00,  2.5285e+00,\n",
      "        -1.0354e+01,  6.5895e-01,  3.2782e-01, -3.4083e+00, -5.5059e+00,\n",
      "        -1.5545e-01,  1.1072e+00, -4.7929e-01, -1.6185e-01, -1.0629e+00,\n",
      "        -7.8924e-01,  3.3197e+00, -8.1913e-01,  2.3777e-01, -2.1897e+00],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.018207108601927757\n",
      "ltscale_hat:\n",
      "-0.02096734568476677\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 209786.99790257215;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 221561.5907993078\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "0.02496996708214283\n",
      "ldfraw_sigma:\n",
      "0.9896432757377625\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "ltscale_sigma:\n",
      "0.9876028299331665\n",
      "mode_hat:\n",
      "-0.006707297172397375\n",
      "mode_sigma:\n",
      "0.9753099083900452\n",
      "t_part_hat:\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,\n",
      "         0.0057,  0.0000,  0.0030,  0.0000,  0.0000, -0.0060,  0.0000,  0.0000,\n",
      "        -0.0082,  0.0000,  0.0000,  0.0000, -0.0030,  0.0000,  0.0082,  0.0000,\n",
      "        -0.0140,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0140,  0.0000,\n",
      "         0.0000,  0.0119,  0.0000, -0.0107,  0.0000,  0.0000,  0.0057,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0057, -0.0182,  0.0000,  0.0000,  0.0000,\n",
      "         0.0057,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0057,  0.0000,  0.0000,  0.0000, -0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,\n",
      "         0.0000,  0.0000, -0.0140, -0.0030,  0.0000, -0.0082, -0.0025, -0.0057,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0025,  0.0000,\n",
      "        -0.0030,  0.0000, -0.0140,  0.0000,  0.0057,  0.0107,  0.0057, -0.0082,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0000,  0.0000,\n",
      "         0.0000, -0.0140,  0.0000, -0.0082,  0.0000,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000, -0.0030,  0.0000,  0.0000,  0.0057,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0107,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0182,  0.0000,  0.0030,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0107,  0.0000,  0.0140, -0.0085,  0.0000,  0.0000, -0.0030,  0.0000,\n",
      "         0.0000,  0.0030,  0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0140,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0030,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,  0.0000,  0.0107,\n",
      "         0.0107,  0.0140,  0.0057,  0.0000,  0.0030, -0.0136,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0140,  0.0000,  0.0082,  0.0000,  0.0000, -0.0071,\n",
      "         0.0000,  0.0030,  0.0000,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0030,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0140,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0082,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0140, -0.0140,  0.0000,  0.0000,  0.0000,\n",
      "         0.0140,  0.0000,  0.0057,  0.0000,  0.0000,  0.0000,  0.0030,  0.0107,\n",
      "         0.0000,  0.0057,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0030,\n",
      "        -0.0082,  0.0000,  0.0000,  0.0000,  0.0030, -0.0140,  0.0000,  0.0145,\n",
      "         0.0000,  0.0000,  0.0000, -0.0082,  0.0000,  0.0000,  0.0000, -0.0082,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,  0.0082,\n",
      "         0.0000,  0.0000,  0.0030,  0.0000, -0.0107,  0.0000,  0.0000,  0.0000,\n",
      "         0.0082,  0.0000,  0.0000, -0.0107,  0.0057,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0057,  0.0000,  0.0030, -0.0082,  0.0000,  0.0000,  0.0000,  0.0078,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0107,  0.0000,  0.0000,  0.0136,  0.0000,  0.0000,  0.0000, -0.0082,\n",
      "         0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0030,\n",
      "         0.0000,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000, -0.0140,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0107,  0.0000,  0.0172,  0.0000,  0.0140,  0.0124,  0.0000,  0.0000,\n",
      "         0.0057, -0.0145,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0140,  0.0000, -0.0035,  0.0000,  0.0057, -0.0030,  0.0000,  0.0000],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_part_sigma:\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0057, 1.0000, 1.0000, 1.0057,\n",
      "        1.0000, 1.0030, 1.0000, 1.0000, 1.0061, 1.0000, 1.0000, 1.0082, 1.0000,\n",
      "        1.0000, 1.0000, 1.0030, 1.0000, 1.0082, 1.0000, 1.0141, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0108, 0.9861, 1.0000, 1.0000, 0.9913, 1.0000, 1.0108, 1.0000,\n",
      "        1.0000, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000, 1.0057, 0.9940, 1.0000,\n",
      "        1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000,\n",
      "        1.0000, 0.9861, 0.9970, 1.0000, 1.0082, 0.9893, 0.9943, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0104, 1.0000, 1.0030, 1.0000, 1.0141,\n",
      "        1.0000, 0.9943, 0.9893, 1.0057, 0.9919, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9893, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000, 0.9919, 1.0000,\n",
      "        0.9861, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 0.9943, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0183, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0108, 1.0000, 0.9861, 0.9864, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000,\n",
      "        1.0030, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0082, 1.0000, 0.9893, 1.0108, 0.9861, 1.0057, 1.0000,\n",
      "        1.0030, 1.0096, 1.0000, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 1.0082,\n",
      "        1.0000, 1.0000, 1.0009, 1.0000, 1.0030, 1.0000, 1.0000, 1.0030, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 1.0141, 1.0000,\n",
      "        1.0000, 1.0000, 0.9861, 1.0000, 1.0082, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0141, 1.0141, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000,\n",
      "        1.0057, 1.0000, 1.0000, 1.0000, 0.9970, 0.9893, 1.0000, 1.0057, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0030, 1.0082, 1.0000, 1.0000, 1.0000, 1.0030, 0.9861,\n",
      "        1.0000, 0.9974, 1.0000, 1.0000, 1.0000, 1.0082, 1.0000, 1.0000, 1.0000,\n",
      "        1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000, 1.0000, 0.9919, 1.0000,\n",
      "        1.0000, 0.9970, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000,\n",
      "        1.0000, 1.0108, 1.0057, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 0.9970,\n",
      "        1.0082, 1.0000, 1.0000, 1.0000, 0.9877, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 0.9949, 1.0000, 1.0000,\n",
      "        1.0000, 1.0082, 0.9893, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9970, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000,\n",
      "        0.9915, 1.0000, 0.9861, 0.9922, 1.0000, 1.0000, 0.9943, 0.9856, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 1.0026, 1.0000,\n",
      "        1.0057, 0.9970, 1.0000, 1.0000], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1248.707454442978;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "Final mean_losses: 1241.5024478859127\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.024972543120384216\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 3142.057717561722;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 3097.4072506185803\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-2.5405, -0.2396, -2.7810,  1.4372,  1.2068,  1.8348, -2.0887, -1.7662,\n",
      "         0.9705,  0.2193, -1.7468, -1.8223, -1.3015, -0.8762, -1.7446, -1.3513,\n",
      "        -1.8002,  0.2313, -0.4036, -1.5680, -0.3920, -1.2071,  2.1218, -0.9210,\n",
      "        -1.0343,  0.4334, -1.3164,  1.4580,  2.9016,  3.0545, -1.6347,  1.5272,\n",
      "         1.6240,  1.7460,  1.5395, -2.9615, -0.8630, -0.5482, -1.2144,  0.3437,\n",
      "        -0.0811, -0.0525, -0.6720,  0.3979,  0.7152, -0.4148, -0.4183,  2.0267,\n",
      "        -0.4977, -0.7983, -2.7882,  0.4771, -1.5871, -2.3694, -1.2189,  1.2727,\n",
      "        -0.3019,  0.6703,  3.1520,  1.8499,  1.9365,  3.0815,  1.1658,  1.1248,\n",
      "         1.3961, -2.0124, -0.8981, -2.1887, -1.7957, -0.5322,  0.2251, -2.5106,\n",
      "         0.9456, -3.5831,  1.1000,  0.5772,  0.2260,  2.2463,  4.1672,  1.9954,\n",
      "        -0.3724, -1.5611, -1.3650, -1.7499,  0.2370,  1.1781, -2.9601, -0.3540,\n",
      "        -0.7300, -0.4868,  0.0948,  0.5454,  2.9797, -1.2123, -0.2799,  1.8564,\n",
      "         1.1149,  1.4029,  0.3378,  0.8188, -0.1577, -3.2728, -0.1123,  1.2440,\n",
      "        -0.3239,  0.0155,  1.2453, -1.4457, -2.1021,  0.5023, -3.3919,  1.4645,\n",
      "        -0.8728,  0.1655, -1.4230,  1.2043,  2.2518,  1.0488, -0.2071, -0.5349,\n",
      "        -2.3746, -1.2984, -1.6650,  0.0379, -1.5739, -0.1738,  0.3633,  0.9468,\n",
      "         0.1933,  0.3416, -2.4598, -1.3627, -0.7408,  2.1973,  1.4076, -1.9239,\n",
      "        -0.4363,  1.3049, -1.8730, -1.3697,  1.6861,  1.6500,  3.0549,  2.5941,\n",
      "        -2.6645,  5.3004,  2.3412, -0.6964,  1.0226,  0.0997, -0.5937,  0.0733,\n",
      "         0.7081, -0.2624,  1.0112,  2.4173, -0.1833, -0.5055,  0.8456, -0.7361,\n",
      "         0.4403,  1.9800, -3.1708, -0.4469,  2.1798,  0.8714,  1.0516,  2.6546,\n",
      "         0.6387, -1.9191,  1.8782,  0.3069, -0.2422,  0.1930, -0.5953, -0.4821,\n",
      "         0.5505,  0.4781,  0.1404,  2.8865,  2.4765,  0.2325, -1.2706, -1.2874,\n",
      "         1.4420,  1.4566,  2.1212,  2.3147,  0.9758,  0.4796,  1.4660,  3.3162,\n",
      "         1.2582, -0.8286, -1.4335, -0.6387,  0.6020,  0.5291,  0.1734, -0.6267,\n",
      "        -2.3801, -1.9496,  0.8517, -0.3365,  1.5136, -2.3479, -2.5787, -0.0191,\n",
      "         1.6221, -0.3778,  1.5132,  2.1490,  1.0283,  0.3605, -2.5051, -0.4627,\n",
      "        -2.4117, -0.1261,  0.3064, -0.5565,  0.6427, -0.2606,  1.1922, -0.3723,\n",
      "         0.9917,  0.1610, -2.5751, -3.1736, -3.6448,  0.0556,  0.6253,  1.0547,\n",
      "         5.0899, -0.8858,  1.4350,  1.9221,  0.0269, -2.1910, -1.3137, -1.5198,\n",
      "         0.4747,  0.4868, -0.1734,  0.0694,  2.1023, -1.0055, -0.2372, -0.1337,\n",
      "        -0.4504, -1.1866,  2.1329, -0.4865,  1.6951,  2.2858,  1.3677, -0.6463,\n",
      "        -0.2832,  0.0921, -2.2939, -1.2648, -2.1787,  0.2038,  1.3826,  0.7358,\n",
      "         0.8256, -2.3603,  0.9817, -0.1153,  1.1293, -0.5727, -0.4999,  2.0823,\n",
      "        -0.6936, -0.6315,  1.7530, -0.3424, -0.5840, -0.1411, -0.2511, -1.5288,\n",
      "         0.0533,  1.5790, -2.1363, -0.7674,  1.9028, -0.8809,  0.1788, -1.5476,\n",
      "        -2.7885,  1.8579, -1.1265,  1.6268,  1.4305, -0.0804,  1.2665, -2.2487,\n",
      "         3.0518, -0.3410,  1.2860, -0.8341, -1.1315, -0.3334, -0.0659,  1.4550,\n",
      "        -2.3286, -1.4036,  0.0181,  2.1167, -1.2364, -1.0943,  1.1859, -0.7041,\n",
      "         0.1843,  1.4363, -1.9895,  0.7012,  0.8152,  0.3155, -0.7840,  0.2056,\n",
      "         0.7951, -2.8989, -1.2246, -1.3364, -1.0427, -1.4751,  2.1432,  0.9923,\n",
      "         1.6283,  1.3102,  0.3285, -0.2174, -0.1223, -1.4417,  1.8170, -0.5765,\n",
      "        -2.3092,  0.7130,  2.1172, -0.9534,  1.7786,  1.6461, -1.6193, -1.4285,\n",
      "        -1.4460, -0.1606, -0.3058, -0.6933, -0.1177,  1.9347,  0.7875, -0.5768,\n",
      "        -1.7328,  0.7835,  0.8313,  0.1173, -0.6881, -0.0705,  3.1703,  0.4200,\n",
      "         2.6245, -2.7181,  2.6395,  1.1654, -1.3645, -0.8473, -0.0689, -1.7304,\n",
      "         1.9108, -0.3480,  0.2306,  1.8909, -1.8001,  0.4503, -2.4024, -0.5745,\n",
      "         0.2924, -0.8197,  0.9691, -0.3102, -0.1832, -0.5834,  0.6905, -0.5340,\n",
      "         1.8845, -1.5886, -0.4374, -2.1008, -1.2829, -0.6303, -4.6421, -0.9638,\n",
      "         0.3665, -1.7617,  0.5972,  0.6774,  0.3987, -2.8706,  4.5349, -0.0701],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.024915488436818123\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 89172.77459955215;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean_losses: 84524.43548244872\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "0.023838378489017487\n",
      "ldfraw_sigma:\n",
      "0.9941590428352356\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "ltscale_sigma:\n",
      "0.9905450940132141\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "mode_sigma:\n",
      "0.9979970455169678\n",
      "t_part_hat:\n",
      "tensor([ 0.0000,  0.0057, -0.0082,  0.0082,  0.0000,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0057,  0.0000,  0.0000,  0.0082,  0.0057,  0.0082,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0107,  0.0000,\n",
      "         0.0000,  0.0030,  0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0057,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,\n",
      "         0.0000,  0.0000,  0.0000,  0.0030,  0.0000,  0.0000,  0.0000,  0.0057,\n",
      "         0.0000,  0.0140,  0.0000,  0.0000,  0.0082,  0.0107,  0.0057,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0057,  0.0000,  0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0030,  0.0000,  0.0000,  0.0025,  0.0140,  0.0000,  0.0000,  0.0182,\n",
      "         0.0000,  0.0000,  0.0000,  0.0057,  0.0000,  0.0107,  0.0107,  0.0082,\n",
      "         0.0140,  0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0057,\n",
      "         0.0082,  0.0000,  0.0140,  0.0000, -0.0107,  0.0057,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0107,  0.0000,  0.0000,  0.0107,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,  0.0107,  0.0000,\n",
      "        -0.0030,  0.0000,  0.0140, -0.0140,  0.0000,  0.0057,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0057,  0.0000,  0.0057,  0.0000, -0.0030,\n",
      "         0.0000,  0.0000,  0.0000,  0.0030,  0.0107,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0085,  0.0000,  0.0000,  0.0136,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0082,  0.0000, -0.0030, -0.0030,  0.0000,\n",
      "         0.0000,  0.0107,  0.0000,  0.0107,  0.0000,  0.0124,  0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0140,\n",
      "        -0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,  0.0000,\n",
      "         0.0000,  0.0124,  0.0140,  0.0000,  0.0000,  0.0000, -0.0030,  0.0000,\n",
      "        -0.0140,  0.0057,  0.0000,  0.0000,  0.0057,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0057,  0.0000,  0.0000,  0.0000, -0.0030,  0.0140,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0030,  0.0000,  0.0000,  0.0082,  0.0000,  0.0000,\n",
      "         0.0000,  0.0082,  0.0000,  0.0000,  0.0107,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0057,  0.0000,  0.0000,  0.0000,  0.0082,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,\n",
      "         0.0057,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0082,  0.0107,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0140,  0.0000, -0.0030,  0.0000,  0.0082,  0.0000,  0.0082,\n",
      "         0.0000, -0.0060,  0.0000,  0.0140,  0.0000,  0.0000,  0.0082, -0.0030,\n",
      "         0.0000,  0.0000, -0.0140,  0.0057,  0.0000,  0.0000, -0.0133,  0.0000,\n",
      "         0.0107,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,  0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0140,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0140,  0.0000,\n",
      "         0.0000, -0.0060,  0.0000, -0.0140,  0.0000,  0.0000,  0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0140,\n",
      "         0.0140,  0.0108,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0107, -0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,\n",
      "         0.0057, -0.0124,  0.0000,  0.0000,  0.0000, -0.0030,  0.0030,  0.0030],\n",
      "       requires_grad=True)\n",
      "t_part_sigma:\n",
      "tensor([1.0000, 0.9943, 0.9919, 1.0082, 1.0000, 0.9861, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0057,\n",
      "        1.0000, 1.0000, 0.9919, 0.9943, 0.9919, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 0.9970, 1.0030, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9919, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000,\n",
      "        1.0000, 0.9943, 1.0000, 0.9861, 1.0000, 1.0000, 1.0082, 0.9893, 1.0057,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0057, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9970,\n",
      "        1.0000, 1.0000, 0.9893, 0.9861, 1.0000, 1.0000, 0.9940, 1.0000, 1.0000,\n",
      "        1.0000, 1.0057, 1.0000, 0.9893, 0.9893, 0.9919, 1.0141, 1.0000, 0.9893,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0082, 1.0000, 0.9861, 1.0000,\n",
      "        1.0108, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000,\n",
      "        1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 1.0000, 1.0108, 1.0000,\n",
      "        0.9970, 1.0000, 0.9861, 0.9861, 1.0000, 1.0057, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0057, 1.0000, 0.9943, 1.0000, 0.9970, 1.0000, 1.0000,\n",
      "        1.0000, 1.0030, 0.9893, 1.0000, 1.0000, 1.0000, 0.9858, 1.0000, 1.0000,\n",
      "        0.9865, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0082,\n",
      "        1.0000, 1.0030, 1.0030, 1.0000, 1.0000, 1.0108, 1.0000, 0.9893, 1.0000,\n",
      "        0.9877, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9861, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9919,\n",
      "        1.0000, 1.0000, 0.9877, 1.0141, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000,\n",
      "        1.0141, 1.0057, 1.0000, 1.0000, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0057, 1.0000, 1.0000, 1.0000, 1.0030, 0.9861, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9970,\n",
      "        1.0000, 1.0000, 1.0082, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000, 1.0000,\n",
      "        1.0108, 1.0141, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000, 0.9919,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000, 1.0000,\n",
      "        1.0000, 1.0057, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0082, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0141, 1.0000, 1.0030, 1.0000, 1.0082, 1.0000, 1.0082, 1.0000, 1.0061,\n",
      "        1.0000, 0.9861, 1.0000, 1.0000, 0.9919, 0.9970, 1.0000, 1.0000, 0.9861,\n",
      "        1.0057, 1.0000, 1.0000, 0.9945, 1.0000, 0.9893, 1.0000, 0.9919, 1.0000,\n",
      "        1.0000, 1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000, 0.9861,\n",
      "        1.0000, 1.0000, 1.0004, 1.0000, 0.9861, 1.0000, 1.0000, 1.0108, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 1.0141,\n",
      "        1.0026, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000, 1.0108, 0.9970, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9919, 0.9943, 1.0124, 1.0000, 1.0000,\n",
      "        1.0000, 1.0030, 1.0030, 1.0030], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1226.1007583141327;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "Final mean_losses: 1225.6603939572974\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.004153558984398842\n",
      "ltscale_hat:\n",
      "-0.024856004863977432\n",
      "mode_hat:\n",
      "0.022536804899573326\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 3803.6912269592285;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "Final mean_losses: 3723.9051478634287\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-5.6333e+00,  1.6353e+00,  8.0400e-01,  4.2753e-01, -3.1260e-01,\n",
      "        -5.0925e+00,  4.3945e-02, -1.9350e+00,  6.1658e+00, -1.1045e-01,\n",
      "         3.8252e-01,  4.6270e+00,  1.2439e+00, -7.7367e-01,  3.7946e+00,\n",
      "         1.3231e-01, -2.5535e-01,  2.0956e-01,  1.0776e+00,  5.4404e+00,\n",
      "        -1.7954e+00, -4.3689e-01,  3.8610e+00,  1.1113e+00, -2.2398e+00,\n",
      "         5.7292e+00, -2.4164e+00,  1.6364e+00, -6.1994e-01, -4.9276e-01,\n",
      "        -5.0978e+00, -6.6662e+00, -7.9763e-02,  2.5378e+00,  3.5191e-01,\n",
      "        -2.5506e+00,  9.3364e-01,  2.4240e+00, -5.2299e-02,  4.0263e-01,\n",
      "        -3.7006e-01, -3.7350e-01,  2.1751e-01, -1.5591e+00, -8.7995e-01,\n",
      "        -9.9503e-02,  5.4825e-01, -7.4613e-01,  1.3428e+00,  8.0929e+00,\n",
      "         5.9072e-01,  3.4800e-01, -1.5751e+00, -2.3097e+00, -2.9911e-01,\n",
      "         1.5565e-01, -1.4124e+00,  3.8216e+00, -2.9179e+00, -1.1224e+00,\n",
      "         2.4224e+00,  1.6440e+00, -5.7477e+00, -8.3010e-01,  9.6523e-02,\n",
      "        -4.5932e-01, -2.7269e+00, -1.7350e+00,  1.6716e+00, -8.2522e-01,\n",
      "        -1.2285e+00,  3.0507e+00, -1.1439e+00,  1.2066e+00, -1.8187e+00,\n",
      "         3.1142e+00, -3.0784e+00,  7.7797e-01,  3.9258e-02,  6.1732e-01,\n",
      "         2.5826e-01, -2.1811e+00, -4.6683e-01, -6.8704e-01, -3.9406e-01,\n",
      "        -1.9117e+00, -6.6905e-01, -5.0014e+00,  1.2791e-01, -2.8141e+00,\n",
      "        -2.5953e+00, -2.8459e+00,  9.2368e-01, -3.0871e+00,  9.9843e-01,\n",
      "        -4.2444e+00, -1.2132e+00, -1.7748e+00, -2.7277e-01,  2.0278e+00,\n",
      "        -4.7455e-01,  1.5954e+00, -2.2172e+00, -7.1968e-01, -5.4547e-01,\n",
      "         4.2177e-01, -6.3173e-01, -8.1439e-02,  2.7957e-01,  1.6353e+00,\n",
      "        -1.6375e+00,  3.3370e-01,  5.8391e-01, -4.5423e+00,  1.9685e+00,\n",
      "        -1.5022e+00,  6.1619e-01,  4.9793e+00,  7.0596e-01, -2.6279e+00,\n",
      "         1.0277e+00, -1.4842e+00, -1.1495e+00,  2.1921e-01, -2.6065e+00,\n",
      "        -2.1094e+00,  8.7117e+00,  1.5186e+00,  6.3691e-01,  4.1975e+00,\n",
      "         5.5343e+00,  4.8469e-01, -2.1237e+00,  1.2242e+00, -1.5611e+00,\n",
      "         1.4491e+01, -4.1368e-01, -9.3553e-02,  7.3996e+00,  7.4849e-01,\n",
      "         1.2483e+00, -5.3492e+00,  8.3338e+00, -2.3606e+00,  2.5901e-01,\n",
      "         3.5789e-01,  1.2845e+01, -2.4889e+00, -6.5402e-01,  1.4360e+00,\n",
      "        -1.3804e+00, -1.1989e-01, -6.9091e+00,  1.4570e+01,  3.1290e-01,\n",
      "        -2.4395e+00,  2.6426e+00,  3.1109e+00, -1.5446e+00,  3.0408e+00,\n",
      "        -2.0268e+00,  2.2213e+00, -9.7450e-01,  1.2771e-02, -1.1882e-01,\n",
      "         1.2029e+00,  2.4433e+00,  6.1352e+00,  3.5635e+00, -1.1191e-01,\n",
      "         1.7778e-01, -2.6865e+00, -1.3439e+00,  3.1241e+00,  4.2665e-01,\n",
      "         4.4762e-01,  1.6482e+00,  2.6394e+00,  4.4025e-01, -7.7484e-02,\n",
      "        -1.0338e+00, -3.2779e+00, -1.5004e+00, -1.0000e+00,  6.5192e+00,\n",
      "        -1.4998e+00,  3.6274e+00,  7.0930e-01,  8.4217e+00, -2.5880e+00,\n",
      "        -3.3617e+00, -1.5183e+00,  1.1677e+00,  4.8047e-01, -8.1664e-01,\n",
      "         4.6078e-01, -9.5395e-01, -1.9221e+00,  7.1922e-01, -2.0131e+00,\n",
      "         1.8725e+00,  1.1764e+00,  5.5833e-01,  3.5832e+00,  3.0505e-01,\n",
      "        -2.4931e+00,  1.5764e+00, -9.5526e-01,  1.3660e+00,  2.0417e-02,\n",
      "        -1.0767e+00,  9.4816e-01,  1.9684e+00,  6.1395e-01,  1.4725e+00,\n",
      "         2.6919e+00, -1.4452e+00,  3.1295e+00, -1.2948e+00,  7.3893e-02,\n",
      "        -1.2587e+00, -4.4914e-01,  1.0062e+00,  1.5622e+00,  3.3453e-01,\n",
      "        -3.7780e-01,  1.6945e-01, -2.5247e+00, -7.0588e-01, -8.5860e-01,\n",
      "        -9.7887e-01,  3.3974e-01,  9.1906e-01, -2.3022e+00,  3.9466e+00,\n",
      "         1.0106e+00, -1.1148e+00,  1.4715e+00,  4.0912e+00,  1.2943e+00,\n",
      "        -6.2587e-01,  4.4920e-01, -2.4699e+00, -7.8366e+00,  1.9790e+00,\n",
      "        -1.1353e+00,  2.1864e-01, -5.2707e+00, -2.3613e-01,  6.5515e+00,\n",
      "         9.0590e-01, -5.8918e-01,  1.0821e+00, -2.4624e+00,  5.8451e-01,\n",
      "        -7.1862e-01, -8.5027e+00,  4.1761e-01, -5.1184e-01,  1.8137e+00,\n",
      "        -1.1152e+00, -1.4080e-01, -1.6928e+00,  4.8587e+00, -3.8706e+00,\n",
      "         3.0981e+00,  4.3233e+00,  1.3878e+00,  1.1150e+00, -7.2865e+00,\n",
      "        -4.7941e-01,  1.6097e+00,  1.1431e-01,  2.4631e+00, -1.1362e+00,\n",
      "        -1.2228e+00, -3.2841e+00, -4.6262e+00,  9.3798e-01, -1.2749e+00,\n",
      "         1.3254e+00, -1.5645e+00,  1.7512e+00, -2.6450e+00, -9.2285e-01,\n",
      "        -5.7452e+00, -6.3973e+00, -4.0823e-02, -1.4630e+00,  5.2905e+00,\n",
      "         1.8294e-01,  7.9670e-01, -8.5804e+00,  1.5034e-01, -1.0310e+00,\n",
      "         7.2422e-02, -4.5605e-01,  1.1268e-01,  5.3509e-01, -1.6727e+00,\n",
      "        -4.8050e+00, -5.2320e-01, -6.3960e-01,  1.2043e+00,  2.7822e-01,\n",
      "        -6.4038e-01,  1.8763e+00, -1.0756e+01,  2.6266e+00,  3.6049e+00,\n",
      "        -2.5800e+00, -8.0985e-01, -5.2606e-01, -1.0791e-01, -2.3388e-01,\n",
      "        -4.0659e+00,  1.3443e+00, -1.4394e+00,  5.8780e-01,  4.9603e-01,\n",
      "        -6.6764e-02, -1.0713e+00, -2.8426e+00, -1.4038e-01,  4.0436e-01,\n",
      "        -2.6814e+00,  6.6932e-01,  6.4899e-01, -8.5480e-01,  1.0025e-01,\n",
      "        -1.5230e+00, -2.3296e+00,  2.8181e+00, -6.3640e-01,  1.7897e+00,\n",
      "         3.2136e+00,  5.2222e-01, -9.2443e-01, -3.9022e+00,  1.2459e+01,\n",
      "        -2.8920e+00, -6.0840e+00, -4.1451e-01, -4.8297e+00, -1.9267e-01,\n",
      "         7.3278e-01,  1.7676e+00,  1.3748e+00, -2.7435e+00,  2.3897e+00,\n",
      "         2.4702e+00, -1.1284e-01, -8.1038e-01,  4.3008e+00, -4.2833e+00,\n",
      "        -1.4102e+00,  1.2388e+00, -6.6752e-01, -3.4406e+00, -9.7622e-01,\n",
      "        -1.6590e+00,  4.2280e+00,  2.3811e+00,  8.2222e+00, -2.1728e-01,\n",
      "         5.1595e-01, -1.0651e+00, -1.9448e+00, -3.6679e+00, -1.4253e+00,\n",
      "         3.5412e-01,  8.4763e-01,  6.4619e-01,  1.6856e+00, -4.4666e-01,\n",
      "        -5.1956e-02,  7.2615e-01,  5.4399e-01,  4.3249e+00, -3.6390e+00,\n",
      "        -7.1384e-01,  5.9262e-01, -8.1198e-01,  1.8298e+00,  2.5228e+00,\n",
      "        -1.0354e+01,  6.7845e-01,  3.2782e-01, -3.3911e+00, -5.5059e+00,\n",
      "        -1.5545e-01,  1.0965e+00, -4.7929e-01, -1.6185e-01, -1.0547e+00,\n",
      "        -7.8924e-01,  3.3304e+00, -8.0842e-01,  2.2374e-01, -2.1872e+00],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.0010411270195618272\n",
      "ltscale_hat:\n",
      "-0.021423786878585815\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 43602.29743826389;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 41840.43802468218\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "0.024424616247415543\n",
      "ldfraw_sigma:\n",
      "0.99896639585495\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "ltscale_sigma:\n",
      "1.002007007598877\n",
      "mode_hat:\n",
      "0.016287757083773613\n",
      "mode_sigma:\n",
      "0.9809511303901672\n",
      "t_part_hat:\n",
      "tensor([-0.0082,  0.0000,  0.0030,  0.0057,  0.0000, -0.0082,  0.0000,  0.0140,\n",
      "         0.0000, -0.0082,  0.0000,  0.0000,  0.0107,  0.0136,  0.0108,  0.0000,\n",
      "         0.0000,  0.0158,  0.0140,  0.0000,  0.0000, -0.0082,  0.0000,  0.0107,\n",
      "         0.0000,  0.0000,  0.0000,  0.0140,  0.0000, -0.0008, -0.0082, -0.0082,\n",
      "         0.0140,  0.0000, -0.0082,  0.0000,  0.0140,  0.0057,  0.0107,  0.0000,\n",
      "        -0.0082,  0.0000,  0.0140,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0140,  0.0140,  0.0140,  0.0057,\n",
      "         0.0000,  0.0000, -0.0107,  0.0000,  0.0000,  0.0000, -0.0140,  0.0140,\n",
      "         0.0140,  0.0000,  0.0000,  0.0030,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0082, -0.0107,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0140, -0.0025,  0.0000,  0.0000,  0.0000,  0.0172, -0.0136,\n",
      "         0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,  0.0030,  0.0000,\n",
      "         0.0000,  0.0000,  0.0107,  0.0107,  0.0000,  0.0000, -0.0158, -0.0084,\n",
      "         0.0000,  0.0000,  0.0057,  0.0000,  0.0057,  0.0140,  0.0000, -0.0057,\n",
      "         0.0000, -0.0082, -0.0107,  0.0000,  0.0030,  0.0000,  0.0000, -0.0071,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0082,  0.0140,  0.0082,  0.0106,\n",
      "         0.0082,  0.0000,  0.0071, -0.0025,  0.0000,  0.0030, -0.0082,  0.0000,\n",
      "         0.0140,  0.0097,  0.0082,  0.0000,  0.0000,  0.0000,  0.0214, -0.0057,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0107,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0108,  0.0000,  0.0140,  0.0000,  0.0124,  0.0000,  0.0000,  0.0108,\n",
      "         0.0000,  0.0140,  0.0140,  0.0000,  0.0030,  0.0000,  0.0030,  0.0140,\n",
      "        -0.0082,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0148,  0.0140,  0.0000,  0.0000,  0.0000, -0.0082,\n",
      "         0.0000,  0.0030,  0.0000,  0.0000,  0.0030, -0.0107,  0.0030,  0.0000,\n",
      "         0.0000,  0.0000,  0.0140,  0.0107,  0.0120,  0.0000,  0.0082, -0.0057,\n",
      "         0.0158,  0.0000,  0.0157,  0.0000, -0.0001,  0.0000,  0.0000,  0.0124,\n",
      "        -0.0027,  0.0108,  0.0000,  0.0057,  0.0000,  0.0000,  0.0057,  0.0107,\n",
      "         0.0030,  0.0140,  0.0000, -0.0030,  0.0000,  0.0030, -0.0057,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0071,  0.0000,  0.0000,\n",
      "         0.0000,  0.0098, -0.0030,  0.0000,  0.0000, -0.0009,  0.0107, -0.0124,\n",
      "         0.0000,  0.0000,  0.0057,  0.0000,  0.0134,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0057,  0.0000,  0.0000,  0.0000,  0.0000, -0.0097,  0.0057,\n",
      "         0.0000,  0.0000,  0.0204,  0.0030,  0.0000, -0.0140, -0.0013,  0.0000,\n",
      "        -0.0107,  0.0000,  0.0000,  0.0140,  0.0000,  0.0000,  0.0000, -0.0140,\n",
      "         0.0181,  0.0000,  0.0140,  0.0000, -0.0107, -0.0030, -0.0082,  0.0030,\n",
      "         0.0140,  0.0082, -0.0082,  0.0000, -0.0158,  0.0190,  0.0000,  0.0107,\n",
      "        -0.0057,  0.0000,  0.0158, -0.0082,  0.0000, -0.0108, -0.0145,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0107,  0.0000,  0.0000,  0.0000, -0.0030,\n",
      "        -0.0082,  0.0030,  0.0000, -0.0057,  0.0000, -0.0030,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0140,  0.0000,  0.0000,  0.0107,\n",
      "         0.0000,  0.0140,  0.0000, -0.0030,  0.0000,  0.0000,  0.0057,  0.0082,\n",
      "         0.0124,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,\n",
      "         0.0000,  0.0000,  0.0107,  0.0140,  0.0000,  0.0000,  0.0030,  0.0000,\n",
      "         0.0030,  0.0057,  0.0000, -0.0107,  0.0030, -0.0082,  0.0000,  0.0000,\n",
      "         0.0140,  0.0107,  0.0107,  0.0000, -0.0107,  0.0107,  0.0000, -0.0107,\n",
      "         0.0000,  0.0000,  0.0030,  0.0107,  0.0000,  0.0025,  0.0030,  0.0158,\n",
      "         0.0000,  0.0000,  0.0092, -0.0057,  0.0000,  0.0172, -0.0107,  0.0167,\n",
      "         0.0107,  0.0000,  0.0082,  0.0082,  0.0000,  0.0000, -0.0082,  0.0030,\n",
      "         0.0000,  0.0140,  0.0089, -0.0057,  0.0000,  0.0107,  0.0000,  0.0000],\n",
      "       requires_grad=True)\n",
      "t_part_sigma:\n",
      "tensor([1.0082, 1.0000, 1.0030, 1.0057, 1.0000, 1.0082, 1.0000, 0.9861, 1.0000,\n",
      "        0.9919, 1.0000, 1.0000, 0.9893, 0.9866, 0.9893, 1.0000, 1.0000, 1.0159,\n",
      "        1.0141, 1.0000, 1.0000, 1.0082, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000,\n",
      "        0.9861, 1.0000, 0.9881, 1.0082, 0.9919, 0.9861, 1.0000, 0.9919, 1.0000,\n",
      "        1.0141, 1.0057, 0.9893, 1.0000, 0.9919, 1.0000, 1.0141, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9861, 0.9861,\n",
      "        1.0141, 1.0057, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 1.0000, 0.9861,\n",
      "        1.0141, 0.9861, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0082, 1.0108, 1.0108, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0141, 0.9905, 1.0000, 1.0000, 1.0000, 0.9830, 1.0137, 1.0000, 1.0000,\n",
      "        1.0000, 1.0057, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 1.0000, 0.9893,\n",
      "        1.0108, 1.0000, 1.0000, 0.9876, 1.0137, 1.0000, 1.0000, 0.9943, 1.0000,\n",
      "        1.0057, 0.9861, 1.0000, 0.9943, 1.0000, 0.9919, 1.0108, 1.0000, 0.9970,\n",
      "        1.0000, 1.0000, 0.9930, 1.0000, 1.0000, 1.0000, 1.0000, 1.0082, 0.9861,\n",
      "        0.9919, 0.9855, 1.0082, 1.0000, 0.9930, 0.9893, 1.0000, 1.0030, 0.9919,\n",
      "        1.0000, 0.9861, 1.0038, 1.0082, 1.0000, 1.0000, 1.0000, 1.0072, 1.0057,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0026, 1.0000,\n",
      "        1.0141, 1.0000, 1.0125, 1.0000, 1.0000, 1.0108, 1.0000, 1.0141, 0.9861,\n",
      "        1.0000, 1.0030, 1.0000, 1.0030, 0.9861, 0.9919, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0111, 1.0141, 1.0000,\n",
      "        1.0000, 1.0000, 1.0082, 1.0000, 0.9970, 1.0000, 1.0000, 0.9970, 1.0108,\n",
      "        0.9970, 1.0000, 1.0000, 1.0000, 1.0141, 1.0108, 1.0070, 1.0000, 1.0082,\n",
      "        1.0057, 0.9992, 1.0000, 1.0189, 1.0000, 1.0023, 1.0000, 1.0000, 0.9877,\n",
      "        1.0027, 0.9893, 1.0000, 1.0057, 1.0000, 1.0000, 0.9943, 1.0108, 0.9970,\n",
      "        0.9861, 1.0000, 0.9970, 1.0000, 1.0030, 0.9943, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9973, 1.0000, 1.0000, 1.0000, 1.0071, 1.0030,\n",
      "        1.0000, 1.0000, 1.0228, 0.9893, 0.9922, 1.0000, 1.0000, 1.0057, 1.0000,\n",
      "        1.0052, 1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9904, 0.9943, 1.0000, 1.0000, 1.0055, 0.9970, 1.0000, 0.9861,\n",
      "        0.9781, 1.0000, 0.9893, 1.0000, 1.0000, 1.0141, 1.0000, 1.0000, 1.0000,\n",
      "        0.9861, 1.0181, 1.0000, 1.0141, 1.0000, 0.9893, 1.0030, 1.0082, 0.9970,\n",
      "        0.9861, 1.0082, 0.9919, 1.0000, 0.9889, 0.9812, 1.0000, 0.9893, 1.0057,\n",
      "        1.0000, 1.0155, 1.0082, 1.0000, 0.9975, 0.9856, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 0.9970, 1.0082, 1.0030, 1.0000,\n",
      "        0.9943, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0141, 1.0000, 1.0000, 1.0108, 1.0000, 0.9861, 1.0000, 1.0030, 1.0000,\n",
      "        1.0000, 1.0057, 1.0082, 0.9922, 0.9893, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9943, 1.0000, 1.0000, 0.9893, 1.0141, 1.0000, 1.0000, 1.0030,\n",
      "        1.0000, 0.9970, 0.9943, 1.0000, 0.9893, 1.0030, 0.9919, 1.0000, 1.0000,\n",
      "        0.9861, 1.0108, 0.9893, 1.0000, 0.9962, 0.9893, 1.0000, 0.9893, 1.0000,\n",
      "        1.0000, 1.0030, 0.9893, 1.0000, 0.9893, 0.9970, 1.0159, 1.0000, 1.0000,\n",
      "        1.0109, 0.9943, 1.0000, 1.0173, 1.0108, 1.0063, 1.0108, 1.0000, 1.0082,\n",
      "        1.0082, 1.0000, 1.0000, 1.0082, 1.0030, 1.0000, 0.9861, 1.0052, 0.9943,\n",
      "        1.0000, 0.9893, 1.0000, 1.0000], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1040.45831823349;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "Final mean_losses: 1042.1123517742424\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.024951180443167686\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 16776.144504070282;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "Final mean_losses: 16429.509817798113\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-2.5405, -0.2396, -2.7703,  1.4372,  1.2098,  1.8348, -2.0951, -1.7504,\n",
      "         0.9735,  0.2374, -1.7468, -1.8223, -1.3015, -0.8705, -1.7528, -1.3513,\n",
      "        -1.7866,  0.2313, -0.3939, -1.5623, -0.3887, -1.2021,  2.1218, -0.9103,\n",
      "        -1.0343,  0.4391, -1.3083,  1.4580,  2.9156,  3.0387, -1.6290,  1.5272,\n",
      "         1.6347,  1.7642,  1.5338, -2.9760, -0.8523, -0.5482, -1.2144,  0.3467,\n",
      "        -0.0621, -0.0443, -0.6720,  0.3979,  0.7152, -0.4148, -0.4183,  2.0348,\n",
      "        -0.5060, -0.8025, -2.7882,  0.4663, -1.5871, -2.3613, -1.2219,  1.2797,\n",
      "        -0.3019,  0.6843,  3.1520,  1.8499,  1.9365,  3.0733,  1.1658,  1.1217,\n",
      "         1.3961, -2.0124, -0.8845, -2.1857, -1.7900, -0.5446,  0.2251, -2.5106,\n",
      "         0.9456, -3.5856,  1.1029,  0.5665,  0.2260,  2.2266,  4.1565,  2.0112,\n",
      "        -0.3627, -1.5611, -1.3650, -1.7354,  0.2263,  1.1781, -2.9461, -0.3540,\n",
      "        -0.7300, -0.4868,  0.0948,  0.5575,  2.9797, -1.1999, -0.2769,  1.8594,\n",
      "         1.1149,  1.4250,  0.3378,  0.8043, -0.1411, -3.2627, -0.1123,  1.2522,\n",
      "        -0.3239,  0.0103,  1.2453, -1.4317, -2.0964,  0.5080, -3.3919,  1.4645,\n",
      "        -0.8588,  0.1655, -1.4230,  1.2183,  2.2518,  1.0570, -0.2071, -0.5509,\n",
      "        -2.3828, -1.2984, -1.6625,  0.0519, -1.5769, -0.1738,  0.3633,  0.9327,\n",
      "         0.1963,  0.3620, -2.4514, -1.3487, -0.7408,  2.1973,  1.4076, -1.9098,\n",
      "        -0.4363,  1.3049, -1.8648, -1.3590,  1.6968,  1.6500,  3.0549,  2.5941,\n",
      "        -2.6645,  5.3004,  2.3355, -0.6823,  1.0226,  0.0920, -0.5937,  0.0830,\n",
      "         0.6974, -0.2516,  1.0284,  2.4395, -0.1752, -0.5163,  0.8538, -0.7361,\n",
      "         0.4403,  1.9741, -3.1765, -0.4362,  2.1640,  0.8795,  1.0459,  2.6546,\n",
      "         0.6400, -1.9191,  1.8839,  0.3012, -0.2563,  0.1790, -0.5953, -0.4795,\n",
      "         0.5505,  0.4888,  0.1511,  2.8722,  2.4765,  0.2202, -1.2706, -1.2981,\n",
      "         1.4420,  1.4566,  2.1212,  2.3204,  0.9758,  0.4852,  1.4660,  3.3162,\n",
      "         1.2471, -0.8342, -1.4335, -0.6251,  0.5990,  0.5373,  0.1734, -0.6210,\n",
      "        -2.3801, -1.9496,  0.8376, -0.3365,  1.5300, -2.3504, -2.5927, -0.0191,\n",
      "         1.6361, -0.3588,  1.5132,  2.1334,  1.0390,  0.3630, -2.5051, -0.4710,\n",
      "        -2.4117, -0.1402,  0.3222, -0.5565,  0.6427, -0.2606,  1.1922, -0.3683,\n",
      "         0.9917,  0.1768, -2.5561, -3.1843, -3.6448,  0.0680,  0.6348,  1.0718,\n",
      "         5.0899, -0.8915,  1.4491,  1.9191,  0.0326, -2.2051, -1.2997, -1.5171,\n",
      "         0.4747,  0.4678, -0.1734,  0.0750,  2.1130, -1.0055, -0.2342, -0.1337,\n",
      "        -0.4423, -1.1877,  2.1359, -0.4895,  1.6981,  2.2888,  1.3758, -0.6381,\n",
      "        -0.2674,  0.0925, -2.2803, -1.2648, -2.1756,  0.2038,  1.3826,  0.7465,\n",
      "         0.8256, -2.3603,  0.9899, -0.0939,  1.1293, -0.5727, -0.4968,  2.0823,\n",
      "        -0.6936, -0.6315,  1.7530, -0.3331, -0.5700, -0.1468, -0.2618, -1.5288,\n",
      "         0.0614,  1.5931, -2.1363, -0.7814,  1.9084, -0.8809,  0.1788, -1.5461,\n",
      "        -2.7834,  1.8579, -1.1265,  1.6350,  1.4412, -0.0804,  1.2665, -2.2487,\n",
      "         3.0488, -0.3328,  1.2890, -0.8341, -1.1133, -0.3334, -0.0659,  1.4691,\n",
      "        -2.3427, -1.4036,  0.0181,  2.1197, -1.2257, -1.1025,  1.1859, -0.6908,\n",
      "         0.1843,  1.4282, -1.9977,  0.7012,  0.8122,  0.3345, -0.7699,  0.2106,\n",
      "         0.7951, -2.8799, -1.2139, -1.3364, -1.0454, -1.4669,  2.1556,  1.0064,\n",
      "         1.6283,  1.3249,  0.3285, -0.2117, -0.1223, -1.4335,  1.8170, -0.5765,\n",
      "        -2.3174,  0.7130,  2.1172, -0.9464,  1.7786,  1.6461, -1.6193, -1.4204,\n",
      "        -1.4460, -0.1525, -0.2934, -0.6933, -0.1177,  1.9347,  0.7875, -0.5627,\n",
      "        -1.7194,  0.7727,  0.8343,  0.1143, -0.6709, -0.0830,  3.1703,  0.4256,\n",
      "         2.6301, -2.7099,  2.6395,  1.1621, -1.3537, -0.8440, -0.0607, -1.7304,\n",
      "         1.9026, -0.3537,  0.2306,  1.8909, -1.7971,  0.4503, -2.4024, -0.5826,\n",
      "         0.2894, -0.8197,  0.9748, -0.3127, -0.1802, -0.5834,  0.6947, -0.5481,\n",
      "         1.8762, -1.5763, -0.4230, -2.1008, -1.2799, -0.6303, -4.6421, -0.9587,\n",
      "         0.3665, -1.7510,  0.5942,  0.6774,  0.3957, -2.8706,  4.5349, -0.0594],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.025000562891364098\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "mode_hat:\n",
      "0.02500000037252903\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 39941.19300246239;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n",
      "/anaconda3/lib/python3.7/site-packages/pyro/util.py:178: UserWarning: Found auxiliary vars in the model: {'t_part'}\n",
      "  warnings.warn(\"Found auxiliary vars in the model: {}\".format(aux_vars & model_vars))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean_losses: 49676.83073903609\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "0.024517089128494263\n",
      "ldfraw_sigma:\n",
      "1.0113962888717651\n",
      "ltscale_hat:\n",
      "-0.02500000037252903\n",
      "ltscale_sigma:\n",
      "1.0194188356399536\n",
      "mode_hat:\n",
      "-0.0007876335876062512\n",
      "mode_sigma:\n",
      "1.007574200630188\n",
      "t_part_hat:\n",
      "tensor([-0.0082,  0.0000, -0.0071,  0.0000,  0.0025,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0057,  0.0082,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,  0.0030,\n",
      "         0.0107,  0.0030,  0.0030, -0.0107,  0.0025, -0.0108,  0.0000,  0.0000,\n",
      "        -0.0030,  0.0030, -0.0057,  0.0000,  0.0057,  0.0107, -0.0107,  0.0071,\n",
      "         0.0000,  0.0030,  0.0107,  0.0000,  0.0057,  0.0000, -0.0082,  0.0000,\n",
      "         0.0172,  0.0000,  0.0000, -0.0007,  0.0000,  0.0107,  0.0190,  0.0030,\n",
      "         0.0000,  0.0030, -0.0169, -0.0082, -0.0057, -0.0107, -0.0057,  0.0000,\n",
      "         0.0195,  0.0000,  0.0000,  0.0000,  0.0000,  0.0140,  0.0108,  0.0107,\n",
      "         0.0097,  0.0000,  0.0030,  0.0000, -0.0082,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000, -0.0140,  0.0000,  0.0204,  0.0000,  0.0000,  0.0030,  0.0030,\n",
      "         0.0140, -0.0192,  0.0000, -0.0097,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0082,  0.0082,  0.0000,  0.0082,  0.0057,  0.0030,  0.0000,  0.0057,\n",
      "         0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0057,  0.0000,  0.0000,  0.0082,  0.0000,  0.0082, -0.0140,  0.0124,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082,  0.0082,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0057,  0.0140, -0.0026, -0.0140,  0.0000,  0.0057,  0.0000, -0.0172,\n",
      "        -0.0107,  0.0000, -0.0030, -0.0145,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0107,  0.0000,  0.0000,  0.0000,  0.0030,  0.0000,  0.0000,\n",
      "         0.0140,  0.0000,  0.0057,  0.0140,  0.0000,  0.0000,  0.0000, -0.0156,\n",
      "         0.0057,  0.0000,  0.0000, -0.0057,  0.0000,  0.0071,  0.0000,  0.0107,\n",
      "         0.0000, -0.0057,  0.0107,  0.0107,  0.0000,  0.0000,  0.0000, -0.0082,\n",
      "         0.0000,  0.0057,  0.0000,  0.0140,  0.0000,  0.0000, -0.0030,  0.0082,\n",
      "         0.0000,  0.0082,  0.0000,  0.0107,  0.0082,  0.0000,  0.0097,  0.0082,\n",
      "         0.0158,  0.0000,  0.0000, -0.0057,  0.0124,  0.0030,  0.0000,  0.0030,\n",
      "        -0.0182,  0.0107,  0.0124,  0.0000,  0.0000, -0.0057,  0.0000,  0.0000,\n",
      "         0.0030,  0.0111,  0.0000,  0.0140,  0.0107, -0.0082, -0.0082,  0.0030,\n",
      "        -0.0107,  0.0000,  0.0000,  0.0000,  0.0030,  0.0176,  0.0000,  0.0000,\n",
      "         0.0000,  0.0082, -0.0107,  0.0000, -0.0030,  0.0000,  0.0000,  0.0000,\n",
      "         0.0140,  0.0000,  0.0190,  0.0082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0030,  0.0107,  0.0140,  0.0182,  0.0000, -0.0082,  0.0000,  0.0140,\n",
      "         0.0000,  0.0000,  0.0030,  0.0140,  0.0107,  0.0082,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0082,  0.0107,  0.0000,  0.0057,  0.0082,  0.0057,\n",
      "         0.0057, -0.0107,  0.0000,  0.0000,  0.0000,  0.0000,  0.0030,  0.0057,\n",
      "         0.0000,  0.0000,  0.0140,  0.0000,  0.0140,  0.0000, -0.0130, -0.0107,\n",
      "         0.0107,  0.0000,  0.0000,  0.0057,  0.0030,  0.0000,  0.0000, -0.0107,\n",
      "         0.0000,  0.0140,  0.0000,  0.0000,  0.0057,  0.0030,  0.0000,  0.0000,\n",
      "         0.0107,  0.0030,  0.0000,  0.0082,  0.0000,  0.0140,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0107,  0.0000, -0.0140,  0.0000,  0.0172,  0.0000,\n",
      "         0.0082,  0.0140, -0.0057,  0.0000,  0.0000,  0.0140,  0.0000,  0.0000,\n",
      "         0.0140,  0.0000,  0.0000, -0.0190,  0.0000,  0.0000,  0.0000,  0.0057,\n",
      "         0.0140,  0.0000,  0.0000, -0.0057,  0.0000,  0.0140,  0.0030,  0.0107,\n",
      "         0.0000,  0.0000,  0.0107,  0.0000,  0.0140,  0.0057, -0.0057,  0.0000,\n",
      "         0.0000,  0.0000, -0.0140,  0.0000,  0.0057,  0.0000,  0.0000,  0.0190,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,  0.0182,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0030,  0.0000,  0.0000,  0.0082, -0.0104,\n",
      "         0.0107,  0.0000,  0.0000,  0.0000, -0.0008,  0.0000,  0.0000,  0.0000,\n",
      "         0.0190,  0.0000,  0.0140,  0.0082,  0.0000,  0.0000,  0.0107,  0.0000,\n",
      "         0.0000,  0.0034,  0.0000, -0.0107, -0.0082,  0.0082, -0.0057, -0.0190,\n",
      "         0.0057,  0.0025,  0.0000,  0.0030,  0.0140, -0.0030,  0.0000, -0.0107],\n",
      "       requires_grad=True)\n",
      "t_part_sigma:\n",
      "tensor([1.0082, 1.0000, 0.9973, 1.0000, 1.0026, 1.0000, 1.0000, 1.0000, 0.9943,\n",
      "        0.9919, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 1.0030, 0.9893, 1.0030,\n",
      "        0.9970, 1.0108, 1.0026, 0.9893, 1.0000, 1.0000, 1.0030, 0.9970, 1.0057,\n",
      "        1.0000, 1.0057, 1.0108, 0.9893, 1.0027, 1.0000, 1.0030, 1.0108, 1.0000,\n",
      "        0.9943, 1.0000, 1.0082, 1.0000, 1.0056, 1.0000, 1.0000, 1.0071, 1.0000,\n",
      "        1.0108, 1.0055, 0.9970, 1.0000, 1.0030, 0.9940, 0.9919, 1.0057, 1.0108,\n",
      "        1.0057, 1.0000, 0.9896, 1.0000, 1.0000, 1.0000, 1.0000, 1.0141, 0.9975,\n",
      "        0.9893, 1.0097, 1.0000, 0.9970, 1.0000, 1.0082, 0.9861, 1.0000, 1.0000,\n",
      "        1.0000, 0.9861, 1.0000, 0.9902, 1.0000, 1.0000, 0.9970, 1.0030, 0.9861,\n",
      "        0.9801, 1.0000, 0.9948, 1.0000, 1.0000, 1.0000, 1.0000, 0.9919, 1.0082,\n",
      "        1.0000, 0.9919, 1.0057, 0.9970, 1.0000, 0.9943, 1.0000, 1.0108, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 1.0000, 1.0000, 1.0082,\n",
      "        1.0000, 0.9919, 1.0141, 1.0078, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0082, 1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0057, 1.0141, 1.0002, 1.0141, 1.0000, 0.9943, 1.0000,\n",
      "        1.0173, 0.9893, 1.0000, 1.0030, 1.0011, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 1.0030, 1.0000, 1.0000, 1.0141,\n",
      "        1.0000, 1.0057, 1.0141, 1.0000, 1.0000, 1.0000, 1.0199, 0.9943, 1.0000,\n",
      "        1.0000, 0.9943, 1.0000, 0.9973, 1.0000, 0.9893, 1.0000, 0.9943, 1.0108,\n",
      "        1.0108, 1.0000, 1.0000, 1.0000, 0.9919, 1.0000, 1.0057, 1.0000, 1.0141,\n",
      "        1.0000, 1.0000, 1.0030, 1.0082, 1.0000, 0.9919, 1.0000, 1.0108, 1.0082,\n",
      "        1.0000, 1.0052, 0.9919, 0.9889, 1.0000, 1.0000, 1.0057, 0.9877, 1.0030,\n",
      "        1.0000, 1.0030, 0.9787, 0.9893, 0.9877, 1.0000, 1.0000, 1.0057, 1.0000,\n",
      "        1.0000, 0.9970, 0.9842, 1.0000, 1.0141, 0.9893, 0.9919, 0.9919, 0.9970,\n",
      "        1.0108, 1.0000, 1.0000, 1.0000, 1.0030, 1.0032, 1.0000, 1.0000, 1.0000,\n",
      "        1.0082, 1.0108, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000,\n",
      "        0.9812, 1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0030, 1.0108, 0.9861,\n",
      "        0.9877, 1.0000, 1.0082, 1.0000, 1.0141, 1.0000, 1.0000, 0.9970, 0.9861,\n",
      "        1.0108, 1.0082, 1.0000, 1.0000, 1.0000, 1.0000, 1.0082, 0.9893, 1.0000,\n",
      "        1.0057, 1.0082, 1.0057, 0.9943, 0.9893, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9970, 1.0057, 1.0000, 1.0000, 0.9861, 1.0000, 1.0141, 1.0000, 1.0146,\n",
      "        1.0108, 1.0108, 1.0000, 1.0000, 0.9943, 1.0030, 1.0000, 1.0000, 1.0108,\n",
      "        1.0000, 1.0141, 1.0000, 1.0000, 0.9943, 1.0030, 1.0000, 1.0000, 0.9893,\n",
      "        0.9970, 1.0000, 1.0082, 1.0000, 0.9861, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9893, 1.0000, 1.0141, 1.0000, 1.0086, 1.0000, 0.9919, 1.0141, 0.9943,\n",
      "        1.0000, 1.0000, 0.9861, 1.0000, 1.0000, 1.0141, 1.0000, 1.0000, 0.9978,\n",
      "        1.0000, 1.0000, 1.0000, 0.9943, 1.0141, 1.0000, 1.0000, 1.0057, 1.0000,\n",
      "        0.9861, 0.9970, 1.0108, 1.0000, 1.0000, 1.0108, 1.0000, 1.0141, 0.9943,\n",
      "        0.9943, 1.0000, 1.0000, 1.0000, 0.9861, 1.0000, 0.9969, 1.0000, 1.0000,\n",
      "        0.9969, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9943, 0.9940, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 0.9919, 0.9991, 1.0108,\n",
      "        1.0000, 1.0000, 1.0000, 1.0108, 1.0000, 1.0000, 1.0000, 1.0192, 1.0000,\n",
      "        0.9861, 1.0082, 1.0000, 1.0000, 0.9893, 1.0000, 1.0000, 0.9966, 1.0000,\n",
      "        0.9893, 1.0082, 0.9919, 0.9943, 0.9886, 0.9943, 0.9929, 1.0000, 1.0030,\n",
      "        0.9861, 0.9970, 1.0000, 0.9893], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1044.8085675239563;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7114081dbb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     result = trainGuide(guidename,nparticles,trueparams,\n\u001b[1;32m     20\u001b[0m                                         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"testresults/demoT_2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                        subsample_N = nsamps)\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maniter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnparticles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mguidenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/eipython/eipython/multisiteT.py\u001b[0m in \u001b[0;36mtrainGuide\u001b[0;34m(guidename, nparticles, trueparams, filename, errors, subsample_N, N)\u001b[0m\n\u001b[1;32m    918\u001b[0m                             \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                             \u001b[0mmaxError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                             save_data,weight,ts(10.),ts(10.))\n\u001b[0m\u001b[1;32m    921\u001b[0m                         \u001b[0;31m#N,full_N,indices,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                         \u001b[0;31m#x,     full_x,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'requires_grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mwarn_if_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "  for nsamps in [12,25,50,150,400]:\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [ndom_fat_params,ndom_norm_params,]:#tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,\n",
    "                                        filename=\"testresults/demoT_2.csv\",\n",
    "                                       subsample_N = nsamps)\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
