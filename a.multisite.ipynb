{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([-2.1861,  0.4473,  3.2066, -3.0650])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1322.112264752388;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1086.2202850580215;\n",
      "mode_hat tensor(0.2719, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4717, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5028, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 1200.8989969491959;\n",
      "mode_hat tensor(0.4320, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9511, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9966, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1000.0911220312119;\n",
      "mode_hat tensor(0.5315, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3802, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3964, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 926.0144784450531;\n",
      "mode_hat tensor(0.5191, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7253, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7698, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 1153.8798500299454;\n",
      "mode_hat tensor(0.5827, requires_grad=True)\n",
      "ltscale_hat tensor(-2.0610, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0764, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "Final mean_losses: 1167.0000329274728\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.5273, -4.4343], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.198077917098999\n",
      "ltscale_hat:\n",
      "-2.2061281204223633\n",
      "mode_hat:\n",
      "0.6295467615127563\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([ 3.7712, -0.5903,  0.9481, -1.9907])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 2061.2415319681168;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1177.7431785464287;\n",
      "mode_hat tensor(0.4890, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4374, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4629, requires_grad=True)\n",
      "epoch 200 loss = 1230.8749812841415;\n",
      "mode_hat tensor(0.4843, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7780, requires_grad=True)\n",
      "ldfraw_hat tensor(0.8322, requires_grad=True)\n",
      "epoch 300 loss = 1153.508530318737;\n",
      "mode_hat tensor(0.4886, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0934, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1927, requires_grad=True)\n",
      "epoch 400 loss = 1113.9581979513168;\n",
      "mode_hat tensor(0.4833, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3709, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4355, requires_grad=True)\n",
      "epoch 500 loss = 982.1664552688599;\n",
      "mode_hat tensor(0.4946, requires_grad=True)\n",
      "ltscale_hat tensor(-1.6129, requires_grad=True)\n",
      "ldfraw_hat tensor(1.6980, requires_grad=True)\n",
      "epoch 600 loss = 1145.7470479011536;\n",
      "mode_hat tensor(0.5004, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8710, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8785, requires_grad=True)\n",
      "Final mean_losses: 1224.680017229713\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 2.9732, -0.9496,  0.4446, -2.3478,  2.7372, -2.1619,  2.9057,  3.6207,\n",
      "        -4.9748, -2.2767], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.5963, -4.4083], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.8945361375808716\n",
      "ltscale_hat:\n",
      "-1.9617074728012085\n",
      "mode_hat:\n",
      "0.5007238984107971\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([ 0.1612,  0.9445, -3.1755, -3.2897])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 14976.01558125019;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 2875.088267147541;\n",
      "mode_hat tensor(0.1369, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4887, requires_grad=True)\n",
      "epoch 200 loss = 102551.32290112972;\n",
      "mode_hat tensor(0.1460, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0024, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9582, requires_grad=True)\n",
      "epoch 300 loss = 5697.064233332872;\n",
      "mode_hat tensor(0.1555, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5018, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4233, requires_grad=True)\n",
      "epoch 400 loss = 4235.937912344933;\n",
      "mode_hat tensor(0.2053, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9929, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8891, requires_grad=True)\n",
      "epoch 500 loss = 7075.61753565073;\n",
      "mode_hat tensor(0.3075, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4752, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3385, requires_grad=True)\n",
      "Final mean_losses: 12352.87121683628\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.647918939590454\n",
      "ldfraw_sigma:\n",
      "0.8724916577339172\n",
      "ltscale_hat:\n",
      "-2.809115409851074\n",
      "ltscale_sigma:\n",
      "1.0345661640167236\n",
      "mode_hat:\n",
      "0.2978689968585968\n",
      "mode_sigma:\n",
      "0.43706563115119934\n",
      "t_part_hat:\n",
      "tensor([ 0.0050,  0.1531, -0.2877, -0.2772, -0.3208,  0.4223, -0.3143,  0.2817,\n",
      "         0.4250,  0.2949], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.9591, 1.1700, 0.9964, 1.1291, 0.9785, 0.9664, 0.9630, 1.1268, 0.9478,\n",
      "        1.0597], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([ 4.9386,  0.8101,  0.9556, -1.8085])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "complaint 9 assert approx_eq: tensor([[ 99],\n",
      "        [253],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 927.6608],\n",
      "        [-963.1616],\n",
      "        [-857.9235]], grad_fn=<IndexBackward>) tensor([[-949.9432],\n",
      "        [ 970.5527],\n",
      "        [ 872.8273]], grad_fn=<IndexBackward>) tensor([[ 316.0919],\n",
      "        [-300.2943],\n",
      "        [-299.3047]], grad_fn=<IndexBackward>) tensor([[-293.9695],\n",
      "        [ 292.9210],\n",
      "        [ 284.5509]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1599],\n",
      "        [ 0.0178],\n",
      "        [ 0.1501]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1194.5406266450882;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint 8 assert approx_eq: tensor([[ 99],\n",
      "        [253],\n",
      "        [260],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 929.7208],\n",
      "        [-961.6545],\n",
      "        [ 783.0964],\n",
      "        [-856.1370]], grad_fn=<IndexBackward>) tensor([[-951.8252],\n",
      "        [ 969.0529],\n",
      "        [-803.5749],\n",
      "        [ 871.1644]], grad_fn=<IndexBackward>) tensor([[ 315.7807],\n",
      "        [-299.5644],\n",
      "        [ 298.3148],\n",
      "        [-298.5569]], grad_fn=<IndexBackward>) tensor([[-293.5256],\n",
      "        [ 292.1854],\n",
      "        [-277.8476],\n",
      "        [ 283.8322]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.1507],\n",
      "        [ 0.0194],\n",
      "        [-0.0112],\n",
      "        [ 0.3027]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "complaint 7 assert approx_eq: tensor([[ 99],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 929.1696],\n",
      "        [-861.2089]], grad_fn=<IndexBackward>) tensor([[-951.3961],\n",
      "        [ 874.6519]], grad_fn=<IndexBackward>) tensor([[ 315.1274],\n",
      "        [-298.5607]], grad_fn=<IndexBackward>) tensor([[-292.8749],\n",
      "        [ 283.2351]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0260],\n",
      "        [-1.8825]], grad_fn=<IndexBackward>)\n",
      "yay 1 fix_m_grad\n",
      "complaint 6 assert approx_eq: tensor([[ 99],\n",
      "        [260],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 929.7319],\n",
      "        [ 783.3046],\n",
      "        [-855.2076]], grad_fn=<IndexBackward>) tensor([[-951.9438],\n",
      "        [-803.8163],\n",
      "        [ 870.4288]], grad_fn=<IndexBackward>) tensor([[ 315.3777],\n",
      "        [ 297.9597],\n",
      "        [-298.0392]], grad_fn=<IndexBackward>) tensor([[-293.0892],\n",
      "        [-277.4363],\n",
      "        [ 283.3430]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0765],\n",
      "        [0.0116],\n",
      "        [0.5250]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[253],\n",
      "        [260],\n",
      "        [366]]) \n",
      "              1.. tensor([[-961.3936],\n",
      "        [ 783.0790],\n",
      "        [-856.1721]], grad_fn=<IndexBackward>) tensor([[ 968.8182],\n",
      "        [-803.6147],\n",
      "        [ 871.1331]], grad_fn=<IndexBackward>) tensor([[-299.6928],\n",
      "        [ 298.5119],\n",
      "        [-298.7408]], grad_fn=<IndexBackward>) tensor([[ 292.2960],\n",
      "        [-277.9877],\n",
      "        [ 283.9391]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0278],\n",
      "        [-0.0115],\n",
      "        [ 0.1594]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[ 99],\n",
      "        [253],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 929.2589],\n",
      "        [-961.0795],\n",
      "        [-856.3338]], grad_fn=<IndexBackward>) tensor([[-951.6725],\n",
      "        [ 968.5003],\n",
      "        [ 871.1439]], grad_fn=<IndexBackward>) tensor([[ 316.2202],\n",
      "        [-299.9235],\n",
      "        [-299.0240]], grad_fn=<IndexBackward>) tensor([[-293.9611],\n",
      "        [ 292.5187],\n",
      "        [ 284.1545]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1545],\n",
      "        [ 0.0161],\n",
      "        [-0.0593]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[ 99],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 929.5676],\n",
      "        [-856.1875]], grad_fn=<IndexBackward>) tensor([[-951.8304],\n",
      "        [ 871.0948]], grad_fn=<IndexBackward>) tensor([[ 316.1031],\n",
      "        [-298.8563]], grad_fn=<IndexBackward>) tensor([[-293.7798],\n",
      "        [ 284.0114]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0605],\n",
      "        [0.0624]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[ 99],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 928.6409],\n",
      "        [-856.5895]], grad_fn=<IndexBackward>) tensor([[-951.0306],\n",
      "        [ 871.5258]], grad_fn=<IndexBackward>) tensor([[ 316.0761],\n",
      "        [-298.9743]], grad_fn=<IndexBackward>) tensor([[-293.7919],\n",
      "        [ 284.1247]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1055],\n",
      "        [ 0.0866]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[ 99],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 928.4609],\n",
      "        [-856.8550]], grad_fn=<IndexBackward>) tensor([[-950.7923],\n",
      "        [ 871.8152]], grad_fn=<IndexBackward>) tensor([[ 316.0812],\n",
      "        [-299.0313]], grad_fn=<IndexBackward>) tensor([[-293.7867],\n",
      "        [ 284.1898]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0370],\n",
      "        [ 0.1187]], grad_fn=<IndexBackward>)\n",
      "yay -20\n",
      "complaint 0 assert approx_eq: tensor([[ 99],\n",
      "        [366]]) \n",
      "              1.. tensor([[ 927.5199],\n",
      "        [-857.4223]], grad_fn=<IndexBackward>) tensor([[-949.9537],\n",
      "        [ 872.3860]], grad_fn=<IndexBackward>) tensor([[ 316.0862],\n",
      "        [-299.2101]], grad_fn=<IndexBackward>) tensor([[-293.8542],\n",
      "        [ 284.3744]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.2018],\n",
      "        [ 0.1280]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -80\n",
      "complaint -20\n",
      "yay -140\n",
      "yay -200\n",
      "complaint -40\n",
      "yay -260\n",
      "epoch 100 loss = 1382.0601416826248;\n",
      "mode_hat tensor(0.2009, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2053, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2605, requires_grad=True)\n",
      "yay -320\n",
      "complaint -60\n",
      "yay -380\n",
      "complaint -80\n",
      "yay -440\n",
      "yay -500\n",
      "complaint -100\n",
      "yay -560\n",
      "epoch 200 loss = 1461.5366685986519;\n",
      "mode_hat tensor(0.3602, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4393, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4504, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1085.6907437443733;\n",
      "mode_hat tensor(0.3754, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5917, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5479, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 1181.1703711748123;\n",
      "mode_hat tensor(0.4901, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7372, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6347, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "complaint -120\n",
      "yay -1460\n",
      "epoch 500 loss = 1070.161878168583;\n",
      "mode_hat tensor(0.5865, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9099, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7172, requires_grad=True)\n",
      "Final mean_losses: 1245.8103991573748\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.0751, -4.0254], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.7172194719314575\n",
      "ltscale_hat:\n",
      "-0.9098751544952393\n",
      "mode_hat:\n",
      "0.5865411162376404\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([ 1.7102, -5.1904,  1.1465,  1.4114])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 3880.810669183731;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1061.580748140812;\n",
      "mode_hat tensor(0.4827, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2739, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2669, requires_grad=True)\n",
      "epoch 200 loss = 1211.1788353919983;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode_hat tensor(0.4924, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4120, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3697, requires_grad=True)\n",
      "epoch 300 loss = 1360.5107984542847;\n",
      "mode_hat tensor(0.4971, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5983, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4786, requires_grad=True)\n",
      "epoch 400 loss = 1189.2472705245018;\n",
      "mode_hat tensor(0.5082, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7943, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6258, requires_grad=True)\n",
      "epoch 500 loss = 947.0685949325562;\n",
      "mode_hat tensor(0.5005, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9256, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6420, requires_grad=True)\n",
      "epoch 600 loss = 1059.6252037286758;\n",
      "mode_hat tensor(0.4956, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0887, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5978, requires_grad=True)\n",
      "epoch 700 loss = 1211.6054866313934;\n",
      "mode_hat tensor(0.4996, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2909, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6317, requires_grad=True)\n",
      "Final mean_losses: 1320.5364133468254\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 1.1348, -5.5549,  0.6519,  0.9273, -2.7258,  1.0023,  4.8005, -0.3090,\n",
      "         5.6833,  1.4942], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.1326, -3.9728], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.6220988035202026\n",
      "ltscale_hat:\n",
      "-1.3512144088745117\n",
      "mode_hat:\n",
      "0.5022040605545044\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([-3.4672,  2.7095,  2.7642, -4.2493])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 12 33.333333333333336\n",
      "epoch 0 loss = 35933.44438779354;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 11319.048022866249;\n",
      "mode_hat tensor(0.1003, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4859, requires_grad=True)\n",
      "epoch 200 loss = 14444.787600934505;\n",
      "mode_hat tensor(0.1400, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0037, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9722, requires_grad=True)\n",
      "epoch 300 loss = 10931.62165760994;\n",
      "mode_hat tensor(0.1844, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5032, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4518, requires_grad=True)\n",
      "epoch 400 loss = 13476.866097569466;\n",
      "mode_hat tensor(0.2341, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9960, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9194, requires_grad=True)\n",
      "epoch 500 loss = 7825.071934521198;\n",
      "mode_hat tensor(0.2413, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4860, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3723, requires_grad=True)\n",
      "Final mean_losses: 30547.715348509268\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.5516269207000732\n",
      "ldfraw_sigma:\n",
      "0.8343349099159241\n",
      "ltscale_hat:\n",
      "-2.674640655517578\n",
      "ltscale_sigma:\n",
      "0.835740327835083\n",
      "mode_hat:\n",
      "0.23015190660953522\n",
      "mode_sigma:\n",
      "0.491041898727417\n",
      "t_part_hat:\n",
      "tensor([-0.3548,  0.3628,  0.2908, -0.2248, -0.3695,  0.2512,  0.1353, -0.1389,\n",
      "         0.1186,  0.0235], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([1.0082, 1.0695, 1.1189, 1.0293, 0.9749, 1.0423, 1.0558, 1.1985, 0.9096,\n",
      "        1.1965], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([-3.3809,  0.1020,  4.2784, -0.5064])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1023.013793349266;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1061.8700125813484;\n",
      "mode_hat tensor(0.3655, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4852, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4972, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 1200.1019726991653;\n",
      "mode_hat tensor(0.4815, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9179, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9531, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1092.4939427375793;\n",
      "mode_hat tensor(0.5237, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2857, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3599, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 1087.574757874012;\n",
      "mode_hat tensor(0.5260, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5604, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5875, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 1142.7554000020027;\n",
      "mode_hat tensor(0.5468, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8604, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8287, requires_grad=True)\n",
      "Final mean_losses: 1149.335952132992\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.5095, -4.3404], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.8286705017089844\n",
      "ltscale_hat:\n",
      "-1.8604365587234497\n",
      "mode_hat:\n",
      "0.5467982292175293\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([-1.5653, -0.0088,  7.4358,  0.4960])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 1342.3731126785278;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1008.4707921743393;\n",
      "mode_hat tensor(0.2948, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4934, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4988, requires_grad=True)\n",
      "epoch 200 loss = 1206.2588831186295;\n",
      "mode_hat tensor(0.3049, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9682, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9840, requires_grad=True)\n",
      "epoch 300 loss = 1133.5255683660507;\n",
      "mode_hat tensor(0.2938, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3629, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4444, requires_grad=True)\n",
      "epoch 400 loss = 1046.4831630587578;\n",
      "mode_hat tensor(0.3125, requires_grad=True)\n",
      "ltscale_hat tensor(-1.6660, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8042, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500 loss = 1221.0397753119469;\n",
      "mode_hat tensor(0.3000, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9192, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0504, requires_grad=True)\n",
      "Final mean_losses: 1322.100297963852\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-1.6650, -0.2225,  6.7835,  0.1353, -4.1919, -0.9346, -2.3507,  3.0437,\n",
      "        -2.9460, -3.4304], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.6274, -4.5040], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.188868761062622\n",
      "ltscale_hat:\n",
      "-2.0657155513763428\n",
      "mode_hat:\n",
      "0.31035077571868896\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([ 2.0392,  2.5257,  0.9254, -0.6166])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 8349.584856569767;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 3539.254716157913;\n",
      "mode_hat tensor(0.1740, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4845, requires_grad=True)\n",
      "epoch 200 loss = 3227.144408404827;\n",
      "mode_hat tensor(0.2404, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0046, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9629, requires_grad=True)\n",
      "epoch 300 loss = 3047.9943920373917;\n",
      "mode_hat tensor(0.2672, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5047, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4373, requires_grad=True)\n",
      "epoch 400 loss = 11086.964341163635;\n",
      "mode_hat tensor(0.2033, requires_grad=True)\n",
      "ltscale_hat tensor(-2.0030, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8949, requires_grad=True)\n",
      "epoch 500 loss = 2889.5446561574936;\n",
      "mode_hat tensor(0.2037, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4901, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3359, requires_grad=True)\n",
      "epoch 600 loss = 5085.896171867847;\n",
      "mode_hat tensor(0.2248, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9585, requires_grad=True)\n",
      "ldfraw_hat tensor(2.7437, requires_grad=True)\n",
      "epoch 700 loss = 3242.6888239979744;\n",
      "mode_hat tensor(0.2922, requires_grad=True)\n",
      "ltscale_hat tensor(-3.4056, requires_grad=True)\n",
      "ldfraw_hat tensor(3.1212, requires_grad=True)\n",
      "epoch 800 loss = 7657.912506639957;\n",
      "mode_hat tensor(0.2655, requires_grad=True)\n",
      "ltscale_hat tensor(-3.8435, requires_grad=True)\n",
      "ldfraw_hat tensor(3.4633, requires_grad=True)\n",
      "epoch 900 loss = 4309.309667289257;\n",
      "mode_hat tensor(0.2984, requires_grad=True)\n",
      "ltscale_hat tensor(-4.2716, requires_grad=True)\n",
      "ldfraw_hat tensor(3.7011, requires_grad=True)\n",
      "epoch 1000 loss = 2196.402793467045;\n",
      "mode_hat tensor(0.3108, requires_grad=True)\n",
      "ltscale_hat tensor(-4.6961, requires_grad=True)\n",
      "ldfraw_hat tensor(3.8392, requires_grad=True)\n",
      "epoch 1100 loss = 2616.750015974045;\n",
      "mode_hat tensor(0.3680, requires_grad=True)\n",
      "ltscale_hat tensor(-5.1448, requires_grad=True)\n",
      "ldfraw_hat tensor(3.9721, requires_grad=True)\n",
      "epoch 1200 loss = 16863.740880012512;\n",
      "mode_hat tensor(0.3541, requires_grad=True)\n",
      "ltscale_hat tensor(-5.5871, requires_grad=True)\n",
      "ldfraw_hat tensor(4.0197, requires_grad=True)\n",
      "Final mean_losses: 5576.874020024964\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "4.059551239013672\n",
      "ldfraw_sigma:\n",
      "0.6488545536994934\n",
      "ltscale_hat:\n",
      "-5.927233695983887\n",
      "ltscale_sigma:\n",
      "1.0079976320266724\n",
      "mode_hat:\n",
      "0.46556344628334045\n",
      "mode_sigma:\n",
      "0.1340053528547287\n",
      "t_part_hat:\n",
      "tensor([ 0.8241,  0.9480,  0.4738, -0.2445,  1.2093, -0.7889, -0.7200,  0.7281,\n",
      "         0.6735,  0.5974], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([1.1856, 1.2410, 0.8419, 1.3641, 0.9359, 1.3718, 0.8474, 1.0023, 1.3005,\n",
      "        1.3509], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([-1.5238, -1.3193, -2.1219,  0.7164])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1138.4521550536156;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "complaint 9 assert approx_eq: tensor([[ 30],\n",
      "        [286],\n",
      "        [314]]) \n",
      "              1.. tensor([[-813.3762],\n",
      "        [ 997.0757],\n",
      "        [ 852.2939]], grad_fn=<IndexBackward>) tensor([[  823.4453],\n",
      "        [-1027.6663],\n",
      "        [ -884.6112]], grad_fn=<IndexBackward>) tensor([[-285.6231],\n",
      "        [ 330.9292],\n",
      "        [ 319.3542]], grad_fn=<IndexBackward>) tensor([[ 275.6329],\n",
      "        [-300.3244],\n",
      "        [-287.0231]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0789],\n",
      "        [0.0143],\n",
      "        [0.0139]], grad_fn=<IndexBackward>)\n",
      "complaint 8 assert approx_eq: tensor([[ 30],\n",
      "        [309],\n",
      "        [314]]) \n",
      "              1.. tensor([[-814.4923],\n",
      "        [-786.0739],\n",
      "        [ 851.4083]], grad_fn=<IndexBackward>) tensor([[ 824.4517],\n",
      "        [ 811.2264],\n",
      "        [-883.7373]], grad_fn=<IndexBackward>) tensor([[-284.8793],\n",
      "        [-302.0431],\n",
      "        [ 318.3584]], grad_fn=<IndexBackward>) tensor([[ 274.8316],\n",
      "        [ 276.9019],\n",
      "        [-286.0162]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0883],\n",
      "        [ 0.0112],\n",
      "        [ 0.0132]], grad_fn=<IndexBackward>)\n",
      "complaint 7 assert approx_eq: tensor([[ 30],\n",
      "        [286],\n",
      "        [314]]) \n",
      "              1.. tensor([[-815.4836],\n",
      "        [ 994.8661],\n",
      "        [ 850.2369]], grad_fn=<IndexBackward>) tensor([[  825.4343],\n",
      "        [-1025.4998],\n",
      "        [ -882.6039]], grad_fn=<IndexBackward>) tensor([[-284.1329],\n",
      "        [ 328.8339],\n",
      "        [ 317.3419]], grad_fn=<IndexBackward>) tensor([[ 274.0620],\n",
      "        [-298.2192],\n",
      "        [-285.0027]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1202],\n",
      "        [-0.0189],\n",
      "        [-0.0279]], grad_fn=<IndexBackward>)\n",
      "complaint 6 assert approx_eq: tensor([[ 30],\n",
      "        [314]]) \n",
      "              1.. tensor([[-815.7670],\n",
      "        [ 849.0620]], grad_fn=<IndexBackward>) tensor([[ 825.9769],\n",
      "        [-881.4298]], grad_fn=<IndexBackward>) tensor([[-283.4071],\n",
      "        [ 316.4387]], grad_fn=<IndexBackward>) tensor([[ 273.4049],\n",
      "        [-284.0822]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.2076],\n",
      "        [-0.0114]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[ 30],\n",
      "        [175],\n",
      "        [286],\n",
      "        [314]]) \n",
      "              1.. tensor([[  -817.7130],\n",
      "        [150773.7969],\n",
      "        [   992.1249],\n",
      "        [   847.8140]], grad_fn=<IndexBackward>) tensor([[    827.6670],\n",
      "        [-151012.0000],\n",
      "        [  -1022.7858],\n",
      "        [   -880.1796]], grad_fn=<IndexBackward>) tensor([[-282.9290],\n",
      "        [1774.7170],\n",
      "        [ 326.9961],\n",
      "        [ 315.5882]], grad_fn=<IndexBackward>) tensor([[  272.8101],\n",
      "        [-1536.5011],\n",
      "        [ -296.3551],\n",
      "        [ -283.2106]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1649],\n",
      "        [ 0.0128],\n",
      "        [-0.0199],\n",
      "        [ 0.0119]], grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint 4 assert approx_eq: tensor([[ 30],\n",
      "        [286],\n",
      "        [314]]) \n",
      "              1.. tensor([[-817.3760],\n",
      "        [ 990.7219],\n",
      "        [ 846.4321]], grad_fn=<IndexBackward>) tensor([[  827.8174],\n",
      "        [-1021.3919],\n",
      "        [ -878.8362]], grad_fn=<IndexBackward>) tensor([[-282.1862],\n",
      "        [ 326.1054],\n",
      "        [ 314.7207]], grad_fn=<IndexBackward>) tensor([[ 272.2143],\n",
      "        [-295.4488],\n",
      "        [-282.3390]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.4694],\n",
      "        [-0.0134],\n",
      "        [-0.0225]], grad_fn=<IndexBackward>)\n",
      "yay -20\n",
      "complaint 3 assert approx_eq: tensor([[ 30],\n",
      "        [309],\n",
      "        [314]]) \n",
      "              1.. tensor([[-821.8832],\n",
      "        [-790.8966],\n",
      "        [ 845.4489]], grad_fn=<IndexBackward>) tensor([[ 831.1647],\n",
      "        [ 816.2301],\n",
      "        [-877.8428]], grad_fn=<IndexBackward>) tensor([[-282.2400],\n",
      "        [-299.2409],\n",
      "        [ 314.1324]], grad_fn=<IndexBackward>) tensor([[ 271.8446],\n",
      "        [ 273.8881],\n",
      "        [-281.7511]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-1.1138],\n",
      "        [-0.0193],\n",
      "        [-0.0126]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[ 30],\n",
      "        [175],\n",
      "        [286],\n",
      "        [314]]) \n",
      "              1.. tensor([[  -823.0240],\n",
      "        [150673.0000],\n",
      "        [   988.4127],\n",
      "        [   844.4294]], grad_fn=<IndexBackward>) tensor([[    832.2797],\n",
      "        [-150911.4062],\n",
      "        [  -1019.0660],\n",
      "        [   -876.7849]], grad_fn=<IndexBackward>) tensor([[-281.9312],\n",
      "        [1765.3518],\n",
      "        [ 324.9030],\n",
      "        [ 313.5744]], grad_fn=<IndexBackward>) tensor([[  271.5081],\n",
      "        [-1526.9342],\n",
      "        [ -294.2379],\n",
      "        [ -281.1724]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-1.1673],\n",
      "        [ 0.0114],\n",
      "        [ 0.0118],\n",
      "        [ 0.0465]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[ 14],\n",
      "        [ 30],\n",
      "        [314]]) \n",
      "              1.. tensor([[ 697.1506],\n",
      "        [-823.0830],\n",
      "        [ 843.1510]], grad_fn=<IndexBackward>) tensor([[-697.3758],\n",
      "        [ 832.6931],\n",
      "        [-875.5201]], grad_fn=<IndexBackward>) tensor([[ 253.9129],\n",
      "        [-281.5016],\n",
      "        [ 312.9935]], grad_fn=<IndexBackward>) tensor([[-253.6989],\n",
      "        [ 271.1806],\n",
      "        [-280.5856]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0112],\n",
      "        [-0.7109],\n",
      "        [ 0.0388]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[ 30],\n",
      "        [286],\n",
      "        [309],\n",
      "        [314]]) \n",
      "              1.. tensor([[-822.7649],\n",
      "        [ 986.2292],\n",
      "        [-793.3322],\n",
      "        [ 842.2719]], grad_fn=<IndexBackward>) tensor([[  832.6605],\n",
      "        [-1016.9379],\n",
      "        [  818.7849],\n",
      "        [ -874.7266]], grad_fn=<IndexBackward>) tensor([[-281.0367],\n",
      "        [ 323.7788],\n",
      "        [-298.2952],\n",
      "        [ 312.4747]], grad_fn=<IndexBackward>) tensor([[ 270.7959],\n",
      "        [-293.0896],\n",
      "        [ 272.8293],\n",
      "        [-280.0670]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.3452],\n",
      "        [-0.0195],\n",
      "        [-0.0132],\n",
      "        [-0.0469]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -80\n",
      "complaint -20\n",
      "yay -140\n",
      "complaint -40\n",
      "yay -200\n",
      "complaint -60\n",
      "yay -260\n",
      "complaint -80\n",
      "epoch 100 loss = 1197.7796100378036;\n",
      "mode_hat tensor(0.2258, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3814, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1683, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "complaint -100\n",
      "epoch 200 loss = 1196.8311665654182;\n",
      "mode_hat tensor(0.3420, requires_grad=True)\n",
      "ltscale_hat tensor(-0.6253, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2378, requires_grad=True)\n",
      "yay -620\n",
      "complaint -120\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1418.195406794548;\n",
      "mode_hat tensor(0.4228, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8298, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2776, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "complaint -140\n",
      "yay -1100\n",
      "complaint -160\n",
      "yay -1160\n",
      "epoch 400 loss = 1272.6583238840103;\n",
      "mode_hat tensor(0.4016, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9897, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2640, requires_grad=True)\n",
      "complaint -180\n",
      "yay -1220\n",
      "complaint -200\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 1360.4383752346039;\n",
      "mode_hat tensor(0.4315, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1905, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2707, requires_grad=True)\n",
      "Final mean_losses: 1564.786600360725\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.3852, -4.2037], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.2706604599952698\n",
      "ltscale_hat:\n",
      "-1.1905094385147095\n",
      "mode_hat:\n",
      "0.43154630064964294\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([ 1.5780, -3.8409,  1.1502,  2.1799])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 1352.1735870838165;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1237.3725070357323;\n",
      "mode_hat tensor(0.2799, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2933, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1710, requires_grad=True)\n",
      "epoch 200 loss = 1223.9967893958092;\n",
      "mode_hat tensor(0.2750, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4692, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2193, requires_grad=True)\n",
      "epoch 300 loss = 1343.9669085144997;\n",
      "mode_hat tensor(0.2960, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7209, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3000, requires_grad=True)\n",
      "epoch 400 loss = 1609.2697941064835;\n",
      "mode_hat tensor(0.2887, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9341, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3606, requires_grad=True)\n",
      "epoch 500 loss = 1292.7165594100952;\n",
      "mode_hat tensor(0.2872, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0894, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3418, requires_grad=True)\n",
      "epoch 600 loss = 1134.0293772220612;\n",
      "mode_hat tensor(0.2965, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2134, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3342, requires_grad=True)\n",
      "Final mean_losses: 1271.7888433923688\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 1.1473, -3.7829,  0.6562,  1.5793,  0.5573, -0.8556, -1.9893,  4.6832,\n",
      "         0.3543, -1.7603], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.2294, -4.0864], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.3435359299182892\n",
      "ltscale_hat:\n",
      "-1.2999142408370972\n",
      "mode_hat:\n",
      "0.29422661662101746\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([ 3.0203,  3.8077, -3.2618,  1.8528])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 25 16.0\n",
      "epoch 0 loss = 8439.442453980446;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 loss = 11748.478569090366;\n",
      "mode_hat tensor(0.2239, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4821, requires_grad=True)\n",
      "epoch 200 loss = 4721.609377801418;\n",
      "mode_hat tensor(0.2940, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9619, requires_grad=True)\n",
      "epoch 300 loss = 4262.777403116226;\n",
      "mode_hat tensor(0.4451, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5010, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4294, requires_grad=True)\n",
      "epoch 400 loss = 4105.639841556549;\n",
      "mode_hat tensor(0.5689, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9953, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8735, requires_grad=True)\n",
      "epoch 500 loss = 12586.319640159607;\n",
      "mode_hat tensor(0.6282, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4732, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3112, requires_grad=True)\n",
      "Final mean_losses: 13905.100007680589\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.311185598373413\n",
      "ldfraw_sigma:\n",
      "0.979842483997345\n",
      "ltscale_hat:\n",
      "-2.4731550216674805\n",
      "ltscale_sigma:\n",
      "0.9943132400512695\n",
      "mode_hat:\n",
      "0.6282443404197693\n",
      "mode_sigma:\n",
      "0.5009928941726685\n",
      "t_part_hat:\n",
      "tensor([ 0.4116,  0.4509, -0.3904,  0.2776,  0.2577, -0.5194, -0.4192,  0.4337,\n",
      "        -0.0012,  0.4394], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([1.0903, 1.1935, 1.0186, 1.1162, 0.9119, 0.9818, 1.0415, 1.1047, 1.0638,\n",
      "        1.0682], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([-0.6581,  1.0145,  1.1360,  2.5667])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1147.8732126951218;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1172.8442543148994;\n",
      "mode_hat tensor(0.2834, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5040, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5012, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 1151.1910291910172;\n",
      "mode_hat tensor(0.4133, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9684, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9669, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1130.9263966083527;\n",
      "mode_hat tensor(0.4242, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3613, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3630, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 1114.5546612143517;\n",
      "mode_hat tensor(0.4489, requires_grad=True)\n",
      "ltscale_hat tensor(-1.6276, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5918, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 1041.7465098500252;\n",
      "mode_hat tensor(0.4685, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8571, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7137, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 1162.908290863037;\n",
      "mode_hat tensor(0.4420, requires_grad=True)\n",
      "ltscale_hat tensor(-2.1112, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7618, requires_grad=True)\n",
      "yay -1820\n",
      "Final mean_losses: 1145.224555256326\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.6098, -4.4459], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.7748584747314453\n",
      "ltscale_hat:\n",
      "-2.1410655975341797\n",
      "mode_hat:\n",
      "0.4740888476371765\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([ 2.4485,  2.1644, -2.6825,  1.6368])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 1728.513236105442;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1211.4591397047043;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5017, requires_grad=True)\n",
      "epoch 200 loss = 1089.0727363824844;\n",
      "mode_hat tensor(0.5897, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9747, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9772, requires_grad=True)\n",
      "epoch 300 loss = 1015.618389904499;\n",
      "mode_hat tensor(0.6102, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3644, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3646, requires_grad=True)\n",
      "epoch 400 loss = 1223.073464691639;\n",
      "mode_hat tensor(0.6059, requires_grad=True)\n",
      "ltscale_hat tensor(-1.6655, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5471, requires_grad=True)\n",
      "epoch 500 loss = 1051.4587730169296;\n",
      "mode_hat tensor(0.6200, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9117, requires_grad=True)\n",
      "ldfraw_hat tensor(1.6391, requires_grad=True)\n",
      "epoch 600 loss = 1195.4840596914291;\n",
      "mode_hat tensor(0.6286, requires_grad=True)\n",
      "ltscale_hat tensor(-2.1201, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7082, requires_grad=True)\n",
      "epoch 700 loss = 1082.8232634663582;\n",
      "mode_hat tensor(0.6320, requires_grad=True)\n",
      "ltscale_hat tensor(-2.3593, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8163, requires_grad=True)\n",
      "epoch 800 loss = 1146.6839346885681;\n",
      "mode_hat tensor(0.6336, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5276, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8313, requires_grad=True)\n",
      "Final mean_losses: 1146.5708119955252\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 1.5162,  1.2577, -3.2730,  0.8696,  3.6199, -1.4604, -2.3091,  3.8093,\n",
      "        -0.2718, -0.9065], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.4909, -3.9985], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.8288581371307373\n",
      "ltscale_hat:\n",
      "-2.5714190006256104\n",
      "mode_hat:\n",
      "0.6334371566772461\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([ 2.0225, -0.0204, -1.2180, -0.1478])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 49164.07283055782;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 17067.97278022766;\n",
      "mode_hat tensor(0.1155, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldfraw_hat tensor(0.4853, requires_grad=True)\n",
      "epoch 200 loss = 3056.2139533162117;\n",
      "mode_hat tensor(0.2529, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0040, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9578, requires_grad=True)\n",
      "epoch 300 loss = 7311.187024831772;\n",
      "mode_hat tensor(0.2960, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5019, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4307, requires_grad=True)\n",
      "epoch 400 loss = 10362.902704775333;\n",
      "mode_hat tensor(0.3461, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9968, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8706, requires_grad=True)\n",
      "epoch 500 loss = 4737.813280582428;\n",
      "mode_hat tensor(0.4064, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4855, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3074, requires_grad=True)\n",
      "epoch 600 loss = 3721.6297800540924;\n",
      "mode_hat tensor(0.4318, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9552, requires_grad=True)\n",
      "ldfraw_hat tensor(2.7271, requires_grad=True)\n",
      "epoch 700 loss = 4597.376797020435;\n",
      "mode_hat tensor(0.4528, requires_grad=True)\n",
      "ltscale_hat tensor(-3.4137, requires_grad=True)\n",
      "ldfraw_hat tensor(3.1063, requires_grad=True)\n",
      "epoch 800 loss = 5091.654142975807;\n",
      "mode_hat tensor(0.4323, requires_grad=True)\n",
      "ltscale_hat tensor(-3.8440, requires_grad=True)\n",
      "ldfraw_hat tensor(3.4198, requires_grad=True)\n",
      "epoch 900 loss = 11288.651333451271;\n",
      "mode_hat tensor(0.4099, requires_grad=True)\n",
      "ltscale_hat tensor(-4.2745, requires_grad=True)\n",
      "ldfraw_hat tensor(3.6553, requires_grad=True)\n",
      "epoch 1000 loss = 2519.7013771533966;\n",
      "mode_hat tensor(0.4508, requires_grad=True)\n",
      "ltscale_hat tensor(-4.7017, requires_grad=True)\n",
      "ldfraw_hat tensor(3.8436, requires_grad=True)\n",
      "epoch 1100 loss = 2576.7831406593323;\n",
      "mode_hat tensor(0.4795, requires_grad=True)\n",
      "ltscale_hat tensor(-5.1238, requires_grad=True)\n",
      "ldfraw_hat tensor(3.8519, requires_grad=True)\n",
      "epoch 1200 loss = 4450.091474056244;\n",
      "mode_hat tensor(0.4517, requires_grad=True)\n",
      "ltscale_hat tensor(-5.5840, requires_grad=True)\n",
      "ldfraw_hat tensor(3.9147, requires_grad=True)\n",
      "epoch 1300 loss = 5471.85415828228;\n",
      "mode_hat tensor(0.4585, requires_grad=True)\n",
      "ltscale_hat tensor(-6.0416, requires_grad=True)\n",
      "ldfraw_hat tensor(3.9170, requires_grad=True)\n",
      "epoch 1400 loss = 2496.519471645355;\n",
      "mode_hat tensor(0.5163, requires_grad=True)\n",
      "ltscale_hat tensor(-6.4647, requires_grad=True)\n",
      "ldfraw_hat tensor(3.8870, requires_grad=True)\n",
      "epoch 1500 loss = 4177.400762856007;\n",
      "mode_hat tensor(0.4793, requires_grad=True)\n",
      "ltscale_hat tensor(-6.9018, requires_grad=True)\n",
      "ldfraw_hat tensor(3.8615, requires_grad=True)\n",
      "epoch 1600 loss = 1345.8948529958725;\n",
      "mode_hat tensor(0.4442, requires_grad=True)\n",
      "ltscale_hat tensor(-7.3089, requires_grad=True)\n",
      "ldfraw_hat tensor(3.7080, requires_grad=True)\n",
      "epoch 1700 loss = 1054.0102659463882;\n",
      "mode_hat tensor(0.4476, requires_grad=True)\n",
      "ltscale_hat tensor(-7.7752, requires_grad=True)\n",
      "ldfraw_hat tensor(3.6962, requires_grad=True)\n",
      "epoch 1800 loss = 1047.4682078361511;\n",
      "mode_hat tensor(0.4704, requires_grad=True)\n",
      "ltscale_hat tensor(-8.2275, requires_grad=True)\n",
      "ldfraw_hat tensor(3.6437, requires_grad=True)\n",
      "epoch 1900 loss = 3219.4789568185806;\n",
      "mode_hat tensor(0.4390, requires_grad=True)\n",
      "ltscale_hat tensor(-8.5601, requires_grad=True)\n",
      "ldfraw_hat tensor(3.5047, requires_grad=True)\n",
      "epoch 2000 loss = 1236.0806896686554;\n",
      "mode_hat tensor(0.4560, requires_grad=True)\n",
      "ltscale_hat tensor(-8.9164, requires_grad=True)\n",
      "ldfraw_hat tensor(3.4153, requires_grad=True)\n",
      "epoch 2100 loss = 1343.7779471874237;\n",
      "mode_hat tensor(0.4309, requires_grad=True)\n",
      "ltscale_hat tensor(-9.3943, requires_grad=True)\n",
      "ldfraw_hat tensor(3.3065, requires_grad=True)\n",
      "epoch 2200 loss = 1152.8081941008568;\n",
      "mode_hat tensor(0.4103, requires_grad=True)\n",
      "ltscale_hat tensor(-9.7172, requires_grad=True)\n",
      "ldfraw_hat tensor(3.3298, requires_grad=True)\n",
      "epoch 2300 loss = 1536.1790246367455;\n",
      "mode_hat tensor(0.4606, requires_grad=True)\n",
      "ltscale_hat tensor(-9.9783, requires_grad=True)\n",
      "ldfraw_hat tensor(3.2595, requires_grad=True)\n",
      "epoch 2400 loss = 1109.7376087903976;\n",
      "mode_hat tensor(0.4437, requires_grad=True)\n",
      "ltscale_hat tensor(-10.2304, requires_grad=True)\n",
      "ldfraw_hat tensor(3.1220, requires_grad=True)\n",
      "epoch 2500 loss = 1102.9275305867195;\n",
      "mode_hat tensor(0.4284, requires_grad=True)\n",
      "ltscale_hat tensor(-10.5472, requires_grad=True)\n",
      "ldfraw_hat tensor(3.0233, requires_grad=True)\n",
      "epoch 2600 loss = 1096.642548084259;\n",
      "mode_hat tensor(0.4134, requires_grad=True)\n",
      "ltscale_hat tensor(-10.8142, requires_grad=True)\n",
      "ldfraw_hat tensor(2.8918, requires_grad=True)\n",
      "epoch 2700 loss = 1137.6868566274643;\n",
      "mode_hat tensor(0.4652, requires_grad=True)\n",
      "ltscale_hat tensor(-11.0693, requires_grad=True)\n",
      "ldfraw_hat tensor(2.8223, requires_grad=True)\n",
      "epoch 2800 loss = 909.3004059791565;\n",
      "mode_hat tensor(0.4767, requires_grad=True)\n",
      "ltscale_hat tensor(-11.3587, requires_grad=True)\n",
      "ldfraw_hat tensor(2.8015, requires_grad=True)\n",
      "epoch 2900 loss = 1021.4880723953247;\n",
      "mode_hat tensor(0.4587, requires_grad=True)\n",
      "ltscale_hat tensor(-11.6153, requires_grad=True)\n",
      "ldfraw_hat tensor(2.6563, requires_grad=True)\n",
      "epoch 3000 loss = 900.4504242241383;\n",
      "mode_hat tensor(0.4307, requires_grad=True)\n",
      "ltscale_hat tensor(-11.8750, requires_grad=True)\n",
      "ldfraw_hat tensor(2.5544, requires_grad=True)\n",
      "Final mean_losses: 1280.1939471297926\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.5544025897979736\n",
      "ldfraw_sigma:\n",
      "0.6054052710533142\n",
      "ltscale_hat:\n",
      "-11.875021934509277\n",
      "ltscale_sigma:\n",
      "8.359403610229492\n",
      "mode_hat:\n",
      "0.43068835139274597\n",
      "mode_sigma:\n",
      "0.028698956593871117\n",
      "t_part_hat:\n",
      "tensor([ 1.4577, -0.3954, -1.5896, -0.4875, -2.0275,  1.7804,  0.1813, -1.3662,\n",
      "         1.2221,  0.3081], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.5577, 1.0241, 0.6024, 0.8469, 0.4777, 1.1934, 1.1410, 0.8624, 1.1187,\n",
      "        1.4682], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([2.8203, 2.9665, 1.1652, 1.0362])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "complaint 9 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[857.0244]], grad_fn=<IndexBackward>) tensor([[-866.7433]], grad_fn=<IndexBackward>) tensor([[292.2999]], grad_fn=<IndexBackward>) tensor([[-282.7651]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1840]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1219.613764345646;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint 8 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[856.4156]], grad_fn=<IndexBackward>) tensor([[-865.8818]], grad_fn=<IndexBackward>) tensor([[291.6831]], grad_fn=<IndexBackward>) tensor([[-282.0499]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.1669]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "complaint 7 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[851.8289]], grad_fn=<IndexBackward>) tensor([[-861.9561]], grad_fn=<IndexBackward>) tensor([[290.0587]], grad_fn=<IndexBackward>) tensor([[-280.6344]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.7029]], grad_fn=<IndexBackward>)\n",
      "complaint 6 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[851.1791]], grad_fn=<IndexBackward>) tensor([[-861.1410]], grad_fn=<IndexBackward>) tensor([[289.3106]], grad_fn=<IndexBackward>) tensor([[-279.8201]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.4714]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[393]]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1.. tensor([[849.6544]], grad_fn=<IndexBackward>) tensor([[-859.9536]], grad_fn=<IndexBackward>) tensor([[288.3612]], grad_fn=<IndexBackward>) tensor([[-278.9769]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.9148]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[852.6395]], grad_fn=<IndexBackward>) tensor([[-861.7564]], grad_fn=<IndexBackward>) tensor([[287.8371]], grad_fn=<IndexBackward>) tensor([[-278.0412]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.6790]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[850.5276]], grad_fn=<IndexBackward>) tensor([[-860.0385]], grad_fn=<IndexBackward>) tensor([[286.6036]], grad_fn=<IndexBackward>) tensor([[-276.9454]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.1473]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[849.8665]], grad_fn=<IndexBackward>) tensor([[-859.2474]], grad_fn=<IndexBackward>) tensor([[285.6554]], grad_fn=<IndexBackward>) tensor([[-275.9516]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.3229]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[847.9998]], grad_fn=<IndexBackward>) tensor([[-857.7358]], grad_fn=<IndexBackward>) tensor([[284.5659]], grad_fn=<IndexBackward>) tensor([[-274.9806]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1507]], grad_fn=<IndexBackward>)\n",
      "yay -20\n",
      "complaint 0 assert approx_eq: tensor([[393]]) \n",
      "              1.. tensor([[848.0546]], grad_fn=<IndexBackward>) tensor([[-857.5605]], grad_fn=<IndexBackward>) tensor([[283.7658]], grad_fn=<IndexBackward>) tensor([[-274.0949]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.1650]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -80\n",
      "yay -140\n",
      "complaint -20\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1164.5098110437393;\n",
      "mode_hat tensor(0.2569, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4895, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0830, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "complaint -40\n",
      "yay -440\n",
      "complaint -60\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 1256.7096077799797;\n",
      "mode_hat tensor(0.3529, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8952, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0542, requires_grad=True)\n",
      "yay -620\n",
      "complaint -80\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "complaint -100\n",
      "yay -860\n",
      "complaint -120\n",
      "epoch 300 loss = 1411.0946675539017;\n",
      "mode_hat tensor(0.3739, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2487, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2228, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "complaint -140\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 1204.4834129214287;\n",
      "mode_hat tensor(0.4442, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5901, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4336, requires_grad=True)\n",
      "yay -1220\n",
      "complaint -160\n",
      "yay -1280\n",
      "complaint -180\n",
      "yay -1340\n",
      "complaint -200\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 1243.2582023739815;\n",
      "mode_hat tensor(0.4257, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8810, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6628, requires_grad=True)\n",
      "yay -1520\n",
      "Final mean_losses: 1220.1969161170582\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.5987, -4.4789], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.6820827722549438\n",
      "ltscale_hat:\n",
      "-1.9115711450576782\n",
      "mode_hat:\n",
      "0.411593496799469\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([ 2.2279, -1.0608, -3.0647,  0.4418])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 1580.913530409336;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 1328.4404668211937;\n",
      "mode_hat tensor(0.4113, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1739, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1649, requires_grad=True)\n",
      "epoch 200 loss = 1331.9474148750305;\n",
      "mode_hat tensor(0.4056, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2221, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1280, requires_grad=True)\n",
      "epoch 300 loss = 1243.9419801831245;\n",
      "mode_hat tensor(0.4224, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2415, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1033, requires_grad=True)\n",
      "epoch 400 loss = 1245.421264052391;\n",
      "mode_hat tensor(0.4105, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3141, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1306, requires_grad=True)\n",
      "epoch 500 loss = 1222.2952051758766;\n",
      "mode_hat tensor(0.4275, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3419, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1172, requires_grad=True)\n",
      "epoch 600 loss = 1271.4233062267303;\n",
      "mode_hat tensor(0.4276, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3827, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1050, requires_grad=True)\n",
      "epoch 700 loss = 1318.5619805455208;\n",
      "mode_hat tensor(0.4242, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4020, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0913, requires_grad=True)\n",
      "epoch 800 loss = 1175.3341382741928;\n",
      "mode_hat tensor(0.4169, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4481, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0046, requires_grad=True)\n",
      "Final mean_losses: 1271.055803935089\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 1.5694, -1.4372, -3.3288,  0.0560, -2.4710,  6.6663, -3.0751,  0.3014,\n",
      "        -9.3879, -1.3393], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-4.5686, -4.5484], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.02609625644981861\n",
      "ltscale_hat:\n",
      "-0.43952658772468567\n",
      "mode_hat:\n",
      "0.42779284715652466\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: not enough values to unpack (expected 3, got 0)\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv created\n",
      "400\n",
      "tensor([-2.7972,  1.9395,  8.6295,  2.1863])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 10982.276640415192;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 15944.429376721382;\n",
      "mode_hat tensor(0.1834, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4793, requires_grad=True)\n",
      "epoch 200 loss = 27308.209135055542;\n",
      "mode_hat tensor(0.3216, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0036, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9530, requires_grad=True)\n",
      "epoch 300 loss = 19414.651022076607;\n",
      "mode_hat tensor(0.5059, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5018, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4313, requires_grad=True)\n",
      "epoch 400 loss = 22915.989546358585;\n",
      "mode_hat tensor(0.6285, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9872, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8922, requires_grad=True)\n",
      "epoch 500 loss = 22945.899322211742;\n",
      "mode_hat tensor(0.7606, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4670, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ldfraw_hat tensor(2.3432, requires_grad=True)\n",
      "Final mean_losses: 16128.063162152224\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.3431708812713623\n",
      "ldfraw_sigma:\n",
      "0.9870926737785339\n",
      "ltscale_hat:\n",
      "-2.4670374393463135\n",
      "ltscale_sigma:\n",
      "1.045401692390442\n",
      "mode_hat:\n",
      "0.7606381773948669\n",
      "mode_sigma:\n",
      "0.40733084082603455\n",
      "t_part_hat:\n",
      "tensor([-0.7021,  0.3991,  0.6976,  0.5390,  0.7375,  0.1209, -0.7287, -0.7108,\n",
      "        -0.6929,  0.6286], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([1.0564, 1.2225, 0.9259, 0.9708, 1.1309, 1.0603, 1.0261, 0.8938, 1.3354,\n",
      "        0.9587], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcnFWd7/HPr3pLZ+msnYUsJEBAIsqWAYRxXggKAWcM1xHFcYRxmMvVwXm5zOiAM1fU0Rmd6zJyVRwUNIyMgAgXUDSGsAjIkoWQkISQJmtn607S6TW9Vf3uH3W6u7q7eq+nq6rzfb9e/aqnznOe55yT6tSvz3nOcx5zd0RERKIUy3YFRERk7FOwERGRyCnYiIhI5BRsREQkcgo2IiISOQUbERGJnIKNiIhETsFGREQip2AjIiKRK8x2BXLFjBkzfOHChdmuhohIXlm3bt1hdy8fKJ+CTbBw4ULWrl2b7WqIiOQVM9s9mHwaRhMRkcgp2IiISOQUbEREJHIKNiIiEjkFGxERiZyCjYiIRE7BRkREIqdgk6Pi7e289tQqPJHIdlVEREZMN3XmqJcf+QV/eOBeYoWFLHnnu7JdHRGREVHPJkc11dYC0NzQkOWaiIiMnIKNiIhETsFGREQip2AjIiKRU7AREZHIKdiIiEjkFGxERCRyCjYiIhI5BRsREYmcgo2IiEROwUZERCKnYCMiIpFTsBERkcgp2IiISOQUbEREJHIKNiIiEjkFGxERiZyCjYiIRC7SYGNmu8xsk5ltMLO1IW2ama0ys+3hdWpINzO73cwqzGyjmZ2Xcp4bQv7tZnZDSvr54fwV4VjrrwwREcmO0ejZvMvdz3H3peH9LcBqd18MrA7vAa4CFoefm4A7IBk4gNuAC4ELgNtSgscdIW/HccsGKENERLIgG8Noy4EVYXsFcE1K+j2e9CIwxczmAFcCq9z9qLvXAKuAZWFfmbu/4O4O3NPjXOnKEBGRLIg62DjwOzNbZ2Y3hbRZ7n4AILzODOlzgb0px1aGtP7SK9Ok91eGiIhkQWHE57/E3feb2UxglZm93k9eS5Pmw0gftBAAbwJYsGDBUA4VEZEhiLRn4+77w2sV8DDJay6HwhAY4bUqZK8E5qccPg/YP0D6vDTp9FNGz/rd6e5L3X1peXn5cJspIiIDiCzYmNkEM5vUsQ1cAbwGPAp0zCi7AXgkbD8KXB9mpV0E1IYhsJXAFWY2NUwMuAJYGfbVm9lFYRba9T3Ola4MERHJgiiH0WYBD4fZyIXAf7v7b81sDfCAmd0I7AGuDfkfB64GKoAm4GMA7n7UzP4FWBPyfcXdj4btTwA/BUqB34QfgK/3UYaIiGRBZMHG3XcAZ6dJPwJcnibdgZv7ONfdwN1p0tcCZw22DBERyQ6tICAiIpFTsBERkcgp2IiISOQUbEREJHIKNiIiEjkFG0mrva2NxmM12a6GiIwRCjZj3BsvPU9T7bEhH/fIN7/KD//XRyOokYiciBRsxrDmxgYe+/a/8dDXvzTkY3dtWJf5ConICUvBZgzZ+cpatr3wbOf7RDwOQF112qXhRERGjYJNln3ruj/jse98vZ8cg1/I+qGvf4lf/cc3Rl4pEZEMU7DJNnfeePG5aIuI9OwiIgNTsMl56R7bIyKSXxRsREQkcgo2IiISOQUbERGJnIKNiIhETsHmROCajyYi2aVgM4aFR3KLiGSdgo2IiEROwUZERCKnYCMiIpFTsBERkcgp2JwINBtNRLJMwWYs02w0EckRCjY5T70SEcl/CjYiIhK5yIONmRWY2Stm9qvwfpGZvWRm283sfjMrDukl4X1F2L8w5Ry3hvRtZnZlSvqykFZhZrekpKctIz9pKExE8t9o9Gw+BWxNef8N4DvuvhioAW4M6TcCNe5+GvCdkA8zWwJcB7wVWAb8IASwAuD7wFXAEuDDIW9/ZYiISBZEGmzMbB7wXuDH4b0BlwEPhiwrgGvC9vLwnrD/8pB/OXCfu7e4+06gArgg/FS4+w53bwXuA5YPUMYJyXXdR0SyLOqezX8AnwcS4f104Ji7t4f3lcDcsD0X2AsQ9teG/J3pPY7pK72/Mk4opiE4EckRkQUbM/tToMrd16Ump8nqA+zLVHq6Ot5kZmvNbG11dXW6LHlNPRoRyRVR9mwuAd5nZrtIDnFdRrKnM8XMCkOeecD+sF0JzAcI+ycDR1PTexzTV/rhfsroxt3vdPel7r60vLx8+C0VEZF+RRZs3P1Wd5/n7gtJXuB/0t0/AjwFfCBkuwF4JGw/Gt4T9j/p7h7Srwuz1RYBi4GXgTXA4jDzrDiU8Wg4pq8yTig9h9G2v/wHdm/ckKXaiMiJLBv32fwj8FkzqyB5feWukH4XMD2kfxa4BcDdNwMPAFuA3wI3u3s8XJP5JLCS5Gy3B0Le/sqI1IbfPU5DzdHRKGpYHv3Wv/Lg1/4529UQkRNQ4cBZRs7dnwaeDts7SM4k65mnGbi2j+O/BnwtTfrjwONp0tOWEaXaqkOsvusHbH7mCT7ytW+PZtEiIjlPKwhkSCKenPzW3FCf5ZqkoXkCIpJlCjaZpi92EZFeFGwyJZdXWM7hqonIiUHB5kSg3paIZJmCTc4bQaRQj0ZEcoSCjYiIRE7BJsMyv0TMyLsnrsdCi0iWKdhkSE4ueqkYIyI5QsHmBGC5PFNORE4ICjYnAA2jiUi2KdjkqaP7K4m3tw+cUUQkByjY5KGGmqP85DMf56mf3pntqoiIDIqCTaZlfMiq9/k61l+r3PrasM8hIjKaFGwyJQsX4Qe6FqMndYpIrlCwyXm9g9jQZ5dpNpqIZJeCzQlBPRwRyS4FGxERiZyCTYbplhYRkd4UbDIkKzfpDzKyKQCKSLYp2OS8dJFikJFNUUZEcoSCzQlAS6OJSLYp2OS8TDxiIAPVEBEZAQWbjNM3u4hITwo2GRPNWNXx+lqef+BneCLRa5/Cmojki8JsV2DsiOar/8Vf3gfAvLecxclvPyeZONS4pnE0Ecky9WzyhCfiQz9GQUZEckRkwcbMxpnZy2b2qpltNrMvh/RFZvaSmW03s/vNrDikl4T3FWH/wpRz3RrSt5nZlSnpy0JahZndkpKetoxo5fCUL01HE5Esi7Jn0wJc5u5nA+cAy8zsIuAbwHfcfTFQA9wY8t8I1Lj7acB3Qj7MbAlwHfBWYBnwAzMrMLMC4PvAVcAS4MMhL/2UEblR7U0MtqwR1Em9IxHJhMiCjSc1hLdF4ceBy4AHQ/oK4JqwvTy8J+y/3JLLGy8H7nP3FnffCVQAF4SfCnff4e6twH3A8nBMX2VEZugrMedHWSIimTCoYGNmnzKzMku6y8zWm9kVgziuwMw2AFXAKuBN4Ji7dzzPuBKYG7bnAnsBwv5aYHpqeo9j+kqf3k8ZOWPj6pUcqNg2rGPV2xCRfDPY2Wh/7e7fDddLyoGPAT8BftffQe4eB84xsynAw8CZ6bKF13R/rns/6ekCZX/5ezGzm4CbABYsWJAuS2RW3fl/Iz3/Mz+7m7WPPQToIWoikn2DHUbr+AK/GviJu7/KEK6Iu/sx4GngImCKmXUEuXnA/rBdCcwHCPsnA0dT03sc01f64X7K6FmvO919qbsvLS8vH2xzsm4ww2gdgUZEJBcMNtisM7PfkQw2K81sEtD7LsMUZlYeejSYWSnwbmAr8BTwgZDtBuCRsP1oeE/Y/6Qnx4seBa4Ls9UWAYuBl4E1wOIw86yY5CSCR8MxfZURvVHtRAyuMMvlmXIickIY7DDajSRnlO1w9yYzm0ZyKK0/c4AVYdZYDHjA3X9lZluA+8zsq8ArwF0h/13Af5lZBckezXUA7r7ZzB4AtgDtwM1heA4z+ySwEigA7nb3zeFc/9hHGdEZ1e/zoRXW1tLMI9/8ap/7n/6vu9j+0vP8z+/dPdKKiYikNdhg8w5gg7s3mtlfAucB3+3vAHffCJybJn0HyZlkPdObgWv7ONfXgK+lSX8ceHywZZzIKta82Oe+db96uO8D3XWfjoiM2GCH0e4AmszsbODzwG7gnshqJSIiY8pgg017uBayHPiuu38XmBRdtUREZCwZ7DBavZndCnwUeGe4DlMUXbVkMHS/jYjki8H2bD5EcvmZv3b3gyRvkvw/kdUqj43GPS26hCIi+WZQwSYEmHuByWb2p0Czu+uaTTeKACIifRnscjUfJHlvy7XAB4GXzOwD/R8lHX7+xc/z3ev/fETnyNaAmVYfEJFMGOw1m38C/sjdqyB5wybwBF2LXUo/9m/bEs2JFQdEJE8M9ppNrCPQBEeGcKxkQLdBOl20EZE8M9iezW/NbCXw8/D+Q6S5mVIYnUcwaxaaiOSZQQUbd/+cmf05cAnJP7LvdPd+bjs/8UT9jBmFFxHJZ4Pt2eDuvwR+GWFdZLA0jCYieabfYGNm9aT/o9pIPoyzLJJaSS/pH9IzGkN20RchImNfv8HG3bUkTQ7SIwNEJN9oRlmmRXTxXh0MEclnCjYiIhI5BZsMyfSimD1nt2ngTETymYJNjhpU8NL9NiKSJxRs8kS3sDKKU5/1GAMRyQQFmwzTV7OISG8KNnlC12xEJJ8p2GTM6PdpNMIlIvlCwWYUNdXVZuQ8Wq1GRPKNgs0ouu+Lnxv2samdmHQ9mrrD1cM+t4hI1BRsMq2fsa2aA/sjK/axb/9rZOcWERkpBZs8kTpylm4Yra2lJaKSdWFIREZOwSavKRCISH6ILNiY2Xwze8rMtprZZjP7VEifZmarzGx7eJ0a0s3MbjezCjPbaGbnpZzrhpB/u5ndkJJ+vpltCsfcbmGNl77KiFTE3/vdTx/NDIH9b2xl/W8ei+TcInJii7Jn0w78vbufCVwE3GxmS4BbgNXuvhhYHd4DXAUsDj83AXdAMnAAtwEXAhcAt6UEjztC3o7jloX0vsoYI6KJbD//35/jqZ/+ZyTnFpETW2TBxt0PuPv6sF0PbAXmAsuBFSHbCuCasL0cuMeTXgSmmNkc4EpglbsfdfcaYBWwLOwrc/cXPLmmyj09zpWujJyw9dmnhnzMQH2ZqB9LLSIyEqNyzcbMFgLnAi8Bs9z9ACQDEjAzZJsL7E05rDKk9ZdemSadfsqIXMdaYi1NjXz7uvex85W13fYfrHiDx7/3rdGqjohITog82JjZROCXwKfdva6/rGnSfBjpQ6nbTWa21szWVldn9j6Vw3t2457gxYfu75be2tw82Lp1e5+uYaOxSKZWKRCRTIg02JhZEclAc6+7PxSSD4UhMMJrVUivBOanHD4P2D9A+rw06f2V0Y273+nuS919aXl5+fAa2XWuQeUb7GjXkAOJhtFEJIdFORvNgLuAre7+7ZRdjwIdM8puAB5JSb8+zEq7CKgNQ2ArgSvMbGqYGHAFsDLsqzezi0JZ1/c4V7oy8lZqKFFvQ0TyTWGE574E+Ciwycw2hLQvAF8HHjCzG4E9wLVh3+PA1UAF0AR8DMDdj5rZvwBrQr6vuPvRsP0J4KdAKfCb8EM/ZYiISBZEFmzc/Tn6nkR1eZr8Dtzcx7nuBu5Ok74WOCtN+pF0ZWSD97zaMszhroE6MxpEE5FcphUE8pmG00QkTyjYZEz6b37r0efo+X6wuh01mhdtdIFIRDJAwWas0Gw0EclhCjZ5Qv0LEclnCjYZNuD9MRnsgHSbfKCejYjkMAUbERGJnIJNhkR9Hb3bTZ0aVBORPKNgE7HRu88mmmE0BTYRyQQFGxERiZyCTab1GE+LqseRriwRkVylYDPKBht8ej5iYMCbOjUZTURymIJNpmS4l9FzCrX6MCKSzxRsIqYL7CIiCjYiIjIKFGwyrGc/ptc1mmFOfU571GhMENAkBBHJAAWbUTbcVWVSv/LTzg/QcjUiksMUbDIk+9dmFGxEJHcp2IiISOQUbEZd5q7ZZLsvJSIyWAo2eWLAtdE0iiYiOUzBJtN63YwZRf9jNB8LPXpFicjYpWAjIiKRU7DJlD7uR+l5n01kU5Q1jiYiOUzBZrQNMyZk7aZOEZEMULDJE91v6ow2yLy66vFIzy8iJx4Fm0zL0ASBoQ63ZfK5OU/8+AcZO5eICEQYbMzsbjOrMrPXUtKmmdkqM9seXqeGdDOz282swsw2mtl5KcfcEPJvN7MbUtLPN7NN4ZjbLXw791VGrhhsUIi69zJY2V8ZQUTGgih7Nj8FlvVIuwVY7e6LgdXhPcBVwOLwcxNwByQDB3AbcCFwAXBbSvC4I+TtOG7ZAGVEqq/YcOCN1zNy/gFDlOYHiEgOiyzYuPvvgaM9kpcDK8L2CuCalPR7POlFYIqZzQGuBFa5+1F3rwFWAcvCvjJ3f8GTXYB7epwrXRl54VjzMR5787Fe6eliWa70fkREBjLa12xmufsBgPA6M6TPBfam5KsMaf2lV6ZJ76+MvPD533+eLzz3BRpa6/vOlIUY89rh16htqR39gkVkTMiVCQJ9Lf011PShFWp2k5mtNbO11dXVQz08rXTXOBLFJbRPnNxRaL/HVzVVARD3xNAKjvg+mw//+sN8bOXHIi1DRMau0Q42h8IQGOG1KqRXAvNT8s0D9g+QPi9Nen9l9OLud7r7UndfWl5ePuxGDaTx1LdxfP5iQp2GdY6+jnr437/C1uefGWbNhmZ7zfZRKUdExp7RDjaPAh0zym4AHklJvz7MSrsIqA1DYCuBK8xsapgYcAWwMuyrN7OLwiy063ucK10ZEYt2bKuvs+9Y9zKP3/5/IixY14VEZOQKozqxmf0cuBSYYWaVJGeVfR14wMxuBPYA14bsjwNXAxVAE/AxAHc/amb/AqwJ+b7i7h2TDj5BcsZbKfCb8EM/ZeS0qqYqPv7ExznUdCiZoNllIjKGRBZs3P3Dfey6PE1eB27u4zx3A3enSV8LnJUm/Ui6MnJBf32Eh7Y/1H2Yqo/M22u2U5aI7GMTEYlErkwQGBNiJHjX1Negbn/a/e2Tp/d57EA3e378iY+z7tA63v/o+1mx+adDPl5EJJsUbDLolElHeeukSnj8c2n3e0HfPZKBJg4Y8PvK3wOw7ei2YddxOHQ/j4iMlIJNhrj7iPoWQ+mZdEyvTg0C8fa2EZQ+uPJERIZLwSajwpdyX70UG8fWF9LfGDmUKdHpehr1tT0Xa8gc9WxEZKQUbDLI0mylKih5G5ufrQWb0GufN7dhKfdxHmw82Gc56XoaHTeDZprijIhkgoJNFPropRgFnVs91X3z11y2vuvG0srGyl55+jWEoLCnbs8QT62IIyIjo2CTAV/+8pd54ZU1A/ZsBjK/anzXGcL3e3zchM6lbjqu64x0WOu9D7+XlnjLoPMr2IjISCnYjJC74+6sXbuxK0IM8vrLaZMOM7Gw60u/eeY8zjl8DsXxYoxk4GladGbnUjeJphbm1c9jUt3UjsKHXe/2RPvgMyvWiMgI6e7AEUrtZXSEmMqG/Tyz9+mBjmT5vK0cbpvAXQfeRWFjLW3TZ3NqPUxvnk4hU4AjnbljCcO/9ywXnnlhSDnQ7WzD6Ut99unPcsrkUwbMp56NiIyUgs0IpRvS2nh4E3fVHuW9zO6WHi/sPXT1vaKbYAGMq6zoTJvSNiV57pR8y18tY9bEI2zITLUBWLV7FQB/xckZPKuISG8aRhuh+9fdnzbd0nQGmicc7trfY58XlfRbzoHFf8yfzN/X/ZhB1XCkXD0bERkxBZsR2raj627+bdMv4Cku4urGJooHeB6N4VQxrfN9vLT3dOie136q6LHcTUqvqiAe3XI1us9GREZKwWaESnbN6NyuGzeDZ3gHAH/Zkv4mS8cxnPkTanmU93Smt5dN65W3fdLUbu+bGde5nSgs7tbfGNdW0Lm9d8umbiVamp6Ju/Puyndz5d4r09YzNd8jFaP0lAYRGbN0zWaErCX9P+G0RJx0t2W6tXP57ArOnlLB3Szp46zJh5E2z+1+8f7/0RUYGhe/HTt6EGvo/fjoB758a+f2BxdsYv6EWrbUzmRrywJ2HhnHXx2rw1vqmdw2uTNfQcEM3nfSH3jp8Gz2Hy/rTL/45xfTVpS5ns3KH79GS2Mb7/vUuRk7p4jkPvVsouJ9XOkwp2r8W3icS9nD3LSHpuuJpNNaMj5tupvROm0WDsyfkFwe51jp29g0851Mnj2Rv685xu6Hvt7tmKKy61nf8hneMzv5mIOC4rcBxcw9XDqouvTlcGUDjce6JkZUrK1i79aaEZ1TRPKPgs0IxUi/AOYr7dfRcOZSPnvms732PV+8mJcZ+V/2nuZ+nslFx2HGDFpmzad57qkAbGw/l2fiyUf8NBdPAuDBnV1DdG2Tp9M0vpKDbYtJAFY4l6IJ76Fo/GVc+srIHpd9/1dfZsWtz4/oHCKS/xRsRqiY42nTW5kIwJNc3C09kzO73AwvKKBp/mIS4fEF1y6sZFFy5jTtZcmA8lDhpbSUVgPQVFTW6zzNJy2isWwHh2c/x/qCc7CO0dXYeMA4+ehbRzT1bTDzCxIJ54effJrNz+4bOLOI5B0FmxGyRP/fpM9yYY+Ugb95BzuMlvAErVPKiU+cTNu0WRjOzw7fQUXzJX0ec7y4jHg/t4C+XnB6Sh2NgpKlXLXtJhbWvI3i9lJe+d2eSGanxdsSxNsTPPeL7QNnFpG8o2AzUuluqBlh/sQgP5ZxheXEwhRrN+PSWTtoLzjO8fHpnxTa4V7+R5/7jsWmkhpsLJYcdpvQOpl37riWPzxUQeW23tdcEok24kNYb62nzgCmWdYiY5KCzYj1/nb878T7+8wdL2gexDkHd89MU3ELzbMWJN/ExvNC6/epKV8Dsa57fNLd7bNj0CsGdNWjtG0ii4+cnzxne+82v7zmfTz9TPfZdS1NXdezEvEEiX56gbkea9rbG3l92220tzem3V9Xtwn3+CjXSiR/KNiMUL239kp7I9b3l3nttE197huJ9rJJOL2/7J6q/cSQz9VxXSm5ynQyXJ277z195m9pOUTt0f3sffbvePbpP+tM//UPNnZu33Hz0/zyG2vTHp9IOMfrW8N2C/F4+utgAC8/toNXV+/tltbWVsPqJ0/lwIGHOtOaWw7S0PBGn+cZqj1772bfvp/xzO/fTmvrkW77Dhz8f6xZew07dt6esfJExhoFmxGK8Mb9IfEC4/Ds3rO+np84OU3uAc8GQNGEOIPpa2zZ+o/sXPklGg+8nf2bFgHJL/tDO7vf2Fq1u+ueoMOVXdtP/GQL937xxc6ia469RMWb38TTrMKw5te7ul3XcXfeeONfAKjc97PO9Oefv4SXXr5qwLoPWkqvZc/en3Rut7XVsGXL3wNQXx/NHxIiY4GCzRiXKBjGdZQwphVvPZlJ83vfNLpv//20tHQ9GTSRaCXe3BXUnnjidH7xnR+TiBf0OrbD/V9dg7vTeryd7WsOdRWN8eqrN7J79x3U1b3a5/EHDz7KsWNr2bLlVip3PR2q3btn5+6sXfdBDh56jJpja/pu8wBSZxG2t8CxQ00A3Xph6YKjiCQp2Eg3i9u3U1ByVuf70mnJa0wF3rVSQnX1Sra+/oW0x7fUzuf4kVOo23Vx2v2pnr3vDX70md/3k6PvbuPmLZ9h3foPsXGlU/HYN2lrnMbh7Wfw/IPbu82We+T//paXfvRxNm/+NOvXX0dDY+/Zbk1NO1n95KlUVz/R1ca99dTXdj0t9eiRrnq+eH8Z9972Yq86JhK9h1RFJEnL1Ug37lCYEmwS7b1Xo26qOgP3ZM/mxUfeZP3v/qpzX33l+bQ2zBxUWZueSXNPTaKQur3nUzyxioaG11m77s+ZN+W/qdycYOmys3tlr99/DgA7f/dFEm0TgL1c8Gddy/zs29K9/lW7qyk8eSHjJhR1ptXWJh/c8OqGz1BUUsrFFz7LA19bQ6yoiatuPsDkKUuoq++6/tR46DQAPOHdFkttbBz6NaLnfrGd+UumcfJbpw+cWSSPKdhIN8UF3Yeijr35rl55jm5bxqFTvsKDL9/IofUfoeevUcux+SOqw/4XPg7A/NMfBOCJO5MzwF5//sXOPAfX/QVtTdNItCWX00kGmqQ7P/UMZ3wghsV6D2v95vZmps97hff/w3kUlRTQ0tTOr/59Eif98Xx2rfoi05c8RvM5x8I5x/Pr/6gHXuItH+xdz4Q7pAydzZr1p932Nze2YTGjpLTv/2avrt7Lq6v3cvMPL+vvn0Qk7ynYjFBBeynxwr5nT+WbI22D65W8+ZsvRlwTWPfgmYybMjHtvnRBMFXdngsYN21n97S9SwE4UtnAjz79eybM2gwtZ9N6PMauVcn2HNnyZ9z3pc29zrfvhf9Jw/6zWfjur3WmJeLO4coGXn/gRyy68jY2v3YmU0vqqK0+zvH6Np69P9nTufmHl3Ub2ntzfTXx9gSTZ3Zfd66tJU5rczsTJvf/bKOejje08sh3XuGSaxdz0qlTKCga3dHxxtoWag42Me+MqQNnzjB3p7bqOFNmpV8nUHKHjdVnlZjZMuC7QAHwY3f/en/5ly5d6mvXpp+a25/vfXxV2llgPY1rmsWE+lM5MusPQy5jNI1rmsOkusXZrkbGzbnwxxx46W8yes7x0xppOprmOUQ9TC4vpbY6+QfJmZfMYevzBwY4AqbPnci5VywgEXc2PrWXd1xzKhtW72XvlqNc85lzmTyzlBW3/oHJM0uprer6Y2fOqZN5/+eS90M1N7YRKzCOVDYwdc4ENj65lzW/3sXk8lIKi2OUzSjl6k+8HYB1v93F5PLxbHq6kraWOO/66Ftoa4kz59TJbHvxIKedP5NYYQwzsDB0uPqnW9i3/Rj1R5LX9f72B+/CYkZ7W5y25jjFpYUUFCYD344N1bS1xDnjwtlU762nbPo4SsYX0ZdEPMFd//Ac7/zgYt7yjjm99h/aWUdxaQGHdtaxesVWln/mXGbMm0hhcYz21gRtLXEmTRuX5szDV3f4OAd31HL6BbMHztxDPJ5g+8uHOOPC2WBQd7iZyeVdf2y4O4d21jH7lO6zR5sb20jEnfFlxbg7nnBiBQP/MdF4rIXNz+7jj967CItFO2XWzNa5+9IB843FYGNmBcAbwHuASmAN8GF339LXMcMNNj//wiepb3g3zYX1NBfVU9Q+nqLW6Rwre51Jx06jqH1Cyo2VjmEkYi0cmbWOadXn0Tix1PldAAAL7UlEQVRxNy2lR8BjYOlnMxW1TKa0aQ5NE/bRXpycHTauqZxYfBylx2fRXthI04S9tJU0YPEivCB5M+XE+pNpmLQbgPEN82iaWMn4aoOSBTSVJdMn1C2ksWxXZ1nTDy4l5kWYFeEkZ5D0/A2xlNd0eTzltWP/UGhO1+iZe8ZU9qVZEaI/b33nSbS3Jtj2UrqHaHR3yQdOY/vaKqp21QEwYXIxjbXJiRTnX3UyNQea2LGhujPvuAlFJBLOU//1euc53nLxHNqOt/PmK9VDqmf5gklU76mnqKSAOadNYc/m5P1Rl37kDMaXFVN3uJna6uMk4gk2P7ufi645hSP7Gjnz4jkUFMawmDFpWgkrbu3+B+LpF8xixyvVtLcleM+NS5h7+lRKxhfS0tRO9Z7k/8/VP93K7FMns2DJNJZcchJrfr2Tdb/d3e08Z148h61/OMCp55Z3tm3JJXO4+M9P47kHK3j9D11/lHz0q+9g5Y9eo2p3PZd+5AxqDjXx+gsHmH7SRJb9r7PwBNRWH2fq7PGsXrGVXRu7ngp8/lUn8/Z3zWfT05UkEk5DTTML3zaDowcaKZ8/iRnzJlI2Y/iru5/oweYdwJfc/crw/lYAd/+3vo4ZTrDxRIJX/u4nzJx0+rDrmsBJkKCQ5DRhx7lr3JOc3X4yf9R+GlVWywwvIxa+4ptoodnamObph5cA2olzMHaMeYnptNIOQHGPEdPDVsfBWC1nxefTQhsFxHCgiL6nK4+GhDuP1bZntQ4iJ5ob/u1iJk4dXk9wsMFmrF6zmQuk3mZeCb1WxMTMbgJuAliwYMGQC7FYjGeLKzjtUAVHxscoScQoa4vRXBgjBsTC3/SGEbOC5DNuPIHjxKyAOHFibp15OvoEF1AI7GMjlUCMAyTACsDjlLa201pYwB4zYhYjQYICd8yNRMxIrgiTfPhaTaKVyY1tNJcUM741Ts3EEuIGJe0JLOG0FRey3nZQbEXMKTyJ6qYdtBYWYjaeRKKeAjPcipleX0dT6SSaCkvAG/CCJiYcTzC+pYCm0llYQTGNrW1MShRQ6gmKJ8ZJFE6h3Yooih+jINZM0ZEG6qedRklpjLLSFuKJOC1eRkmsGUvU0bL3KLEZM5h+5eW8c+oaps2exBuv/pZ5cz7DgrPKOPBGnKrKN2htibPwzCUkSp5j38a5xIpamHd6OcfrW2iqc2YuLKCpLsaeTe20Hj9O4cQ9zFt0MU/cvYMzLq3ipEWnsOX5SmYumEnh+P3U7J3B/LOMQ9vLsHFbKbQFxBOHKS4tov7YIdzqaak5iylzWjjwOkydd5zG+hqam47gx9+G00pD9RRmLKpn3lumMHHSKbz+wgHmnj6VvVuP0nishZamdqbOmUBRcazbja0AxeMKaG1OTso4+7L5bH3hAAWFxvH6NopKCmhrSe6bOLWEkxZPoWp3PbXVx5Mz4YLZp5RRtaueRMKZNG0c9UebiRUYZ15yEm3N7ZRMKGLTU5XMmD+Rw5UNlE4qpq25HffkAqjz3jKVytdrmHvGVAqLYux+rfsKCf2ZPncCR/YlJ3DECoxE3Jl9ymQS8USvtg5k3MQimhu6P7KjbMY46g4PZomnLqVlxRyv65qGPnXOBGoONGIx6/bv1tOsRWUc2lnXLa2gMEa8feC+dumkZN3T/e1+0uIp7N9+bFB1j8WSy/Cm1rPjMx2MwnC9rr2te53LF0zC3Tm8twFI9+8a/d3pY7Vncy1wpbv/TXj/UeACd/+7vo4Z7jCaiMiJbLA9m7F6U2clkDr/dh7Q/1LIIiISmbEabNYAi81skZkVA9cBj2a5TiIiJ6wxec3G3dvN7JPASpJTn+929943T4iIyKgYk8EGwN0fBx7Pdj1ERGTsDqOJiEgOUbAREZHIKdiIiEjkFGxERCRyY/KmzuEws2pg94AZ05sBHB4wV34YK20ZK+0AtSVXjZW2jLQdJ7t7+UCZFGwywMzWDuYO2nwwVtoyVtoBakuuGittGa12aBhNREQip2AjIiKRU7DJjDuzXYEMGittGSvtALUlV42VtoxKO3TNRkREIqeejYiIRE7BZoTMbJmZbTOzCjO7Jdv1GYiZ7TKzTWa2wczWhrRpZrbKzLaH16kh3czs9tC2jWZ2XpbrfreZVZnZaylpQ667md0Q8m83sxtyqC1fMrN94bPZYGZXp+y7NbRlm5ldmZKe1d8/M5tvZk+Z2VYz22xmnwrpefe59NOWfPxcxpnZy2b2amjLl0P6IjN7Kfwb3x9WxcfMSsL7irB/4UBtHDJ3188wf0iuKP0mcApQDLwKLMl2vQao8y5gRo+0fwduCdu3AN8I21cDvyH5GL+LgJeyXPc/Ac4DXhtu3YFpwI7wOjVsT82RtnwJ+Ic0eZeE360SYFH4nSvIhd8/YA5wXtieBLwR6pt3n0s/bcnHz8WAiWG7CHgp/Hs/AFwX0n8IfCJs/y3ww7B9HXB/f20cTp3UsxmZC4AKd9/h7q3AfcDyLNdpOJYDK8L2CuCalPR7POlFYIqZzclGBQHc/ffA0R7JQ637lcAqdz/q7jXAKmBZ9LXvro+29GU5cJ+7t7j7TqCC5O9e1n//3P2Au68P2/XAVpKPZc+7z6WftvQllz8Xd/eG8LYo/DhwGfBgSO/5uXR8Xg8Cl5uZ0Xcbh0zBZmTmAntT3lfS/y9nLnDgd2a2zsxuCmmz3P0AJP/DATNDej60b6h1z/U2fTIML93dMfREnrQlDL2cS/Kv6Lz+XHq0BfLwczGzAjPbAFSRDN5vAsfcvT1NvTrrHPbXAtPJYFsUbEbG0qTl+vS+S9z9POAq4GYz+5N+8uZj+zr0VfdcbtMdwKnAOcAB4FshPefbYmYTgV8Cn3b3uv6ypknL9bbk5efi7nF3PweYR7I3cma6bOE18rYo2IxMJTA/5f08YH+W6jIo7r4/vFYBD5P8JTzUMTwWXqtC9nxo31DrnrNtcvdD4QsiAfyIruGKnG6LmRWR/HK+190fCsl5+bmka0u+fi4d3P0Y8DTJazZTzKzjoZmp9eqsc9g/meQwb8baomAzMmuAxWGGRzHJC2uPZrlOfTKzCWY2qWMbuAJ4jWSdO2b/3AA8ErYfBa4PM4guAmo7hkZyyFDrvhK4wsymhuGQK0Ja1vW4HvY/SH42kGzLdWHG0CJgMfAyOfD7F8b17wK2uvu3U3bl3efSV1vy9HMpN7MpYbsUeDfJa1BPAR8I2Xp+Lh2f1weAJz05Q6CvNg7daM6QGIs/JGfXvEFyPPSfsl2fAep6CsmZJa8CmzvqS3JsdjWwPbxOC+kGfD+0bROwNMv1/znJYYw2kn9x3TicugN/TfJCZwXwsRxqy3+Fum4M/8nnpOT/p9CWbcBVufL7B/wxyWGVjcCG8HN1Pn4u/bQlHz+XtwOvhDq/BnwxpJ9CMlhUAL8ASkL6uPC+Iuw/ZaA2DvVHKwiIiEjkNIwmIiKRU7AREZHIKdiIiEjkFGxERCRyCjYiIhI5BRuRMcDMLjWzX2W7HiJ9UbAREZHIKdiIjCIz+8vwnJENZvafYbHEBjP7lpmtN7PVZlYe8p5jZi+GBSAftq5nwpxmZk+EZ5WsN7NTw+knmtmDZva6md0b7ogXyQkKNiKjxMzOBD5EcjHUc4A48BFgArDekwukPgPcFg65B/hHd387yTvYO9LvBb7v7mcDF5NciQCSqxR/muQzSE4BLom8USKDVDhwFhHJkMuB84E1odNRSnKBygRwf8jzM+AhM5sMTHH3Z0L6CuAXYW27ue7+MIC7NwOE873s7pXh/QZgIfBc9M0SGZiCjcjoMWCFu9/aLdHsf/fI198aUv0NjbWkbMfR/2/JIRpGExk9q4EPmNlMADObZmYnk/x/2LES718Az7l7LVBjZu8M6R8FnvHk81UqzeyacI4SMxs/qq0QGQb95SMyStx9i5n9M8knpcZIrvh8M9AIvNXM1pF8QuKHwiE3AD8MwWQH8LGQ/lHgP83sK+Ec145iM0SGRas+i2SZmTW4+8Rs10MkShpGExGRyKlnIyIikVPPRkREIqdgIyIikVOwERGRyCnYiIhI5BRsREQkcgo2IiISuf8P0bpS0UGhWR8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "  for nsamps in [12,25,50]:#,150,400]:\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [ndom_norm_params,ndom_fat_params,]:#tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,\n",
    "                                        filename=\"testresults/demoT_2.csv\",\n",
    "                                      \n",
    "                                        subsample_N = nsamps)\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "MCMC, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
