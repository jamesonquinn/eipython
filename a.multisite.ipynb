{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.4283, 0.6877, 0.9501, 0.3907])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 203.91335368156433;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 167.21069049835205;\n",
      "mode_hat tensor(0.2697, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4974, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4255, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 151.25056338310242;\n",
      "mode_hat tensor(0.4696, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9166, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5056, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 152.5960443019867;\n",
      "mode_hat tensor(0.4635, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0525, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2539, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "complaint 9 dm.grad\n",
      "complaint 8 dtr.grad\n",
      "complaint 7 ddfr.grad\n",
      "complaint 6 dm.grad\n",
      "complaint 5 dtr.grad\n",
      "complaint 4 ddfr.grad\n",
      "complaint 3 dm.grad\n",
      "complaint 2 dtr.grad\n",
      "complaint 1 ddfr.grad\n",
      "yay -1040\n",
      "complaint 0 dm.grad\n",
      "complaint 0\n",
      "complaint -20\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 130.17599523067474;\n",
      "mode_hat tensor(0.5124, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1298, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1205, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "complaint -40\n",
      "yay -1340\n",
      "yay -1400\n",
      "epoch 500 loss = 141.40341913700104;\n",
      "mode_hat tensor(0.4908, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1191, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1278, requires_grad=True)\n",
      "yay -1460\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "epoch 600 loss = 180.39544904232025;\n",
      "mode_hat tensor(0.4633, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1503, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2692, requires_grad=True)\n",
      "yay -1760\n",
      "yay -1820\n",
      "yay -1880\n",
      "yay -1940\n",
      "yay -2000\n",
      "epoch 700 loss = 312.4034814834595;\n",
      "mode_hat tensor(0.4799, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1496, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4521, requires_grad=True)\n",
      "yay -2060\n",
      "yay -2120\n",
      "yay -2180\n",
      "yay -2240\n",
      "yay -2300\n",
      "epoch 800 loss = 150.38542819023132;\n",
      "mode_hat tensor(0.4870, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1185, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4955, requires_grad=True)\n",
      "yay -2360\n",
      "yay -2420\n",
      "yay -2480\n",
      "Final mean_losses: 146.007657213367\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.49282506108283997\n",
      "ltscale_hat:\n",
      "-1.1319351196289062\n",
      "mode_hat:\n",
      "0.48610225319862366\n",
      "thetapsi:\n",
      "tensor([-4.5720, -4.5643], requires_grad=True)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 155.42076015472412;\n",
      "mode_hat tensor(0.4872, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1339, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4903, requires_grad=True)\n",
      "Final mean_losses: 146.19591927219415\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.4903227388858795\n",
      "ltscale_hat:\n",
      "-1.1338855028152466\n",
      "mode_hat:\n",
      "0.4871838092803955\n",
      "thetapsi:\n",
      "tensor([-4.5720, -4.5643], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.4283, 0.6877, 0.9501, 0.3907])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 2290.806118249893;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 222.93986177444458;\n",
      "mode_hat tensor(0.2571, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5037, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4355, requires_grad=True)\n",
      "epoch 200 loss = 137.79775738716125;\n",
      "mode_hat tensor(0.2647, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9395, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5590, requires_grad=True)\n",
      "epoch 300 loss = 188.58448898792267;\n",
      "mode_hat tensor(0.2616, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1203, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2908, requires_grad=True)\n",
      "epoch 400 loss = 157.23340272903442;\n",
      "mode_hat tensor(0.2632, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2149, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0316, requires_grad=True)\n",
      "epoch 500 loss = 133.88066923618317;\n",
      "mode_hat tensor(0.2990, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2661, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2946, requires_grad=True)\n",
      "epoch 600 loss = 170.72540187835693;\n",
      "mode_hat tensor(0.3013, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3354, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4878, requires_grad=True)\n",
      "epoch 700 loss = 176.13115763664246;\n",
      "mode_hat tensor(0.3299, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3449, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6615, requires_grad=True)\n",
      "epoch 800 loss = 106.63298296928406;\n",
      "mode_hat tensor(0.3222, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3626, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8670, requires_grad=True)\n",
      "epoch 900 loss = 157.87297320365906;\n",
      "mode_hat tensor(0.3197, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3503, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9904, requires_grad=True)\n",
      "Final mean_losses: 146.5101165441678\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 0.0907,  0.3414,  0.6040,  0.0604,  0.1305,  0.5650, -0.1351,  0.3129,\n",
      "        -0.0527, -0.7478,  0.3613,  1.0240, -0.1131,  0.2376,  0.4504, -0.4048,\n",
      "         0.7176,  0.1527,  0.7022,  0.2856,  0.1848,  0.6748,  0.2176,  0.1418,\n",
      "         0.5124,  1.7242,  1.0430,  0.0217, -0.5638,  0.0757,  0.1543, -0.1276,\n",
      "         0.2641, -0.4514, -0.2213, -0.0395, -1.0298, -1.4372,  0.9838, -0.2189,\n",
      "        -0.6556,  0.3886,  0.1893, -0.0393], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-1.006461501121521\n",
      "ltscale_hat:\n",
      "-1.3711239099502563\n",
      "mode_hat:\n",
      "0.3181755542755127\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "epoch 0 loss = 191.13645470142365;\n",
      "mode_hat tensor(0.3148, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3713, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0098, requires_grad=True)\n",
      "Final mean_losses: 147.40264330731293\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 0.0873,  0.3399,  0.6029,  0.0586,  0.1302,  0.5619, -0.1343,  0.3114,\n",
      "        -0.0546, -0.7457,  0.3602,  1.0228, -0.1098,  0.2359,  0.4479, -0.4079,\n",
      "         0.7160,  0.1505,  0.7010,  0.2843,  0.1845,  0.6745,  0.2164,  0.1402,\n",
      "         0.5121,  1.7235,  1.0429,  0.0231, -0.5647,  0.0756,  0.1529, -0.1292,\n",
      "         0.2647, -0.4517, -0.2205, -0.0380, -1.0297, -1.4362,  0.9853, -0.2169,\n",
      "        -0.6549,  0.3877,  0.1879, -0.0395], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-1.0097755193710327\n",
      "ltscale_hat:\n",
      "-1.371265172958374\n",
      "mode_hat:\n",
      "0.3148178160190582\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.4283, 0.6877, 0.9501, 0.3907])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 28403.466966040432;\n",
      "epoch 100 loss = 9165.140231847763;\n",
      "epoch 200 loss = 21127.555602148175;\n",
      "epoch 300 loss = 2490.33755671978;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400 loss = 2595.158232152462;\n",
      "epoch 500 loss = 505.8039312362671;\n",
      "epoch 600 loss = 177.99281531572342;\n",
      "epoch 700 loss = -12.012946605682373;\n",
      "epoch 800 loss = -39.35949778556824;\n",
      "epoch 900 loss = -56.27802896499634;\n",
      "epoch 1000 loss = -66.0110833644867;\n",
      "epoch 1100 loss = -58.39477115869522;\n",
      "epoch 1200 loss = -64.46861934661865;\n",
      "epoch 1300 loss = -54.311669923365116;\n",
      "epoch 1400 loss = -65.90234631299973;\n",
      "epoch 1500 loss = -65.48752725124359;\n",
      "epoch 1600 loss = -62.315265864133835;\n",
      "epoch 1700 loss = -62.32133513689041;\n",
      "epoch 1800 loss = -64.40463596582413;\n",
      "epoch 1900 loss = -62.43239429593086;\n",
      "epoch 2000 loss = -65.2049572467804;\n",
      "epoch 2100 loss = -65.55862095952034;\n",
      "epoch 2200 loss = -65.27878504991531;\n",
      "epoch 2300 loss = -63.39809538424015;\n",
      "epoch 2400 loss = -63.66725440323353;\n",
      "epoch 2500 loss = -63.45386281609535;\n",
      "epoch 2600 loss = -69.81781232357025;\n",
      "epoch 2700 loss = -65.64019668102264;\n",
      "epoch 2800 loss = -63.85003635287285;\n",
      "Final mean_losses: -65.27907461614625\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 4.2488e-01, -1.2301e+00,  4.9635e-01, -1.4103e-03,  2.5706e-01,\n",
      "         4.8309e-01, -4.8141e-02,  2.7865e-02,  4.6486e-01, -2.1042e-01,\n",
      "         1.7870e-01, -1.6713e-01, -8.6062e-01,  2.7780e-01,  9.1359e-01,\n",
      "        -2.0948e-01,  1.3018e-01,  3.3098e-01, -4.8716e-01,  5.9764e-01,\n",
      "         2.5102e-02,  6.0129e-01,  1.7633e-01,  9.7414e-02,  5.8138e-01,\n",
      "         1.4047e-01,  4.7141e-02,  3.9202e-01,  1.6037e+00,  9.1145e-01,\n",
      "        -5.6514e-02, -6.7169e-01, -3.4924e-02,  3.7164e-02, -2.4820e-01,\n",
      "         1.3301e-01, -5.7242e-01, -3.1773e-01, -1.5886e-01, -1.1328e+00,\n",
      "        -1.5418e+00,  8.7904e-01, -3.2876e-01, -7.3597e-01,  2.5290e-01,\n",
      "         7.1439e-02, -1.3219e-01], requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0077, 0.2116, 1.0514, 0.0883, 0.0734, 0.0971, 0.0477, 0.0373, 0.0586,\n",
      "        0.0601, 0.0556, 0.0451, 0.0673, 0.0974, 0.1290, 0.0843, 0.1244, 0.0954,\n",
      "        0.0736, 0.0793, 0.0687, 0.1309, 0.0545, 0.0931, 0.0567, 0.1314, 0.0753,\n",
      "        0.0251, 0.0532, 0.1058, 0.1405, 0.0318, 0.1412, 0.1210, 0.0166, 0.1398,\n",
      "        0.0609, 0.0383, 0.0352, 0.0348, 0.0522, 0.0385, 0.1261, 0.1267, 0.1102,\n",
      "        0.0410, 0.0407], grad_fn=<AddBackward0>)\n",
      "epoch 0 loss = 162.32542645931244;\n",
      "Final mean_losses: -60.72698459463707\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 0.4228, -1.2312,  0.4957, -0.0038,  0.2575,  0.4826, -0.0484,  0.0292,\n",
      "         0.4627, -0.2098,  0.1779, -0.1679, -0.8625,  0.2756,  0.9133, -0.2121,\n",
      "         0.1267,  0.3303, -0.4880,  0.5975,  0.0242,  0.6006,  0.1780,  0.0953,\n",
      "         0.5790,  0.1389,  0.0461,  0.3932,  1.6033,  0.9106, -0.0563, -0.6708,\n",
      "        -0.0335,  0.0373, -0.2484,  0.1295, -0.5727, -0.3174, -0.1599, -1.1342,\n",
      "        -1.5411,  0.8776, -0.3262, -0.7370,  0.2530,  0.0716, -0.1307],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0077, 0.2120, 1.0500, 0.0882, 0.0736, 0.0973, 0.0478, 0.0374, 0.0587,\n",
      "        0.0601, 0.0556, 0.0451, 0.0673, 0.0973, 0.1289, 0.0843, 0.1241, 0.0955,\n",
      "        0.0738, 0.0794, 0.0688, 0.1306, 0.0546, 0.0930, 0.0567, 0.1313, 0.0751,\n",
      "        0.0251, 0.0533, 0.1058, 0.1404, 0.0319, 0.1413, 0.1209, 0.0166, 0.1396,\n",
      "        0.0611, 0.0382, 0.0352, 0.0348, 0.0522, 0.0386, 0.1267, 0.1268, 0.1099,\n",
      "        0.0411, 0.0408], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 0.6921,  0.3034, -0.3755,  0.5891])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 198.27561736106873;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 199.6804839372635;\n",
      "mode_hat tensor(0.1662, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4837, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4765, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 171.7639274597168;\n",
      "mode_hat tensor(0.4216, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8997, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7430, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 153.74564838409424;\n",
      "mode_hat tensor(0.5016, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0049, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5611, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 129.91384041309357;\n",
      "mode_hat tensor(0.4855, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0591, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4361, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 162.51173412799835;\n",
      "mode_hat tensor(0.4975, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0530, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2452, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 162.16651940345764;\n",
      "mode_hat tensor(0.5013, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0535, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1578, requires_grad=True)\n",
      "yay -1820\n",
      "yay -1880\n",
      "yay -1940\n",
      "yay -2000\n",
      "yay -2060\n",
      "epoch 700 loss = 125.63964235782623;\n",
      "mode_hat tensor(0.4700, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0080, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1095, requires_grad=True)\n",
      "yay -2120\n",
      "yay -2180\n",
      "yay -2240\n",
      "yay -2300\n",
      "yay -2360\n",
      "epoch 800 loss = 134.2823269367218;\n",
      "mode_hat tensor(0.4846, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0817, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1387, requires_grad=True)\n",
      "yay -2420\n",
      "yay -2480\n",
      "yay -2540\n",
      "yay -2600\n",
      "yay -2660\n",
      "epoch 900 loss = 131.99954533576965;\n",
      "mode_hat tensor(0.5107, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0403, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0866, requires_grad=True)\n",
      "yay -2720\n",
      "Final mean_losses: 148.7328941100927\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.10666941106319427\n",
      "ltscale_hat:\n",
      "-1.059895396232605\n",
      "mode_hat:\n",
      "0.5329151749610901\n",
      "thetapsi:\n",
      "tensor([-4.5867, -4.5886], requires_grad=True)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 158.00781512260437;\n",
      "mode_hat tensor(0.5312, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0639, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1060, requires_grad=True)\n",
      "Final mean_losses: 148.91839253034294\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.10602962970733643\n",
      "ltscale_hat:\n",
      "-1.0639495849609375\n",
      "mode_hat:\n",
      "0.5311934351921082\n",
      "thetapsi:\n",
      "tensor([-4.5867, -4.5886], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 0.6921,  0.3034, -0.3755,  0.5891])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 2681.373232126236;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "epoch 100 loss = 135.52661311626434;\n",
      "mode_hat tensor(0.2366, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5049, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4779, requires_grad=True)\n",
      "epoch 200 loss = 115.31268048286438;\n",
      "mode_hat tensor(0.2368, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9104, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7084, requires_grad=True)\n",
      "epoch 300 loss = 188.8462736606598;\n",
      "mode_hat tensor(0.2510, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0230, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5130, requires_grad=True)\n",
      "epoch 400 loss = 159.49798572063446;\n",
      "mode_hat tensor(0.2463, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0576, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3323, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500 loss = 150.5390247106552;\n",
      "mode_hat tensor(0.2467, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1444, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1939, requires_grad=True)\n",
      "epoch 600 loss = 134.82722067832947;\n",
      "mode_hat tensor(0.2522, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1320, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1130, requires_grad=True)\n",
      "epoch 700 loss = 144.65545761585236;\n",
      "mode_hat tensor(0.2297, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1163, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0611, requires_grad=True)\n",
      "epoch 800 loss = 175.66150772571564;\n",
      "mode_hat tensor(0.2421, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1204, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0738, requires_grad=True)\n",
      "Final mean_losses: 151.97413907914253\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 0.4178,  0.0670, -0.5796,  0.3569,  0.3146,  0.9684, -0.2442,  0.4166,\n",
      "        -0.2867,  0.4546,  1.0485, -0.3426, -0.0283, -0.3147,  1.8696, -0.0318,\n",
      "        -1.0519,  0.5247,  0.8318,  0.8973,  0.1422, -0.0072,  0.1917, -0.5690,\n",
      "         0.0428,  0.6455,  0.4244, -0.1183, -0.5529,  0.5469,  0.6526,  0.3077,\n",
      "        -0.4641,  0.0279,  1.0679,  0.6060,  0.3916,  0.0866,  0.4679,  0.1977,\n",
      "         0.4658,  0.3499, -0.4965,  0.5192], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.007998389191925526\n",
      "ltscale_hat:\n",
      "-1.0689746141433716\n",
      "mode_hat:\n",
      "0.24886876344680786\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "epoch 0 loss = 187.64498376846313;\n",
      "mode_hat tensor(0.2459, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0668, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0085, requires_grad=True)\n",
      "Final mean_losses: 152.68755597292895\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 0.4160,  0.0654, -0.5788,  0.3564,  0.3133,  0.9691, -0.2455,  0.4166,\n",
      "        -0.2884,  0.4527,  1.0480, -0.3415, -0.0289, -0.3141,  1.8697, -0.0334,\n",
      "        -1.0529,  0.5202,  0.8302,  0.8961,  0.1400, -0.0068,  0.1893, -0.5684,\n",
      "         0.0439,  0.6451,  0.4229, -0.1195, -0.5520,  0.5436,  0.6507,  0.3050,\n",
      "        -0.4632,  0.0240,  1.0683,  0.6049,  0.3910,  0.0839,  0.4673,  0.1982,\n",
      "         0.4636,  0.3486, -0.4949,  0.5213], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.008522075600922108\n",
      "ltscale_hat:\n",
      "-1.0667998790740967\n",
      "mode_hat:\n",
      "0.2459295243024826\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 0.6921,  0.3034, -0.3755,  0.5891])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 7256.800517630763;\n",
      "epoch 100 loss = 15406.380397319794;\n",
      "epoch 200 loss = 9272.993832349777;\n",
      "epoch 300 loss = 12074.855974853039;\n",
      "epoch 400 loss = 1133.7471714615822;\n",
      "epoch 500 loss = 460.79654121398926;\n",
      "epoch 600 loss = 215.79480217769742;\n",
      "epoch 700 loss = 578.7954403162003;\n",
      "epoch 800 loss = -25.384801924228668;\n",
      "epoch 900 loss = -56.089765310287476;\n",
      "epoch 1000 loss = -49.446770787239075;\n",
      "epoch 1100 loss = -46.416515588760376;\n",
      "epoch 1200 loss = -65.60552525520325;\n",
      "epoch 1300 loss = -67.35355561971664;\n",
      "epoch 1400 loss = -58.265612840652466;\n",
      "epoch 1500 loss = -64.50636798143387;\n",
      "epoch 1600 loss = -64.75916612148285;\n",
      "epoch 1700 loss = -66.29361176490784;\n",
      "epoch 1800 loss = -64.13775864243507;\n",
      "epoch 1900 loss = -64.6900863647461;\n",
      "epoch 2000 loss = -67.79180508852005;\n",
      "epoch 2100 loss = -65.66776943206787;\n",
      "epoch 2200 loss = -67.22509805765003;\n",
      "Final mean_losses: -64.63237428754293\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 0.3629, -1.0703,  1.3969,  0.3165, -0.0445, -0.6990,  0.2254,  0.2077,\n",
      "         0.8580, -0.3425,  0.2958, -0.4348,  0.3363,  0.9391, -0.4795, -0.1517,\n",
      "        -0.4359,  1.7395, -0.1238, -1.1355,  0.4490,  0.6951,  0.7701,  0.0441,\n",
      "        -0.1182,  0.1284, -0.6771, -0.0538,  0.5527,  0.3233, -0.1965, -0.6415,\n",
      "         0.4503,  0.5556,  0.2070, -0.5791, -0.0969,  0.9267,  0.5262,  0.2609,\n",
      "        -0.0054,  0.3597,  0.0913,  0.3803,  0.2344, -0.6441,  0.4226],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0072, 0.1898, 1.1270, 0.0879, 0.0716, 0.0976, 0.0475, 0.0388, 0.0518,\n",
      "        0.0644, 0.0573, 0.0485, 0.0675, 0.0984, 0.1141, 0.0907, 0.1255, 0.1088,\n",
      "        0.0746, 0.0826, 0.0756, 0.1193, 0.0565, 0.0925, 0.0576, 0.1318, 0.0762,\n",
      "        0.0268, 0.0528, 0.1005, 0.1450, 0.0335, 0.1445, 0.1090, 0.0176, 0.1323,\n",
      "        0.0482, 0.0390, 0.0340, 0.0348, 0.0501, 0.0402, 0.1292, 0.1532, 0.1028,\n",
      "        0.0406, 0.0398], grad_fn=<AddBackward0>)\n",
      "epoch 0 loss = 157.0387756228447;\n",
      "Final mean_losses: -60.198951289335184\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 0.3645, -1.0721,  1.3998,  0.3177, -0.0451, -0.6994,  0.2253,  0.2081,\n",
      "         0.8573, -0.3429,  0.2958, -0.4325,  0.3353,  0.9358, -0.4783, -0.1517,\n",
      "        -0.4323,  1.7371, -0.1245, -1.1368,  0.4483,  0.6949,  0.7710,  0.0446,\n",
      "        -0.1186,  0.1295, -0.6759, -0.0560,  0.5517,  0.3225, -0.1937, -0.6391,\n",
      "         0.4509,  0.5545,  0.2064, -0.5791, -0.0960,  0.9260,  0.5241,  0.2610,\n",
      "        -0.0033,  0.3584,  0.0936,  0.3823,  0.2363, -0.6443,  0.4231],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0072, 0.1896, 1.1296, 0.0881, 0.0719, 0.0977, 0.0476, 0.0388, 0.0518,\n",
      "        0.0642, 0.0573, 0.0485, 0.0676, 0.0985, 0.1145, 0.0907, 0.1256, 0.1091,\n",
      "        0.0748, 0.0825, 0.0756, 0.1195, 0.0567, 0.0926, 0.0576, 0.1320, 0.0764,\n",
      "        0.0268, 0.0529, 0.1005, 0.1449, 0.0335, 0.1444, 0.1092, 0.0176, 0.1324,\n",
      "        0.0483, 0.0390, 0.0340, 0.0348, 0.0501, 0.0403, 0.1290, 0.1531, 0.1025,\n",
      "        0.0406, 0.0397], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [ndom_fat_params,ndom_norm_params,]:#tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,filename=\"testresults/demoT_2.csv\")\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
