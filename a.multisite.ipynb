{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-3.1530,  2.8530,  7.0121, -1.9480])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "complaint 9 assert approx_eq( tensor([-3.0477e+01,  2.2707e+01,  3.4140e+02, -7.2898e+00, -7.6376e-04,\n",
      "         4.2220e+02, -3.2963e+01,  2.1136e+01, -1.6135e+02, -1.6080e+03,\n",
      "         1.6094e+02,  3.7022e+03, -3.3902e+01, -3.2368e+01,  2.7839e+01,\n",
      "        -3.7951e+02,  8.0901e+01, -1.4550e+00,  1.4342e+03,  2.2841e+01,\n",
      "         3.4191e+00,  3.2697e+02, -2.0009e-02, -1.7532e-02,  1.9859e+02,\n",
      "         1.0352e+04,  2.0725e+03,  1.7727e-01, -7.4991e+02, -1.2566e+01,\n",
      "         5.6341e+01, -6.8516e+01,  1.9236e+01, -4.2105e+02, -2.0938e+02,\n",
      "        -5.4872e+00, -4.3203e+03, -1.4299e+04,  2.4729e+03, -1.7158e+01,\n",
      "        -9.0065e+02,  1.6510e+01,  1.5763e-03, -3.5424e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 3.0764e+01, -2.2878e+01, -3.4252e+02,  7.3238e+00,  7.6799e-04,\n",
      "        -4.2256e+02,  3.3109e+01, -2.1223e+01,  1.6151e+02,  1.6089e+03,\n",
      "        -1.6168e+02, -3.7058e+03,  3.4177e+01,  3.3021e+01, -2.8163e+01,\n",
      "         3.8023e+02, -8.1283e+01,  1.4750e+00, -1.4373e+03, -2.2928e+01,\n",
      "        -3.4902e+00, -3.2734e+02,  2.1472e-02,  1.7894e-02, -1.9865e+02,\n",
      "        -1.0352e+04, -2.0748e+03, -1.8844e-01,  7.5006e+02,  1.3017e+01,\n",
      "        -5.6863e+01,  6.8532e+01, -1.9746e+01,  4.2139e+02,  2.0953e+02,\n",
      "         5.5021e+00,  4.3206e+03,  1.4300e+04, -2.4732e+03,  1.7585e+01,\n",
      "         9.0383e+02, -1.6823e+01, -1.5858e-03,  3.5484e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ -15.5083,   13.9439,   34.9710,   -9.4382,   -0.4437,   36.5998,\n",
      "         -15.6940,   13.4896,  -26.4737,  -57.4506,   27.1207,   78.4068,\n",
      "         -16.0258,  -16.3492,   15.1254,  -35.7458,   21.3602,   -5.5655,\n",
      "          57.6175,   13.8362,    7.4950,   33.6706,   -1.4079,   -1.2804,\n",
      "          28.2312,  106.2179,   63.9336,    2.8939,  -44.0170,  -12.0767,\n",
      "          19.3391,  -19.7743,   13.7876,  -36.5463,  -28.8338,   -8.5528,\n",
      "         -78.9335, -118.2958,   65.6401,  -13.1882,  -49.9726,   12.8389,\n",
      "           0.5652,  -15.9416], grad_fn=<MulBackward0>) tensor([  15.2214,  -13.7732,  -33.8512,    9.4042,    0.4437,  -36.2465,\n",
      "          15.5476,  -13.4025,   26.3085,   56.5881,  -26.3802,  -74.7553,\n",
      "          15.7511,   15.6957,  -14.8014,   35.0187,  -20.9779,    5.5455,\n",
      "         -54.5581,  -13.7494,   -7.4239,  -33.2961,    1.4064,    1.2800,\n",
      "         -28.1737, -105.2217,  -61.6183,   -2.8827,   43.8684,   11.6260,\n",
      "         -18.6785,   19.7588,  -13.2778,   36.2120,   28.6865,    8.5379,\n",
      "          78.6319,  117.1820,  -65.2917,   12.7612,   46.7858,  -12.5258,\n",
      "          -0.5652,   15.8816], grad_fn=<MulBackward0>)\n",
      "complaint 8 assert2 approx_eq( tensor([ 3.8147e-06,  1.9073e-06, -5.7220e-05, -9.5367e-07,  1.7881e-07,\n",
      "         2.6703e-05, -3.7193e-05,  9.5367e-07, -3.2425e-05, -3.0518e-05,\n",
      "        -1.9073e-05,  1.2970e-04,  1.3351e-05, -1.4305e-05, -1.3351e-05,\n",
      "         3.4332e-05, -1.1253e-04,  4.7684e-07, -5.7220e-05, -9.5367e-07,\n",
      "         4.7684e-07, -7.6294e-06,  0.0000e+00,  0.0000e+00,  1.7166e-05,\n",
      "        -8.9264e-04,  8.3923e-05,  7.1526e-07,  3.4332e-05,  0.0000e+00,\n",
      "         1.3874e-01,  2.2888e-04,  5.7220e-06,  0.0000e+00, -1.7166e-05,\n",
      "        -9.5367e-07, -4.0436e-04, -4.9591e-04,  2.2888e-05,  5.7220e-06,\n",
      "        -4.1962e-05,  9.5367e-07,  2.3842e-07,  9.5367e-06],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 7 dm.grad\n",
      "complaint 6 ddfr.grad\n",
      "complaint 5 dtr.grad\n",
      "epoch 0 loss = 179.5549132823944;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "yay 7 fix_m_grad\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "complaint 4 assert approx_eq( tensor([-3.1068e+01,  2.2310e+01,  3.3885e+02, -7.5057e+00, -1.3128e-03,\n",
      "         4.1918e+02, -3.3553e+01,  2.0742e+01, -1.6298e+02, -1.6155e+03,\n",
      "         1.5942e+02,  3.6894e+03, -3.4528e+01, -3.3053e+01,  2.7406e+01,\n",
      "        -3.8243e+02,  7.9940e+01, -1.5330e+00,  1.4275e+03,  2.2425e+01,\n",
      "         3.3215e+00,  3.2443e+02, -2.4728e-02, -2.1569e-02,  1.9676e+02,\n",
      "         1.0326e+04,  2.0638e+03,  1.6577e-01, -7.5441e+02, -1.2978e+01,\n",
      "         5.5331e+01, -6.9222e+01,  1.8962e+01, -4.2414e+02, -2.1131e+02,\n",
      "        -5.6624e+00, -4.3348e+03, -1.4331e+04,  2.4630e+03, -1.7624e+01,\n",
      "        -9.0596e+02,  1.6233e+01,  9.5510e-04, -3.6024e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 3.1339e+01, -2.2467e+01, -3.3994e+02,  7.5371e+00,  1.3190e-03,\n",
      "        -4.1953e+02,  3.3691e+01, -2.0822e+01,  1.6314e+02,  1.6164e+03,\n",
      "        -1.6013e+02, -3.6930e+03,  3.4788e+01,  3.3672e+01, -2.7706e+01,\n",
      "         3.8314e+02, -8.0303e+01,  1.5513e+00, -1.4305e+03, -2.2505e+01,\n",
      "        -3.3831e+00, -3.2479e+02,  2.6264e-02,  2.1947e-02, -1.9681e+02,\n",
      "        -1.0327e+04, -2.0661e+03, -1.7474e-01,  7.5456e+02,  1.3400e+01,\n",
      "        -5.5919e+01,  6.9307e+01, -1.9429e+01,  4.2447e+02,  2.1146e+02,\n",
      "         5.6761e+00,  4.3351e+03,  1.4332e+04, -2.4633e+03,  1.8024e+01,\n",
      "         9.0908e+02, -1.6518e+01, -9.6001e-04,  3.6081e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ -18.0118,   16.0168,   40.2106,  -11.0307,   -0.6155,   42.2457,\n",
      "         -18.2572,   15.5102,  -30.7487,  -66.5243,   31.1795,   90.1072,\n",
      "         -18.6146,  -18.9094,   17.3510,  -41.3911,   24.5713,   -6.5460,\n",
      "          66.1119,   15.9120,    8.5637,   38.8462,   -1.7326,   -1.5850,\n",
      "          32.6033,  122.8135,   73.5702,    3.2484,  -51.0837,  -13.9957,\n",
      "          22.1319,  -22.9904,   15.7532,  -42.3916,  -33.4876,  -10.0091,\n",
      "         -91.5206, -136.9937,   75.9034,  -15.2903,  -57.4378,   14.6998,\n",
      "           0.5538,  -18.5625], grad_fn=<MulBackward0>) tensor([  17.7406,  -15.8599,  -39.1274,   10.9993,    0.6155,  -41.9032,\n",
      "          18.1186,  -15.4304,   30.5890,   65.6786,  -30.4696,  -86.5294,\n",
      "          18.3545,   18.2903,  -17.0515,   40.6829,  -24.2091,    6.5277,\n",
      "         -63.1237,  -15.8323,   -8.5020,  -38.4842,    1.7311,    1.5846,\n",
      "         -32.5480, -121.8355,  -71.3055,   -3.2394,   50.9384,   13.5741,\n",
      "         -21.5445,   22.9988,  -15.2859,   42.0658,   33.3448,    9.9955,\n",
      "          91.2242,  135.8983,  -75.5624,   14.8897,   54.3193,  -14.4143,\n",
      "          -0.5538,   18.5058], grad_fn=<MulBackward0>)\n",
      "complaint 3 assert2 approx_eq( tensor([ 9.5367e-06,  0.0000e+00,  4.9591e-05, -1.9073e-06, -4.7684e-07,\n",
      "         2.2888e-05, -9.5367e-06, -2.8610e-06, -1.3351e-05, -7.6294e-06,\n",
      "        -2.2888e-05,  4.2725e-04, -2.4796e-05,  0.0000e+00,  1.9073e-06,\n",
      "        -1.5259e-05, -1.7166e-04, -4.7684e-07,  7.6294e-05, -5.7220e-06,\n",
      "         0.0000e+00, -1.5259e-05,  4.7684e-07, -7.1526e-07, -6.1035e-05,\n",
      "         3.9673e-04, -7.6294e-06,  2.3842e-07, -1.1444e-05, -9.5367e-07,\n",
      "        -1.0300e-04,  9.3378e-02,  3.8147e-06, -2.2888e-05,  1.1444e-05,\n",
      "         9.5367e-07, -4.7302e-04, -7.4768e-04,  1.6022e-04,  2.8610e-06,\n",
      "        -8.3923e-05, -9.5367e-07, -4.7684e-07,  5.7220e-06],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 2 dm.grad\n",
      "complaint 1 ddfr.grad\n",
      "complaint 0 dtr.grad\n",
      "complaint 0\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "complaint -20\n",
      "yay -260\n",
      "epoch 100 loss = 212.0380940437317;\n",
      "mode_hat tensor(-0.0346, requires_grad=True)\n",
      "ltscale_hat tensor(0.4982, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4560, requires_grad=True)\n",
      "complaint -40\n",
      "complaint -60\n",
      "yay -320\n",
      "yay -380\n",
      "complaint -80\n",
      "complaint -100\n",
      "yay -440\n",
      "complaint -120\n",
      "yay -500\n",
      "epoch 200 loss = 260.6866261959076;\n",
      "mode_hat tensor(-0.0507, requires_grad=True)\n",
      "ltscale_hat tensor(0.9246, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7352, requires_grad=True)\n",
      "yay -560\n",
      "complaint -140\n",
      "complaint -160\n",
      "complaint -180\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "complaint -200\n",
      "complaint -220\n",
      "epoch 300 loss = 189.42098760604858;\n",
      "mode_hat tensor(-0.0609, requires_grad=True)\n",
      "ltscale_hat tensor(1.3105, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9593, requires_grad=True)\n",
      "yay -800\n",
      "complaint -240\n",
      "yay -860\n",
      "complaint -260\n",
      "complaint -280\n",
      "complaint -300\n",
      "yay -920\n",
      "complaint -320\n",
      "complaint -340\n",
      "yay -980\n",
      "complaint -360\n",
      "complaint -380\n",
      "yay -1040\n",
      "epoch 400 loss = 180.4110586643219;\n",
      "mode_hat tensor(-0.0173, requires_grad=True)\n",
      "ltscale_hat tensor(1.4882, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0024, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint -400\n",
      "yay -1100\n",
      "yay -1160\n",
      "complaint -420\n",
      "yay -1220\n",
      "complaint -440\n",
      "yay -1280\n",
      "complaint -460\n",
      "yay -1340\n",
      "epoch 500 loss = 218.01439213752747;\n",
      "mode_hat tensor(-0.0255, requires_grad=True)\n",
      "ltscale_hat tensor(1.5523, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9250, requires_grad=True)\n",
      "Final mean_losses: 185.8783044376894\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(-0.0255, requires_grad=True)), ('t_scale_raw', tensor(1.5523, requires_grad=True)), ('t_part', tensor([-0.0693,  0.1396, 12.7776,  5.4797,  2.7973,  5.8580,  4.3634,  2.8726],\n",
      "       grad_fn=<IndexSelectBackward>))]), 'logPosterior': tensor(21.3749, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 5.4686e+03, -0.0000e+00,  9.6827e+02,  8.8620e+02,  1.3878e+02,\n",
      "          1.6389e+02,  5.0495e+02,  2.3045e+03,  2.3332e+02,  2.6868e+02],\n",
      "        [-0.0000e+00,  7.3014e+00,  8.0993e-03, -1.6299e-02, -9.8646e-02,\n",
      "         -2.7295e-01, -2.5214e-01, -2.6488e-01, -2.8518e-01, -2.5553e-01],\n",
      "        [ 9.6827e+02,  8.0993e-03,  9.6833e+02, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 8.8620e+02, -1.6299e-02, -0.0000e+00,  8.8626e+02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.3878e+02, -9.8646e-02, -0.0000e+00, -0.0000e+00,  1.3877e+02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.6389e+02, -2.7295e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          1.6390e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 5.0495e+02, -2.5214e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  5.0499e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3045e+03, -2.6488e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  2.3045e+03, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3332e+02, -2.8518e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.3335e+02, -0.0000e+00],\n",
      "        [ 2.6868e+02, -2.5553e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.6872e+02]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[0.2627, 1.4374],\n",
      "        [1.4374, 8.0866]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0.0256, 0.0000],\n",
      "        [0.0000, 0.7865]], grad_fn=<MulBackward0>), 'grad': tensor([ 6.3180, -1.7419, -0.0173,  0.0346,  1.0245,  0.9841,  0.6317,  1.0116,\n",
      "         0.8722,  0.6456], grad_fn=<CatBackward>), 'df': tensor(3.1160, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.1706, -4.2006], requires_grad=True), 'latentpsiraw': tensor([-6.6279], requires_grad=True)}\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "latentpsi:\n",
      "tensor([-6.6279], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.9249759316444397\n",
      "ltscale_hat:\n",
      "1.5522551536560059\n",
      "mode_hat:\n",
      "-0.025537768378853798\n",
      "thetapsi:\n",
      "tensor([-4.1706, -4.2006], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-3.1530,  2.8530,  7.0121, -1.9480])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 665.5992574691772;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "epoch 100 loss = 316.1667104959488;\n",
      "mode_hat tensor(0.1001, requires_grad=True)\n",
      "ltscale_hat tensor(0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4984, requires_grad=True)\n",
      "epoch 200 loss = 405.9020230770111;\n",
      "mode_hat tensor(0.0780, requires_grad=True)\n",
      "ltscale_hat tensor(1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9522, requires_grad=True)\n",
      "epoch 300 loss = 325.97182619571686;\n",
      "mode_hat tensor(0.0859, requires_grad=True)\n",
      "ltscale_hat tensor(1.4687, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.3203, requires_grad=True)\n",
      "epoch 400 loss = 363.6699882745743;\n",
      "mode_hat tensor(0.0898, requires_grad=True)\n",
      "ltscale_hat tensor(1.6322, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.1945, requires_grad=True)\n",
      "epoch 500 loss = 320.9312697649002;\n",
      "mode_hat tensor(0.0912, requires_grad=True)\n",
      "ltscale_hat tensor(1.6174, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9154, requires_grad=True)\n",
      "epoch 600 loss = 281.29317224025726;\n",
      "mode_hat tensor(0.1065, requires_grad=True)\n",
      "ltscale_hat tensor(1.6707, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7083, requires_grad=True)\n",
      "epoch 700 loss = 284.3499684333801;\n",
      "mode_hat tensor(0.0854, requires_grad=True)\n",
      "ltscale_hat tensor(1.6725, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5221, requires_grad=True)\n",
      "epoch 800 loss = 323.7717126607895;\n",
      "mode_hat tensor(0.1136, requires_grad=True)\n",
      "ltscale_hat tensor(1.6641, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3691, requires_grad=True)\n",
      "Final mean_losses: 317.9689238537685\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(0.1067, requires_grad=True)), ('t_scale_raw', tensor(1.7136, requires_grad=True)), ('t_part', tensor([-3.2588e+00,  2.7223e+00,  6.9028e+00, -2.0433e+00, -1.9938e-01,\n",
      "         7.3809e+00, -3.3242e+00,  2.6621e+00, -5.5593e+00, -1.1839e+01,\n",
      "         5.3524e+00,  1.5366e+01, -3.3752e+00, -3.3532e+00,  2.9597e+00,\n",
      "        -7.3420e+00,  4.2205e+00, -1.2488e+00,  1.1214e+01,  2.7188e+00,\n",
      "         1.4161e+00,  6.8103e+00, -3.8510e-01, -3.7276e-01,  5.7362e+00,\n",
      "         2.1693e+01,  1.2666e+01,  4.9251e-01, -9.1787e+00, -2.5154e+00,\n",
      "         3.7766e+00, -4.2137e+00,  2.6413e+00, -7.6061e+00, -6.0319e+00,\n",
      "        -1.8681e+00, -1.6389e+01, -2.4371e+01,  1.3420e+01, -2.7399e+00,\n",
      "        -9.7926e+00,  2.4826e+00, -2.4282e-03, -3.3867e+00],\n",
      "       requires_grad=True))]), 'logPosterior': tensor(-1838723.2500, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 2.5656e+04, -0.0000e+00,  1.0777e+02,  ...,  9.2159e+01,\n",
      "          8.1558e+01,  1.2090e+03],\n",
      "        [-0.0000e+00,  4.0187e+01,  2.1404e-01,  ..., -1.7889e-01,\n",
      "          1.7419e-04,  2.1866e-01],\n",
      "        [ 1.0777e+02,  2.1404e-01,  1.0780e+02,  ..., -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.2159e+01, -1.7889e-01, -0.0000e+00,  ...,  9.2193e+01,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        [ 8.1558e+01,  1.7419e-04, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          8.1600e+01, -0.0000e+00],\n",
      "        [ 1.2090e+03,  2.1866e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "         -0.0000e+00,  1.2090e+03]], grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[ 0.9042, -0.2562],\n",
      "        [-0.2562, 40.1804]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([-2.6879e+04, -1.9878e+00,  2.0085e+03, -5.5349e+03, -1.2487e+03,\n",
      "        -6.4274e+01, -3.2603e+02, -6.1162e+03,  7.0310e+02,  7.0658e+03,\n",
      "         1.1145e+03,  2.3347e+03, -5.3761e+03, -1.5384e+04,  2.2255e+03,\n",
      "         1.4074e+04, -5.7732e+01, -3.7019e+00, -7.4835e+03,  6.6977e+02,\n",
      "        -4.4940e+03,  1.7644e+03,  3.0390e+03, -1.9041e+03,  1.5430e+03,\n",
      "        -3.9010e+03, -3.0455e+04, -5.6647e+03, -1.1975e+03, -2.1237e+02,\n",
      "        -2.0932e+01, -3.1367e+02, -9.0444e+03,  8.7300e+01, -2.2027e+02,\n",
      "         2.1394e+03,  5.2267e+02, -3.1376e+02,  1.1183e+03,  3.7087e+04,\n",
      "        -2.1417e+03,  2.4383e+03, -8.1808e+03,  8.0282e+02,  2.1584e+02,\n",
      "         1.8269e+03], grad_fn=<CatBackward>), 'df': tensor(3.4433, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.6052, -4.6052], requires_grad=True), 'latentpsiraw': tensor([-7.8657], requires_grad=True)}\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "full_tmode:\n",
      "tensor([-3.2588e+00,  2.7223e+00,  6.9028e+00, -2.0433e+00, -1.9938e-01,\n",
      "         7.3809e+00, -3.3242e+00,  2.6621e+00, -5.5593e+00, -1.1839e+01,\n",
      "         5.3524e+00,  1.5366e+01, -3.3752e+00, -3.3532e+00,  2.9597e+00,\n",
      "        -7.3420e+00,  4.2205e+00, -1.2488e+00,  1.1214e+01,  2.7188e+00,\n",
      "         1.4161e+00,  6.8103e+00, -3.8510e-01, -3.7276e-01,  5.7362e+00,\n",
      "         2.1693e+01,  1.2666e+01,  4.9251e-01, -9.1787e+00, -2.5154e+00,\n",
      "         3.7766e+00, -4.2137e+00,  2.6413e+00, -7.6061e+00, -6.0319e+00,\n",
      "        -1.8681e+00, -1.6389e+01, -2.4371e+01,  1.3420e+01, -2.7399e+00,\n",
      "        -9.7926e+00,  2.4826e+00, -2.4282e-03, -3.3867e+00],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-7.8657], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.32074400782585144\n",
      "ltscale_hat:\n",
      "1.7136483192443848\n",
      "mode_hat:\n",
      "0.1066712960600853\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-3.1530,  2.8530,  7.0121, -1.9480])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 24770.17691066861;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 loss = 202358.53004160523;\n",
      "epoch 200 loss = 261364.96635240316;\n",
      "epoch 300 loss = 28822.87375099212;\n",
      "epoch 400 loss = 31531.313693381846;\n",
      "epoch 500 loss = 125172.58460955275;\n",
      "Final mean_losses: 122999.86315491058\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "auto_loc:\n",
      "tensor([-0.6277, -0.1175,  0.9661, -0.6340,  0.8562,  0.7495, -0.4845,  0.1834,\n",
      "         0.8279, -0.6774,  0.6152, -0.6283, -0.7925,  0.7353,  0.7799, -0.6990,\n",
      "        -0.7048,  0.7013, -0.7206,  0.8825, -0.2856,  0.7808,  0.6620,  0.6487,\n",
      "         0.7092,  0.1300,  0.0999,  0.7734,  0.7689,  0.7650,  0.4703, -0.7570,\n",
      "        -0.5449,  0.7209, -0.8100,  0.7586, -0.8826, -0.7353, -0.4228, -0.7419,\n",
      "        -0.7405,  0.7508, -0.6476, -0.8757,  0.7038,  0.2178, -0.8096],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.7005, 0.2434, 1.2897, 0.9476, 1.0747, 0.9770, 0.7828, 0.7983, 1.0778,\n",
      "        1.0701, 1.1594, 1.1962, 1.0384, 1.0095, 1.0629, 1.0122, 1.0112, 1.1412,\n",
      "        0.9165, 1.0246, 0.7420, 1.1199, 1.1222, 0.9300, 1.0253, 0.6795, 0.8024,\n",
      "        1.1959, 1.0135, 1.1593, 0.7659, 1.0137, 0.9768, 0.9854, 1.1294, 0.9887,\n",
      "        1.1138, 1.0620, 0.7037, 1.1276, 0.9423, 0.9550, 0.9346, 1.0818, 0.9389,\n",
      "        0.7591, 0.9930], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.8322, 0.9737, 0.4756, 0.9593])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 91.56298851966858;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "yay -1400\n",
      "yay -1460\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "epoch 100 loss = 51.704352617263794;\n",
      "mode_hat tensor(0.2671, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3221, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0192, requires_grad=True)\n",
      "yay -1700\n",
      "yay -1760\n",
      "yay -1820\n",
      "yay -1880\n",
      "yay -1940\n",
      "epoch 200 loss = 48.05179762840271;\n",
      "mode_hat tensor(0.4892, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7983, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3173, requires_grad=True)\n",
      "yay -2000\n",
      "yay -2060\n",
      "yay -2120\n",
      "yay -2180\n",
      "yay -2240\n",
      "epoch 300 loss = 63.57978069782257;\n",
      "mode_hat tensor(0.5158, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2414, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6801, requires_grad=True)\n",
      "yay -2300\n",
      "yay -2360\n",
      "yay -2420\n",
      "yay -2480\n",
      "yay -2540\n",
      "epoch 400 loss = 41.97426462173462;\n",
      "mode_hat tensor(0.5400, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5335, requires_grad=True)\n",
      "ldfraw_hat tensor(0.8461, requires_grad=True)\n",
      "yay -2600\n",
      "yay -2660\n",
      "yay -2720\n",
      "yay -2780\n",
      "yay -2840\n",
      "epoch 500 loss = 58.79836940765381;\n",
      "mode_hat tensor(0.5498, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7074, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9599, requires_grad=True)\n",
      "yay -2900\n",
      "yay -2960\n",
      "yay -3020\n",
      "yay -3080\n",
      "yay -3140\n",
      "epoch 600 loss = 48.95858716964722;\n",
      "mode_hat tensor(0.5370, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8023, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9692, requires_grad=True)\n",
      "yay -3200\n",
      "yay -3260\n",
      "yay -3320\n",
      "yay -3380\n",
      "yay -3440\n",
      "epoch 700 loss = 51.988109827041626;\n",
      "mode_hat tensor(0.5396, requires_grad=True)\n",
      "ltscale_hat tensor(-1.8733, requires_grad=True)\n",
      "ldfraw_hat tensor(1.0021, requires_grad=True)\n",
      "yay -3500\n",
      "yay -3560\n",
      "yay -3620\n",
      "yay -3680\n",
      "yay -3740\n",
      "epoch 800 loss = 44.438448667526245;\n",
      "mode_hat tensor(0.5531, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9034, requires_grad=True)\n",
      "ldfraw_hat tensor(1.0590, requires_grad=True)\n",
      "yay -3800\n",
      "yay -3860\n",
      "yay -3920\n",
      "yay -3980\n",
      "yay -4040\n",
      "epoch 900 loss = 55.750155568122864;\n",
      "mode_hat tensor(0.5475, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9633, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1522, requires_grad=True)\n",
      "yay -4100\n",
      "yay -4160\n",
      "Final mean_losses: 56.50567326625944\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(0.5382, requires_grad=True)), ('t_scale_raw', tensor(-1.9773, requires_grad=True)), ('t_part', tensor([ 0.1168, -0.1815,  0.1546,  0.3526, -0.2857,  0.1053,  0.1544,  0.0559],\n",
      "       grad_fn=<IndexSelectBackward>))]), 'logPosterior': tensor(21.5712, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 1.4183e+03, -0.0000e+00,  1.2095e+02,  1.6389e+02,  8.0109e+01,\n",
      "          2.6868e+02,  2.3332e+02,  1.7594e+02,  2.3662e+02,  1.3878e+02],\n",
      "        [-0.0000e+00,  2.7178e+00, -1.6831e+00,  2.3858e+00, -2.1199e+00,\n",
      "         -3.1531e+00,  3.0308e+00, -1.5357e+00, -2.1181e+00, -8.4809e-01],\n",
      "        [ 1.2095e+02, -1.6831e+00,  1.3492e+02, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.6389e+02,  2.3858e+00, -0.0000e+00,  1.7599e+02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 8.0109e+01, -2.1199e+00, -0.0000e+00, -0.0000e+00,  9.3049e+01,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.6868e+02, -3.1531e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          2.7485e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3332e+02,  3.0308e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  2.4178e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.7594e+02, -1.5357e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  1.9017e+02, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3662e+02, -2.1181e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.4956e+02, -0.0000e+00],\n",
      "        [ 1.3878e+02, -8.4809e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  1.5389e+02]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[88.1974,  5.4635],\n",
      "        [ 5.4635,  2.5070]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([ 35.9062,  -1.9565,   7.7115, -11.5198,   9.9904,  18.9176, -16.5243,\n",
      "          6.9857,   9.9804,   3.7718], grad_fn=<CatBackward>), 'df': tensor(5.8670, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-3.9292, -3.9190], requires_grad=True), 'latentpsiraw': tensor([-8.4950], requires_grad=True)}\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "latentpsi:\n",
      "tensor([-8.4950], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.1466443538665771\n",
      "ltscale_hat:\n",
      "-1.9772969484329224\n",
      "mode_hat:\n",
      "0.5382193922996521\n",
      "thetapsi:\n",
      "tensor([-3.9292, -3.9190], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.8322, 0.9737, 0.4756, 0.9593])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 4144.907026290894;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 203.4670740365982;\n",
      "mode_hat tensor(0.2640, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5048, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4992, requires_grad=True)\n",
      "epoch 200 loss = 196.60277020931244;\n",
      "mode_hat tensor(0.2812, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9808, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9703, requires_grad=True)\n",
      "epoch 300 loss = 183.15744245052338;\n",
      "mode_hat tensor(0.2629, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2053, requires_grad=True)\n",
      "ldfraw_hat tensor(1.2553, requires_grad=True)\n",
      "epoch 400 loss = 199.40248692035675;\n",
      "mode_hat tensor(0.2996, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2153, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3409, requires_grad=True)\n",
      "epoch 500 loss = 184.07331824302673;\n",
      "mode_hat tensor(0.2945, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2182, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3584, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600 loss = 203.7879263162613;\n",
      "mode_hat tensor(0.3289, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2629, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3747, requires_grad=True)\n",
      "epoch 700 loss = 199.2291957139969;\n",
      "mode_hat tensor(0.3482, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3102, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3244, requires_grad=True)\n",
      "epoch 800 loss = 180.46476662158966;\n",
      "mode_hat tensor(0.3403, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3645, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3061, requires_grad=True)\n",
      "epoch 900 loss = 196.8425898551941;\n",
      "mode_hat tensor(0.3424, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3116, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1950, requires_grad=True)\n",
      "Final mean_losses: 192.76051005604194\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(0.3477, requires_grad=True)), ('t_scale_raw', tensor(-1.3348, requires_grad=True)), ('t_part', tensor([ 4.7464e-01,  6.4070e-01,  1.1234e-01,  6.0746e-01, -2.4534e-02,\n",
      "        -1.1722e-04,  1.5887e-01,  5.1728e-01,  3.5296e-01, -1.1333e-01,\n",
      "        -9.1729e-02, -2.8460e-01,  3.2290e-01, -4.6497e-02,  6.5464e-01,\n",
      "         4.2131e-01, -1.6045e-01,  1.0520e-01, -8.5900e-01,  8.1107e-01,\n",
      "         2.9642e-01,  5.9600e-01,  6.6505e-01, -7.1772e-01,  1.9222e-01,\n",
      "        -3.5808e-02,  2.7209e-01,  4.8842e-01,  5.9983e-01,  6.8213e-01,\n",
      "         9.2115e-02,  2.4708e-01,  1.5604e+00,  4.9381e-01, -5.8861e-02,\n",
      "        -9.5163e-02, -3.8537e-01,  2.2765e-01,  5.6535e-02, -2.1635e-02,\n",
      "        -4.9872e-01,  3.9206e-01,  2.8170e-01, -2.9035e-01],\n",
      "       requires_grad=True))]), 'logPosterior': tensor(-3325.5569, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 2.5656e+04, -0.0000e+00,  8.0109e+01,  ...,  7.4769e+01,\n",
      "          3.0898e+02,  3.4049e+02],\n",
      "        [-0.0000e+00,  2.5123e+01, -2.8584e+00,  ..., -2.7013e+00,\n",
      "         -2.2567e+00,  2.2975e+00],\n",
      "        [ 8.0109e+01, -2.8584e+00,  8.3521e+01,  ..., -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        ...,\n",
      "        [ 7.4769e+01, -2.7013e+00, -0.0000e+00,  ...,  7.9112e+01,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        [ 3.0898e+02, -2.2567e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          3.1455e+02, -0.0000e+00],\n",
      "        [ 3.4049e+02,  2.2975e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "         -0.0000e+00,  3.4597e+02]], grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[199.2988,  40.3955],\n",
      "        [ 40.3955,  24.1687]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([-7.1040e+02, -8.4981e-01, -1.2022e+00, -1.0407e+02,  1.1935e+02,\n",
      "         1.4787e+00,  5.3193e+01,  8.7150e+02, -1.2973e+01, -1.0085e+02,\n",
      "         2.3335e+01,  1.5133e+02, -2.0670e+02,  1.6214e+02, -1.2036e+02,\n",
      "         1.1213e+02, -1.4472e+03, -2.7305e+02,  6.1642e+01,  8.2477e+02,\n",
      "         7.2894e+01, -9.4666e+01, -2.6491e+02, -5.8412e+01,  7.4310e+01,\n",
      "         8.6411e+02,  5.3690e+01,  7.5320e+01, -1.1051e+02, -7.0834e+02,\n",
      "        -4.8668e+01, -1.1716e+03,  1.7405e+02,  8.0607e+01, -5.3202e+02,\n",
      "        -2.6276e+02,  2.7819e+01,  3.1133e+02,  3.3116e+02, -2.4582e+01,\n",
      "         3.9265e+01, -2.5216e+01,  4.1190e+02, -6.9519e+01, -6.3251e+01,\n",
      "         5.0389e+01], grad_fn=<CatBackward>), 'df': tensor(6.0663, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.6051, -4.6051], requires_grad=True), 'latentpsiraw': tensor([-7.3746], requires_grad=True)}\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "full_tmode:\n",
      "tensor([ 4.7464e-01,  6.4070e-01,  1.1234e-01,  6.0746e-01, -2.4534e-02,\n",
      "        -1.1722e-04,  1.5887e-01,  5.1728e-01,  3.5296e-01, -1.1333e-01,\n",
      "        -9.1729e-02, -2.8460e-01,  3.2290e-01, -4.6497e-02,  6.5464e-01,\n",
      "         4.2131e-01, -1.6045e-01,  1.0520e-01, -8.5900e-01,  8.1107e-01,\n",
      "         2.9642e-01,  5.9600e-01,  6.6505e-01, -7.1772e-01,  1.9222e-01,\n",
      "        -3.5808e-02,  2.7209e-01,  4.8842e-01,  5.9983e-01,  6.8213e-01,\n",
      "         9.2115e-02,  2.4708e-01,  1.5604e+00,  4.9381e-01, -5.8861e-02,\n",
      "        -9.5163e-02, -3.8537e-01,  2.2765e-01,  5.6535e-02, -2.1635e-02,\n",
      "        -4.9872e-01,  3.9206e-01,  2.8170e-01, -2.9035e-01],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-7.3746], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.2108055353164673\n",
      "ltscale_hat:\n",
      "-1.3347944021224976\n",
      "mode_hat:\n",
      "0.3477427363395691\n",
      "thetapsi:\n",
      "tensor([-4.6051, -4.6051], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.8322, 0.9737, 0.4756, 0.9593])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 8086.612563341856;\n",
      "epoch 100 loss = 1005.2439351323992;\n",
      "epoch 200 loss = 751.4174826145172;\n",
      "epoch 300 loss = 5374.837739288807;\n",
      "epoch 400 loss = 377.98737394809723;\n",
      "epoch 500 loss = 2033.8025041818619;\n",
      "epoch 600 loss = 199.0320339202881;\n",
      "epoch 700 loss = 218.8983324766159;\n",
      "epoch 800 loss = 2449.618934750557;\n",
      "epoch 900 loss = 158.8199275135994;\n",
      "epoch 1000 loss = 1279.2802557945251;\n",
      "epoch 1100 loss = 248.80307185649872;\n",
      "epoch 1200 loss = 26.199077367782593;\n",
      "epoch 1300 loss = 290.5288494825363;\n",
      "epoch 1400 loss = 124.61474108695984;\n",
      "epoch 1500 loss = -15.048323631286621;\n",
      "epoch 1600 loss = 229.23774695396423;\n",
      "epoch 1700 loss = 53.64880657196045;\n",
      "epoch 1800 loss = 82.82066464424133;\n",
      "epoch 1900 loss = 158.47846043109894;\n",
      "epoch 2000 loss = 77.77840614318848;\n",
      "epoch 2100 loss = -14.844585180282593;\n",
      "Final mean_losses: 205.2548607807593\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "auto_loc:\n",
      "tensor([ 5.1581e-01, -2.5911e+00,  2.2607e+00,  8.5489e-02,  7.1060e-02,\n",
      "        -1.0873e-03,  8.0192e-02, -5.8085e-02, -2.8362e-02, -4.6991e-03,\n",
      "         7.1915e-02,  6.7231e-02, -9.3063e-02, -9.2010e-02, -1.0624e-01,\n",
      "         4.7723e-02, -5.6911e-02,  1.3250e-01,  1.0988e-02, -4.0897e-02,\n",
      "        -1.7828e-02, -2.1385e-01,  1.0004e-01,  2.0189e-02,  7.7359e-02,\n",
      "         1.3048e-01, -1.3003e-01, -4.7799e-03, -8.9458e-02,  1.2282e-02,\n",
      "         6.5781e-02,  1.0963e-01,  8.7872e-02, -1.1511e-02,  1.6362e-02,\n",
      "         1.1632e-01,  1.0356e-01, -6.2661e-02, -7.3481e-02, -1.5151e-01,\n",
      "         2.3513e-02, -4.0825e-02, -6.9200e-02, -8.4814e-02,  8.5355e-02,\n",
      "         6.9345e-02, -9.7638e-02], requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0317, 0.3445, 0.7691, 0.2037, 0.2187, 0.1811, 0.2203, 0.1686, 0.1561,\n",
      "        0.1621, 0.1934, 0.1530, 0.1998, 0.1800, 0.2284, 0.1853, 0.2073, 0.2061,\n",
      "        0.1943, 0.1946, 0.1790, 0.3240, 0.2467, 0.2000, 0.2181, 0.2339, 0.2869,\n",
      "        0.1250, 0.1692, 0.1895, 0.2132, 0.2008, 0.2256, 0.2078, 0.1386, 0.3158,\n",
      "        0.1807, 0.1746, 0.2042, 0.2801, 0.1551, 0.1459, 0.1858, 0.2277, 0.1789,\n",
      "        0.1509, 0.2316], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 1.0512,  4.9847,  5.9340, -2.5476])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 269.69975447654724;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint -480\n",
      "yay -4220\n",
      "yay -4280\n",
      "complaint -500\n",
      "yay -4340\n",
      "yay -4400\n",
      "epoch 100 loss = 226.52590095996857;\n",
      "mode_hat tensor(0.1044, requires_grad=True)\n",
      "ltscale_hat tensor(0.4498, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3684, requires_grad=True)\n",
      "yay -4460\n",
      "complaint -520\n",
      "complaint -540\n",
      "complaint -560\n",
      "yay -4520\n",
      "complaint -580\n",
      "complaint -600\n",
      "yay -4580\n",
      "complaint -620\n",
      "yay -4640\n",
      "epoch 200 loss = 186.81021523475647;\n",
      "mode_hat tensor(0.2049, requires_grad=True)\n",
      "ltscale_hat tensor(0.9011, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6354, requires_grad=True)\n",
      "yay -4700\n",
      "complaint -640\n",
      "yay -4760\n",
      "complaint -660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay -4820\n",
      "complaint -680\n",
      "complaint -700\n",
      "yay -4880\n",
      "yay -4940\n",
      "epoch 300 loss = 179.21594667434692;\n",
      "mode_hat tensor(0.2550, requires_grad=True)\n",
      "ltscale_hat tensor(1.2640, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7605, requires_grad=True)\n",
      "complaint -720\n",
      "complaint -740\n",
      "yay -5000\n",
      "complaint -760\n",
      "yay -5060\n",
      "yay -5120\n",
      "yay -5180\n",
      "epoch 400 loss = 165.83769297599792;\n",
      "mode_hat tensor(0.3444, requires_grad=True)\n",
      "ltscale_hat tensor(1.4852, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8357, requires_grad=True)\n",
      "yay -5240\n",
      "yay -5300\n",
      "yay -5360\n",
      "yay -5420\n",
      "yay -5480\n",
      "epoch 500 loss = 186.5060076713562;\n",
      "mode_hat tensor(0.3809, requires_grad=True)\n",
      "ltscale_hat tensor(1.4675, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6713, requires_grad=True)\n",
      "yay -5540\n",
      "yay -5600\n",
      "yay -5660\n",
      "yay -5720\n",
      "yay -5780\n",
      "epoch 600 loss = 174.3982629776001;\n",
      "mode_hat tensor(0.4027, requires_grad=True)\n",
      "ltscale_hat tensor(1.4504, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5681, requires_grad=True)\n",
      "yay -5840\n",
      "yay -5900\n",
      "yay -5960\n",
      "yay -6020\n",
      "complaint -780\n",
      "yay -6080\n",
      "epoch 700 loss = 177.7753267288208;\n",
      "mode_hat tensor(0.4527, requires_grad=True)\n",
      "ltscale_hat tensor(1.5103, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5091, requires_grad=True)\n",
      "complaint -800\n",
      "yay -6140\n",
      "complaint -820\n",
      "yay -6200\n",
      "complaint -840\n",
      "complaint -860\n",
      "yay -6260\n",
      "complaint -880\n",
      "complaint -900\n",
      "complaint -920\n",
      "complaint -940\n",
      "yay -6320\n",
      "complaint -960\n",
      "complaint -980\n",
      "yay -6380\n",
      "epoch 800 loss = 206.0353879928589;\n",
      "mode_hat tensor(0.4995, requires_grad=True)\n",
      "ltscale_hat tensor(1.5102, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5096, requires_grad=True)\n",
      "complaint -1000\n",
      "complaint -1020\n",
      "complaint -1040\n",
      "yay -6440\n",
      "complaint -1060\n",
      "complaint -1080\n",
      "yay -6500\n",
      "complaint -1100\n",
      "complaint -1120\n",
      "yay -6560\n",
      "complaint -1140\n",
      "complaint -1160\n",
      "yay -6620\n",
      "complaint -1180\n",
      "complaint -1200\n",
      "complaint -1220\n",
      "epoch 900 loss = 175.4201740026474;\n",
      "mode_hat tensor(0.4994, requires_grad=True)\n",
      "ltscale_hat tensor(1.5855, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4811, requires_grad=True)\n",
      "complaint -1240\n",
      "complaint -1260\n",
      "yay -6680\n",
      "complaint -1280\n",
      "complaint -1300\n",
      "complaint -1320\n",
      "complaint -1340\n",
      "complaint -1360\n",
      "complaint -1380\n",
      "complaint -1400\n",
      "complaint -1420\n",
      "complaint -1440\n",
      "complaint -1460\n",
      "complaint -1480\n",
      "complaint -1500\n",
      "complaint -1520\n",
      "yay -6740\n",
      "complaint -1540\n",
      "complaint -1560\n",
      "yay -6800\n",
      "complaint -1580\n",
      "epoch 1000 loss = 154.1270751953125;\n",
      "mode_hat tensor(0.4806, requires_grad=True)\n",
      "ltscale_hat tensor(1.5536, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3202, requires_grad=True)\n",
      "complaint -1600\n",
      "complaint -1620\n",
      "complaint -1640\n",
      "complaint -1660\n",
      "complaint -1680\n",
      "complaint -1700\n",
      "complaint -1720\n",
      "complaint -1740\n",
      "yay -6860\n",
      "complaint -1760\n",
      "yay -6920\n",
      "complaint -1780\n",
      "yay -6980\n",
      "complaint -1800\n",
      "epoch 1100 loss = 170.73775148391724;\n",
      "mode_hat tensor(0.4952, requires_grad=True)\n",
      "ltscale_hat tensor(1.5779, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2579, requires_grad=True)\n",
      "yay -7040\n",
      "complaint -1820\n",
      "complaint -1840\n",
      "complaint -1860\n",
      "Final mean_losses: 178.33985128281935\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(0.5140, requires_grad=True)), ('t_scale_raw', tensor(1.5633, requires_grad=True)), ('t_part', tensor([-5.0110, -2.1007,  3.3362,  3.1841,  8.9684, -1.9545, 11.5578, -3.0585],\n",
      "       grad_fn=<IndexSelectBackward>))]), 'logPosterior': tensor(16.1383, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 4.1927e+03, -0.0000e+00,  8.0109e+01,  9.8133e+02,  1.3878e+02,\n",
      "          9.8211e+02,  7.3532e+02,  9.0839e+01,  5.3584e+02,  6.4839e+02],\n",
      "        [-0.0000e+00,  8.4990e+00,  2.9066e-01,  2.0236e-01, -2.6867e-01,\n",
      "         -2.6303e-01, -2.0353e-01,  1.9143e-01, -1.4185e-01,  2.5785e-01],\n",
      "        [ 8.0109e+01,  2.9066e-01,  8.0128e+01, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 9.8133e+02,  2.0236e-01, -0.0000e+00,  9.8138e+02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.3878e+02, -2.6867e-01, -0.0000e+00, -0.0000e+00,  1.3882e+02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 9.8211e+02, -2.6303e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          9.8214e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 7.3532e+02, -2.0353e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  7.3531e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 9.0839e+01,  1.9143e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  9.0887e+01, -0.0000e+00, -0.0000e+00],\n",
      "        [ 5.3584e+02, -1.4185e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  5.3583e+02, -0.0000e+00],\n",
      "        [ 6.4839e+02,  2.5785e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  6.4843e+02]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[ 0.2144, -0.0651],\n",
      "        [-0.0651,  8.4967]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([ 1.2843, -0.9221, -0.9262, -0.4734,  0.7022,  0.6767,  1.1165, -0.4435,\n",
      "         1.0954, -0.6552], grad_fn=<CatBackward>), 'df': tensor(3.5055, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-3.8789, -3.9056], requires_grad=True), 'latentpsiraw': tensor([-9.6982], requires_grad=True)}\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "latentpsi:\n",
      "tensor([-9.6982], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.23878033459186554\n",
      "ltscale_hat:\n",
      "1.5632998943328857\n",
      "mode_hat:\n",
      "0.5139989256858826\n",
      "thetapsi:\n",
      "tensor([-3.8789, -3.9056], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 1.0512,  4.9847,  5.9340, -2.5476])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 1594.7694832086563;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "epoch 100 loss = 352.3417868614197;\n",
      "mode_hat tensor(0.1624, requires_grad=True)\n",
      "ltscale_hat tensor(0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4917, requires_grad=True)\n",
      "epoch 200 loss = 329.27205514907837;\n",
      "mode_hat tensor(0.1430, requires_grad=True)\n",
      "ltscale_hat tensor(1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9346, requires_grad=True)\n",
      "epoch 300 loss = 259.59106183052063;\n",
      "mode_hat tensor(0.1398, requires_grad=True)\n",
      "ltscale_hat tensor(1.3913, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.1355, requires_grad=True)\n",
      "epoch 400 loss = 280.40919971466064;\n",
      "mode_hat tensor(0.1369, requires_grad=True)\n",
      "ltscale_hat tensor(1.4565, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8760, requires_grad=True)\n",
      "epoch 500 loss = 288.1507954597473;\n",
      "mode_hat tensor(0.1413, requires_grad=True)\n",
      "ltscale_hat tensor(1.4810, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6168, requires_grad=True)\n",
      "epoch 600 loss = 294.00060534477234;\n",
      "mode_hat tensor(0.1430, requires_grad=True)\n",
      "ltscale_hat tensor(1.4884, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3806, requires_grad=True)\n",
      "epoch 700 loss = 303.4519467353821;\n",
      "mode_hat tensor(0.1743, requires_grad=True)\n",
      "ltscale_hat tensor(1.5250, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2011, requires_grad=True)\n",
      "epoch 800 loss = 340.1079486608505;\n",
      "mode_hat tensor(0.1714, requires_grad=True)\n",
      "ltscale_hat tensor(1.5543, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0496, requires_grad=True)\n",
      "epoch 900 loss = 314.28826236724854;\n",
      "mode_hat tensor(0.1788, requires_grad=True)\n",
      "ltscale_hat tensor(1.5723, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0570, requires_grad=True)\n",
      "Final mean_losses: 304.2037184608889\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(0.1747, requires_grad=True)), ('t_scale_raw', tensor(1.5669, requires_grad=True)), ('t_part', tensor([ 8.8601e-01,  4.7847e+00,  5.7327e+00, -2.7443e+00, -7.0345e+00,\n",
      "        -2.7965e-01,  1.7936e+00,  7.6959e-01,  9.2956e+00,  2.3960e+00,\n",
      "         2.3222e+01,  2.2996e+00, -9.0963e+00,  3.2491e+00, -2.6952e+00,\n",
      "         9.9403e-01, -2.4417e+00,  8.6394e-01,  8.6141e-03, -1.0329e+01,\n",
      "        -1.5512e+01,  9.0329e+00, -2.4240e+00,  7.3921e+00,  1.2922e+00,\n",
      "        -3.1701e+00,  3.6661e+00, -4.6863e+00, -2.9399e+00,  2.6662e+00,\n",
      "        -2.0968e-01, -6.0270e+00, -6.0487e+00,  1.1886e+01,  6.5892e+00,\n",
      "         3.7931e+00, -5.6874e+00, -1.4731e+01, -1.7481e+00, -1.6104e+00,\n",
      "        -9.1852e+00,  6.5241e+00,  1.2161e+00,  3.5243e+00],\n",
      "       requires_grad=True))]), 'logPosterior': tensor(-1090329.6250, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 2.5656e+04, -0.0000e+00,  5.0746e+02,  ...,  2.0923e+02,\n",
      "          8.1558e+01,  8.8620e+02],\n",
      "        [-0.0000e+00,  4.2867e+01, -9.2031e-02,  ..., -2.8082e-01,\n",
      "         -1.2421e-01, -2.7456e-01],\n",
      "        [ 5.0746e+02, -9.2031e-02,  5.0751e+02,  ..., -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        ...,\n",
      "        [ 2.0923e+02, -2.8082e-01, -0.0000e+00,  ...,  2.0924e+02,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        [ 8.1558e+01, -1.2421e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          8.1609e+01, -0.0000e+00],\n",
      "        [ 8.8620e+02, -2.7456e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "         -0.0000e+00,  8.8624e+02]], grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[ 1.2277,  0.5275],\n",
      "        [ 0.5275, 42.8569]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([-4.8419e+04, -1.3789e+00, -5.9028e+02, -1.5337e+02, -5.0154e+03,\n",
      "         1.7502e+03,  1.6407e+03,  2.9808e+02, -3.1050e+02, -2.8622e+03,\n",
      "        -1.3473e+04,  6.4878e+02, -3.9751e+04, -2.6911e+02,  4.9928e+03,\n",
      "        -4.0861e+01,  1.7419e+03, -1.4362e+02,  4.8814e+02,  5.9101e+03,\n",
      "         4.5724e+03,  1.2157e+03,  1.9218e+03,  2.3246e+03,  4.9657e+03,\n",
      "        -8.9875e+03, -7.8246e+02, -1.5254e+04, -4.4011e+02,  4.3373e+02,\n",
      "         2.1155e+01,  8.4051e+02,  3.4343e+03,  2.1352e+03, -9.5333e+02,\n",
      "        -9.0369e+02,  1.0310e+01,  4.0528e+03,  8.0427e+01,  2.8653e+03,\n",
      "        -6.3097e+02,  2.3138e+03, -6.1092e+02, -3.2684e+03, -5.9436e+02,\n",
      "        -2.0425e+03], grad_fn=<CatBackward>), 'df': tensor(3.7971, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.6052, -4.6052], requires_grad=True), 'latentpsiraw': tensor([-8.3033], requires_grad=True)}\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "full_tmode:\n",
      "tensor([ 8.8601e-01,  4.7847e+00,  5.7327e+00, -2.7443e+00, -7.0345e+00,\n",
      "        -2.7965e-01,  1.7936e+00,  7.6959e-01,  9.2956e+00,  2.3960e+00,\n",
      "         2.3222e+01,  2.2996e+00, -9.0963e+00,  3.2491e+00, -2.6952e+00,\n",
      "         9.9403e-01, -2.4417e+00,  8.6394e-01,  8.6141e-03, -1.0329e+01,\n",
      "        -1.5512e+01,  9.0329e+00, -2.4240e+00,  7.3921e+00,  1.2922e+00,\n",
      "        -3.1701e+00,  3.6661e+00, -4.6863e+00, -2.9399e+00,  2.6662e+00,\n",
      "        -2.0968e-01, -6.0270e+00, -6.0487e+00,  1.1886e+01,  6.5892e+00,\n",
      "         3.7931e+00, -5.6874e+00, -1.4731e+01, -1.7481e+00, -1.6104e+00,\n",
      "        -9.1852e+00,  6.5241e+00,  1.2161e+00,  3.5243e+00],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-8.3033], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.07735950499773026\n",
      "ltscale_hat:\n",
      "1.5668593645095825\n",
      "mode_hat:\n",
      "0.17471498250961304\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 1.0512,  4.9847,  5.9340, -2.5476])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 32277.82794904709;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 loss = 85827.33444678783;\n",
      "epoch 200 loss = 101442.94301748276;\n",
      "epoch 300 loss = 8337.82966041565;\n",
      "epoch 400 loss = 72325.2259523496;\n",
      "epoch 500 loss = 100788.70821733028;\n",
      "Final mean_losses: 76021.42094581324\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "auto_loc:\n",
      "tensor([-0.1286, -0.1454,  0.8424,  0.4570,  0.8210,  0.7516, -0.7363, -0.7544,\n",
      "         0.0682,  0.6024,  0.3472,  0.7339,  0.5787,  0.7895,  0.6839, -0.7577,\n",
      "         0.7271, -0.6160,  0.4209, -0.6036,  0.4404,  0.2871, -0.8692, -0.7629,\n",
      "         0.8747, -0.6974,  0.7736,  0.5433, -0.6570,  0.8321, -0.7912, -0.6769,\n",
      "         0.7382,  0.0127, -0.8614, -0.8086,  0.7890,  0.8591,  0.6954, -0.8303,\n",
      "        -0.7945, -0.5955, -0.4325, -0.7982,  0.6247,  0.5853,  0.7149],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.6019, 0.2323, 1.1620, 0.7059, 1.0953, 1.1466, 0.9332, 0.9060, 0.6863,\n",
      "        0.8692, 0.8831, 1.1473, 1.0702, 1.1325, 1.0227, 1.0927, 0.9832, 0.9737,\n",
      "        0.8464, 0.9516, 0.8031, 0.7454, 1.3488, 1.1350, 1.0589, 0.8559, 0.9564,\n",
      "        0.9209, 0.9293, 1.0397, 1.0885, 0.9659, 1.0602, 0.7759, 0.9922, 1.0258,\n",
      "        0.9909, 1.1696, 1.1151, 1.0930, 1.1249, 0.8387, 0.8377, 1.0960, 1.0111,\n",
      "        0.8351, 1.0232], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([0.6191, 0.3141, 0.0586, 0.5220])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 84.7675107717514;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay -7100\n",
      "yay -7160\n",
      "yay -7220\n",
      "yay -7280\n",
      "yay -7340\n",
      "epoch 100 loss = 88.25899755954742;\n",
      "mode_hat tensor(0.2620, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3771, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0352, requires_grad=True)\n",
      "yay -7400\n",
      "yay -7460\n",
      "yay -7520\n",
      "yay -7580\n",
      "yay -7640\n",
      "epoch 200 loss = 63.834299206733704;\n",
      "mode_hat tensor(0.4747, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8357, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3719, requires_grad=True)\n",
      "yay -7700\n",
      "yay -7760\n",
      "yay -7820\n",
      "yay -7880\n",
      "yay -7940\n",
      "epoch 300 loss = 65.02041149139404;\n",
      "mode_hat tensor(0.5221, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3203, requires_grad=True)\n",
      "ldfraw_hat tensor(0.8346, requires_grad=True)\n",
      "yay -8000\n",
      "yay -8060\n",
      "yay -8120\n",
      "yay -8180\n",
      "yay -8240\n",
      "epoch 400 loss = 42.81996393203735;\n",
      "mode_hat tensor(0.4960, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7461, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1736, requires_grad=True)\n",
      "yay -8300\n",
      "yay -8360\n",
      "yay -8420\n",
      "yay -8480\n",
      "yay -8540\n",
      "epoch 500 loss = 53.25141000747681;\n",
      "mode_hat tensor(0.4825, requires_grad=True)\n",
      "ltscale_hat tensor(-2.0483, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4123, requires_grad=True)\n",
      "yay -8600\n",
      "yay -8660\n",
      "yay -8720\n",
      "yay -8780\n",
      "yay -8840\n",
      "epoch 600 loss = 33.342132568359375;\n",
      "mode_hat tensor(0.4965, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2247, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4674, requires_grad=True)\n",
      "yay -8900\n",
      "yay -8960\n",
      "yay -9020\n",
      "yay -9080\n",
      "Final mean_losses: 810.2778624244378\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(0.4692, requires_grad=True)), ('t_scale_raw', tensor(-2.2578, requires_grad=True)), ('t_part', tensor([-0.0733,  0.2425, -0.1588, -0.2239,  0.1235, -0.0608, -0.2537, -0.0502],\n",
      "       grad_fn=<IndexSelectBackward>))]), 'logPosterior': tensor(33.1883, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 4.5681e+03, -0.0000e+00,  5.6092e+02,  8.0109e+01,  1.2095e+02,\n",
      "          2.3045e+03,  2.3332e+02,  1.3878e+02,  1.4741e+02,  9.8211e+02],\n",
      "        [-0.0000e+00,  2.2939e+00,  1.1801e+00, -3.0483e+00,  2.3235e+00,\n",
      "          2.9244e+00, -1.8943e+00,  9.8674e-01,  3.1137e+00,  8.1919e-01],\n",
      "        [ 5.6092e+02,  1.1801e+00,  5.7945e+02, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 8.0109e+01, -3.0483e+00, -0.0000e+00,  9.2623e+01, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.2095e+02,  2.3235e+00, -0.0000e+00, -0.0000e+00,  1.3695e+02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3045e+03,  2.9244e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          2.3178e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3332e+02, -1.8943e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  2.5055e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.3878e+02,  9.8674e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  1.5755e+02, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.4741e+02,  3.1137e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  1.5942e+02, -0.0000e+00],\n",
      "        [ 9.8211e+02,  8.1919e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  1.0010e+03]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[118.3959,  -6.2534],\n",
      "        [ -6.2534,   2.0661]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([-44.2313,  -1.7757,  -6.1930,  18.3515, -12.8594, -17.2398,  10.2109,\n",
      "         -5.1542, -18.9972,  -4.2651], grad_fn=<CatBackward>), 'df': tensor(7.4426, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.1696, -4.1774], requires_grad=True), 'latentpsiraw': tensor([-7.3589], requires_grad=True)}\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "latentpsi:\n",
      "tensor([-7.3589], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.5548090934753418\n",
      "ltscale_hat:\n",
      "-2.257827043533325\n",
      "mode_hat:\n",
      "0.4691668748855591\n",
      "thetapsi:\n",
      "tensor([-4.1696, -4.1774], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([0.6191, 0.3141, 0.0586, 0.5220])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 3091.9998111724854;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 194.01118803024292;\n",
      "mode_hat tensor(0.2455, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5038, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5055, requires_grad=True)\n",
      "epoch 200 loss = 142.37295067310333;\n",
      "mode_hat tensor(0.2517, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9876, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9933, requires_grad=True)\n",
      "epoch 300 loss = 198.52970480918884;\n",
      "mode_hat tensor(0.2631, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3673, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4263, requires_grad=True)\n",
      "epoch 400 loss = 192.56820702552795;\n",
      "mode_hat tensor(0.2643, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4199, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5473, requires_grad=True)\n",
      "epoch 500 loss = 110.57224297523499;\n",
      "mode_hat tensor(0.2735, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4243, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5903, requires_grad=True)\n",
      "epoch 600 loss = 203.77487063407898;\n",
      "mode_hat tensor(0.2492, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4312, requires_grad=True)\n",
      "ldfraw_hat tensor(1.6124, requires_grad=True)\n",
      "epoch 700 loss = 173.37268590927124;\n",
      "mode_hat tensor(0.2642, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4391, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5594, requires_grad=True)\n",
      "epoch 800 loss = 235.56715667247772;\n",
      "mode_hat tensor(0.2827, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4418, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5625, requires_grad=True)\n",
      "Final mean_losses: 192.4331450563047\n",
      "save_data {'ahat_data': OrderedDict([('modal_effect', tensor(0.2827, requires_grad=True)), ('t_scale_raw', tensor(-1.4418, requires_grad=True)), ('t_part', tensor([ 0.3206,  0.0628, -0.2396,  0.2347,  0.0607,  0.4718,  0.4664,  0.3076,\n",
      "         0.3065, -0.0357,  0.3863, -0.1660,  0.3228, -0.6273,  0.2747,  0.4062,\n",
      "         0.3328,  0.6870,  1.0432, -0.3010, -0.2653,  0.3115,  0.2967,  0.4184,\n",
      "        -0.0492, -0.0645,  0.0649,  0.6712,  0.4053,  0.8469, -0.0279, -0.2684,\n",
      "        -0.1941,  0.1087,  0.7923,  0.3674, -0.0609,  0.1129,  0.4268,  0.0174,\n",
      "        -0.4692, -0.1036,  0.5392,  0.1374], requires_grad=True))]), 'logPosterior': tensor(-2976.5312, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 2.5656e+04, -0.0000e+00,  1.1958e+02,  ...,  9.2041e+02,\n",
      "          1.7594e+02,  2.0923e+02],\n",
      "        [-0.0000e+00,  2.4731e+01, -2.6579e+00,  ...,  1.0222e+00,\n",
      "         -3.2363e+00, -1.3623e+00],\n",
      "        [ 1.1958e+02, -2.6579e+00,  1.2549e+02,  ..., -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.2041e+02,  1.0222e+00, -0.0000e+00,  ...,  9.2824e+02,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.7594e+02, -3.2363e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          1.7923e+02, -0.0000e+00],\n",
      "        [ 2.0923e+02, -1.3623e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "         -0.0000e+00,  2.1685e+02]], grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[244.2042,  47.0692],\n",
      "        [ 47.0692,  23.5863]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([-1.8805e+03, -2.5576e+00, -4.1777e+01,  1.9750e+01,  1.0116e+03,\n",
      "        -1.0174e+02,  2.4476e+00, -1.2103e+02, -1.1681e+01,  9.5570e-01,\n",
      "        -2.4556e+00, -5.4202e+01,  3.3509e+00,  7.1228e+01, -1.0798e+02,\n",
      "         3.1852e+02,  1.8698e+01, -5.1978e+01,  5.2675e+00, -9.6273e+01,\n",
      "        -1.1797e+02,  3.6484e+02,  1.2786e+02, -2.9193e+01, -7.9165e+02,\n",
      "        -3.5783e+03,  5.1628e+02,  5.5738e+02,  5.2616e+01, -7.5409e+01,\n",
      "        -1.6013e+01, -3.9767e+02,  6.6628e+01,  2.2035e+01,  5.6980e+01,\n",
      "        -2.3966e+02, -3.3022e+02, -3.6664e+01, -1.2264e+02,  1.9470e+02,\n",
      "         8.2131e+01,  1.4753e+02,  3.8844e+01,  8.1839e+02, -1.4580e+02,\n",
      "         4.2199e+01], grad_fn=<CatBackward>), 'df': tensor(7.4757, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.6050, -4.6051], requires_grad=True), 'latentpsiraw': tensor([-7.1304], requires_grad=True)}\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "full_tmode:\n",
      "tensor([ 0.3206,  0.0628, -0.2396,  0.2347,  0.0607,  0.4718,  0.4664,  0.3076,\n",
      "         0.3065, -0.0357,  0.3863, -0.1660,  0.3228, -0.6273,  0.2747,  0.4062,\n",
      "         0.3328,  0.6870,  1.0432, -0.3010, -0.2653,  0.3115,  0.2967,  0.4184,\n",
      "        -0.0492, -0.0645,  0.0649,  0.6712,  0.4053,  0.8469, -0.0279, -0.2684,\n",
      "        -0.1941,  0.1087,  0.7923,  0.3674, -0.0609,  0.1129,  0.4268,  0.0174,\n",
      "        -0.4692, -0.1036,  0.5392,  0.1374], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-7.1304], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.5625447034835815\n",
      "ltscale_hat:\n",
      "-1.441835880279541\n",
      "mode_hat:\n",
      "0.2827146649360657\n",
      "thetapsi:\n",
      "tensor([-4.6050, -4.6051], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([0.6191, 0.3141, 0.0586, 0.5220])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 11226.094002403319;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 loss = 2123.1036526858807;\n",
      "epoch 200 loss = 1917.6392922997475;\n",
      "epoch 300 loss = 2640.5276517271996;\n",
      "epoch 400 loss = 1439.5709319710732;\n",
      "epoch 500 loss = 76.02020066976547;\n",
      "epoch 600 loss = 1283.2291948795319;\n",
      "epoch 700 loss = 772.2495801448822;\n",
      "epoch 800 loss = 298.9580018520355;\n",
      "epoch 900 loss = 276.5695824623108;\n",
      "epoch 1000 loss = 126.24917888641357;\n",
      "epoch 1100 loss = 112.3100129365921;\n",
      "epoch 1200 loss = 185.72681605815887;\n",
      "epoch 1300 loss = 88.80627965927124;\n",
      "epoch 1400 loss = 179.84647369384766;\n",
      "epoch 1500 loss = 616.3581110239029;\n",
      "epoch 1600 loss = 138.17783987522125;\n",
      "epoch 1700 loss = 149.26642513275146;\n",
      "epoch 1800 loss = 44.31414294242859;\n",
      "epoch 1900 loss = 298.64939641952515;\n",
      "epoch 2000 loss = 60.13571286201477;\n",
      "epoch 2100 loss = 159.94102871418;\n",
      "epoch 2200 loss = 973.9959738254547;\n",
      "Final mean_losses: 201.29394918774963\n",
      "save_data {}\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "auto_loc:\n",
      "tensor([ 0.4713, -2.9148,  2.3173,  0.0167, -0.0255, -0.0850,  0.0154, -0.0569,\n",
      "         0.0622,  0.0728,  0.0131,  0.0312, -0.0519,  0.0875, -0.0799,  0.0231,\n",
      "        -0.1064,  0.0263,  0.1038,  0.0245,  0.0777,  0.1193, -0.1130, -0.0525,\n",
      "         0.0445,  0.0741,  0.0318, -0.0584, -0.0396, -0.0102,  0.0202,  0.0975,\n",
      "         0.1570, -0.0843, -0.0532, -0.0697,  0.0096,  0.0856,  0.0499, -0.0633,\n",
      "         0.0126,  0.0672,  0.0146, -0.0840, -0.0512,  0.0711, -0.0317],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0280, 0.3801, 0.7912, 0.1788, 0.1686, 0.2146, 0.1332, 0.1285, 0.2007,\n",
      "        0.1977, 0.1491, 0.1451, 0.1497, 0.1703, 0.1962, 0.1793, 0.2462, 0.1659,\n",
      "        0.1558, 0.1753, 0.2371, 0.2536, 0.2120, 0.1974, 0.1566, 0.1772, 0.1873,\n",
      "        0.1659, 0.1743, 0.1634, 0.2045, 0.1890, 0.2303, 0.1935, 0.2356, 0.1999,\n",
      "        0.1496, 0.2391, 0.1571, 0.1624, 0.1599, 0.1757, 0.1913, 0.2430, 0.1870,\n",
      "        0.2083, 0.1335], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [tdom_fat_params,ndom_fat_params,tdom_norm_params,ndom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,filename=\"testresults/demoT_2.csv\")\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
