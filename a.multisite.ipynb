{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-8.4437,  0.4220, -0.4173,  2.5502])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 10 40.0\n",
      "complaint 9 assert approx_eq: tensor([[ 40],\n",
      "        [158],\n",
      "        [317]]) \n",
      "              1.. tensor([[1066.8685],\n",
      "        [ 896.7516],\n",
      "        [-922.5371]], grad_fn=<IndexBackward>) tensor([[-1102.7489],\n",
      "        [ -929.5502],\n",
      "        [  956.1518]], grad_fn=<IndexBackward>) tensor([[ 346.7514],\n",
      "        [ 327.2442],\n",
      "        [-330.3512]], grad_fn=<IndexBackward>) tensor([[-310.8853],\n",
      "        [-294.2313],\n",
      "        [ 296.9854]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0143],\n",
      "        [ 0.2143],\n",
      "        [ 0.2489]], grad_fn=<IndexBackward>)\n",
      "complaint 8 assert approx_eq: tensor([[ 40],\n",
      "        [158],\n",
      "        [317]]) \n",
      "              1.. tensor([[1066.8685],\n",
      "        [ 896.7516],\n",
      "        [-923.7626]], grad_fn=<IndexBackward>) tensor([[-1102.7489],\n",
      "        [ -929.5502],\n",
      "        [  956.9983]], grad_fn=<IndexBackward>) tensor([[ 346.7514],\n",
      "        [ 327.2442],\n",
      "        [-330.4974]], grad_fn=<IndexBackward>) tensor([[-310.8853],\n",
      "        [-294.2313],\n",
      "        [ 296.9854]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0143],\n",
      "        [ 0.2143],\n",
      "        [-0.2763]], grad_fn=<IndexBackward>)\n",
      "complaint 7 assert approx_eq: tensor([[ 40],\n",
      "        [158],\n",
      "        [317]]) \n",
      "              1.. tensor([[1066.8685],\n",
      "        [ 896.7516],\n",
      "        [-923.7626]], grad_fn=<IndexBackward>) tensor([[-1102.7489],\n",
      "        [ -929.5502],\n",
      "        [  956.9983]], grad_fn=<IndexBackward>) tensor([[ 346.7514],\n",
      "        [ 327.2442],\n",
      "        [-330.4974]], grad_fn=<IndexBackward>) tensor([[-310.8853],\n",
      "        [-294.2313],\n",
      "        [ 296.9854]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0143],\n",
      "        [ 0.2143],\n",
      "        [-0.2763]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1446.763067305088;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint 6 assert approx_eq: tensor([[ 40],\n",
      "        [158],\n",
      "        [317]]) \n",
      "              1.. tensor([[1068.6382],\n",
      "        [ 897.9683],\n",
      "        [-923.7897]], grad_fn=<IndexBackward>) tensor([[-1104.4907],\n",
      "        [ -930.8562],\n",
      "        [  956.5428]], grad_fn=<IndexBackward>) tensor([[ 347.5029],\n",
      "        [ 327.9205],\n",
      "        [-331.0340]], grad_fn=<IndexBackward>) tensor([[-311.6638],\n",
      "        [-294.9760],\n",
      "        [ 297.4407]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0135],\n",
      "        [ 0.0565],\n",
      "        [-0.8402]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[ 40],\n",
      "        [158],\n",
      "        [317]]) \n",
      "              1.. tensor([[1068.6382],\n",
      "        [ 897.9683],\n",
      "        [-922.5642]], grad_fn=<IndexBackward>) tensor([[-1104.4907],\n",
      "        [ -930.8562],\n",
      "        [  955.6967]], grad_fn=<IndexBackward>) tensor([[ 347.5029],\n",
      "        [ 327.9205],\n",
      "        [-330.8875]], grad_fn=<IndexBackward>) tensor([[-311.6638],\n",
      "        [-294.9760],\n",
      "        [ 297.4407]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0135],\n",
      "        [ 0.0565],\n",
      "        [-0.3144]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[ 40],\n",
      "        [158],\n",
      "        [317]]) \n",
      "              1.. tensor([[1068.6382],\n",
      "        [ 897.9683],\n",
      "        [-922.5642]], grad_fn=<IndexBackward>) tensor([[-1104.4907],\n",
      "        [ -930.8562],\n",
      "        [  955.6967]], grad_fn=<IndexBackward>) tensor([[ 347.5029],\n",
      "        [ 327.9205],\n",
      "        [-330.8875]], grad_fn=<IndexBackward>) tensor([[-311.6638],\n",
      "        [-294.9760],\n",
      "        [ 297.4407]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0135],\n",
      "        [ 0.0565],\n",
      "        [-0.3144]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "complaint 3 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 897.6887],\n",
      "        [-922.3546]], grad_fn=<IndexBackward>) tensor([[-930.4765],\n",
      "        [ 955.7419]], grad_fn=<IndexBackward>) tensor([[ 327.4754],\n",
      "        [-330.4477]], grad_fn=<IndexBackward>) tensor([[-294.5240],\n",
      "        [ 297.1035]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.1635],\n",
      "        [0.0431]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 897.6887],\n",
      "        [-923.5800]], grad_fn=<IndexBackward>) tensor([[-930.4765],\n",
      "        [ 956.5881]], grad_fn=<IndexBackward>) tensor([[ 327.4754],\n",
      "        [-330.5940]], grad_fn=<IndexBackward>) tensor([[-294.5240],\n",
      "        [ 297.1035]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.1635],\n",
      "        [-0.4823]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 897.6887],\n",
      "        [-922.3546]], grad_fn=<IndexBackward>) tensor([[-930.4765],\n",
      "        [ 955.7419]], grad_fn=<IndexBackward>) tensor([[ 327.4754],\n",
      "        [-330.4477]], grad_fn=<IndexBackward>) tensor([[-294.5240],\n",
      "        [ 297.1035]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.1635],\n",
      "        [0.0431]], grad_fn=<IndexBackward>)\n",
      "yay 1 fix_m_grad\n",
      "complaint 0 assert approx_eq: tensor([[ 40],\n",
      "        [158],\n",
      "        [317]]) \n",
      "              1.. tensor([[1068.3795],\n",
      "        [ 898.0801],\n",
      "        [-922.6973]], grad_fn=<IndexBackward>) tensor([[-1104.2321],\n",
      "        [ -930.8619],\n",
      "        [  955.8615]], grad_fn=<IndexBackward>) tensor([[ 346.6307],\n",
      "        [ 327.1374],\n",
      "        [-330.0996]], grad_fn=<IndexBackward>) tensor([[-310.7943],\n",
      "        [-294.1519],\n",
      "        [ 296.6551]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0161],\n",
      "        [ 0.2038],\n",
      "        [-0.2803]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "complaint -20\n",
      "yay -20\n",
      "complaint -40\n",
      "complaint -60\n",
      "complaint -80\n",
      "yay -80\n",
      "complaint -100\n",
      "complaint -120\n",
      "yay -140\n",
      "complaint -140\n",
      "complaint -160\n",
      "complaint -180\n",
      "yay -200\n",
      "complaint -200\n",
      "complaint -220\n",
      "complaint -240\n",
      "yay -260\n",
      "complaint -260\n",
      "epoch 100 loss = 1488.1572376290958;\n",
      "mode_hat tensor(0.2310, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2083, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1012, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "complaint -280\n",
      "yay -440\n",
      "complaint -300\n",
      "complaint -320\n",
      "yay -500\n",
      "complaint -340\n",
      "complaint -360\n",
      "complaint -380\n",
      "yay -560\n",
      "complaint -400\n",
      "complaint -420\n",
      "epoch 200 loss = 1245.8883923093476;\n",
      "mode_hat tensor(0.3613, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4527, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1669, requires_grad=True)\n",
      "complaint -440\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "complaint -460\n",
      "yay -860\n",
      "complaint -480\n",
      "epoch 300 loss = 1246.2800093491871;\n",
      "mode_hat tensor(0.4778, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7047, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2926, requires_grad=True)\n",
      "complaint -500\n",
      "yay -920\n",
      "complaint -520\n",
      "complaint -540\n",
      "complaint -560\n",
      "yay -980\n",
      "complaint -580\n",
      "complaint -600\n",
      "complaint -620\n",
      "yay -1040\n",
      "complaint -640\n",
      "complaint -660\n",
      "complaint -680\n",
      "yay -1100\n",
      "complaint -700\n",
      "complaint -720\n",
      "complaint -740\n",
      "yay -1160\n",
      "complaint -760\n",
      "epoch 400 loss = 1217.0112354556718;\n",
      "mode_hat tensor(0.5337, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9681, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4072, requires_grad=True)\n",
      "complaint -780\n",
      "complaint -800\n",
      "yay -1220\n",
      "complaint -820\n",
      "complaint -840\n",
      "complaint -860\n",
      "yay -1280\n",
      "complaint -880\n",
      "complaint -900\n",
      "yay -1340\n",
      "complaint -920\n",
      "complaint -940\n",
      "complaint -960\n",
      "yay -1400\n",
      "complaint -980\n",
      "complaint -1000\n",
      "yay -1460\n",
      "epoch 500 loss = 1662.7399561405182;\n",
      "mode_hat tensor(0.4701, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2864, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4675, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "Final mean_losses: 1381.7900486024303\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-3.8096, -3.7416], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.49501821398735046\n",
      "ltscale_hat:\n",
      "-1.5065219402313232\n",
      "mode_hat:\n",
      "0.4892774522304535\n",
      "0 3 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-8.4437,  0.4220, -0.4173,  2.5502])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 10 40.0\n",
      "epoch 0 loss = 13025.831592261791;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 11681.137141843636;\n",
      "mode_hat tensor(0.1272, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4954, requires_grad=True)\n",
      "epoch 200 loss = 17369.70258924365;\n",
      "mode_hat tensor(0.1445, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9878, requires_grad=True)\n",
      "epoch 300 loss = 7932.741356372833;\n",
      "mode_hat tensor(0.1240, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4738, requires_grad=True)\n",
      "epoch 400 loss = 2574.8007148504257;\n",
      "mode_hat tensor(0.2033, requires_grad=True)\n",
      "ltscale_hat tensor(-2.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9540, requires_grad=True)\n",
      "epoch 500 loss = 5254.875473896662;\n",
      "mode_hat tensor(0.2751, requires_grad=True)\n",
      "ltscale_hat tensor(-2.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(2.4234, requires_grad=True)\n",
      "epoch 600 loss = 4202.674038628737;\n",
      "mode_hat tensor(0.2843, requires_grad=True)\n",
      "ltscale_hat tensor(-2.9987, requires_grad=True)\n",
      "ldfraw_hat tensor(2.8862, requires_grad=True)\n",
      "epoch 700 loss = 2412.519802749157;\n",
      "mode_hat tensor(0.3485, requires_grad=True)\n",
      "ltscale_hat tensor(-3.4806, requires_grad=True)\n",
      "ldfraw_hat tensor(3.3203, requires_grad=True)\n",
      "epoch 800 loss = 8178.467927793662;\n",
      "mode_hat tensor(0.3933, requires_grad=True)\n",
      "ltscale_hat tensor(-3.9621, requires_grad=True)\n",
      "ldfraw_hat tensor(3.6999, requires_grad=True)\n",
      "epoch 900 loss = 4251.488447646299;\n",
      "mode_hat tensor(0.3207, requires_grad=True)\n",
      "ltscale_hat tensor(-4.4410, requires_grad=True)\n",
      "ldfraw_hat tensor(3.9659, requires_grad=True)\n",
      "epoch 1000 loss = 3719.62371096015;\n",
      "mode_hat tensor(0.3102, requires_grad=True)\n",
      "ltscale_hat tensor(-4.9177, requires_grad=True)\n",
      "ldfraw_hat tensor(4.0169, requires_grad=True)\n",
      "epoch 1100 loss = 1818.8218255639076;\n",
      "mode_hat tensor(0.3686, requires_grad=True)\n",
      "ltscale_hat tensor(-5.4001, requires_grad=True)\n",
      "ldfraw_hat tensor(4.0154, requires_grad=True)\n",
      "Final mean_losses: 6646.01586452148\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "4.001876354217529\n",
      "ldfraw_sigma:\n",
      "0.6449609994888306\n",
      "ltscale_hat:\n",
      "-5.445796966552734\n",
      "ltscale_sigma:\n",
      "0.8095577955245972\n",
      "mode_hat:\n",
      "0.3635779619216919\n",
      "mode_sigma:\n",
      "0.12591972947120667\n",
      "t_part_hat:\n",
      "tensor([-0.4527,  0.1853, -0.3554,  0.6086, -0.2011,  0.6860,  0.4742,  0.5228,\n",
      "         0.0318,  0.5207], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.9701, 0.9499, 0.8979, 0.9292, 0.9279, 1.0594, 0.9667, 0.7933, 1.0893,\n",
      "        0.8206], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 3 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-8.4437,  0.4220, -0.4173,  2.5502])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 10 40.0\n",
      "complaint 9 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 896.7516],\n",
      "        [-924.7266]], grad_fn=<IndexBackward>) tensor([[-929.5502],\n",
      "        [ 957.6640]], grad_fn=<IndexBackward>) tensor([[ 327.2442],\n",
      "        [-329.4162]], grad_fn=<IndexBackward>) tensor([[-294.2313],\n",
      "        [ 296.9854]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.2143],\n",
      "        [0.5066]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1352.3698181509972;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint 8 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 895.4531],\n",
      "        [-923.4688]], grad_fn=<IndexBackward>) tensor([[-928.1882],\n",
      "        [ 957.2695]], grad_fn=<IndexBackward>) tensor([[ 325.6601],\n",
      "        [-327.8274]], grad_fn=<IndexBackward>) tensor([[-292.6558],\n",
      "        [ 295.6894]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.2692],\n",
      "        [1.6628]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "complaint 7 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 893.8666],\n",
      "        [-928.7482]], grad_fn=<IndexBackward>) tensor([[-926.6276],\n",
      "        [ 961.3905]], grad_fn=<IndexBackward>) tensor([[ 324.1051],\n",
      "        [-327.0721]], grad_fn=<IndexBackward>) tensor([[-291.1407],\n",
      "        [ 294.4517]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.2035],\n",
      "        [0.0219]], grad_fn=<IndexBackward>)\n",
      "yay 1 fix_m_grad\n",
      "complaint 6 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 895.9781],\n",
      "        [-929.6562]], grad_fn=<IndexBackward>) tensor([[-927.6215],\n",
      "        [ 962.4933]], grad_fn=<IndexBackward>) tensor([[ 323.1616],\n",
      "        [-325.9661]], grad_fn=<IndexBackward>) tensor([[-289.7888],\n",
      "        [ 293.3764]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[1.7293],\n",
      "        [0.2474]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 893.2910],\n",
      "        [-931.1321]], grad_fn=<IndexBackward>) tensor([[-925.3022],\n",
      "        [ 963.9885]], grad_fn=<IndexBackward>) tensor([[ 321.7118],\n",
      "        [-324.9971]], grad_fn=<IndexBackward>) tensor([[-288.5009],\n",
      "        [ 292.3635]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[1.1997],\n",
      "        [0.2228]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 890.5535],\n",
      "        [-933.1568]], grad_fn=<IndexBackward>) tensor([[-922.9481],\n",
      "        [ 965.8628]], grad_fn=<IndexBackward>) tensor([[ 320.2094],\n",
      "        [-324.0416]], grad_fn=<IndexBackward>) tensor([[-287.1752],\n",
      "        [ 291.3100]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.6397],\n",
      "        [-0.0257]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 888.1161],\n",
      "        [-934.6132]], grad_fn=<IndexBackward>) tensor([[-920.8013],\n",
      "        [ 967.3454]], grad_fn=<IndexBackward>) tensor([[ 318.9706],\n",
      "        [-323.2476]], grad_fn=<IndexBackward>) tensor([[-286.0565],\n",
      "        [ 290.4643]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.2289],\n",
      "        [-0.0511]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 887.4262],\n",
      "        [-935.2511]], grad_fn=<IndexBackward>) tensor([[-920.0963],\n",
      "        [ 968.0217]], grad_fn=<IndexBackward>) tensor([[ 318.0075],\n",
      "        [-322.4251]], grad_fn=<IndexBackward>) tensor([[-285.0702],\n",
      "        [ 289.6052]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.2672],\n",
      "        [-0.0493]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 886.0414],\n",
      "        [-935.3004]], grad_fn=<IndexBackward>) tensor([[-919.0767],\n",
      "        [ 968.1202]], grad_fn=<IndexBackward>) tensor([[ 317.0879],\n",
      "        [-321.6624]], grad_fn=<IndexBackward>) tensor([[-284.2510],\n",
      "        [ 288.8118]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.1984],\n",
      "        [-0.0307]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[158],\n",
      "        [317]]) \n",
      "              1.. tensor([[ 883.6423],\n",
      "        [-935.2459]], grad_fn=<IndexBackward>) tensor([[-917.3899],\n",
      "        [ 968.1107]], grad_fn=<IndexBackward>) tensor([[ 316.1277],\n",
      "        [-320.9688]], grad_fn=<IndexBackward>) tensor([[-283.5161],\n",
      "        [ 288.0818]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-1.1359],\n",
      "        [-0.0222]], grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint 0\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 1429.1934242248535;\n",
      "mode_hat tensor(0.1717, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3080, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0824, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "complaint -20\n",
      "yay -560\n",
      "complaint -40\n",
      "epoch 200 loss = 1296.7572730183601;\n",
      "mode_hat tensor(0.3536, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5575, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1661, requires_grad=True)\n",
      "yay -620\n",
      "complaint -60\n",
      "yay -680\n",
      "complaint -80\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1158.7175547480583;\n",
      "mode_hat tensor(0.4092, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8724, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2502, requires_grad=True)\n",
      "complaint -100\n",
      "yay -920\n",
      "yay -980\n",
      "complaint -120\n",
      "yay -1040\n",
      "complaint -140\n",
      "yay -1100\n",
      "complaint -160\n",
      "yay -1160\n",
      "complaint -180\n",
      "epoch 400 loss = 1054.2524038553238;\n",
      "mode_hat tensor(0.4692, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1980, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3812, requires_grad=True)\n",
      "yay -1220\n",
      "complaint -200\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 1400.91815751791;\n",
      "mode_hat tensor(0.5872, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4148, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3395, requires_grad=True)\n",
      "Final mean_losses: 1374.5606760327785\n",
      "file exists: testresults/fit_amortized_laplace_0_N400_S10_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.3691, -4.2390], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.33947449922561646\n",
      "ltscale_hat:\n",
      "-1.4147655963897705\n",
      "mode_hat:\n",
      "0.5871638655662537\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-8.4437,  0.4220, -0.4173,  2.5502])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 10 40.0\n",
      "epoch 0 loss = 3772.5064467191696;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 9294.628442406654;\n",
      "mode_hat tensor(0.1355, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4907, requires_grad=True)\n",
      "epoch 200 loss = 8222.975570619106;\n",
      "mode_hat tensor(0.2328, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0042, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9615, requires_grad=True)\n",
      "epoch 300 loss = 5681.3104283213615;\n",
      "mode_hat tensor(0.2376, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5040, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4388, requires_grad=True)\n",
      "epoch 400 loss = 9912.901081204414;\n",
      "mode_hat tensor(0.3207, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9980, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8984, requires_grad=True)\n",
      "epoch 500 loss = 4702.9228991270065;\n",
      "mode_hat tensor(0.3621, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4815, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3388, requires_grad=True)\n",
      "Final mean_losses: 9818.059149681583\n",
      "file exists: testresults/fit_meanfield_0_N400_S10_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.338756561279297\n",
      "ldfraw_sigma:\n",
      "0.951603889465332\n",
      "ltscale_hat:\n",
      "-2.481454372406006\n",
      "ltscale_sigma:\n",
      "0.9551244974136353\n",
      "mode_hat:\n",
      "0.36208224296569824\n",
      "mode_sigma:\n",
      "0.5099238157272339\n",
      "t_part_hat:\n",
      "tensor([-0.1402,  0.0216, -0.0836,  0.1776, -0.0866,  0.1569,  0.2730,  0.2416,\n",
      "         0.0874,  0.0949], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([1.0617, 0.8655, 1.0949, 1.1100, 1.1090, 0.9814, 1.0954, 1.0364, 1.0383,\n",
      "        1.1321], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 3 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-8.4437,  0.4220, -0.4173,  2.5502])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "complaint 9 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-922.5371]], grad_fn=<IndexBackward>) tensor([[956.1518]], grad_fn=<IndexBackward>) tensor([[-330.3512]], grad_fn=<IndexBackward>) tensor([[296.9854]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.2489]], grad_fn=<IndexBackward>)\n",
      "complaint 8 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-923.7626]], grad_fn=<IndexBackward>) tensor([[956.9983]], grad_fn=<IndexBackward>) tensor([[-330.4974]], grad_fn=<IndexBackward>) tensor([[296.9854]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.2763]], grad_fn=<IndexBackward>)\n",
      "complaint 7 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-922.5371]], grad_fn=<IndexBackward>) tensor([[956.1518]], grad_fn=<IndexBackward>) tensor([[-330.3512]], grad_fn=<IndexBackward>) tensor([[296.9854]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.2489]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1325.7644735972085;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint 6 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-920.6213]], grad_fn=<IndexBackward>) tensor([[954.3544]], grad_fn=<IndexBackward>) tensor([[-329.5956]], grad_fn=<IndexBackward>) tensor([[296.2416]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.3791]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-920.6213]], grad_fn=<IndexBackward>) tensor([[954.3544]], grad_fn=<IndexBackward>) tensor([[-329.5956]], grad_fn=<IndexBackward>) tensor([[296.2416]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.3791]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-920.6213]], grad_fn=<IndexBackward>) tensor([[954.3544]], grad_fn=<IndexBackward>) tensor([[-329.5956]], grad_fn=<IndexBackward>) tensor([[296.2416]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.3791]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "complaint 3 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-921.1628]], grad_fn=<IndexBackward>) tensor([[954.9147]], grad_fn=<IndexBackward>) tensor([[-328.9849]], grad_fn=<IndexBackward>) tensor([[295.6142]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.3812]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-919.9397]], grad_fn=<IndexBackward>) tensor([[954.0692]], grad_fn=<IndexBackward>) tensor([[-328.8392]], grad_fn=<IndexBackward>) tensor([[295.6142]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.9045]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-919.9397]], grad_fn=<IndexBackward>) tensor([[954.0692]], grad_fn=<IndexBackward>) tensor([[-328.8392]], grad_fn=<IndexBackward>) tensor([[295.6142]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.9045]], grad_fn=<IndexBackward>)\n",
      "yay 1 fix_m_grad\n",
      "complaint 0 assert approx_eq: tensor([[317]]) \n",
      "              1.. tensor([[-919.4559]], grad_fn=<IndexBackward>) tensor([[954.0538]], grad_fn=<IndexBackward>) tensor([[-328.0976]], grad_fn=<IndexBackward>) tensor([[294.9955]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[1.4958]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "complaint -20\n",
      "complaint -40\n",
      "yay -260\n",
      "complaint -60\n",
      "complaint -80\n",
      "epoch 100 loss = 1291.239407300949;\n",
      "mode_hat tensor(0.3692, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4092, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0339, requires_grad=True)\n",
      "complaint -100\n",
      "yay -320\n",
      "complaint -120\n",
      "complaint -140\n",
      "complaint -160\n",
      "yay -380\n",
      "complaint -180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint -200\n",
      "complaint -220\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 1270.77910421292;\n",
      "mode_hat tensor(0.5358, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7685, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2138, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "complaint -240\n",
      "complaint -260\n",
      "yay -860\n",
      "complaint -280\n",
      "epoch 300 loss = 1284.9579036633174;\n",
      "mode_hat tensor(0.6193, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0945, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4719, requires_grad=True)\n",
      "complaint -300\n",
      "complaint -320\n",
      "yay -920\n",
      "complaint -340\n",
      "yay -980\n",
      "complaint -360\n",
      "complaint -380\n",
      "complaint -400\n",
      "yay -1040\n",
      "complaint -420\n",
      "complaint -440\n",
      "complaint -460\n",
      "yay -1100\n",
      "complaint -480\n",
      "complaint -500\n",
      "yay -1160\n",
      "complaint -520\n",
      "epoch 400 loss = 1289.756677031517;\n",
      "mode_hat tensor(0.6506, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3864, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6702, requires_grad=True)\n",
      "complaint -540\n",
      "yay -1220\n",
      "complaint -560\n",
      "complaint -580\n",
      "complaint -600\n",
      "yay -1280\n",
      "complaint -620\n",
      "complaint -640\n",
      "complaint -660\n",
      "yay -1340\n",
      "complaint -680\n",
      "yay -1400\n",
      "yay -1460\n",
      "complaint -700\n",
      "epoch 500 loss = 1343.067961215973;\n",
      "mode_hat tensor(0.6138, requires_grad=True)\n",
      "ltscale_hat tensor(-1.6386, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9238, requires_grad=True)\n",
      "Final mean_losses: 1383.8996618742053\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.5536, -4.4110], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.9238460063934326\n",
      "ltscale_hat:\n",
      "-1.6386003494262695\n",
      "mode_hat:\n",
      "0.6137701869010925\n",
      "0 3 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 3 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-8.4437,  0.4220, -0.4173,  2.5502])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "sizes torch.Size([400]) 400 50 8.0\n",
      "epoch 0 loss = 9248.765692512196;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 24984.209040323894;\n",
      "mode_hat tensor(0.2130, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4950, requires_grad=True)\n",
      "epoch 200 loss = 6701.423234244187;\n",
      "mode_hat tensor(0.2679, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9866, requires_grad=True)\n",
      "epoch 300 loss = 3802.033501287301;\n",
      "mode_hat tensor(0.3131, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4697, requires_grad=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-109b3cd55c3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                                         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"testresults/demoT_2.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                                         subsample_N = nsamps)\n\u001b[0m\u001b[0;32m     23\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maniter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnparticles\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mguidenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\multisiteT.py\u001b[0m in \u001b[0;36mtrainGuide\u001b[1;34m(guidename, nparticles, trueparams, filename, errors, subsample_N, N)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;31m##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Final mean_losses:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# get loss and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m# grab a trace from the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \"\"\"\n\u001b[0;32m     51\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[1;32m---> 52\u001b[1;33m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\infer\\enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[1;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \"\"\"\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mguide_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[0;32m     45\u001b[0m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyro\\poutine\\trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\multisiteT.py\u001b[0m in \u001b[0;36mmeanfield\u001b[1;34m(N, full_N, indices, x, full_x, errors, full_errors, maxError, save_data, weight, scalehyper, tailhyper)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mSUBSAMPLE_N\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[0mechs_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mechs_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m     \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[0mbase_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[0mmodal_effect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbase_scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"meanfield\"]#,\"unamortized_laplace\",\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "  for nsamps in [50,10]:#50]:\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [3,1]:#,5]:\n",
    "            for trueparams in [ndom_fat_params,]:#ndom_norm_params,tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,\n",
    "                                        filename=\"testresults/demoT_2.csv\",\n",
    "                                      \n",
    "                                        subsample_N = nsamps)\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "MCMC, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
