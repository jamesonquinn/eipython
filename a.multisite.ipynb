{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "One pair of ts, with pictures:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 257.47677397727966;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint 9 assert approx_eq( tensor([-4.1258e+00,  5.4003e+01,  1.4228e+02, -3.9691e-01,  8.5798e-02,\n",
      "         1.5827e+02, -3.9142e+01,  1.4334e+02, -2.2877e+02, -8.1054e+02,\n",
      "         3.0888e+02,  9.1695e+02, -2.5313e-02, -8.7465e+00,  1.5288e+02,\n",
      "        -7.6804e+01,  9.9370e+01, -3.4312e-02,  2.0037e+03,  2.4101e+01,\n",
      "         1.9645e+01,  4.3910e+02,  1.5797e-05,  4.8168e-02,  4.1783e+02,\n",
      "         9.6623e+02,  3.1752e+03,  7.2010e+00, -1.7388e-01, -1.7089e+00,\n",
      "         2.7563e+02, -7.3497e+00,  1.2755e+01, -2.2216e+01, -4.9741e+01,\n",
      "        -6.6355e+01, -1.5461e+03, -2.2583e+02,  3.8170e+03, -5.2850e+01,\n",
      "        -5.3396e+02,  8.2826e+00,  1.6243e-01, -2.7414e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 4.1924e+00, -5.4232e+01, -1.4293e+02,  3.9954e-01, -8.6207e-02,\n",
      "        -1.5846e+02,  3.9278e+01, -1.4353e+02,  2.2893e+02,  8.1110e+02,\n",
      "        -3.0968e+02, -9.1880e+02,  2.5885e-02,  8.9981e+00, -1.5350e+02,\n",
      "         7.7114e+01, -9.9724e+01,  3.4834e-02, -2.0066e+03, -2.4177e+01,\n",
      "        -1.9850e+01, -4.3945e+02, -1.6847e-05, -4.9045e-02, -4.1790e+02,\n",
      "        -9.6660e+02, -3.1774e+03, -7.4369e+00,  1.7440e-01,  1.7970e+00,\n",
      "        -2.7669e+02,  7.3534e+00, -1.3094e+01,  2.2288e+01,  4.9888e+01,\n",
      "         6.6411e+01,  1.5462e+03,  2.2604e+02, -3.8173e+03,  5.3526e+01,\n",
      "         5.3614e+02, -8.4546e+00, -1.6326e-01,  2.7459e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ -7.3469,  17.1870,  24.0815,  -3.3072,   1.9800,  24.3918, -15.3557,\n",
      "         23.6006, -27.4987, -42.2379,  31.0824,  45.3357,  -1.3418,  -9.7201,\n",
      "         24.6075, -19.3741,  21.1171,  -1.4742,  59.2567,  13.0202,  12.3829,\n",
      "         34.3295,   0.1195,   1.6558,  33.4649,  44.5396,  67.9326,   9.1444,\n",
      "         -2.5012,  -5.7041,  30.2409,  -8.6929,  11.0531, -12.6703, -16.5140,\n",
      "        -18.1565, -51.8331, -27.4359,  70.1530, -17.6517, -38.5727,   9.3976,\n",
      "          2.4505, -13.5352], grad_fn=<MulBackward0>) tensor([  7.2802, -16.9561, -23.4273,   3.3045,  -1.9796, -24.1929,  15.2196,\n",
      "        -23.4090,  27.3390,  41.6779, -30.2745, -43.4849,   1.3412,   9.4684,\n",
      "        -23.9828,  19.0644, -20.7639,   1.4736, -56.3958, -12.9439, -12.1785,\n",
      "        -33.9794,  -0.1195,  -1.6549, -33.4003, -44.1779, -65.7016,  -8.9086,\n",
      "          2.5007,   5.6160, -29.1824,   8.6893, -10.7143,  12.5983,  16.4766,\n",
      "         18.0999,  51.6583,  27.2276, -69.8167,  16.9777,  36.3880,  -9.2256,\n",
      "         -2.4497,  13.4909], grad_fn=<MulBackward0>)\n",
      "complaint 8 assert2 approx_eq( tensor([ 4.7684e-07,  1.7471e-03, -3.8147e-06,  7.1526e-07,  1.1921e-07,\n",
      "         0.0000e+00,  1.1539e-04, -3.8147e-06,  1.7166e-05, -2.2888e-05,\n",
      "         7.0572e-05,  4.9591e-05, -4.7684e-07,  0.0000e+00,  1.3351e-05,\n",
      "        -1.9073e-06,  7.6294e-06, -3.5763e-07, -2.6703e-05, -9.5367e-06,\n",
      "         7.6294e-06, -5.7220e-05, -3.2783e-07, -1.1921e-07, -1.5259e-05,\n",
      "         5.7220e-05,  3.2806e-04,  1.9073e-06, -7.1526e-07, -4.7684e-07,\n",
      "        -2.8610e-05,  0.0000e+00, -1.9073e-06, -4.7684e-06,  1.0954e-01,\n",
      "        -1.1063e-04, -4.5776e-05,  3.8147e-06,  3.4332e-04,  1.6785e-03,\n",
      "        -3.8147e-05, -1.9073e-06,  2.3842e-07,  1.6212e-05],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 7 dm.grad\n",
      "complaint 6 dtr.grad\n",
      "complaint 5 ddfr.grad\n",
      "complaint 4 assert approx_eq( tensor([-4.1535e+00,  5.3853e+01,  1.4200e+02, -4.0255e-01,  8.3819e-02,\n",
      "         1.5796e+02, -3.9263e+01,  1.4306e+02, -2.2915e+02, -8.1144e+02,\n",
      "         3.0841e+02,  9.1598e+02, -2.6211e-02, -8.7942e+00,  1.5258e+02,\n",
      "        -7.6994e+01,  9.9151e+01, -3.5414e-02,  2.0021e+03,  2.4015e+01,\n",
      "         1.9572e+01,  4.3851e+02,  1.0458e-05,  4.6854e-02,  4.1726e+02,\n",
      "         9.6522e+02,  3.1729e+03,  7.1663e+00, -1.7712e-01, -1.7251e+00,\n",
      "         2.7519e+02, -7.3890e+00,  1.2703e+01, -2.2299e+01, -5.0017e+01,\n",
      "        -6.6525e+01, -1.5475e+03, -2.2622e+02,  3.8144e+03, -5.3032e+01,\n",
      "        -5.3465e+02,  8.2429e+00,  1.5940e-01, -2.7509e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 4.2201e+00, -5.4083e+01, -1.4265e+02,  4.0520e-01, -8.4215e-02,\n",
      "        -1.5816e+02,  3.9399e+01, -1.4325e+02,  2.2931e+02,  8.1200e+02,\n",
      "        -3.0921e+02, -9.1783e+02,  2.6798e-02,  9.0455e+00, -1.5321e+02,\n",
      "         7.7303e+01, -9.9503e+01,  3.5948e-02, -2.0049e+03, -2.4091e+01,\n",
      "        -1.9775e+01, -4.3885e+02, -1.1147e-05, -4.7701e-02, -4.1732e+02,\n",
      "        -9.6559e+02, -3.1752e+03, -7.4001e+00,  1.7765e-01,  1.8133e+00,\n",
      "        -2.7625e+02,  7.3926e+00, -1.3040e+01,  2.2371e+01,  5.0119e+01,\n",
      "         6.6582e+01,  1.5476e+03,  2.2642e+02, -3.8148e+03,  5.3697e+01,\n",
      "         5.3684e+02, -8.4134e+00, -1.6021e-01,  2.7553e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ -7.4158,  17.2946,  24.2360,  -3.3470,   1.9790,  24.5533, -15.4828,\n",
      "         23.7564, -27.7148, -42.5589,  31.2872,  45.6361,  -1.3672,  -9.8048,\n",
      "         24.7663, -19.5292,  21.2529,  -1.5005,  59.6506,  13.0993,  12.4556,\n",
      "         34.5627,   0.1049,   1.6524,  33.6945,  44.8478,  68.3961,   9.1923,\n",
      "         -2.5351,  -5.7610,  30.4371,  -8.7723,  11.1139, -12.7783, -16.6652,\n",
      "        -18.3048, -52.2278, -27.6511,  70.6497, -17.7942, -38.8530,   9.4484,\n",
      "          2.4530, -13.6497], grad_fn=<MulBackward0>) tensor([  7.3492, -17.0651, -23.5838,   3.3443,  -1.9786, -24.3551,  15.3469,\n",
      "        -23.5654,  27.5553,  41.9995, -30.4813, -43.7888,   1.3666,   9.5535,\n",
      "        -24.1434,  19.2200, -20.9008,   1.5000, -56.7944, -13.0234, -12.2524,\n",
      "        -34.2134,  -0.1049,  -1.6515, -33.6300, -44.4868, -66.1686,  -8.9585,\n",
      "          2.5346,   5.6727, -29.3812,   8.7687, -10.7775,  12.7063,  16.6132,\n",
      "         18.2483,  52.0532,  27.4431, -70.3139,  17.1180,  36.6707,  -9.2779,\n",
      "         -2.4521,  13.6055], grad_fn=<MulBackward0>)\n",
      "complaint 3 assert2 approx_eq( tensor([-9.5367e-07, -2.0981e-05,  1.5259e-05, -4.7684e-07, -1.1921e-07,\n",
      "        -7.6294e-06,  5.2452e-05, -2.2888e-05, -1.1444e-05,  5.3406e-05,\n",
      "        -2.0981e-05,  5.3406e-05, -1.1921e-07,  0.0000e+00, -1.1444e-05,\n",
      "        -1.7166e-05,  5.3406e-05, -1.1921e-07,  1.4496e-04,  3.8147e-06,\n",
      "         9.5367e-07,  6.1035e-05, -3.9488e-07,  0.0000e+00,  2.2888e-05,\n",
      "        -7.6294e-06,  2.7466e-04, -9.5367e-07, -2.3842e-07,  0.0000e+00,\n",
      "         3.0518e-05, -9.5367e-07,  3.8147e-06, -1.1444e-05,  5.0184e-02,\n",
      "        -9.5367e-05,  2.6703e-05, -7.6294e-06,  3.2043e-04, -1.1133e-02,\n",
      "         1.5259e-05,  0.0000e+00,  0.0000e+00, -1.4305e-05],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 2 dm.grad\n",
      "complaint 1 dtr.grad\n",
      "complaint 0 ddfr.grad\n",
      "complaint 0\n",
      "complaint -20\n",
      "complaint -40\n",
      "complaint -60\n",
      "complaint -80\n",
      "complaint -100\n",
      "complaint -120\n",
      "complaint -140\n",
      "epoch 100 loss = 235.59264135360718;\n",
      "mode_hat tensor(0.0998, requires_grad=True)\n",
      "ltscale_hat tensor(0.3949, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4941, requires_grad=True)\n",
      "complaint -160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "sample:  76%|█████████████████████████        | 798/1050 [00:19<00:01, 246.48it/s, step size=5.79e-01, acc. prob=0.635]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint -180\n",
      "complaint -200\n",
      "complaint -220\n",
      "complaint -240\n",
      "complaint -260\n",
      "complaint -280\n",
      "epoch 200 loss = 206.11843144893646;\n",
      "mode_hat tensor(0.1586, requires_grad=True)\n",
      "ltscale_hat tensor(0.7829, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9570, requires_grad=True)\n",
      "complaint -300\n",
      "complaint -320\n",
      "complaint -340\n",
      "complaint -360\n",
      "complaint -380\n",
      "complaint -400\n",
      "complaint -420\n",
      "complaint -440\n",
      "complaint -460\n",
      "complaint -480\n",
      "complaint -500\n",
      "complaint -520\n",
      "complaint -540\n",
      "complaint -560\n",
      "complaint -580\n",
      "complaint -600\n",
      "complaint -620\n",
      "complaint -640\n",
      "complaint -660\n",
      "complaint -680\n",
      "complaint -700\n",
      "complaint -720\n",
      "epoch 300 loss = 201.22901892662048;\n",
      "mode_hat tensor(0.1607, requires_grad=True)\n",
      "ltscale_hat tensor(0.8142, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.4344, requires_grad=True)\n",
      "complaint -740\n",
      "complaint -760\n",
      "complaint -780\n",
      "complaint -800\n",
      "complaint -820\n",
      "complaint -840\n",
      "complaint -860\n",
      "complaint -880\n",
      "complaint -900\n",
      "complaint -920\n",
      "complaint -940\n",
      "complaint -960\n",
      "complaint -980\n",
      "complaint -1000\n",
      "complaint -1020\n",
      "complaint -1040\n",
      "complaint -1060\n",
      "epoch 400 loss = 202.0620892047882;\n",
      "mode_hat tensor(0.2398, requires_grad=True)\n",
      "ltscale_hat tensor(0.9828, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.9048, requires_grad=True)\n",
      "complaint -1080\n",
      "complaint -1100\n",
      "complaint -1120\n",
      "complaint -1140\n",
      "complaint -1160\n",
      "complaint -1180\n",
      "complaint -1200\n",
      "complaint -1220\n",
      "complaint -1240\n",
      "epoch 500 loss = 191.97738814353943;\n",
      "mode_hat tensor(0.3202, requires_grad=True)\n",
      "ltscale_hat tensor(1.3345, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.9363, requires_grad=True)\n",
      "complaint -1260\n",
      "complaint -1280\n",
      "complaint -1300\n",
      "complaint -1320\n",
      "complaint -1340\n",
      "complaint -1360\n",
      "complaint -1380\n",
      "complaint -1400\n",
      "complaint -1420\n",
      "complaint -1440\n",
      "epoch 600 loss = 185.02017211914062;\n",
      "mode_hat tensor(0.4270, requires_grad=True)\n",
      "ltscale_hat tensor(1.5650, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.4235, requires_grad=True)\n",
      "complaint -1460\n",
      "complaint -1480\n",
      "complaint -1500\n",
      "complaint -1520\n",
      "complaint -1540\n",
      "complaint -1560\n",
      "complaint -1580\n",
      "complaint -1600\n",
      "epoch 700 loss = 174.57563161849976;\n",
      "mode_hat tensor(0.5909, requires_grad=True)\n",
      "ltscale_hat tensor(1.6342, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9117, requires_grad=True)\n",
      "complaint -1620\n",
      "complaint -1640\n",
      "complaint -1660\n",
      "complaint -1680\n",
      "complaint -1700\n",
      "complaint -1720\n",
      "complaint -1740\n",
      "complaint -1760\n",
      "complaint -1780\n",
      "complaint -1800\n",
      "epoch 800 loss = 177.90494418144226;\n",
      "mode_hat tensor(0.6861, requires_grad=True)\n",
      "ltscale_hat tensor(1.6707, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4056, requires_grad=True)\n",
      "complaint -1820\n",
      "complaint -1840\n",
      "complaint -1860\n",
      "epoch 900 loss = 190.46340107917786;\n",
      "mode_hat tensor(0.9078, requires_grad=True)\n",
      "ltscale_hat tensor(1.6611, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0975, requires_grad=True)\n",
      "epoch 1000 loss = 196.106023311615;\n",
      "mode_hat tensor(0.9729, requires_grad=True)\n",
      "ltscale_hat tensor(1.6947, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5980, requires_grad=True)\n",
      "epoch 1100 loss = 179.34744834899902;\n",
      "mode_hat tensor(1.0215, requires_grad=True)\n",
      "ltscale_hat tensor(1.7235, requires_grad=True)\n",
      "ldfraw_hat tensor(1.0910, requires_grad=True)\n",
      "epoch 1200 loss = 188.5144612789154;\n",
      "mode_hat tensor(1.1241, requires_grad=True)\n",
      "ltscale_hat tensor(1.7617, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5715, requires_grad=True)\n",
      "epoch 1300 loss = 187.83086776733398;\n",
      "mode_hat tensor(1.2041, requires_grad=True)\n",
      "ltscale_hat tensor(1.7546, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9140, requires_grad=True)\n",
      "epoch 1400 loss = 171.20929169654846;\n",
      "mode_hat tensor(1.2305, requires_grad=True)\n",
      "ltscale_hat tensor(1.7699, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9468, requires_grad=True)\n",
      "epoch 1500 loss = 178.40320110321045;\n",
      "mode_hat tensor(1.2613, requires_grad=True)\n",
      "ltscale_hat tensor(1.7726, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9593, requires_grad=True)\n",
      "Final mean_losses: 182.87454816571466\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "ldfraw_hat:\n",
      "1.930368185043335\n",
      "lpsi:\n",
      "tensor([-7.9091, -6.7187, -8.2130, -8.1982, -8.1702, -8.0968, -8.3097, -8.2231,\n",
      "        -8.0977, -8.2138], requires_grad=True)\n",
      "ltscale_hat:\n",
      "1.757524847984314\n",
      "mode_hat:\n",
      "1.2016892433166504\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 202.43279647827148;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint -1880\n",
      "complaint -1900\n",
      "epoch 100 loss = 162.78398633003235;\n",
      "mode_hat tensor(-0.3883, requires_grad=True)\n",
      "ltscale_hat tensor(0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5000, requires_grad=True)\n",
      "complaint -1920\n",
      "complaint -1940\n",
      "complaint -1960\n",
      "complaint -1980\n",
      "epoch 200 loss = 118.44608211517334;\n",
      "mode_hat tensor(-0.5054, requires_grad=True)\n",
      "ltscale_hat tensor(1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9616, requires_grad=True)\n",
      "complaint -2000\n",
      "complaint -2020\n",
      "complaint -2040\n",
      "complaint -2060\n",
      "complaint -2080\n",
      "complaint -2100\n",
      "complaint -2120\n",
      "epoch 300 loss = 86.57882237434387;\n",
      "mode_hat tensor(-0.4159, requires_grad=True)\n",
      "ltscale_hat tensor(1.5046, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.3623, requires_grad=True)\n",
      "complaint -2140\n",
      "complaint -2160\n",
      "complaint -2180\n",
      "complaint -2200\n",
      "complaint -2220\n",
      "complaint -2240\n",
      "epoch 400 loss = 62.072874784469604;\n",
      "mode_hat tensor(-0.1202, requires_grad=True)\n",
      "ltscale_hat tensor(2.0042, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8974, requires_grad=True)\n",
      "complaint -2260\n",
      "complaint -2280\n",
      "complaint -2300\n",
      "epoch 500 loss = 57.66342878341675;\n",
      "mode_hat tensor(0.2907, requires_grad=True)\n",
      "ltscale_hat tensor(2.4977, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3984, requires_grad=True)\n",
      "epoch 600 loss = 59.26319670677185;\n",
      "mode_hat tensor(0.5841, requires_grad=True)\n",
      "ltscale_hat tensor(2.7935, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1059, requires_grad=True)\n",
      "epoch 700 loss = 51.45506834983826;\n",
      "mode_hat tensor(0.7263, requires_grad=True)\n",
      "ltscale_hat tensor(2.8069, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6079, requires_grad=True)\n",
      "epoch 800 loss = 56.80392575263977;\n",
      "mode_hat tensor(0.7547, requires_grad=True)\n",
      "ltscale_hat tensor(2.8068, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1057, requires_grad=True)\n",
      "epoch 900 loss = 58.11438012123108;\n",
      "mode_hat tensor(0.7800, requires_grad=True)\n",
      "ltscale_hat tensor(2.7733, requires_grad=True)\n",
      "ldfraw_hat tensor(1.5973, requires_grad=True)\n",
      "epoch 1000 loss = 58.99888372421265;\n",
      "mode_hat tensor(0.7958, requires_grad=True)\n",
      "ltscale_hat tensor(2.7844, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0728, requires_grad=True)\n",
      "epoch 1100 loss = 70.70165777206421;\n",
      "mode_hat tensor(0.9016, requires_grad=True)\n",
      "ltscale_hat tensor(2.7791, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2860, requires_grad=True)\n",
      "epoch 1200 loss = 46.91742658615112;\n",
      "mode_hat tensor(0.8207, requires_grad=True)\n",
      "ltscale_hat tensor(2.7785, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2861, requires_grad=True)\n",
      "epoch 1300 loss = 53.46002435684204;\n",
      "mode_hat tensor(0.8438, requires_grad=True)\n",
      "ltscale_hat tensor(2.7675, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2871, requires_grad=True)\n",
      "epoch 1400 loss = 51.86290097236633;\n",
      "mode_hat tensor(0.8662, requires_grad=True)\n",
      "ltscale_hat tensor(2.7711, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2878, requires_grad=True)\n",
      "Final mean_losses: 57.605720068458034\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "ldfraw_hat:\n",
      "2.2867355346679688\n",
      "lpsi:\n",
      "tensor([-7.0912, -6.2108, -6.1707, -6.1092, -6.2131, -6.1138, -6.1483, -6.1352,\n",
      "        -6.1526, -6.1429], requires_grad=True)\n",
      "ltscale_hat:\n",
      "2.7749104499816895\n",
      "mode_hat:\n",
      "0.848555862903595\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 115.45748162269592;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 55.97200274467468;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2655, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5036, requires_grad=True)\n",
      "epoch 200 loss = 68.64994502067566;\n",
      "mode_hat tensor(0.9650, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7651, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9979, requires_grad=True)\n",
      "epoch 300 loss = 68.2776472568512;\n",
      "mode_hat tensor(0.9560, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1976, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4778, requires_grad=True)\n",
      "epoch 400 loss = 79.62868475914001;\n",
      "mode_hat tensor(0.9564, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2605, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8375, requires_grad=True)\n",
      "epoch 500 loss = 80.52010667324066;\n",
      "mode_hat tensor(0.9579, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2390, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0372, requires_grad=True)\n",
      "epoch 600 loss = 67.12156021595001;\n",
      "mode_hat tensor(0.9728, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2125, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0919, requires_grad=True)\n",
      "epoch 700 loss = 46.34604239463806;\n",
      "mode_hat tensor(0.9600, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2057, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0687, requires_grad=True)\n",
      "epoch 800 loss = 81.32077127695084;\n",
      "mode_hat tensor(0.9912, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2303, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1082, requires_grad=True)\n",
      "epoch 900 loss = 87.58461618423462;\n",
      "mode_hat tensor(0.9552, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2239, requires_grad=True)\n",
      "ldfraw_hat tensor(2.0982, requires_grad=True)\n",
      "Final mean_losses: 75.00881755650668\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "ldfraw_hat:\n",
      "2.1148786544799805\n",
      "lpsi:\n",
      "tensor([-5.1839, -7.8623, -8.2136, -8.1522, -8.1695, -8.2130, -8.0999, -8.1239,\n",
      "        -8.1766, -8.1542], requires_grad=True)\n",
      "ltscale_hat:\n",
      "-1.2415838241577148\n",
      "mode_hat:\n",
      "0.9541477560997009\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 53.977474212646484;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 38.98843836784363;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(0.3943, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4994, requires_grad=True)\n",
      "epoch 200 loss = 34.62658667564392;\n",
      "mode_hat tensor(0.9750, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0841, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9946, requires_grad=True)\n",
      "epoch 300 loss = 14.443723917007446;\n",
      "mode_hat tensor(1.0316, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1798, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4877, requires_grad=True)\n",
      "epoch 400 loss = 28.007311582565308;\n",
      "mode_hat tensor(1.0190, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1889, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9661, requires_grad=True)\n",
      "epoch 500 loss = 30.06386160850525;\n",
      "mode_hat tensor(1.0196, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1885, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2188, requires_grad=True)\n",
      "epoch 600 loss = 27.0135281085968;\n",
      "mode_hat tensor(1.0009, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1813, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2195, requires_grad=True)\n",
      "epoch 700 loss = 22.423550844192505;\n",
      "mode_hat tensor(1.0160, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1722, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2176, requires_grad=True)\n",
      "epoch 800 loss = 20.309873819351196;\n",
      "mode_hat tensor(0.9861, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1817, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2225, requires_grad=True)\n",
      "Final mean_losses: 26.241010784359116\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "ldfraw_hat:\n",
      "2.2188711166381836\n",
      "lpsi:\n",
      "tensor([-7.9998, -8.2106, -7.7302, -7.6826, -7.7475, -7.6210, -7.6762, -7.6856,\n",
      "        -7.7443, -7.7281], requires_grad=True)\n",
      "ltscale_hat:\n",
      "-0.18953309953212738\n",
      "mode_hat:\n",
      "1.0287024974822998\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 325.36020374298096;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint -2320\n",
      "complaint -2340\n",
      "complaint -2360\n",
      "complaint -2380\n",
      "complaint -2400\n",
      "epoch 100 loss = 275.10515427589417;\n",
      "mode_hat tensor(-0.0192, requires_grad=True)\n",
      "ltscale_hat tensor(0.3863, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5050, requires_grad=True)\n",
      "complaint -2420\n",
      "complaint -2440\n",
      "complaint -2460\n",
      "complaint -2480\n",
      "complaint -2500\n",
      "complaint -2520\n",
      "complaint -2540\n",
      "complaint -2560\n",
      "complaint -2580\n",
      "complaint -2600\n",
      "complaint -2620\n",
      "complaint -2640\n",
      "complaint -2660\n",
      "epoch 200 loss = 257.80011010169983;\n",
      "mode_hat tensor(-0.0497, requires_grad=True)\n",
      "ltscale_hat tensor(0.6569, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9883, requires_grad=True)\n",
      "complaint -2680\n",
      "complaint -2700\n",
      "complaint -2720\n",
      "complaint -2740\n",
      "complaint -2760\n",
      "complaint -2780\n",
      "complaint -2800\n",
      "complaint -2820\n",
      "complaint -2840\n",
      "complaint -2860\n",
      "complaint -2880\n",
      "epoch 300 loss = 226.08890843391418;\n",
      "mode_hat tensor(-0.0906, requires_grad=True)\n",
      "ltscale_hat tensor(0.9895, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.4607, requires_grad=True)\n",
      "complaint -2900\n",
      "complaint -2920\n",
      "complaint -2940\n",
      "complaint -2960\n",
      "complaint -2980\n",
      "complaint -3000\n",
      "complaint -3020\n",
      "complaint -3040\n",
      "complaint -3060\n",
      "epoch 400 loss = 199.9448275566101;\n",
      "mode_hat tensor(-0.0802, requires_grad=True)\n",
      "ltscale_hat tensor(1.3294, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.9258, requires_grad=True)\n",
      "complaint -3080\n",
      "complaint -3100\n",
      "complaint -3120\n",
      "complaint -3140\n",
      "complaint -3160\n",
      "complaint -3180\n",
      "complaint -3200\n",
      "complaint -3220\n",
      "complaint -3240\n",
      "complaint -3260\n",
      "complaint -3280\n",
      "complaint -3300\n",
      "complaint -3320\n",
      "complaint -3340\n",
      "complaint -3360\n",
      "complaint -3380\n",
      "complaint -3400\n",
      "complaint -3420\n",
      "complaint -3440\n",
      "complaint -3460\n",
      "complaint -3480\n",
      "complaint -3500\n",
      "complaint -3520\n",
      "complaint -3540\n",
      "epoch 500 loss = 223.26311945915222;\n",
      "mode_hat tensor(-0.0683, requires_grad=True)\n",
      "ltscale_hat tensor(1.3629, requires_grad=True)\n",
      "ldfraw_hat tensor(-2.4047, requires_grad=True)\n",
      "complaint -3560\n",
      "complaint -3580\n",
      "complaint -3600\n",
      "complaint -3620\n",
      "complaint -3640\n",
      "complaint -3660\n",
      "complaint -3680\n",
      "complaint -3700\n",
      "complaint -3720\n",
      "complaint -3740\n",
      "complaint -3760\n",
      "complaint -3780\n",
      "complaint -3800\n",
      "complaint -3820\n",
      "epoch 600 loss = 216.32274222373962;\n",
      "mode_hat tensor(-0.0564, requires_grad=True)\n",
      "ltscale_hat tensor(1.5834, requires_grad=True)\n",
      "ldfraw_hat tensor(-2.8722, requires_grad=True)\n",
      "complaint -3840\n",
      "complaint -3860\n",
      "complaint -3880\n",
      "complaint -3900\n",
      "complaint -3920\n",
      "complaint -3940\n",
      "complaint -3960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint -3980\n",
      "complaint -4000\n",
      "complaint -4020\n",
      "complaint -4040\n",
      "complaint -4060\n",
      "complaint -4080\n",
      "complaint -4100\n",
      "complaint -4120\n",
      "complaint -4140\n",
      "complaint -4160\n",
      "complaint -4180\n",
      "complaint -4200\n",
      "epoch 700 loss = 221.62988686561584;\n",
      "mode_hat tensor(-0.0397, requires_grad=True)\n",
      "ltscale_hat tensor(1.7109, requires_grad=True)\n",
      "ldfraw_hat tensor(-3.3142, requires_grad=True)\n",
      "complaint -4220\n",
      "complaint -4240\n",
      "epoch 800 loss = 204.8559226989746;\n",
      "mode_hat tensor(-0.0102, requires_grad=True)\n",
      "ltscale_hat tensor(1.9482, requires_grad=True)\n",
      "ldfraw_hat tensor(-2.9956, requires_grad=True)\n",
      "epoch 900 loss = 207.0123689174652;\n",
      "mode_hat tensor(0.0647, requires_grad=True)\n",
      "ltscale_hat tensor(1.9862, requires_grad=True)\n",
      "ldfraw_hat tensor(-2.4842, requires_grad=True)\n",
      "epoch 1000 loss = 216.21313452720642;\n",
      "mode_hat tensor(0.1140, requires_grad=True)\n",
      "ltscale_hat tensor(1.9749, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.9766, requires_grad=True)\n",
      "epoch 1100 loss = 220.8438847064972;\n",
      "mode_hat tensor(0.1175, requires_grad=True)\n",
      "ltscale_hat tensor(1.9682, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.4730, requires_grad=True)\n",
      "epoch 1200 loss = 196.8608009815216;\n",
      "mode_hat tensor(0.1960, requires_grad=True)\n",
      "ltscale_hat tensor(2.0008, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9733, requires_grad=True)\n",
      "complaint -4260\n",
      "complaint -4280\n",
      "epoch 1300 loss = 171.31793355941772;\n",
      "mode_hat tensor(0.1921, requires_grad=True)\n",
      "ltscale_hat tensor(1.9974, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6261, requires_grad=True)\n",
      "complaint -4300\n",
      "epoch 1400 loss = 187.85035800933838;\n",
      "mode_hat tensor(0.1941, requires_grad=True)\n",
      "ltscale_hat tensor(1.9976, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6554, requires_grad=True)\n",
      "complaint -4320\n",
      "complaint -4340\n",
      "complaint -4360\n",
      "complaint -4380\n",
      "complaint -4400\n",
      "complaint -4420\n",
      "epoch 1500 loss = 203.55644416809082;\n",
      "mode_hat tensor(0.2618, requires_grad=True)\n",
      "ltscale_hat tensor(2.0030, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5560, requires_grad=True)\n",
      "complaint -4440\n",
      "complaint -4460\n",
      "Final mean_losses: 207.80232050681684\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "ldfraw_hat:\n",
      "-0.5863735675811768\n",
      "lpsi:\n",
      "tensor([-7.7762, -5.8210, -7.5599, -7.7781, -7.7831, -7.7448, -7.8244, -7.9149,\n",
      "        -7.6165, -7.7380], requires_grad=True)\n",
      "ltscale_hat:\n",
      "1.9972902536392212\n",
      "mode_hat:\n",
      "0.34323540329933167\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 222.65757369995117;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "complaint -4480\n",
      "epoch 100 loss = 161.43047332763672;\n",
      "mode_hat tensor(0.3859, requires_grad=True)\n",
      "ltscale_hat tensor(0.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5045, requires_grad=True)\n",
      "complaint -4500\n",
      "complaint -4520\n",
      "complaint -4540\n",
      "complaint -4560\n",
      "complaint -4580\n",
      "complaint -4600\n",
      "complaint -4620\n",
      "epoch 200 loss = 125.88311576843262;\n",
      "mode_hat tensor(0.4690, requires_grad=True)\n",
      "ltscale_hat tensor(1.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9721, requires_grad=True)\n",
      "complaint -4640\n",
      "complaint -4660\n",
      "complaint -4680\n",
      "complaint -4700\n",
      "complaint -4720\n",
      "epoch 300 loss = 99.306649684906;\n",
      "mode_hat tensor(0.6932, requires_grad=True)\n",
      "ltscale_hat tensor(1.5050, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.4164, requires_grad=True)\n",
      "complaint -4740\n",
      "complaint -4760\n",
      "complaint -4780\n",
      "complaint -4800\n",
      "complaint -4820\n",
      "complaint -4840\n",
      "complaint -4860\n",
      "epoch 400 loss = 84.43835544586182;\n",
      "mode_hat tensor(0.7833, requires_grad=True)\n",
      "ltscale_hat tensor(1.9950, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.3529, requires_grad=True)\n",
      "complaint -4880\n",
      "epoch 500 loss = 67.85657715797424;\n",
      "mode_hat tensor(0.9226, requires_grad=True)\n",
      "ltscale_hat tensor(2.4950, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8272, requires_grad=True)\n",
      "complaint -4900\n",
      "complaint -4920\n",
      "complaint -4940\n",
      "complaint -4960\n",
      "complaint -4980\n",
      "complaint -5000\n",
      "complaint -5020\n",
      "epoch 600 loss = 61.55451822280884;\n",
      "mode_hat tensor(0.9720, requires_grad=True)\n",
      "ltscale_hat tensor(2.9429, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3171, requires_grad=True)\n",
      "epoch 700 loss = 65.88210773468018;\n",
      "mode_hat tensor(0.9050, requires_grad=True)\n",
      "ltscale_hat tensor(3.0106, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1875, requires_grad=True)\n",
      "epoch 800 loss = 61.33777928352356;\n",
      "mode_hat tensor(0.7621, requires_grad=True)\n",
      "ltscale_hat tensor(3.0344, requires_grad=True)\n",
      "ldfraw_hat tensor(0.6885, requires_grad=True)\n",
      "epoch 900 loss = 62.315152168273926;\n",
      "mode_hat tensor(0.6744, requires_grad=True)\n",
      "ltscale_hat tensor(3.0304, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1848, requires_grad=True)\n",
      "epoch 1000 loss = 68.46026229858398;\n",
      "mode_hat tensor(0.5720, requires_grad=True)\n",
      "ltscale_hat tensor(3.0365, requires_grad=True)\n",
      "ldfraw_hat tensor(1.6732, requires_grad=True)\n",
      "epoch 1100 loss = 63.86900186538696;\n",
      "mode_hat tensor(0.5163, requires_grad=True)\n",
      "ltscale_hat tensor(3.0492, requires_grad=True)\n",
      "ldfraw_hat tensor(2.1301, requires_grad=True)\n",
      "complaint -5040\n",
      "epoch 1200 loss = 66.6175901889801;\n",
      "mode_hat tensor(0.4623, requires_grad=True)\n",
      "ltscale_hat tensor(3.0546, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2046, requires_grad=True)\n",
      "complaint -5060\n",
      "epoch 1300 loss = 52.47042798995972;\n",
      "mode_hat tensor(0.4619, requires_grad=True)\n",
      "ltscale_hat tensor(3.0527, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2044, requires_grad=True)\n",
      "Final mean_losses: 60.792331673846185\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "ldfraw_hat:\n",
      "2.204183578491211\n",
      "lpsi:\n",
      "tensor([-7.0004, -5.6903, -5.9117, -5.9825, -5.9598, -5.9306, -5.8800, -5.9697,\n",
      "        -5.8802, -5.9384], requires_grad=True)\n",
      "ltscale_hat:\n",
      "3.050933599472046\n",
      "mode_hat:\n",
      "0.42618972063064575\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 111.47640371322632;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint -5080\n",
      "epoch 100 loss = 106.34911918640137;\n",
      "mode_hat tensor(0.4936, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0548, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5037, requires_grad=True)\n",
      "epoch 200 loss = 92.93335473537445;\n",
      "mode_hat tensor(0.9925, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5447, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9902, requires_grad=True)\n",
      "complaint -5100\n",
      "epoch 300 loss = 85.69016718864441;\n",
      "mode_hat tensor(1.1273, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8857, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4104, requires_grad=True)\n",
      "complaint -5120\n",
      "epoch 400 loss = 92.25089049339294;\n",
      "mode_hat tensor(1.0960, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9411, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4078, requires_grad=True)\n",
      "epoch 500 loss = 94.96286082267761;\n",
      "mode_hat tensor(1.1173, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9479, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3985, requires_grad=True)\n",
      "epoch 600 loss = 78.06539297103882;\n",
      "mode_hat tensor(1.1026, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9377, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3618, requires_grad=True)\n",
      "epoch 700 loss = 77.87641441822052;\n",
      "mode_hat tensor(1.0693, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9655, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3447, requires_grad=True)\n",
      "epoch 800 loss = 86.53065228462219;\n",
      "mode_hat tensor(1.1232, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9542, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3651, requires_grad=True)\n",
      "Final mean_losses: 80.99790954326755\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "ldfraw_hat:\n",
      "1.360681414604187\n",
      "lpsi:\n",
      "tensor([-5.3196, -7.2956, -7.8119, -7.7701, -7.8229, -7.7796, -7.8099, -7.8036,\n",
      "        -7.8062, -7.7462], requires_grad=True)\n",
      "ltscale_hat:\n",
      "-0.9594472050666809\n",
      "mode_hat:\n",
      "1.0914980173110962\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace'] {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "generating data {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "creating torch.Size([]) torch.Size([44]) torch.Size([]) torch.Size([44]) torch.Size([44])\n",
      "Not none - creating data.\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 48.003787994384766;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 41.53447985649109;\n",
      "mode_hat tensor(0.5049, requires_grad=True)\n",
      "ltscale_hat tensor(0.4687, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5027, requires_grad=True)\n",
      "epoch 200 loss = 36.46633696556091;\n",
      "mode_hat tensor(0.9729, requires_grad=True)\n",
      "ltscale_hat tensor(0.1784, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9981, requires_grad=True)\n",
      "epoch 300 loss = 36.64224457740784;\n",
      "mode_hat tensor(1.0544, requires_grad=True)\n",
      "ltscale_hat tensor(0.1013, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4906, requires_grad=True)\n",
      "epoch 400 loss = 32.855103492736816;\n",
      "mode_hat tensor(1.0635, requires_grad=True)\n",
      "ltscale_hat tensor(0.0964, requires_grad=True)\n",
      "ldfraw_hat tensor(1.9694, requires_grad=True)\n",
      "epoch 500 loss = 20.07250189781189;\n",
      "mode_hat tensor(1.0564, requires_grad=True)\n",
      "ltscale_hat tensor(0.1065, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2330, requires_grad=True)\n",
      "epoch 600 loss = 38.10846447944641;\n",
      "mode_hat tensor(1.0737, requires_grad=True)\n",
      "ltscale_hat tensor(0.1171, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2308, requires_grad=True)\n",
      "epoch 700 loss = 29.326801776885986;\n",
      "mode_hat tensor(1.0601, requires_grad=True)\n",
      "ltscale_hat tensor(0.1092, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2300, requires_grad=True)\n",
      "epoch 800 loss = 26.207401514053345;\n",
      "mode_hat tensor(1.0628, requires_grad=True)\n",
      "ltscale_hat tensor(0.0995, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2334, requires_grad=True)\n",
      "epoch 900 loss = 25.162129163742065;\n",
      "mode_hat tensor(1.0514, requires_grad=True)\n",
      "ltscale_hat tensor(0.1135, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2304, requires_grad=True)\n",
      "Final mean_losses: 29.533251512488874\n",
      "guidename amortized_deterministic_laplace\n",
      "trueparams {'modal_effect': tensor(1.), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "ldfraw_hat:\n",
      "2.230405807495117\n",
      "lpsi:\n",
      "tensor([-8.3939, -8.3192, -6.7639, -6.8596, -6.8589, -6.8536, -6.8646, -6.8686,\n",
      "        -6.9816, -6.8898], requires_grad=True)\n",
      "ltscale_hat:\n",
      "0.11346855014562607\n",
      "mode_hat:\n",
      "1.0513986349105835\n",
      "0 1 ['amortized_laplace', 'amortized_deterministic_laplace']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"amortized_deterministic_laplace\",]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [tdom_norm_params,ndom_norm_params,tdom_fat_params,ndom_fat_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,filename=\"testresults/demoT_2.csv\")\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running.\n",
      "Reloading polytopize.\n",
      "stan:\n",
      "data {\n",
      "  int<lower=1> N; // number of observations\n",
      "  vector[N] se; // known standard errors\n",
      "  vector[N] x; // observations\n",
      "}\n",
      "parameters {\n",
      "  vector[N] T; // true site difference from mean\n",
      "  real<lower=0> sigma; // t scale\n",
      "  real<lower=1> df;\n",
      "  real mu;\n",
      "}\n",
      "model {\n",
      "  //priors\n",
      "  df - 1 ~ exponential(.2);\n",
      "  sigma ~ exponential(.2);\n",
      "  mu ~ normal(0,20);\n",
      "\n",
      "  //model\n",
      "  T ~ student_t(df, mu, sigma);\n",
      "  x ~ normal(T + mu, se);\n",
      "}\n",
      "\n",
      "Using cached StanModel\n",
      "stan/cached-multisite-eabbd89cdd7801370ad4d7812dad703d.pkl\n",
      "compiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_eabbd89cdd7801370ad4d7812dad703d NOW.\n",
      "C:\\Users\\jameson\\Anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\jameson\\AppData\\Local\\Temp\\tmpx6ezx9r3\\stanfit4anon_model_eabbd89cdd7801370ad4d7812dad703d_4696215286016490192.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n"
     ]
    },
    {
     "ename": "LinkError",
     "evalue": "command 'c:\\\\Rtools\\\\mingw_64\\\\bin\\\\g++.exe' failed with exit status 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDistutilsExecError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\unixccompiler.py\u001b[0m in \u001b[0;36mlink\u001b[1;34m(self, target_desc, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinker\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mld_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mDistutilsExecError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\ccompiler.py\u001b[0m in \u001b[0;36mspawn\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m    908\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mspawn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         \u001b[0mspawn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[1;34m(cmd, search_path, verbose, dry_run)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0m_spawn_nt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\spawn.py\u001b[0m in \u001b[0;36m_spawn_nt\u001b[1;34m(cmd, search_path, verbose, dry_run)\u001b[0m\n\u001b[0;32m     80\u001b[0m             raise DistutilsExecError(\n\u001b[1;32m---> 81\u001b[1;33m                   \"command %r failed with exit status %d\" % (cmd, rc))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDistutilsExecError\u001b[0m: command 'c:\\\\Rtools\\\\mingw_64\\\\bin\\\\g++.exe' failed with exit status 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLinkError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ae459429e64b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stan:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmultisiteMod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStanModel_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multisite\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Dropbox\\eipython\\eipython\\utilities\\stanCache.py\u001b[0m in \u001b[0;36mStanModel_cache\u001b[1;34m(model_name, extension, basepath, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msm\u001b[0m \u001b[1;32mis\u001b[0m  \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compiling\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStanModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compiled\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, charset, model_name, model_code, stanc_ret, boost_lib, eigen_lib, verbose, obfuscate_model_name, extra_compile_args)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mbuild_extension\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mredirect_stderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\command\\build_ext.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;31m# Now actually compile and link everything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_extensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_extensions_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\command\\build_ext.py\u001b[0m in \u001b[0;36mbuild_extensions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_extensions_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_extensions_serial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_extensions_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\command\\build_ext.py\u001b[0m in \u001b[0;36m_build_extensions_serial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter_build_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\command\\build_ext.py\u001b[0m in \u001b[0;36mbuild_extension\u001b[1;34m(self, ext)\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             \u001b[0mbuild_temp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_temp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             target_lang=language)\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mswig_sources\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\ccompiler.py\u001b[0m in \u001b[0;36mlink_shared_object\u001b[1;34m(self, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)\u001b[0m\n\u001b[0;32m    715\u001b[0m                   \u001b[0mlibraries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibrary_dirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime_library_dirs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m                   \u001b[0mexport_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m                   extra_preargs, extra_postargs, build_temp, target_lang)\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\cygwinccompiler.py\u001b[0m in \u001b[0;36mlink\u001b[1;34m(self, target_desc, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)\u001b[0m\n\u001b[0;32m    249\u001b[0m                            \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# export_symbols, we do this in our def-file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m                            \u001b[0mdebug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_preargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_postargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_temp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                            target_lang)\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;31m# -- Miscellaneous methods -----------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\distutils\\unixccompiler.py\u001b[0m in \u001b[0;36mlink\u001b[1;34m(self, target_desc, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinker\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mld_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mDistutilsExecError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLinkError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"skipping %s (up-to-date)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinkError\u001b[0m: command 'c:\\\\Rtools\\\\mingw_64\\\\bin\\\\g++.exe' failed with exit status 1"
     ]
    }
   ],
   "source": [
    "print(\"running.\")\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"stan:\")\n",
    "\n",
    "multisiteMod = StanModel_cache(\"multisite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
