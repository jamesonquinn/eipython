{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-3.1530,  2.8530,  7.0121, -1.9480])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 179.42631673812866;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "complaint 9 assert approx_eq( tensor([-3.1390e+01,  2.2172e+01,  3.3819e+02, -7.6026e+00, -1.6125e-03,\n",
      "         4.1802e+02, -3.3844e+01,  2.0589e+01, -1.6375e+02, -1.6192e+03,\n",
      "         1.5902e+02,  3.6855e+03, -3.4865e+01, -3.3504e+01,  2.7288e+01,\n",
      "        -3.8398e+02,  7.9645e+01, -1.5661e+00,  1.4259e+03,  2.2263e+01,\n",
      "         3.2793e+00,  3.2348e+02, -2.6663e-02, -2.3406e-02,  1.9599e+02,\n",
      "         1.0315e+04,  2.0611e+03,  1.5935e-01, -7.5642e+02, -1.3219e+01,\n",
      "         5.5346e+01, -6.9834e+01,  1.8930e+01, -4.2561e+02, -2.1221e+02,\n",
      "        -5.7398e+00, -4.3411e+03, -1.4345e+04,  2.4589e+03, -1.7898e+01,\n",
      "        -9.0960e+02,  1.6162e+01,  7.4653e-04, -3.6300e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 3.1633e+01, -2.2312e+01, -3.3911e+02,  7.6320e+00,  1.6201e-03,\n",
      "        -4.1832e+02,  3.3968e+01, -2.0661e+01,  1.6389e+02,  1.6199e+03,\n",
      "        -1.5963e+02, -3.6885e+03,  3.5097e+01,  3.4059e+01, -2.7556e+01,\n",
      "         3.8458e+02, -7.9961e+01,  1.5841e+00, -1.4284e+03, -2.2335e+01,\n",
      "        -3.3372e+00, -3.2379e+02,  2.8313e-02,  2.3815e-02, -1.9604e+02,\n",
      "        -1.0316e+04, -2.0630e+03, -1.6790e-01,  7.5655e+02,  1.3609e+01,\n",
      "        -5.5816e+01,  6.9847e+01, -1.9352e+01,  4.2589e+02,  2.1233e+02,\n",
      "         5.7527e+00,  4.3414e+03,  1.4346e+04, -2.4592e+03,  1.8265e+01,\n",
      "         9.1224e+02, -1.6420e+01, -7.5037e-04,  3.6350e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ -15.1662,   13.4122,   33.7197,   -9.2957,   -0.5531,   35.4165,\n",
      "         -15.3641,   12.9829,  -25.8423,  -55.8637,   26.1419,   75.5850,\n",
      "         -15.6706,  -15.9393,   14.5387,  -34.7791,   20.5930,   -5.5322,\n",
      "          55.4561,   13.3199,    7.1555,   32.5650,   -1.4909,   -1.3667,\n",
      "          27.3224,  103.0200,   61.7074,    2.6902,  -42.9033,  -11.8165,\n",
      "          18.5732,  -19.3484,   13.2118,  -35.6127,  -28.1396,   -8.4369,\n",
      "         -76.8344, -114.9927,   63.6566,  -12.8969,  -48.2625,   12.3170,\n",
      "           0.4281,  -15.6158], grad_fn=<MulBackward0>) tensor([  14.9231,  -13.2717,  -32.7959,    9.2664,    0.5531,  -35.1252,\n",
      "          15.2403,  -12.9113,   25.7044,   55.1488,  -25.5310,  -72.5718,\n",
      "          15.4382,   15.3844,  -14.2716,   34.1744,  -20.2776,    5.5142,\n",
      "         -52.9316,  -13.2485,   -7.0976,  -32.2562,    1.4892,    1.3663,\n",
      "         -27.2750, -102.1979,  -59.7972,   -2.6816,   42.7800,   11.4269,\n",
      "         -18.0417,   19.3354,  -12.7900,   35.3348,   28.0169,    8.4240,\n",
      "          76.5846,  114.0714,  -63.3692,   12.5308,   45.6170,  -12.0587,\n",
      "          -0.4280,   15.5652], grad_fn=<MulBackward0>)\n",
      "complaint 8 assert2 approx_eq( tensor([-2.7657e-05, -6.6757e-06,  3.8147e-06,  9.5367e-07, -5.9605e-08,\n",
      "         0.0000e+00, -4.7684e-06, -2.8610e-06, -3.4332e-05,  3.0518e-05,\n",
      "        -3.8147e-06, -7.6294e-06,  8.2016e-05, -1.9073e-05, -5.7220e-06,\n",
      "        -2.2888e-05,  1.2398e-04,  0.0000e+00, -7.6294e-05,  6.6757e-06,\n",
      "         4.7684e-07, -2.6703e-05, -1.1921e-07, -1.1921e-07,  2.2888e-05,\n",
      "         8.2397e-04, -1.1826e-04,  7.1526e-07, -9.1553e-05, -9.5367e-07,\n",
      "         6.2319e-02,  5.7220e-05, -9.5367e-07, -3.4332e-05,  2.0981e-05,\n",
      "        -9.5367e-07, -7.0953e-04, -1.3123e-03, -1.7548e-04, -3.8147e-06,\n",
      "        -3.8147e-06,  9.5367e-07, -2.6822e-07,  1.8120e-05],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 7 dtr.grad\n",
      "complaint 6 ddfr.grad\n",
      "complaint 5 dm.grad\n",
      "complaint 4 assert approx_eq( tensor([-3.1509e+01,  2.2085e+01,  3.3764e+02, -7.6479e+00, -1.7748e-03,\n",
      "         4.1739e+02, -3.3966e+01,  2.0505e+01, -1.6409e+02, -1.6207e+03,\n",
      "         1.5870e+02,  3.6828e+03, -3.4992e+01, -3.3635e+01,  2.7190e+01,\n",
      "        -3.8459e+02,  7.9438e+01, -1.5822e+00,  1.4245e+03,  2.2174e+01,\n",
      "         3.2564e+00,  3.2295e+02, -2.7720e-02, -2.4360e-02,  1.9560e+02,\n",
      "         1.0310e+04,  2.0592e+03,  1.5655e-01, -7.5737e+02, -1.3294e+01,\n",
      "         5.5218e+01, -7.0028e+01,  1.8859e+01, -4.2626e+02, -2.1262e+02,\n",
      "        -5.7770e+00, -4.3442e+03, -1.4352e+04,  2.4568e+03, -1.7986e+01,\n",
      "        -9.1070e+02,  1.6095e+01,  6.5684e-04, -3.6426e+01],\n",
      "       grad_fn=<PowBackward0>) tensor([ 3.1751e+01, -2.2224e+01, -3.3856e+02,  7.6771e+00,  1.7830e-03,\n",
      "        -4.1768e+02,  3.4090e+01, -2.0576e+01,  1.6423e+02,  1.6215e+03,\n",
      "        -1.5930e+02, -3.6858e+03,  3.5224e+01,  3.4187e+01, -2.7455e+01,\n",
      "         3.8519e+02, -7.9751e+01,  1.6001e+00, -1.4270e+03, -2.2245e+01,\n",
      "        -3.3133e+00, -3.2325e+02,  2.9406e-02,  2.4778e-02, -1.9565e+02,\n",
      "        -1.0311e+04, -2.0611e+03, -1.6482e-01,  7.5750e+02,  1.3681e+01,\n",
      "        -5.5674e+01,  7.0041e+01, -1.9277e+01,  4.2654e+02,  2.1274e+02,\n",
      "         5.7898e+00,  4.3444e+03,  1.4353e+04, -2.4571e+03,  1.8350e+01,\n",
      "         9.1334e+02, -1.6351e+01, -6.6016e-04,  3.6477e+01],\n",
      "       grad_fn=<MulBackward0>) tensor([ -15.4064,   13.5912,   34.1883,   -9.4524,   -0.5795,   35.9227,\n",
      "         -15.6097,   13.1571,  -26.2446,  -56.7053,   26.5026,   76.6441,\n",
      "         -15.9187,  -16.1850,   14.7316,  -35.3069,   20.8761,   -5.6327,\n",
      "          56.2219,   13.4992,    7.2425,   33.0281,   -1.5314,   -1.4053,\n",
      "          27.7121,  104.5287,   62.5782,    2.7118,  -43.5612,  -12.0036,\n",
      "          18.8247,  -19.6558,   13.3805,  -36.1587,  -28.5766,   -8.5811,\n",
      "         -77.9978, -116.7155,   64.5857,  -13.1006,  -48.9564,   12.4764,\n",
      "           0.4163,  -15.8666], grad_fn=<MulBackward0>) tensor([  15.1646,  -13.4521,  -33.2684,    9.4232,    0.5795,  -35.6325,\n",
      "          15.4865,  -13.0863,   26.1072,   55.9921,  -25.8948,  -73.6394,\n",
      "          15.6874,   15.6327,  -14.4669,   34.7039,  -20.5629,    5.6149,\n",
      "         -53.7054,  -13.4286,   -7.1856,  -32.7206,    1.5297,    1.4049,\n",
      "         -27.6649, -103.7087,  -60.6736,   -2.7035,   43.4382,   11.6161,\n",
      "         -18.2935,   19.6428,  -12.9632,   35.8817,   28.4542,    8.5683,\n",
      "          77.7486,  115.7963,  -64.2991,   12.7365,   46.3176,  -12.2209,\n",
      "          -0.4163,   15.8162], grad_fn=<MulBackward0>)\n",
      "complaint 3 assert2 approx_eq( tensor([-5.7220e-06,  9.5367e-07,  4.5776e-05,  0.0000e+00,  3.5763e-07,\n",
      "        -7.6294e-06, -5.5313e-05,  5.7220e-06,  1.1444e-05, -7.6294e-05,\n",
      "        -2.6703e-05, -1.8311e-04, -2.8610e-05, -1.5259e-05, -1.3351e-05,\n",
      "        -3.0518e-05,  1.1826e-04,  0.0000e+00, -1.1826e-04, -4.7684e-06,\n",
      "         4.7684e-07,  0.0000e+00, -4.7684e-07,  2.3842e-07,  5.7220e-06,\n",
      "         6.5613e-04,  2.5558e-04,  0.0000e+00, -1.1444e-05, -3.8147e-06,\n",
      "         7.5390e-02,  2.8610e-04,  3.8147e-06, -1.1444e-05,  2.0981e-05,\n",
      "        -1.9073e-06, -6.2561e-04, -2.2888e-04, -2.8992e-04,  1.9073e-06,\n",
      "        -1.1444e-05, -9.5367e-07,  5.9605e-08, -5.6267e-05],\n",
      "       grad_fn=<AddBackward0>)\n",
      "complaint 2 dtr.grad\n",
      "complaint 1 ddfr.grad\n",
      "complaint 0 dm.grad\n",
      "complaint 0\n",
      "yay -80\n",
      "yay -140\n",
      "complaint -20\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 212.04479146003723;\n",
      "mode_hat tensor(-0.0421, requires_grad=True)\n",
      "ltscale_hat tensor(0.4969, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4577, requires_grad=True)\n",
      "yay -320\n",
      "complaint -40\n",
      "complaint -60\n",
      "yay -380\n",
      "complaint -80\n",
      "yay -440\n",
      "yay -500\n",
      "complaint -100\n",
      "complaint -120\n",
      "epoch 200 loss = 237.1758463382721;\n",
      "mode_hat tensor(-0.1215, requires_grad=True)\n",
      "ltscale_hat tensor(0.9328, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7415, requires_grad=True)\n",
      "complaint -140\n",
      "complaint -160\n",
      "yay -560\n",
      "yay -620\n",
      "complaint -180\n",
      "yay -680\n",
      "complaint -200\n",
      "complaint -220\n",
      "yay -740\n",
      "epoch 300 loss = 189.42968082427979;\n",
      "mode_hat tensor(-0.1270, requires_grad=True)\n",
      "ltscale_hat tensor(1.3133, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9711, requires_grad=True)\n",
      "yay -800\n",
      "yay -860\n",
      "complaint -240\n",
      "complaint -260\n",
      "complaint -280\n",
      "yay -920\n",
      "complaint -300\n",
      "complaint -320\n",
      "complaint -340\n",
      "yay -980\n",
      "yay -1040\n",
      "epoch 400 loss = 180.57032215595245;\n",
      "mode_hat tensor(-0.1473, requires_grad=True)\n",
      "ltscale_hat tensor(1.4929, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0230, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay -1100\n",
      "yay -1160\n",
      "complaint -360\n",
      "complaint -380\n",
      "complaint -400\n",
      "yay -1220\n",
      "complaint -420\n",
      "complaint -440\n",
      "yay -1280\n",
      "complaint -460\n",
      "complaint -480\n",
      "complaint -500\n",
      "epoch 500 loss = 215.61747634410858;\n",
      "mode_hat tensor(-0.1138, requires_grad=True)\n",
      "ltscale_hat tensor(1.5544, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9425, requires_grad=True)\n",
      "Final mean_losses: 185.79482702428973\n",
      "save_data {'modal_effect': tensor(-0.1138, requires_grad=True), 't_scale_raw': tensor(1.5544, requires_grad=True), 't_part': tensor([ 0.0205,  0.2294, 12.8695,  5.5697,  2.8870,  5.9479,  4.4532,  2.9623],\n",
      "       grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(21.2693, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 5.4686e+03, -0.0000e+00,  9.6827e+02,  8.8620e+02,  1.3878e+02,\n",
      "          1.6389e+02,  5.0495e+02,  2.3045e+03,  2.3332e+02,  2.6868e+02],\n",
      "        [-0.0000e+00,  7.3943e+00, -2.3905e-03, -2.6680e-02, -9.7110e-02,\n",
      "         -2.7055e-01, -2.5547e-01, -2.6218e-01, -2.8435e-01, -2.5860e-01],\n",
      "        [ 9.6827e+02, -2.3905e-03,  9.6833e+02, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 8.8620e+02, -2.6680e-02, -0.0000e+00,  8.8626e+02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.3878e+02, -9.7110e-02, -0.0000e+00, -0.0000e+00,  1.3877e+02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.6389e+02, -2.7055e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          1.6390e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 5.0495e+02, -2.5547e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  5.0498e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3045e+03, -2.6218e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  2.3045e+03, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3332e+02, -2.8435e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.3335e+02, -0.0000e+00],\n",
      "        [ 2.6868e+02, -2.5860e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  2.6872e+02]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[0.2622, 1.4572],\n",
      "        [1.4572, 8.3311]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0.0296, 0.0000],\n",
      "        [0.0000, 0.9381]], grad_fn=<MulBackward0>), 'grad': tensor([ 6.1803e+00, -1.6294e+00,  5.9764e-03,  6.1815e-02,  7.4501e-01,\n",
      "         9.7046e-01,  6.7919e-01,  9.8716e-01,  8.8961e-01,  6.9199e-01],\n",
      "       grad_fn=<CatBackward>), 'df': tensor(2.3907, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.1432, -4.1725], requires_grad=True), 'latentpsiraw': tensor([-6.5752], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46])\n",
      "file exists: testresults/fit_amortized_laplace_0_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "latentpsi:\n",
      "tensor([-6.5752], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.9425168633460999\n",
      "ltscale_hat:\n",
      "1.5543674230575562\n",
      "mode_hat:\n",
      "-0.11382266879081726\n",
      "thetapsi:\n",
      "tensor([-4.1432, -4.1725], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-3.1530,  2.8530,  7.0121, -1.9480])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 266061.9888395965;\n",
      "epoch 100 loss = 153797.14005842805;\n",
      "epoch 200 loss = 122657.64712104201;\n",
      "epoch 300 loss = 182862.51914954185;\n",
      "epoch 400 loss = 334573.6666689217;\n",
      "epoch 500 loss = 86168.30599662662;\n",
      "epoch 600 loss = 17092.94854307243;\n",
      "epoch 700 loss = 8976.009862154722;\n",
      "epoch 800 loss = 23089.02491647005;\n",
      "epoch 900 loss = 28733.01707327366;\n",
      "Final mean_losses: 134099.61257888516\n",
      "save_data {}\n",
      "file exists: testresults/fit_meanfield_0_N44_mu0.5_sigma2.0_nu2.7+exp-1.0.csv\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(2.)}\n",
      "auto_loc:\n",
      "tensor([-0.8353,  0.2675,  1.6236, -1.1504,  1.3400,  1.3407, -0.7366,  0.3303,\n",
      "         1.2511, -1.1752,  1.3433, -1.3971, -1.3369,  1.3437,  1.2184, -1.3542,\n",
      "        -1.2730,  1.3484, -1.1819,  1.3438, -0.2720,  1.2441,  1.3048,  1.0056,\n",
      "         1.4047,  0.3357,  0.1737,  1.2604,  1.4902,  1.3934,  0.6538, -1.2626,\n",
      "        -0.9186,  1.3494, -1.4443,  1.3172, -1.3654, -1.4510, -0.5350, -1.2327,\n",
      "        -1.2405,  1.4182, -1.0033, -1.2965,  1.2272,  0.3670, -1.0134],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.5119, 0.1536, 0.9289, 0.9328, 1.2604, 1.2316, 0.8049, 0.7180, 1.3461,\n",
      "        1.0119, 1.2086, 1.1630, 1.3993, 1.2318, 1.1952, 1.1138, 1.0628, 1.2799,\n",
      "        1.0514, 1.1519, 0.6597, 1.1963, 1.3564, 0.8739, 1.3318, 0.6772, 0.6664,\n",
      "        1.1944, 1.3269, 1.2430, 0.8721, 1.2655, 0.8607, 1.1094, 1.0566, 1.3039,\n",
      "        1.4083, 1.1580, 0.6105, 1.1101, 1.1351, 1.3578, 0.9266, 1.0588, 0.9705,\n",
      "        0.7591, 1.0896], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-0.1451,  0.3999,  0.4944,  0.6045])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 136.74164021015167;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "yay -1520\n",
      "yay -1580\n",
      "epoch 100 loss = 67.9713613986969;\n",
      "mode_hat tensor(0.2617, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3695, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0892, requires_grad=True)\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "yay -1820\n",
      "yay -1880\n",
      "epoch 200 loss = 81.22342419624329;\n",
      "mode_hat tensor(0.5000, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7459, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1625, requires_grad=True)\n",
      "yay -1940\n",
      "yay -2000\n",
      "complaint -520\n",
      "yay -2060\n",
      "yay -2120\n",
      "yay -2180\n",
      "epoch 300 loss = 75.97364807128906;\n",
      "mode_hat tensor(0.5747, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0357, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0963, requires_grad=True)\n",
      "yay -2240\n",
      "yay -2300\n",
      "yay -2360\n",
      "yay -2420\n",
      "epoch 400 loss = 57.62366724014282;\n",
      "mode_hat tensor(0.5959, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2202, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0068, requires_grad=True)\n",
      "yay -2480\n",
      "yay -2540\n",
      "yay -2600\n",
      "yay -2660\n",
      "yay -2720\n",
      "epoch 500 loss = 71.92520034313202;\n",
      "mode_hat tensor(0.6056, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2630, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1949, requires_grad=True)\n",
      "yay -2780\n",
      "yay -2840\n",
      "yay -2900\n",
      "yay -2960\n",
      "yay -3020\n",
      "epoch 600 loss = 75.56133341789246;\n",
      "mode_hat tensor(0.5750, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3013, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2691, requires_grad=True)\n",
      "yay -3080\n",
      "yay -3140\n",
      "yay -3200\n",
      "yay -3260\n",
      "yay -3320\n",
      "epoch 700 loss = 81.10145330429077;\n",
      "mode_hat tensor(0.5895, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3570, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3922, requires_grad=True)\n",
      "yay -3380\n",
      "yay -3440\n",
      "yay -3500\n",
      "yay -3560\n",
      "yay -3620\n",
      "epoch 800 loss = 69.13563013076782;\n",
      "mode_hat tensor(0.5695, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4505, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4617, requires_grad=True)\n",
      "yay -3680\n",
      "yay -3740\n",
      "yay -3800\n",
      "yay -3860\n",
      "yay -3920\n",
      "epoch 900 loss = 62.562971353530884;\n",
      "mode_hat tensor(0.5812, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4592, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5577, requires_grad=True)\n",
      "yay -3980\n",
      "Final mean_losses: 75.99450213940288\n",
      "save_data {'modal_effect': tensor(0.5987, requires_grad=True), 't_scale_raw': tensor(-1.4500, requires_grad=True), 't_part': tensor([-5.8803e-02, -1.8420e+00, -5.9524e-01, -2.7693e-01,  9.4637e-01,\n",
      "         1.1909e-03, -4.7855e-01, -3.6261e-02], grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(26.0819, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 4.3213e+03, -0.0000e+00,  4.3333e+02,  7.0713e+01,  7.3532e+02,\n",
      "          1.0777e+02,  2.3045e+03,  2.5672e+02,  3.4049e+02,  7.2414e+01],\n",
      "        [-0.0000e+00,  2.2811e+00,  7.1790e-01,  2.1201e-01,  1.8868e+00,\n",
      "          2.3443e+00, -9.7209e-01, -1.4819e-02,  2.2295e+00,  4.4795e-01],\n",
      "        [ 4.3333e+02,  7.1790e-01,  4.4297e+02, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 7.0713e+01,  2.1201e-01, -0.0000e+00,  6.9942e+01, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 7.3532e+02,  1.8868e+00, -0.0000e+00, -0.0000e+00,  7.3536e+02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.0777e+02,  2.3443e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          1.1308e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3045e+03, -9.7209e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  2.3033e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.5672e+02, -1.4819e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  2.6664e+02, -0.0000e+00, -0.0000e+00],\n",
      "        [ 3.4049e+02,  2.2295e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  3.4184e+02, -0.0000e+00],\n",
      "        [ 7.2414e+01,  4.4795e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  8.2228e+01]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[32.1028, -6.6656],\n",
      "        [-6.6656,  2.2085]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[7.4742e-05, 0.0000e+00],\n",
      "        [0.0000e+00, 5.5922e-06]], grad_fn=<MulBackward0>), 'grad': tensor([-44.7569,   0.9987,  -2.6006,  -7.9097, -13.4134, -10.1981,  12.1368,\n",
      "          0.0532, -13.0738,  -1.6131], grad_fn=<CatBackward>), 'df': tensor(2.5823, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-3.8787, -3.8711], requires_grad=True), 'latentpsiraw': tensor([-8.3735], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46])\n",
      "file exists: testresults/fit_amortized_laplace_0_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "latentpsi:\n",
      "tensor([-8.3735], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.5399133563041687\n",
      "ltscale_hat:\n",
      "-1.4499683380126953\n",
      "mode_hat:\n",
      "0.5987486839294434\n",
      "thetapsi:\n",
      "tensor([-3.8787, -3.8711], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv from file\n",
      "44\n",
      "tensor([-0.1451,  0.3999,  0.4944,  0.6045])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 7162.078165054321;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 loss = 6684.550174772739;\n",
      "epoch 200 loss = 4818.412117213011;\n",
      "epoch 300 loss = 2016.3734821677208;\n",
      "epoch 400 loss = 2141.468652755022;\n",
      "epoch 500 loss = 2292.717822790146;\n",
      "epoch 600 loss = 523.778083562851;\n",
      "epoch 700 loss = 102.63057088851929;\n",
      "epoch 800 loss = 39.80470955371857;\n",
      "epoch 900 loss = 207.98594942688942;\n",
      "epoch 1000 loss = 1290.8081616461277;\n",
      "epoch 1100 loss = 1623.8837623596191;\n",
      "epoch 1200 loss = 1297.943263053894;\n",
      "epoch 1300 loss = 61.402620792388916;\n",
      "epoch 1400 loss = 214.84734547138214;\n",
      "epoch 1500 loss = 313.77784287929535;\n",
      "epoch 1600 loss = 293.6226464211941;\n",
      "epoch 1700 loss = 1522.4301439523697;\n",
      "Final mean_losses: 654.7673267346408\n",
      "save_data {}\n",
      "file exists: testresults/fit_meanfield_0_N44_mu0.5_sigma-2.0_nu2.7+exp-1.0.csv\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-2.)}\n",
      "auto_loc:\n",
      "tensor([ 0.7634, -1.6425,  1.9935, -0.2968, -0.0559, -0.1176, -0.0803, -0.0317,\n",
      "        -0.1366,  0.1215,  0.0509, -0.2643, -0.3310,  0.0328, -0.1453, -0.1612,\n",
      "         0.1132, -0.3331, -0.1746, -0.1438, -0.1731,  0.0978,  0.1547,  0.6222,\n",
      "        -0.1329, -0.0920, -0.0598,  0.2950,  0.0648, -0.2569, -0.1379,  0.2150,\n",
      "        -0.4588,  0.2211,  0.0164, -0.1443, -0.0510, -0.0486,  0.1136, -0.1832,\n",
      "        -0.2902,  0.1914, -0.0272, -0.1705, -0.2251, -0.1408,  0.1856],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0595, 0.2253, 0.8070, 0.4267, 0.3056, 0.2716, 0.2186, 0.2185, 0.2334,\n",
      "        0.2923, 0.1867, 0.3546, 0.3310, 0.2455, 0.3302, 0.3430, 0.2845, 0.5157,\n",
      "        0.2811, 0.2273, 0.3063, 0.3107, 0.2511, 0.6446, 0.2118, 0.2912, 0.2221,\n",
      "        0.3701, 0.1942, 0.3260, 0.2687, 0.3913, 0.4770, 0.3125, 0.1872, 0.2823,\n",
      "        0.2123, 0.2058, 0.2482, 0.2414, 0.4229, 0.2409, 0.3017, 0.3016, 0.3339,\n",
      "        0.2450, 0.3253], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 1.0065, -0.0191, 10.7015, -3.8023])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 1074.0327105522156;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay -4040\n",
      "complaint -540\n",
      "complaint -560\n",
      "complaint -580\n",
      "yay -4100\n",
      "yay -4160\n",
      "yay -4220\n",
      "complaint -600\n",
      "epoch 100 loss = 209.39660573005676;\n",
      "mode_hat tensor(0.0588, requires_grad=True)\n",
      "ltscale_hat tensor(0.4392, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3841, requires_grad=True)\n",
      "complaint -620\n",
      "complaint -640\n",
      "yay -4280\n",
      "complaint -660\n",
      "yay -4340\n",
      "complaint -680\n",
      "yay -4400\n",
      "complaint -700\n",
      "yay -4460\n",
      "epoch 200 loss = 206.62737131118774;\n",
      "mode_hat tensor(0.0938, requires_grad=True)\n",
      "ltscale_hat tensor(0.8949, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7979, requires_grad=True)\n",
      "yay -4520\n",
      "complaint -720\n",
      "complaint -740\n",
      "yay -4580\n",
      "complaint -760\n",
      "yay -4640\n",
      "complaint -780\n",
      "yay -4700\n",
      "complaint -800\n",
      "complaint -820\n",
      "epoch 300 loss = 198.14337015151978;\n",
      "mode_hat tensor(0.0641, requires_grad=True)\n",
      "ltscale_hat tensor(1.3432, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0089, requires_grad=True)\n",
      "complaint -840\n",
      "yay -4760\n",
      "complaint -860\n",
      "yay -4820\n",
      "complaint -880\n",
      "complaint -900\n",
      "yay -4880\n",
      "complaint -920\n",
      "complaint -940\n",
      "complaint -960\n",
      "complaint -980\n",
      "complaint -1000\n",
      "yay -4940\n",
      "complaint -1020\n",
      "epoch 400 loss = 154.77196216583252;\n",
      "mode_hat tensor(0.0375, requires_grad=True)\n",
      "ltscale_hat tensor(1.6648, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.0577, requires_grad=True)\n",
      "yay -5000\n",
      "complaint -1040\n",
      "complaint -1060\n",
      "complaint -1080\n",
      "complaint -1100\n",
      "complaint -1120\n",
      "yay -5060\n",
      "complaint -1140\n",
      "yay -5120\n",
      "complaint -1160\n",
      "yay -5180\n",
      "complaint -1180\n",
      "yay -5240\n",
      "epoch 500 loss = 182.8910026550293;\n",
      "mode_hat tensor(0.0804, requires_grad=True)\n",
      "ltscale_hat tensor(1.7413, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9284, requires_grad=True)\n",
      "yay -5300\n",
      "yay -5360\n",
      "yay -5420\n",
      "yay -5480\n",
      "yay -5540\n",
      "epoch 600 loss = 201.1748764514923;\n",
      "mode_hat tensor(0.1817, requires_grad=True)\n",
      "ltscale_hat tensor(1.7960, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7157, requires_grad=True)\n",
      "yay -5600\n",
      "yay -5660\n",
      "yay -5720\n",
      "yay -5780\n",
      "yay -5840\n",
      "epoch 700 loss = 195.99551844596863;\n",
      "mode_hat tensor(0.2704, requires_grad=True)\n",
      "ltscale_hat tensor(1.8598, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6419, requires_grad=True)\n",
      "yay -5900\n",
      "yay -5960\n",
      "yay -6020\n",
      "yay -6080\n",
      "yay -6140\n",
      "epoch 800 loss = 190.3867928981781;\n",
      "mode_hat tensor(0.3335, requires_grad=True)\n",
      "ltscale_hat tensor(1.7901, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3547, requires_grad=True)\n",
      "yay -6200\n",
      "yay -6260\n",
      "yay -6320\n",
      "complaint -1200\n",
      "yay -6380\n",
      "complaint -1220\n",
      "complaint -1240\n",
      "yay -6440\n",
      "epoch 900 loss = 179.69200658798218;\n",
      "mode_hat tensor(0.3870, requires_grad=True)\n",
      "ltscale_hat tensor(1.8646, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1819, requires_grad=True)\n",
      "complaint -1260\n",
      "yay -6500\n",
      "complaint -1280\n",
      "complaint -1300\n",
      "yay -6560\n",
      "complaint -1320\n",
      "Final mean_losses: 192.05307454142664\n",
      "save_data {'modal_effect': tensor(0.4246, requires_grad=True), 't_scale_raw': tensor(1.8480, requires_grad=True), 't_part': tensor([-10.5490,   4.4506,  -4.7101,  12.8311,  -5.2875,  10.2719,   7.1394,\n",
      "          3.1555], grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(22.0139, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 9.0044e+03, -0.0000e+00,  3.4049e+02,  9.2041e+02,  5.0495e+02,\n",
      "          9.8211e+02,  5.2989e+03,  1.4741e+02,  7.4769e+01,  7.3532e+02],\n",
      "        [-0.0000e+00,  1.1224e+01,  1.8036e-01, -2.0599e-01,  2.1087e-01,\n",
      "         -1.4529e-01,  2.1884e-01, -1.8464e-01, -2.2206e-01, -1.6868e-01],\n",
      "        [ 3.4049e+02,  1.8036e-01,  3.4049e+02, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 9.2041e+02, -2.0599e-01, -0.0000e+00,  9.2043e+02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 5.0495e+02,  2.1087e-01, -0.0000e+00, -0.0000e+00,  5.0496e+02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 9.8211e+02, -1.4529e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          9.8211e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 5.2989e+03,  2.1884e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  5.2989e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.4741e+02, -1.8464e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  1.4741e+02, -0.0000e+00, -0.0000e+00],\n",
      "        [ 7.4769e+01, -2.2206e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  7.4779e+01, -0.0000e+00],\n",
      "        [ 7.3532e+02, -1.6868e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  7.3534e+02]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[ 0.0917,  0.3166],\n",
      "        [ 0.3166, 11.2231]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<MulBackward0>), 'grad': tensor([ 1.5723,  0.5589, -0.7930,  0.5509, -0.5728,  0.7846, -0.6180,  0.7921,\n",
      "         0.7240,  0.4197], grad_fn=<CatBackward>), 'df': tensor(2.8969, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-3.8699, -3.8673], requires_grad=True), 'latentpsiraw': tensor([-8.6839], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46])\n",
      "file exists: testresults/fit_amortized_laplace_0_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "latentpsi:\n",
      "tensor([-8.6839], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.1075347363948822\n",
      "ltscale_hat:\n",
      "1.848044753074646\n",
      "mode_hat:\n",
      "0.42457959055900574\n",
      "thetapsi:\n",
      "tensor([-3.8699, -3.8673], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 1.0065, -0.0191, 10.7015, -3.8023])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "esize torch.Size([44])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss = 157375.42185938358;\n",
      "epoch 100 loss = 72067.52770739421;\n",
      "epoch 200 loss = 77036.10818329453;\n",
      "epoch 300 loss = 195338.03497835994;\n",
      "epoch 400 loss = 44208.28505577147;\n",
      "epoch 500 loss = 116939.58634781465;\n",
      "epoch 600 loss = 200395.8311527446;\n",
      "epoch 700 loss = 146561.1198580861;\n",
      "epoch 800 loss = 76893.12634125352;\n",
      "epoch 900 loss = 233241.54473295808;\n",
      "epoch 1000 loss = 174739.13301879168;\n",
      "epoch 1100 loss = 120405.7529232204;\n",
      "Final mean_losses: 129043.17868969057\n",
      "save_data {}\n",
      "file exists: testresults/fit_meanfield_0_N44_mu0.5_sigma2.0_nu2.7+exp3.0.csv\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(2.)}\n",
      "auto_loc:\n",
      "tensor([-0.2520,  0.4809,  1.9084,  0.7031,  0.1102,  1.8858, -1.4054,  1.6197,\n",
      "         1.5347, -0.6106, -1.6597,  1.7253, -1.6470, -1.6561, -1.4078,  0.0458,\n",
      "         1.6139, -0.6113,  1.4076,  1.5055,  1.5820, -1.4995,  1.7794,  1.6252,\n",
      "         1.5681, -1.6989,  1.5720, -1.6760, -1.5710,  1.1571, -0.6979, -1.6004,\n",
      "         1.5137,  0.6267, -1.6636, -1.6570, -1.1012,  1.6889, -1.6259, -1.5993,\n",
      "         1.6897,  1.6355, -1.7357,  1.7571,  0.3610,  1.5433,  1.6607],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.5777, 0.1446, 1.0012, 0.6753, 0.6135, 1.5105, 1.3570, 1.2800, 1.3361,\n",
      "        0.9390, 1.2584, 1.3532, 1.2099, 1.4433, 0.9193, 0.7356, 1.3340, 0.7337,\n",
      "        1.2284, 1.2679, 1.2483, 1.4751, 1.4711, 1.4528, 1.2224, 1.5935, 1.4208,\n",
      "        1.3909, 1.1217, 1.1264, 0.6994, 1.6048, 1.4031, 0.7066, 1.4282, 1.4574,\n",
      "        1.0934, 1.3998, 1.5015, 1.5321, 1.5158, 1.6086, 1.3318, 1.4735, 0.6213,\n",
      "        1.6521, 1.4838], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([0.2674, 0.4915, 0.0769, 0.7012])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 412.32268822193146;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay -6620\n",
      "yay -6680\n",
      "yay -6740\n",
      "yay -6800\n",
      "yay -6860\n",
      "epoch 100 loss = 83.20129477977753;\n",
      "mode_hat tensor(0.2436, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3469, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0740, requires_grad=True)\n",
      "yay -6920\n",
      "yay -6980\n",
      "yay -7040\n",
      "yay -7100\n",
      "yay -7160\n",
      "epoch 200 loss = 82.07521271705627;\n",
      "mode_hat tensor(0.4638, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8116, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4198, requires_grad=True)\n",
      "yay -7220\n",
      "yay -7280\n",
      "yay -7340\n",
      "yay -7400\n",
      "yay -7460\n",
      "epoch 300 loss = 65.61675477027893;\n",
      "mode_hat tensor(0.4807, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3069, requires_grad=True)\n",
      "ldfraw_hat tensor(0.8994, requires_grad=True)\n",
      "yay -7520\n",
      "yay -7580\n",
      "yay -7640\n",
      "yay -7700\n",
      "yay -7760\n",
      "epoch 400 loss = 40.26280689239502;\n",
      "mode_hat tensor(0.4967, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7738, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3197, requires_grad=True)\n",
      "yay -7820\n",
      "yay -7880\n",
      "yay -7940\n",
      "yay -8000\n",
      "yay -8060\n",
      "epoch 500 loss = 35.409597277641296;\n",
      "mode_hat tensor(0.4869, requires_grad=True)\n",
      "ltscale_hat tensor(-2.1533, requires_grad=True)\n",
      "ldfraw_hat tensor(1.6561, requires_grad=True)\n",
      "yay -8120\n",
      "yay -8180\n",
      "yay -8240\n",
      "yay -8300\n",
      "yay -8360\n",
      "epoch 600 loss = 40.19168722629547;\n",
      "mode_hat tensor(0.4831, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4611, requires_grad=True)\n",
      "ldfraw_hat tensor(1.7977, requires_grad=True)\n",
      "yay -8420\n",
      "yay -8480\n",
      "yay -8540\n",
      "yay -8600\n",
      "yay -8660\n",
      "epoch 700 loss = 31.84034299850464;\n",
      "mode_hat tensor(0.5196, requires_grad=True)\n",
      "ltscale_hat tensor(-2.6100, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8644, requires_grad=True)\n",
      "yay -8720\n",
      "yay -8780\n",
      "yay -8840\n",
      "yay -8900\n",
      "yay -8960\n",
      "epoch 800 loss = 48.93625807762146;\n",
      "mode_hat tensor(0.5013, requires_grad=True)\n",
      "ltscale_hat tensor(-2.7158, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8343, requires_grad=True)\n",
      "yay -9020\n",
      "yay -9080\n",
      "yay -9140\n",
      "yay -9200\n",
      "Final mean_losses: 51.156403775986526\n",
      "save_data {'modal_effect': tensor(0.4774, requires_grad=True), 't_scale_raw': tensor(-2.7455, requires_grad=True), 't_part': tensor([ 0.1628, -0.0651,  0.3123,  0.2209,  0.1855,  0.0726,  0.3537,  0.2495],\n",
      "       grad_fn=<IndexSelectBackward>), 'logPosterior': tensor(34.0807, grad_fn=<AddBackward0>), 'raw_hessian': tensor([[ 4.9484e+03, -0.0000e+00,  1.1958e+02,  2.5672e+02,  7.3532e+02,\n",
      "          2.3045e+03,  6.4839e+02,  2.0923e+02,  1.3878e+02,  5.3584e+02],\n",
      "        [-0.0000e+00,  1.2466e+00, -2.3852e+00,  1.0880e+00, -3.1601e+00,\n",
      "         -2.8598e+00, -2.5990e+00, -1.2062e+00, -3.1520e+00, -3.0084e+00],\n",
      "        [ 1.1958e+02, -2.3852e+00,  1.4093e+02, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.5672e+02,  1.0880e+00, -0.0000e+00,  2.8290e+02, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 7.3532e+02, -3.1601e+00, -0.0000e+00, -0.0000e+00,  7.4653e+02,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.3045e+03, -2.8598e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "          2.3220e+03, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 6.4839e+02, -2.5990e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00,  6.6826e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "        [ 2.0923e+02, -1.2062e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00,  2.3516e+02, -0.0000e+00, -0.0000e+00],\n",
      "        [ 1.3878e+02, -3.1520e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  1.4745e+02, -0.0000e+00],\n",
      "        [ 5.3584e+02, -3.0084e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  5.5129e+02]],\n",
      "       grad_fn=<NegBackward>), 'fixed_hessian_upper': tensor([[186.5746,  16.4733],\n",
      "        [ 16.4733,   1.4914]], grad_fn=<MulBackward0>), 'head_adjustment': tensor([[50.8310,  0.0000],\n",
      "        [ 0.0000,  0.4063]], grad_fn=<MulBackward0>), 'grad': tensor([182.8967,   0.2584,  18.4373,  -7.8742,  29.3919,  23.5155,  20.5440,\n",
      "          8.7569,  31.2397,  25.6326], grad_fn=<CatBackward>), 'df': tensor(7.7940, grad_fn=<AddBackward0>), 'thetapsiraw': tensor([-4.0872, -4.0884], requires_grad=True), 'latentpsiraw': tensor([-7.9423], requires_grad=True)}\n",
      "size etc torch.Size([46, 46]) torch.Size([46])\n",
      "file exists: testresults/fit_amortized_laplace_0_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "latentpsi:\n",
      "tensor([-7.9423], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "1.759521722793579\n",
      "ltscale_hat:\n",
      "-2.745532989501953\n",
      "mode_hat:\n",
      "0.47740352153778076\n",
      "thetapsi:\n",
      "tensor([-4.0872, -4.0884], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv from file\n",
      "44\n",
      "tensor([0.2674, 0.4915, 0.0769, 0.7012])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 10287.0890160352;\n",
      "epoch 100 loss = 1891.0168939828873;\n",
      "epoch 200 loss = 3741.408209592104;\n",
      "epoch 300 loss = 2478.5364955067635;\n",
      "epoch 400 loss = 1757.0405440926552;\n",
      "epoch 500 loss = 613.2107274532318;\n",
      "epoch 600 loss = 996.8687043190002;\n",
      "epoch 700 loss = 630.162467956543;\n",
      "epoch 800 loss = 627.781594991684;\n",
      "epoch 900 loss = 222.71304154396057;\n",
      "epoch 1000 loss = 236.13738203048706;\n",
      "epoch 1100 loss = 1356.9320764541626;\n",
      "epoch 1200 loss = 301.2036714553833;\n",
      "epoch 1300 loss = 368.08555471897125;\n",
      "epoch 1400 loss = 440.6300733089447;\n",
      "epoch 1500 loss = 85.44021773338318;\n",
      "epoch 1600 loss = 254.57874965667725;\n",
      "epoch 1700 loss = 21.76108193397522;\n",
      "epoch 1800 loss = 20.404860734939575;\n",
      "epoch 1900 loss = 275.6111705303192;\n",
      "epoch 2000 loss = 414.67109632492065;\n",
      "epoch 2100 loss = 17.67427659034729;\n",
      "epoch 2200 loss = 98.95384383201599;\n",
      "epoch 2300 loss = 309.43447256088257;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean_losses: 142.0974812485012\n",
      "save_data {}\n",
      "file exists: testresults/fit_meanfield_0_N44_mu0.5_sigma-2.0_nu2.7+exp3.0.csv\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-2.)}\n",
      "auto_loc:\n",
      "tensor([ 0.5159, -3.2659,  2.3591, -0.0333, -0.0063, -0.1096,  0.0577, -0.0750,\n",
      "         0.0050, -0.0464, -0.0541,  0.0983, -0.0579, -0.0131,  0.0513,  0.0368,\n",
      "        -0.0114, -0.0775,  0.0175, -0.0299,  0.0281,  0.0548, -0.0437, -0.0442,\n",
      "        -0.0618, -0.0411, -0.0156,  0.0612,  0.1174,  0.0462,  0.0260,  0.0663,\n",
      "        -0.0611,  0.0547,  0.0896,  0.0572,  0.0402, -0.0708,  0.0311, -0.0348,\n",
      "         0.0514, -0.0696,  0.0040, -0.1105,  0.0870, -0.0658,  0.0043],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0289, 0.4606, 0.7550, 0.1816, 0.1565, 0.1914, 0.1536, 0.1703, 0.1619,\n",
      "        0.1575, 0.1674, 0.1845, 0.1756, 0.1653, 0.1758, 0.1480, 0.1810, 0.1696,\n",
      "        0.1524, 0.1996, 0.1418, 0.1948, 0.1325, 0.1590, 0.1563, 0.1793, 0.1759,\n",
      "        0.1358, 0.1901, 0.2192, 0.1842, 0.1297, 0.2063, 0.1966, 0.1195, 0.1741,\n",
      "        0.1662, 0.1660, 0.1422, 0.1208, 0.1401, 0.2412, 0.1802, 0.2145, 0.1733,\n",
      "        0.2019, 0.1120], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [tdom_fat_params,ndom_fat_params,tdom_norm_params,ndom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,filename=\"testresults/demoT_2.csv\")\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
