{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.4283, 0.6877, 0.9501, 0.3907])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 159.05414724349976;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 114.5458732843399;\n",
      "mode_hat tensor(0.2622, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5011, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4178, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 111.24070799350739;\n",
      "mode_hat tensor(0.4550, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9680, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4985, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "complaint 9 dtr.grad\n",
      "complaint 8 ddfr.grad\n",
      "complaint 7 dm.grad\n",
      "complaint 6 dtr.grad\n",
      "complaint 5 ddfr.grad\n",
      "complaint 4 dm.grad\n",
      "complaint 3 dtr.grad\n",
      "complaint 2 ddfr.grad\n",
      "complaint 1 dm.grad\n",
      "complaint 0 dtr.grad\n",
      "complaint 0\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 92.6575129032135;\n",
      "mode_hat tensor(0.4582, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2541, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2641, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 87.11340546607971;\n",
      "mode_hat tensor(0.5073, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3453, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0300, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 83.60881507396698;\n",
      "mode_hat tensor(0.4800, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3556, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2485, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 131.8284046649933;\n",
      "mode_hat tensor(0.4408, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4375, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4235, requires_grad=True)\n",
      "yay -1820\n",
      "yay -1880\n",
      "complaint -20\n",
      "yay -1940\n",
      "yay -2000\n",
      "epoch 700 loss = 248.80640482902527;\n",
      "mode_hat tensor(0.4750, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4735, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6699, requires_grad=True)\n",
      "yay -2060\n",
      "yay -2120\n",
      "yay -2180\n",
      "yay -2240\n",
      "yay -2300\n",
      "epoch 800 loss = 85.86955833435059;\n",
      "mode_hat tensor(0.4892, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4202, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8017, requires_grad=True)\n",
      "yay -2360\n",
      "complaint -40\n",
      "yay -2420\n",
      "yay -2480\n",
      "complaint -60\n",
      "complaint -80\n",
      "yay -2540\n",
      "yay -2600\n",
      "epoch 900 loss = 121.67221128940582;\n",
      "mode_hat tensor(0.4730, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4302, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8252, requires_grad=True)\n",
      "Final mean_losses: 95.41126947920898\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.8252066969871521\n",
      "ltscale_hat:\n",
      "-1.4301702976226807\n",
      "mode_hat:\n",
      "0.4729902148246765\n",
      "thetapsi:\n",
      "tensor([-4.5727, -4.5648], requires_grad=True)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 81.43734014034271;\n",
      "mode_hat tensor(0.4728, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4294, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8249, requires_grad=True)\n",
      "Final mean_losses: 95.13179089243165\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.8248691558837891\n",
      "ltscale_hat:\n",
      "-1.42937171459198\n",
      "mode_hat:\n",
      "0.47279635071754456\n",
      "thetapsi:\n",
      "tensor([-4.5727, -4.5648], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.4283, 0.6877, 0.9501, 0.3907])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 1308.1904082298279;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 100.18078029155731;\n",
      "mode_hat tensor(0.2608, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5044, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3942, requires_grad=True)\n",
      "epoch 200 loss = 110.86301112174988;\n",
      "mode_hat tensor(0.2690, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9622, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4796, requires_grad=True)\n",
      "epoch 300 loss = 97.88043344020844;\n",
      "mode_hat tensor(0.2678, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2200, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2465, requires_grad=True)\n",
      "epoch 400 loss = 70.0072979927063;\n",
      "mode_hat tensor(0.2914, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2181, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0481, requires_grad=True)\n",
      "epoch 500 loss = 98.98851132392883;\n",
      "mode_hat tensor(0.3051, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3385, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2936, requires_grad=True)\n",
      "epoch 600 loss = 79.97988903522491;\n",
      "mode_hat tensor(0.3045, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3434, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5319, requires_grad=True)\n",
      "epoch 700 loss = 81.38825678825378;\n",
      "mode_hat tensor(0.3146, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3857, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7452, requires_grad=True)\n",
      "epoch 800 loss = 93.64338171482086;\n",
      "mode_hat tensor(0.3059, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3845, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.8880, requires_grad=True)\n",
      "Final mean_losses: 98.98435660810851\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 0.0887,  0.3009,  0.5897,  0.0796,  0.1304,  0.5743, -0.1107,  0.2933,\n",
      "        -0.0441, -0.7404,  0.3552,  0.9792, -0.0889,  0.2228,  0.4111, -0.3740,\n",
      "         0.6897,  0.1279,  0.6576,  0.3202,  0.2064,  0.6829,  0.2410,  0.1430,\n",
      "         0.5192,  1.7173,  1.0190,  0.0329, -0.5444,  0.0243,  0.1219, -0.1428,\n",
      "         0.2188, -0.4469, -0.2163, -0.0458, -0.9975, -1.4342,  0.9969, -0.1813,\n",
      "        -0.5770,  0.3768,  0.1995, -0.0521], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.9428688287734985\n",
      "ltscale_hat:\n",
      "-1.4277876615524292\n",
      "mode_hat:\n",
      "0.3336098790168762\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "epoch 0 loss = 85.52037358283997;\n",
      "mode_hat tensor(0.3323, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4294, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9414, requires_grad=True)\n",
      "epoch 100 loss = 94.21695017814636;\n",
      "mode_hat tensor(0.3675, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5746, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9431, requires_grad=True)\n",
      "epoch 200 loss = 90.27215707302094;\n",
      "mode_hat tensor(0.4019, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7946, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9841, requires_grad=True)\n",
      "epoch 300 loss = 81.32993042469025;\n",
      "mode_hat tensor(0.4222, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9895, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.1251, requires_grad=True)\n",
      "epoch 400 loss = 72.63666665554047;\n",
      "mode_hat tensor(0.3938, requires_grad=True)\n",
      "ltscale_hat tensor(-2.1199, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.4000, requires_grad=True)\n",
      "epoch 500 loss = 76.96689867973328;\n",
      "mode_hat tensor(0.4115, requires_grad=True)\n",
      "ltscale_hat tensor(-2.1912, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.6183, requires_grad=True)\n",
      "epoch 600 loss = 89.30874502658844;\n",
      "mode_hat tensor(0.4009, requires_grad=True)\n",
      "ltscale_hat tensor(-2.2568, requires_grad=True)\n",
      "ldfraw_hat tensor(-1.7543, requires_grad=True)\n",
      "Final mean_losses: 85.71236005149335\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 8.3674e-04,  1.6208e-01,  2.4982e-01, -2.8753e-03,  4.4377e-02,\n",
      "         3.1642e-01, -9.0313e-02,  7.2315e-02, -1.0476e-01, -6.6373e-01,\n",
      "         9.7806e-02,  4.9188e-01, -6.6070e-02,  4.5320e-02,  1.5557e-01,\n",
      "        -2.7985e-01,  2.7637e-01,  1.7906e-02,  2.1880e-01,  1.0765e-01,\n",
      "         4.6259e-02,  3.6190e-01,  3.3772e-02,  2.8920e-02,  3.4246e-01,\n",
      "         1.5775e+00,  5.1875e-01, -1.2265e-02, -5.6798e-01, -1.0975e-02,\n",
      "        -1.9387e-02, -1.8318e-01,  3.8610e-02, -4.0223e-01, -2.2891e-01,\n",
      "        -1.0859e-01, -1.0362e+00, -1.5129e+00,  8.7256e-01, -1.0725e-01,\n",
      "        -1.9530e-01,  1.3007e-01,  7.1196e-02, -8.7850e-02],\n",
      "       requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-1.7548881769180298\n",
      "ltscale_hat:\n",
      "-2.2944767475128174\n",
      "mode_hat:\n",
      "0.4139867424964905\n",
      "thetapsi:\n",
      "tensor([-4.5651, -4.5651], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "44\n",
      "tensor([0.4283, 0.6877, 0.9501, 0.3907])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 2310.2975472807884;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 loss = 10813.803342580795;\n",
      "epoch 200 loss = 5030.71759301424;\n",
      "epoch 300 loss = 1471.0414806604385;\n",
      "epoch 400 loss = 1026.0514063835144;\n",
      "epoch 500 loss = 252.21788609027863;\n",
      "epoch 600 loss = 75.70229411125183;\n",
      "epoch 700 loss = 46.097921043634415;\n",
      "epoch 800 loss = 31.205780744552612;\n",
      "epoch 900 loss = 36.93725919723511;\n",
      "epoch 1000 loss = 16.05419024825096;\n",
      "epoch 1100 loss = 20.216801524162292;\n",
      "epoch 1200 loss = 18.528644919395447;\n",
      "epoch 1300 loss = 20.691720873117447;\n",
      "epoch 1400 loss = 18.02424931526184;\n",
      "epoch 1500 loss = 18.86056751012802;\n",
      "epoch 1600 loss = 19.711280465126038;\n",
      "epoch 1700 loss = 16.944834768772125;\n",
      "epoch 1800 loss = 24.193077266216278;\n",
      "epoch 1900 loss = 17.999032735824585;\n",
      "epoch 2000 loss = 17.841221570968628;\n",
      "epoch 2100 loss = 16.55372565984726;\n",
      "epoch 2200 loss = 17.119277834892273;\n",
      "epoch 2300 loss = 16.921180963516235;\n",
      "epoch 2400 loss = 12.36062103509903;\n",
      "epoch 2500 loss = 14.817954875528812;\n",
      "epoch 2600 loss = 17.945165991783142;\n",
      "epoch 2700 loss = 15.220783486962318;\n",
      "epoch 2800 loss = 21.538156300783157;\n",
      "epoch 2900 loss = 11.097091555595398;\n",
      "epoch 3000 loss = 16.542401146143675;\n",
      "Final mean_losses: 16.344647704708397\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 0.4432, -1.2323,  0.3961,  0.0205,  0.2555,  0.4823, -0.0381,  0.0268,\n",
      "         0.4567, -0.2276,  0.1694, -0.1675, -0.8223,  0.2570,  0.8919, -0.1623,\n",
      "         0.0906,  0.2949, -0.4822,  0.6094,  0.0488,  0.5401,  0.1879,  0.0813,\n",
      "         0.5394,  0.0929,  0.0391,  0.3818,  1.6088,  0.8854, -0.0403, -0.6600,\n",
      "        -0.0127,  0.0200, -0.2519,  0.1237, -0.5598, -0.3265, -0.1638, -1.1066,\n",
      "        -1.5438,  0.8910, -0.2767, -0.6873,  0.2989,  0.0824, -0.1302],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0114, 0.2198, 1.0421, 0.1155, 0.1067, 0.1379, 0.0690, 0.0528, 0.0792,\n",
      "        0.0854, 0.0760, 0.0647, 0.0913, 0.1250, 0.1828, 0.1080, 0.1775, 0.1288,\n",
      "        0.1075, 0.1101, 0.1001, 0.1694, 0.0744, 0.1280, 0.0840, 0.1933, 0.0966,\n",
      "        0.0368, 0.0733, 0.1406, 0.1811, 0.0437, 0.1812, 0.1634, 0.0253, 0.1845,\n",
      "        0.0747, 0.0573, 0.0488, 0.0493, 0.0713, 0.0565, 0.1735, 0.2094, 0.1458,\n",
      "        0.0560, 0.0545], grad_fn=<AddBackward0>)\n",
      "epoch 0 loss = 91.24720448255539;\n",
      "Final mean_losses: 17.842698840265335\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 0.4441, -1.2341,  0.3985,  0.0207,  0.2573,  0.4845, -0.0388,  0.0260,\n",
      "         0.4572, -0.2261,  0.1679, -0.1655, -0.8212,  0.2544,  0.8917, -0.1650,\n",
      "         0.0941,  0.2924, -0.4812,  0.6106,  0.0478,  0.5379,  0.1881,  0.0813,\n",
      "         0.5386,  0.0917,  0.0426,  0.3825,  1.6076,  0.8828, -0.0403, -0.6595,\n",
      "        -0.0132,  0.0186, -0.2516,  0.1255, -0.5584, -0.3240, -0.1625, -1.1091,\n",
      "        -1.5440,  0.8907, -0.2740, -0.6900,  0.2961,  0.0827, -0.1307],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0115, 0.2199, 1.0421, 0.1154, 0.1069, 0.1380, 0.0691, 0.0529, 0.0794,\n",
      "        0.0854, 0.0761, 0.0647, 0.0914, 0.1251, 0.1827, 0.1079, 0.1774, 0.1287,\n",
      "        0.1075, 0.1100, 0.1002, 0.1693, 0.0745, 0.1279, 0.0839, 0.1933, 0.0968,\n",
      "        0.0368, 0.0733, 0.1406, 0.1813, 0.0436, 0.1812, 0.1633, 0.0253, 0.1849,\n",
      "        0.0746, 0.0574, 0.0488, 0.0493, 0.0714, 0.0565, 0.1730, 0.2094, 0.1459,\n",
      "        0.0560, 0.0545], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 0.6921,  0.3034, -0.3755,  0.5891])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 101.91609406471252;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 132.80678796768188;\n",
      "mode_hat tensor(0.1750, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4996, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4679, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 79.23797345161438;\n",
      "mode_hat tensor(0.4645, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9749, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7771, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 99.19147372245789;\n",
      "mode_hat tensor(0.4958, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2384, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5422, requires_grad=True)\n",
      "yay -920\n",
      "complaint 9 ddfr.grad\n",
      "complaint 8 dtr.grad\n",
      "complaint 7 dm.grad\n",
      "complaint 6 ddfr.grad\n",
      "complaint 5 dtr.grad\n",
      "complaint 4 dm.grad\n",
      "complaint 3 ddfr.grad\n",
      "complaint 2 dtr.grad\n",
      "complaint 1 dm.grad\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 85.51074588298798;\n",
      "mode_hat tensor(0.4677, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3181, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2593, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 69.69944167137146;\n",
      "mode_hat tensor(0.5411, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3085, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0072, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "yay -1760\n",
      "epoch 600 loss = 116.3247355222702;\n",
      "mode_hat tensor(0.5026, requires_grad=True)\n",
      "ltscale_hat tensor(-1.3806, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2294, requires_grad=True)\n",
      "yay -1820\n",
      "complaint 0 ddfr.grad\n",
      "complaint 0\n",
      "complaint -20\n",
      "complaint -40\n",
      "yay -1880\n",
      "yay -1940\n",
      "complaint -60\n",
      "complaint -80\n",
      "epoch 700 loss = 82.72241520881653;\n",
      "mode_hat tensor(0.4761, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4173, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4180, requires_grad=True)\n",
      "yay -2000\n",
      "complaint -100\n",
      "yay -2060\n",
      "yay -2120\n",
      "yay -2180\n",
      "Final mean_losses: 96.52808633649842\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.5479620099067688\n",
      "ltscale_hat:\n",
      "-1.434009313583374\n",
      "mode_hat:\n",
      "0.4972844123840332\n",
      "thetapsi:\n",
      "tensor([-4.5719, -4.5764], requires_grad=True)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 93.21557688713074;\n",
      "mode_hat tensor(0.4979, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4346, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5460, requires_grad=True)\n",
      "Final mean_losses: 96.46183614751106\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.5460123419761658\n",
      "ltscale_hat:\n",
      "-1.4345996379852295\n",
      "mode_hat:\n",
      "0.49785518646240234\n",
      "thetapsi:\n",
      "tensor([-4.5719, -4.5764], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 0.6921,  0.3034, -0.3755,  0.5891])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 1244.0133248567581;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 90.35791981220245;\n",
      "mode_hat tensor(0.2668, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5044, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4628, requires_grad=True)\n",
      "epoch 200 loss = 110.23456382751465;\n",
      "mode_hat tensor(0.2503, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9650, requires_grad=True)\n",
      "ldfraw_hat tensor(0.7330, requires_grad=True)\n",
      "epoch 300 loss = 79.94690775871277;\n",
      "mode_hat tensor(0.2536, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1312, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5588, requires_grad=True)\n",
      "epoch 400 loss = 91.26631999015808;\n",
      "mode_hat tensor(0.2561, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1584, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4565, requires_grad=True)\n",
      "epoch 500 loss = 90.81800746917725;\n",
      "mode_hat tensor(0.2532, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1783, requires_grad=True)\n",
      "ldfraw_hat tensor(0.3879, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600 loss = 75.74005270004272;\n",
      "mode_hat tensor(0.2679, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2045, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2875, requires_grad=True)\n",
      "epoch 700 loss = 66.46301126480103;\n",
      "mode_hat tensor(0.2725, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2823, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2482, requires_grad=True)\n",
      "epoch 800 loss = 121.50896000862122;\n",
      "mode_hat tensor(0.2973, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2222, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1215, requires_grad=True)\n",
      "epoch 900 loss = 91.274010181427;\n",
      "mode_hat tensor(0.2925, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2342, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0475, requires_grad=True)\n",
      "Final mean_losses: 100.9465822551153\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 0.3784, -0.0036, -0.6351,  0.3006,  0.2281,  0.9209, -0.2964,  0.3620,\n",
      "        -0.3686,  0.3907,  0.9904, -0.3739, -0.0795, -0.3033,  1.8025, -0.0502,\n",
      "        -1.0710,  0.5223,  0.7537,  0.8065,  0.1153, -0.0616,  0.1259, -0.5924,\n",
      "        -0.0049,  0.5983,  0.3466, -0.1533, -0.5584,  0.4340,  0.5912,  0.2782,\n",
      "        -0.4553, -0.0076,  0.9887,  0.5794,  0.3294,  0.0756,  0.4333,  0.1140,\n",
      "         0.4200,  0.2952, -0.5806,  0.4851], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.044771865010261536\n",
      "ltscale_hat:\n",
      "-1.2376993894577026\n",
      "mode_hat:\n",
      "0.2967585027217865\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "epoch 0 loss = 98.54006433486938;\n",
      "mode_hat tensor(0.2969, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2389, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0472, requires_grad=True)\n",
      "Final mean_losses: 100.89845189671037\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([ 0.3770, -0.0061, -0.6356,  0.2996,  0.2318,  0.9196, -0.2950,  0.3604,\n",
      "        -0.3678,  0.3896,  0.9905, -0.3758, -0.0778, -0.3031,  1.8024, -0.0497,\n",
      "        -1.0720,  0.5219,  0.7517,  0.8041,  0.1138, -0.0637,  0.1257, -0.5922,\n",
      "        -0.0071,  0.5975,  0.3438, -0.1511, -0.5584,  0.4336,  0.5928,  0.2779,\n",
      "        -0.4537, -0.0089,  0.9876,  0.5798,  0.3268,  0.0745,  0.4349,  0.1147,\n",
      "         0.4206,  0.2962, -0.5779,  0.4848], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.04717278480529785\n",
      "ltscale_hat:\n",
      "-1.2388795614242554\n",
      "mode_hat:\n",
      "0.2969459593296051\n",
      "thetapsi:\n",
      "tensor([-4.6052, -4.6052], requires_grad=True)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N44_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "44\n",
      "tensor([ 0.6921,  0.3034, -0.3755,  0.5891])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([44])\n",
      "epoch 0 loss = 7513.449478276074;\n",
      "epoch 100 loss = 3350.798580557108;\n",
      "epoch 200 loss = 1924.3295012563467;\n",
      "epoch 300 loss = 1066.0923272371292;\n",
      "epoch 400 loss = 822.8621689155698;\n",
      "epoch 500 loss = 104.614049077034;\n",
      "epoch 600 loss = 111.42689943313599;\n",
      "epoch 700 loss = 125.58174163103104;\n",
      "epoch 800 loss = 39.874284625053406;\n",
      "epoch 900 loss = 35.006696701049805;\n",
      "epoch 1000 loss = 16.424851179122925;\n",
      "epoch 1100 loss = 18.709719479084015;\n",
      "epoch 1200 loss = 15.736535549163818;\n",
      "epoch 1300 loss = 15.357226217864081;\n",
      "epoch 1400 loss = 13.581892669200897;\n",
      "epoch 1500 loss = 18.320923507213593;\n",
      "epoch 1600 loss = 14.937216639518738;\n",
      "epoch 1700 loss = 18.905827224254608;\n",
      "epoch 1800 loss = 17.994171738624573;\n",
      "epoch 1900 loss = 16.369983315467834;\n",
      "epoch 2000 loss = 14.9843168258667;\n",
      "epoch 2100 loss = 16.32062527537346;\n",
      "epoch 2200 loss = 16.38210368156433;\n",
      "epoch 2300 loss = 16.226667642593384;\n",
      "epoch 2400 loss = 15.2012038230896;\n",
      "epoch 2500 loss = 16.975877583026886;\n",
      "Final mean_losses: 16.455314253342227\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 0.4320, -1.1128,  1.2627,  0.2320, -0.0677, -0.7563,  0.1591,  0.1372,\n",
      "         0.7674, -0.4109,  0.2300, -0.4971,  0.2685,  0.8746, -0.4901, -0.2138,\n",
      "        -0.4400,  1.6591, -0.1540, -1.1675,  0.3877,  0.5856,  0.6997, -0.0310,\n",
      "        -0.2170,  0.0512, -0.7239, -0.1202,  0.4719,  0.1979, -0.2502, -0.7012,\n",
      "         0.3684,  0.4808,  0.1169, -0.5936, -0.1296,  0.8834,  0.4514,  0.1811,\n",
      "        -0.0744,  0.2945,  0.0373,  0.2928,  0.1803, -0.6960,  0.3503],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0111, 0.1917, 1.1891, 0.1175, 0.1105, 0.1342, 0.0707, 0.0580, 0.0766,\n",
      "        0.0838, 0.0822, 0.0620, 0.0943, 0.1445, 0.1553, 0.1194, 0.1877, 0.1285,\n",
      "        0.1164, 0.1147, 0.0999, 0.1789, 0.0759, 0.1303, 0.0776, 0.1808, 0.1053,\n",
      "        0.0366, 0.0779, 0.1514, 0.1770, 0.0461, 0.1957, 0.1570, 0.0221, 0.1892,\n",
      "        0.0681, 0.0566, 0.0524, 0.0487, 0.0705, 0.0586, 0.1725, 0.1822, 0.1473,\n",
      "        0.0571, 0.0523], grad_fn=<AddBackward0>)\n",
      "epoch 0 loss = 81.84038257598877;\n",
      "Final mean_losses: 17.76301561979516\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "auto_loc:\n",
      "tensor([ 0.4332, -1.1129,  1.2613,  0.2313, -0.0690, -0.7558,  0.1587,  0.1365,\n",
      "         0.7653, -0.4089,  0.2311, -0.4934,  0.2672,  0.8728, -0.4885, -0.2125,\n",
      "        -0.4376,  1.6561, -0.1521, -1.1661,  0.3880,  0.5852,  0.6992, -0.0300,\n",
      "        -0.2163,  0.0490, -0.7224, -0.1193,  0.4689,  0.1976, -0.2507, -0.7028,\n",
      "         0.3686,  0.4795,  0.1163, -0.5944, -0.1309,  0.8796,  0.4537,  0.1812,\n",
      "        -0.0731,  0.2937,  0.0404,  0.2935,  0.1791, -0.6942,  0.3471],\n",
      "       requires_grad=True)\n",
      "auto_scale:\n",
      "tensor([0.0111, 0.1916, 1.1890, 0.1179, 0.1105, 0.1344, 0.0707, 0.0582, 0.0766,\n",
      "        0.0838, 0.0820, 0.0618, 0.0944, 0.1450, 0.1555, 0.1196, 0.1874, 0.1284,\n",
      "        0.1165, 0.1150, 0.0998, 0.1793, 0.0757, 0.1307, 0.0775, 0.1807, 0.1051,\n",
      "        0.0366, 0.0779, 0.1511, 0.1771, 0.0461, 0.1957, 0.1571, 0.0220, 0.1893,\n",
      "        0.0679, 0.0566, 0.0523, 0.0486, 0.0704, 0.0587, 0.1726, 0.1827, 0.1476,\n",
      "        0.0569, 0.0524], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [ndom_fat_params,ndom_norm_params,]:#tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,filename=\"testresults/demoT_2.csv\")\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
