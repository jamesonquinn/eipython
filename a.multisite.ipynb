{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-23.3890,   7.4639,   3.0788,   1.8308])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "complaint 9 assert approx_eq: tensor([[  0],\n",
      "        [ 19],\n",
      "        [115],\n",
      "        [117],\n",
      "        [134],\n",
      "        [143],\n",
      "        [167],\n",
      "        [317],\n",
      "        [361],\n",
      "        [385]]) \n",
      "              1.. tensor([[-1.2473e+04],\n",
      "        [ 1.1854e+07],\n",
      "        [-7.3752e+03],\n",
      "        [ 8.4210e+03],\n",
      "        [-1.1677e+04],\n",
      "        [-1.4080e+04],\n",
      "        [ 8.3148e+03],\n",
      "        [-6.1614e+03],\n",
      "        [ 7.7498e+03],\n",
      "        [-1.3580e+04]], grad_fn=<IndexBackward>) tensor([[ 1.2580e+04],\n",
      "        [-1.1854e+07],\n",
      "        [ 7.4347e+03],\n",
      "        [-8.4658e+03],\n",
      "        [ 1.1686e+04],\n",
      "        [ 1.4085e+04],\n",
      "        [-8.3158e+03],\n",
      "        [ 6.1651e+03],\n",
      "        [-7.7572e+03],\n",
      "        [ 1.3583e+04]], grad_fn=<IndexBackward>) tensor([[-3530.9932],\n",
      "        [33463.9727],\n",
      "        [-2932.6611],\n",
      "        [ 3039.3743],\n",
      "        [-3333.6743],\n",
      "        [-3542.6824],\n",
      "        [ 2967.7979],\n",
      "        [-2689.7786],\n",
      "        [ 2907.7075],\n",
      "        [-3496.6426]], grad_fn=<IndexBackward>) tensor([[  3424.7231],\n",
      "        [-33386.5664],\n",
      "        [  2873.1663],\n",
      "        [ -2994.8147],\n",
      "        [  3324.5193],\n",
      "        [  3537.1223],\n",
      "        [ -2966.7559],\n",
      "        [  2685.9966],\n",
      "        [ -2900.3916],\n",
      "        [  3494.0732]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0415],\n",
      "        [ 1.4062],\n",
      "        [-0.0149],\n",
      "        [-0.1738],\n",
      "        [-0.0320],\n",
      "        [ 0.0132],\n",
      "        [ 0.0850],\n",
      "        [-0.0125],\n",
      "        [-0.0479],\n",
      "        [ 0.0186]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1288.1433289051056;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint 8 assert approx_eq: tensor([[  0],\n",
      "        [ 19],\n",
      "        [115],\n",
      "        [117],\n",
      "        [167],\n",
      "        [343],\n",
      "        [361],\n",
      "        [363]]) \n",
      "              1.. tensor([[-1.2481e+04],\n",
      "        [ 1.1853e+07],\n",
      "        [-7.3808e+03],\n",
      "        [ 8.4155e+03],\n",
      "        [ 8.3084e+03],\n",
      "        [-1.4819e+04],\n",
      "        [ 7.7439e+03],\n",
      "        [ 1.2512e+04]], grad_fn=<IndexBackward>) tensor([[ 1.2587e+04],\n",
      "        [-1.1853e+07],\n",
      "        [ 7.4403e+03],\n",
      "        [-8.4600e+03],\n",
      "        [-8.3095e+03],\n",
      "        [ 1.4874e+04],\n",
      "        [-7.7513e+03],\n",
      "        [-1.2582e+04]], grad_fn=<IndexBackward>) tensor([[-3531.4792],\n",
      "        [33459.5898],\n",
      "        [-2933.1711],\n",
      "        [ 3038.4424],\n",
      "        [ 2966.7061],\n",
      "        [-3663.9795],\n",
      "        [ 2906.6575],\n",
      "        [ 3487.4387]], grad_fn=<IndexBackward>) tensor([[  3425.0723],\n",
      "        [-33382.1016],\n",
      "        [  2873.5774],\n",
      "        [ -2993.7480],\n",
      "        [ -2965.6926],\n",
      "        [  3609.4158],\n",
      "        [ -2899.3357],\n",
      "        [ -3417.8369]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0286],\n",
      "        [-0.5117],\n",
      "        [-0.0425],\n",
      "        [ 0.2041],\n",
      "        [-0.0256],\n",
      "        [-0.0149],\n",
      "        [-0.0464],\n",
      "        [ 0.0100]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "complaint 7 assert approx_eq: tensor([[  0],\n",
      "        [  8],\n",
      "        [ 19],\n",
      "        [115],\n",
      "        [117],\n",
      "        [134],\n",
      "        [143],\n",
      "        [167],\n",
      "        [317],\n",
      "        [361],\n",
      "        [363],\n",
      "        [385]]) \n",
      "              1.. tensor([[-1.2481e+04],\n",
      "        [ 6.4971e+03],\n",
      "        [ 1.1853e+07],\n",
      "        [-7.3807e+03],\n",
      "        [ 8.4148e+03],\n",
      "        [-1.1685e+04],\n",
      "        [-1.4089e+04],\n",
      "        [ 8.3078e+03],\n",
      "        [-6.1666e+03],\n",
      "        [ 7.7439e+03],\n",
      "        [ 1.2512e+04],\n",
      "        [-1.3589e+04]], grad_fn=<IndexBackward>) tensor([[ 1.2587e+04],\n",
      "        [-6.5011e+03],\n",
      "        [-1.1853e+07],\n",
      "        [ 7.4404e+03],\n",
      "        [-8.4595e+03],\n",
      "        [ 1.1694e+04],\n",
      "        [ 1.4094e+04],\n",
      "        [-8.3090e+03],\n",
      "        [ 6.1704e+03],\n",
      "        [-7.7512e+03],\n",
      "        [-1.2581e+04],\n",
      "        [ 1.3592e+04]], grad_fn=<IndexBackward>) tensor([[-3531.2544],\n",
      "        [ 2737.3083],\n",
      "        [33456.0508],\n",
      "        [-2932.9509],\n",
      "        [ 3038.1069],\n",
      "        [-3333.7139],\n",
      "        [-3542.6875],\n",
      "        [ 2966.3135],\n",
      "        [-2689.9602],\n",
      "        [ 2906.3564],\n",
      "        [ 3487.1228],\n",
      "        [-3496.6421]], grad_fn=<IndexBackward>) tensor([[  3424.7324],\n",
      "        [ -2733.3291],\n",
      "        [-33378.4766],\n",
      "        [  2873.2969],\n",
      "        [ -2993.3967],\n",
      "        [  3324.5510],\n",
      "        [  3537.1069],\n",
      "        [ -2965.3440],\n",
      "        [  2686.1682],\n",
      "        [ -2898.9944],\n",
      "        [ -3417.4397],\n",
      "        [  3494.0676]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0532],\n",
      "        [-0.0154],\n",
      "        [ 0.5742],\n",
      "        [-0.0149],\n",
      "        [ 0.0784],\n",
      "        [ 0.0393],\n",
      "        [-0.0181],\n",
      "        [-0.1965],\n",
      "        [-0.0117],\n",
      "        [ 0.0715],\n",
      "        [ 0.0269],\n",
      "        [ 0.0242]], grad_fn=<IndexBackward>)\n",
      "yay 1 fix_m_grad\n",
      "complaint 6 assert approx_eq: tensor([[  8],\n",
      "        [ 19],\n",
      "        [ 31],\n",
      "        [117],\n",
      "        [134],\n",
      "        [143],\n",
      "        [167],\n",
      "        [243],\n",
      "        [308],\n",
      "        [361],\n",
      "        [363]]) \n",
      "              1.. tensor([[ 6.4975e+03],\n",
      "        [ 1.1853e+07],\n",
      "        [-1.3221e+04],\n",
      "        [ 8.4154e+03],\n",
      "        [-1.1684e+04],\n",
      "        [-1.4088e+04],\n",
      "        [ 8.3084e+03],\n",
      "        [-6.1381e+03],\n",
      "        [ 1.3917e+04],\n",
      "        [ 7.7442e+03],\n",
      "        [ 1.2512e+04]], grad_fn=<IndexBackward>) tensor([[-6.5015e+03],\n",
      "        [-1.1853e+07],\n",
      "        [ 1.3228e+04],\n",
      "        [-8.4600e+03],\n",
      "        [ 1.1693e+04],\n",
      "        [ 1.4094e+04],\n",
      "        [-8.3095e+03],\n",
      "        [ 6.1387e+03],\n",
      "        [-1.3930e+04],\n",
      "        [-7.7515e+03],\n",
      "        [-1.2582e+04]], grad_fn=<IndexBackward>) tensor([[ 2737.5786],\n",
      "        [33458.6484],\n",
      "        [-3470.5747],\n",
      "        [ 3038.4607],\n",
      "        [-3333.9185],\n",
      "        [-3542.8936],\n",
      "        [ 2966.6064],\n",
      "        [-2681.4248],\n",
      "        [ 3538.2156],\n",
      "        [ 2906.6152],\n",
      "        [ 3487.5002]], grad_fn=<IndexBackward>) tensor([[ -2733.5837],\n",
      "        [-33380.9922],\n",
      "        [  3463.6738],\n",
      "        [ -2993.6707],\n",
      "        [  3324.7427],\n",
      "        [  3537.3145],\n",
      "        [ -2965.6160],\n",
      "        [  2680.8433],\n",
      "        [ -3524.9045],\n",
      "        [ -2899.2612],\n",
      "        [ -3417.7451]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0227],\n",
      "        [ 0.6562],\n",
      "        [-0.0122],\n",
      "        [ 0.1953],\n",
      "        [ 0.0244],\n",
      "        [ 0.0156],\n",
      "        [-0.1208],\n",
      "        [ 0.0103],\n",
      "        [-0.0142],\n",
      "        [ 0.0127],\n",
      "        [ 0.0149]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[  0],\n",
      "        [  8],\n",
      "        [ 19],\n",
      "        [115],\n",
      "        [117],\n",
      "        [134],\n",
      "        [143],\n",
      "        [167],\n",
      "        [317],\n",
      "        [361],\n",
      "        [363]]) \n",
      "              1.. tensor([[-1.2480e+04],\n",
      "        [ 6.4975e+03],\n",
      "        [ 1.1853e+07],\n",
      "        [-7.3799e+03],\n",
      "        [ 8.4144e+03],\n",
      "        [-1.1684e+04],\n",
      "        [-1.4088e+04],\n",
      "        [ 8.3083e+03],\n",
      "        [-6.1662e+03],\n",
      "        [ 7.7441e+03],\n",
      "        [ 1.2512e+04]], grad_fn=<IndexBackward>) tensor([[ 1.2586e+04],\n",
      "        [-6.5015e+03],\n",
      "        [-1.1853e+07],\n",
      "        [ 7.4397e+03],\n",
      "        [-8.4593e+03],\n",
      "        [ 1.1693e+04],\n",
      "        [ 1.4094e+04],\n",
      "        [-8.3095e+03],\n",
      "        [ 6.1700e+03],\n",
      "        [-7.7515e+03],\n",
      "        [-1.2581e+04]], grad_fn=<IndexBackward>) tensor([[-3531.6111],\n",
      "        [ 2737.5139],\n",
      "        [33458.0078],\n",
      "        [-2933.1709],\n",
      "        [ 3038.3403],\n",
      "        [-3333.8647],\n",
      "        [-3542.8235],\n",
      "        [ 2966.5322],\n",
      "        [-2690.0474],\n",
      "        [ 2906.5513],\n",
      "        [ 3487.4910]], grad_fn=<IndexBackward>) tensor([[  3424.8577],\n",
      "        [ -2733.5244],\n",
      "        [-33380.2695],\n",
      "        [  2873.3933],\n",
      "        [ -2993.6055],\n",
      "        [  3324.6709],\n",
      "        [  3537.2380],\n",
      "        [ -2965.5513],\n",
      "        [  2686.2549],\n",
      "        [ -2899.1982],\n",
      "        [ -3417.6707]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0142],\n",
      "        [-0.0100],\n",
      "        [ 0.7383],\n",
      "        [-0.0120],\n",
      "        [-0.1899],\n",
      "        [-0.0132],\n",
      "        [ 0.0151],\n",
      "        [-0.1616],\n",
      "        [ 0.0132],\n",
      "        [-0.0190],\n",
      "        [-0.0283]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[  0],\n",
      "        [ 19],\n",
      "        [115]]) \n",
      "              1.. tensor([[-1.2479e+04],\n",
      "        [ 1.1853e+07],\n",
      "        [-7.3793e+03]], grad_fn=<IndexBackward>) tensor([[ 1.2586e+04],\n",
      "        [-1.1853e+07],\n",
      "        [ 7.4391e+03]], grad_fn=<IndexBackward>) tensor([[-3532.0801],\n",
      "        [33462.3906],\n",
      "        [-2933.5256]], grad_fn=<IndexBackward>) tensor([[  3425.2222],\n",
      "        [-33384.5703],\n",
      "        [  2873.6877]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0103],\n",
      "        [-0.1797],\n",
      "        [-0.0332]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[ 19],\n",
      "        [115],\n",
      "        [117],\n",
      "        [167],\n",
      "        [317],\n",
      "        [361],\n",
      "        [385]]) \n",
      "              1.. tensor([[ 1.1854e+07],\n",
      "        [-7.3766e+03],\n",
      "        [ 8.4173e+03],\n",
      "        [ 8.3122e+03],\n",
      "        [-6.1635e+03],\n",
      "        [ 7.7473e+03],\n",
      "        [-1.3584e+04]], grad_fn=<IndexBackward>) tensor([[-1.1854e+07],\n",
      "        [ 7.4365e+03],\n",
      "        [-8.4624e+03],\n",
      "        [-8.3132e+03],\n",
      "        [ 6.1673e+03],\n",
      "        [-7.7546e+03],\n",
      "        [ 1.3587e+04]], grad_fn=<IndexBackward>) tensor([[33465.0820],\n",
      "        [-2933.4573],\n",
      "        [ 3039.4019],\n",
      "        [ 2967.5808],\n",
      "        [-2690.1985],\n",
      "        [ 2907.5337],\n",
      "        [-3497.0830]], grad_fn=<IndexBackward>) tensor([[-33387.1797],\n",
      "        [  2873.5669],\n",
      "        [ -2994.5784],\n",
      "        [ -2966.5188],\n",
      "        [  2686.3918],\n",
      "        [ -2900.1526],\n",
      "        [  3494.4912]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.9023],\n",
      "        [-0.0393],\n",
      "        [-0.2234],\n",
      "        [ 0.1382],\n",
      "        [-0.0117],\n",
      "        [ 0.0237],\n",
      "        [-0.0117]], grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complaint 2 assert approx_eq: tensor([[  0],\n",
      "        [  8],\n",
      "        [ 19],\n",
      "        [ 31],\n",
      "        [115],\n",
      "        [117],\n",
      "        [134],\n",
      "        [167],\n",
      "        [308],\n",
      "        [340],\n",
      "        [361]]) \n",
      "              1.. tensor([[-1.2475e+04],\n",
      "        [ 6.4998e+03],\n",
      "        [ 1.1854e+07],\n",
      "        [-1.3218e+04],\n",
      "        [-7.3768e+03],\n",
      "        [ 8.4171e+03],\n",
      "        [-1.1681e+04],\n",
      "        [ 8.3112e+03],\n",
      "        [ 1.3921e+04],\n",
      "        [-1.5537e+04],\n",
      "        [ 7.7465e+03]], grad_fn=<IndexBackward>) tensor([[ 1.2582e+04],\n",
      "        [-6.5038e+03],\n",
      "        [-1.1854e+07],\n",
      "        [ 1.3225e+04],\n",
      "        [ 7.4367e+03],\n",
      "        [-8.4621e+03],\n",
      "        [ 1.1690e+04],\n",
      "        [-8.3123e+03],\n",
      "        [-1.3934e+04],\n",
      "        [ 1.5543e+04],\n",
      "        [-7.7539e+03]], grad_fn=<IndexBackward>) tensor([[-3532.4172],\n",
      "        [ 2738.5173],\n",
      "        [33466.6016],\n",
      "        [-3471.0344],\n",
      "        [-2933.6931],\n",
      "        [ 3039.5779],\n",
      "        [-3334.3650],\n",
      "        [ 2967.5896],\n",
      "        [ 3539.3762],\n",
      "        [-3661.1746],\n",
      "        [ 2907.5803]], grad_fn=<IndexBackward>) tensor([[  3425.3545],\n",
      "        [ -2734.5073],\n",
      "        [-33388.6172],\n",
      "        [  3464.1052],\n",
      "        [  2873.7576],\n",
      "        [ -2994.6511],\n",
      "        [  3325.1436],\n",
      "        [ -2966.5903],\n",
      "        [ -3526.0012],\n",
      "        [  3655.3635],\n",
      "        [ -2900.2212]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0222],\n",
      "        [ 0.0149],\n",
      "        [-0.0156],\n",
      "        [-0.0161],\n",
      "        [ 0.0322],\n",
      "        [-0.0117],\n",
      "        [-0.0154],\n",
      "        [-0.1042],\n",
      "        [ 0.0205],\n",
      "        [-0.0103],\n",
      "        [-0.0852]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[  0],\n",
      "        [  8],\n",
      "        [ 19],\n",
      "        [115],\n",
      "        [117],\n",
      "        [167],\n",
      "        [361]]) \n",
      "              1.. tensor([[-1.2473e+04],\n",
      "        [ 6.5011e+03],\n",
      "        [ 1.1854e+07],\n",
      "        [-7.3753e+03],\n",
      "        [ 8.4190e+03],\n",
      "        [ 8.3134e+03],\n",
      "        [ 7.7482e+03]], grad_fn=<IndexBackward>) tensor([[ 1.2580e+04],\n",
      "        [-6.5051e+03],\n",
      "        [-1.1854e+07],\n",
      "        [ 7.4352e+03],\n",
      "        [-8.4639e+03],\n",
      "        [-8.3143e+03],\n",
      "        [-7.7556e+03]], grad_fn=<IndexBackward>) tensor([[-3529.5354],\n",
      "        [ 2736.4968],\n",
      "        [33439.9336],\n",
      "        [-2931.2380],\n",
      "        [ 3037.4331],\n",
      "        [ 2965.4597],\n",
      "        [ 2905.4580]], grad_fn=<IndexBackward>) tensor([[  3422.4055],\n",
      "        [ -2732.4934],\n",
      "        [-33361.9062],\n",
      "        [  2871.2532],\n",
      "        [ -2992.4275],\n",
      "        [ -2964.3896],\n",
      "        [ -2898.0737]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0127],\n",
      "        [-0.0190],\n",
      "        [ 2.0273],\n",
      "        [-0.0190],\n",
      "        [ 0.1541],\n",
      "        [ 0.1628],\n",
      "        [-0.0142]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[  8],\n",
      "        [ 19],\n",
      "        [ 31],\n",
      "        [117],\n",
      "        [134],\n",
      "        [167],\n",
      "        [340],\n",
      "        [343],\n",
      "        [361],\n",
      "        [363],\n",
      "        [385]]) \n",
      "              1.. tensor([[ 6.5021e+03],\n",
      "        [ 1.1854e+07],\n",
      "        [-1.3214e+04],\n",
      "        [ 8.4196e+03],\n",
      "        [-1.1677e+04],\n",
      "        [ 8.3141e+03],\n",
      "        [-1.5533e+04],\n",
      "        [-1.4809e+04],\n",
      "        [ 7.7493e+03],\n",
      "        [ 1.2518e+04],\n",
      "        [-1.3581e+04]], grad_fn=<IndexBackward>) tensor([[-6.5062e+03],\n",
      "        [-1.1854e+07],\n",
      "        [ 1.3221e+04],\n",
      "        [-8.4647e+03],\n",
      "        [ 1.1686e+04],\n",
      "        [-8.3152e+03],\n",
      "        [ 1.5538e+04],\n",
      "        [ 1.4864e+04],\n",
      "        [-7.7567e+03],\n",
      "        [-1.2588e+04],\n",
      "        [ 1.3583e+04]], grad_fn=<IndexBackward>) tensor([[ 2734.8054],\n",
      "        [33417.5859],\n",
      "        [-3465.5750],\n",
      "        [ 3035.5242],\n",
      "        [-3329.1077],\n",
      "        [ 2963.5481],\n",
      "        [-3655.4270],\n",
      "        [-3659.0137],\n",
      "        [ 2903.6475],\n",
      "        [ 3484.2444],\n",
      "        [-3491.7905]], grad_fn=<IndexBackward>) tensor([[ -2730.7961],\n",
      "        [-33339.5156],\n",
      "        [  3458.6382],\n",
      "        [ -2990.5544],\n",
      "        [  3319.8823],\n",
      "        [ -2962.5354],\n",
      "        [  3649.6130],\n",
      "        [  3604.0493],\n",
      "        [ -2896.2646],\n",
      "        [ -3414.0935],\n",
      "        [  3489.1975]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0107],\n",
      "        [ 2.0703],\n",
      "        [-0.0100],\n",
      "        [-0.1230],\n",
      "        [ 0.0198],\n",
      "        [-0.0596],\n",
      "        [ 0.0122],\n",
      "        [ 0.0103],\n",
      "        [-0.0420],\n",
      "        [-0.0249],\n",
      "        [ 0.0134]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -20\n",
      "complaint -20\n",
      "yay -80\n",
      "complaint -40\n",
      "yay -140\n",
      "complaint -60\n",
      "yay -200\n",
      "complaint -80\n",
      "yay -260\n",
      "epoch 100 loss = 1022.922855257988;\n",
      "mode_hat tensor(0.0408, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2682, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0961, requires_grad=True)\n",
      "complaint -100\n",
      "yay -320\n",
      "complaint -120\n",
      "yay -380\n",
      "complaint -140\n",
      "yay -440\n",
      "complaint -160\n",
      "yay -500\n",
      "complaint -180\n",
      "yay -560\n",
      "epoch 200 loss = 1303.2322264909744;\n",
      "mode_hat tensor(0.0416, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5669, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1331, requires_grad=True)\n",
      "complaint -200\n",
      "yay -620\n",
      "complaint -220\n",
      "yay -680\n",
      "complaint -240\n",
      "yay -740\n",
      "complaint -260\n",
      "yay -800\n",
      "complaint -280\n",
      "yay -860\n",
      "epoch 300 loss = 1535.0646722316742;\n",
      "mode_hat tensor(0.1097, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8379, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2146, requires_grad=True)\n",
      "complaint -300\n",
      "yay -920\n",
      "complaint -320\n",
      "yay -980\n",
      "complaint -340\n",
      "yay -1040\n",
      "complaint -360\n",
      "yay -1100\n",
      "complaint -380\n",
      "yay -1160\n",
      "epoch 400 loss = 1095.2378916740417;\n",
      "mode_hat tensor(0.2673, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0256, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2513, requires_grad=True)\n",
      "complaint -400\n",
      "yay -1220\n",
      "complaint -420\n",
      "yay -1280\n",
      "complaint -440\n",
      "yay -1340\n",
      "complaint -460\n",
      "yay -1400\n",
      "complaint -480\n",
      "yay -1460\n",
      "epoch 500 loss = 1488.7752978801727;\n",
      "mode_hat tensor(0.4128, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1715, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2537, requires_grad=True)\n",
      "Final mean_losses: 1446.7430121310372\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.4525, -4.1265], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.25368431210517883\n",
      "ltscale_hat:\n",
      "-1.1714533567428589\n",
      "mode_hat:\n",
      "0.4127630591392517\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-23.3890,   7.4639,   3.0788,   1.8308])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 2405.9942796230316;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "epoch 100 loss = 2870.5213284492493;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1232, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1062, requires_grad=True)\n",
      "epoch 200 loss = 1367.6281605958939;\n",
      "mode_hat tensor(0.8428, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2387, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1191, requires_grad=True)\n",
      "epoch 300 loss = 1020.7425979375839;\n",
      "mode_hat tensor(0.8417, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3603, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1482, requires_grad=True)\n",
      "epoch 400 loss = 1395.842255949974;\n",
      "mode_hat tensor(0.8474, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4299, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2401, requires_grad=True)\n",
      "epoch 500 loss = 1778.0588910579681;\n",
      "mode_hat tensor(0.8358, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5753, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3562, requires_grad=True)\n",
      "epoch 600 loss = 1931.8280116319656;\n",
      "mode_hat tensor(0.8401, requires_grad=True)\n",
      "ltscale_hat tensor(-0.6299, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.5043, requires_grad=True)\n",
      "epoch 700 loss = 2790.422239780426;\n",
      "mode_hat tensor(0.8430, requires_grad=True)\n",
      "ltscale_hat tensor(-0.6911, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6124, requires_grad=True)\n",
      "epoch 800 loss = 1483.9251807928085;\n",
      "mode_hat tensor(0.8531, requires_grad=True)\n",
      "ltscale_hat tensor(-0.6863, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7187, requires_grad=True)\n",
      "epoch 900 loss = 2038.8276506662369;\n",
      "mode_hat tensor(0.8541, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7466, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7784, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000 loss = 1272.095805644989;\n",
      "mode_hat tensor(0.8439, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8355, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.9150, requires_grad=True)\n",
      "Final mean_losses: 1486.1780762842566\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-24.2137,   6.5907,   2.1657,   0.9404,  -0.9186, -16.6321,  -0.6432,\n",
      "        -11.1648,  17.8361,   1.8774], grad_fn=<SliceBackward>) (10 elems)\n",
      "gammapsi:\n",
      "tensor([-3.9870, -3.6294], grad_fn=<SliceBackward>) (10 elems)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.9166986346244812\n",
      "ltscale_hat:\n",
      "-0.8424400687217712\n",
      "mode_hat:\n",
      "0.8501335978507996\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-23.3890,   7.4639,   3.0788,   1.8308])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 565607.5247049332;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 15968.73675531149;\n",
      "mode_hat tensor(0.1145, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5039, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4822, requires_grad=True)\n",
      "epoch 200 loss = 44835.492304325104;\n",
      "mode_hat tensor(0.2261, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0012, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9585, requires_grad=True)\n",
      "epoch 300 loss = 2734578.0820551515;\n",
      "mode_hat tensor(0.1974, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4967, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4247, requires_grad=True)\n",
      "epoch 400 loss = 24305.0684851408;\n",
      "mode_hat tensor(0.2074, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9842, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8743, requires_grad=True)\n",
      "epoch 500 loss = 28889.86579054594;\n",
      "mode_hat tensor(0.3290, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4487, requires_grad=True)\n",
      "ldfraw_hat tensor(2.3227, requires_grad=True)\n",
      "Final mean_losses: 20332456.751693606\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.3227264881134033\n",
      "ldfraw_sigma:\n",
      "0.8748548626899719\n",
      "ltscale_hat:\n",
      "-2.448709487915039\n",
      "ltscale_sigma:\n",
      "0.7485965490341187\n",
      "mode_hat:\n",
      "0.3289960026741028\n",
      "mode_sigma:\n",
      "0.6993789672851562\n",
      "t_part_hat:\n",
      "tensor([-0.2647,  0.2645,  0.2395,  0.2315,  0.0134, -0.2937,  0.0757, -0.2328,\n",
      "         0.2608,  0.2970], grad_fn=<SliceBackward>) (10 elems)\n",
      "t_part_sigma:\n",
      "tensor([0.9796, 1.1054, 0.9788, 0.8765, 0.9461, 1.0352, 1.1137, 1.1921, 1.0379,\n",
      "        1.1974], grad_fn=<SliceBackward>) (10 elems)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "exception: [Errno 2] No such file or directory: 'testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv'\n",
      "generating data {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "creating torch.Size([]) torch.Size([400]) torch.Size([]) torch.Size([400]) torch.Size([400])\n",
      "Not none - creating data.\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv created\n",
      "400\n",
      "tensor([-7.4653, -3.8462,  0.4073, -0.9869])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "complaint 9 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6648.9575]], grad_fn=<IndexBackward>) tensor([[-6657.1133]], grad_fn=<IndexBackward>) tensor([[2212.0681]], grad_fn=<IndexBackward>) tensor([[-2210.3472]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-6.4348]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 1329.8351414203644;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint 8 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6644.3521]], grad_fn=<IndexBackward>) tensor([[-6652.2720]], grad_fn=<IndexBackward>) tensor([[2210.9177]], grad_fn=<IndexBackward>) tensor([[-2209.1152]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-6.1174]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "complaint 7 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6639.8936]], grad_fn=<IndexBackward>) tensor([[-6647.5293]], grad_fn=<IndexBackward>) tensor([[2209.8159]], grad_fn=<IndexBackward>) tensor([[-2207.9155]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.7354]], grad_fn=<IndexBackward>)\n",
      "yay 1 fix_m_grad\n",
      "complaint 6 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6637.0518]], grad_fn=<IndexBackward>) tensor([[-6644.6030]], grad_fn=<IndexBackward>) tensor([[2208.9216]], grad_fn=<IndexBackward>) tensor([[-2206.9888]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.6184]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6633.4678]], grad_fn=<IndexBackward>) tensor([[-6640.8896]], grad_fn=<IndexBackward>) tensor([[2207.9705]], grad_fn=<IndexBackward>) tensor([[-2205.9907]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.4421]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6630.9951]], grad_fn=<IndexBackward>) tensor([[-6638.4058]], grad_fn=<IndexBackward>) tensor([[2207.1682]], grad_fn=<IndexBackward>) tensor([[-2205.1802]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.4226]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6629.4077]], grad_fn=<IndexBackward>) tensor([[-6637.0015]], grad_fn=<IndexBackward>) tensor([[2206.4031]], grad_fn=<IndexBackward>) tensor([[-2204.4709]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.6616]], grad_fn=<IndexBackward>)\n",
      "complaint 2 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6627.0874]], grad_fn=<IndexBackward>) tensor([[-6634.6440]], grad_fn=<IndexBackward>) tensor([[2205.6204]], grad_fn=<IndexBackward>) tensor([[-2203.6714]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.6077]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6625.4102]], grad_fn=<IndexBackward>) tensor([[-6633.0591]], grad_fn=<IndexBackward>) tensor([[2204.9451]], grad_fn=<IndexBackward>) tensor([[-2203.0220]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.7258]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[18]]) \n",
      "              1.. tensor([[6623.3921]], grad_fn=<IndexBackward>) tensor([[-6631.0396]], grad_fn=<IndexBackward>) tensor([[2204.2810]], grad_fn=<IndexBackward>) tensor([[-2202.3528]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-5.7192]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -20\n",
      "complaint -20\n",
      "yay -80\n",
      "complaint -40\n",
      "yay -140\n",
      "yay -200\n",
      "complaint -60\n",
      "yay -260\n",
      "complaint -80\n",
      "epoch 100 loss = 1193.884243607521;\n",
      "mode_hat tensor(0.2234, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3850, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4541, requires_grad=True)\n",
      "yay -320\n",
      "complaint -100\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 1352.271815776825;\n",
      "mode_hat tensor(0.3225, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7220, requires_grad=True)\n",
      "ldfraw_hat tensor(0.8384, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1200.8956680297852;\n",
      "mode_hat tensor(0.3660, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0264, requires_grad=True)\n",
      "ldfraw_hat tensor(1.1574, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9d393822b8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"testresults/demoT_2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                         subsample_N = nsamps)\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maniter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnparticles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mguidenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/eipython/eipython/multisiteT.py\u001b[0m in \u001b[0;36mtrainGuide\u001b[0;34m(guidename, nparticles, trueparams, filename, errors, subsample_N, N)\u001b[0m\n\u001b[1;32m   1032\u001b[0m                             \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                             \u001b[0mmaxError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                             save_data,weight,ts(10.),ts(10.))\n\u001b[0m\u001b[1;32m   1035\u001b[0m                         \u001b[0;31m#N,full_N,indices,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                         \u001b[0;31m#x,     full_x,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'requires_grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mwarn_if_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "  for nsamps in [12,25,50]:#,150,400]:\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [ndom_fat_params,ndom_norm_params,]:#tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,\n",
    "                                        filename=\"testresults/demoT_2.csv\",\n",
    "                                      \n",
    "                                        subsample_N = nsamps)\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
