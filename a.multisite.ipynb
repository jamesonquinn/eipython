{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "Scratch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyro/__init__.py\n",
      "/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import pyro\n",
    "\n",
    "print(pyro.__file__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amortizable hierarchical t model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading polytopize.\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "complaint 9 assert approx_eq: tensor([[243],\n",
      "        [249]]) \n",
      "              1.. tensor([[-380.5245],\n",
      "        [ 363.9728]], grad_fn=<IndexBackward>) tensor([[ 380.1057],\n",
      "        [-364.1782]], grad_fn=<IndexBackward>) tensor([[-127.9025],\n",
      "        [ 125.9813]], grad_fn=<IndexBackward>) tensor([[ 127.4307],\n",
      "        [-125.7649]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.8907],\n",
      "        [ 0.0110]], grad_fn=<IndexBackward>)\n",
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 850.2816998958588;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "complaint 8 assert approx_eq: tensor([[243],\n",
      "        [249]]) \n",
      "              1.. tensor([[-380.4729],\n",
      "        [ 363.2229]], grad_fn=<IndexBackward>) tensor([[ 380.3338],\n",
      "        [-363.4233]], grad_fn=<IndexBackward>) tensor([[-127.5123],\n",
      "        [ 125.5161]], grad_fn=<IndexBackward>) tensor([[ 127.1340],\n",
      "        [-125.2977]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.5174],\n",
      "        [ 0.0180]], grad_fn=<IndexBackward>)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "complaint 7 assert approx_eq: tensor([[243]]) \n",
      "              1.. tensor([[-379.8965]], grad_fn=<IndexBackward>) tensor([[380.4741]], grad_fn=<IndexBackward>) tensor([[-126.3558]], grad_fn=<IndexBackward>) tensor([[126.2158]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.4376]], grad_fn=<IndexBackward>)\n",
      "complaint 6 assert approx_eq: tensor([[243],\n",
      "        [249]]) \n",
      "              1.. tensor([[-382.1916],\n",
      "        [ 360.8485]], grad_fn=<IndexBackward>) tensor([[ 382.2683],\n",
      "        [-361.0775]], grad_fn=<IndexBackward>) tensor([[-126.1539],\n",
      "        [ 123.7213]], grad_fn=<IndexBackward>) tensor([[ 125.8466],\n",
      "        [-123.5126]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.2306],\n",
      "        [-0.0202]], grad_fn=<IndexBackward>)\n",
      "complaint 5 assert approx_eq: tensor([[243],\n",
      "        [249]]) \n",
      "              1.. tensor([[-382.6242],\n",
      "        [ 360.2585]], grad_fn=<IndexBackward>) tensor([[ 382.8203],\n",
      "        [-360.4306]], grad_fn=<IndexBackward>) tensor([[-125.7148],\n",
      "        [ 123.1768]], grad_fn=<IndexBackward>) tensor([[ 125.4462],\n",
      "        [-122.9485]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0725],\n",
      "        [ 0.0562]], grad_fn=<IndexBackward>)\n",
      "complaint 4 assert approx_eq: tensor([[243],\n",
      "        [249]]) \n",
      "              1.. tensor([[-382.6285],\n",
      "        [ 359.9117]], grad_fn=<IndexBackward>) tensor([[ 382.9438],\n",
      "        [-360.0834]], grad_fn=<IndexBackward>) tensor([[-125.2619],\n",
      "        [ 122.6930]], grad_fn=<IndexBackward>) tensor([[ 125.0318],\n",
      "        [-122.4643]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0852],\n",
      "        [0.0570]], grad_fn=<IndexBackward>)\n",
      "complaint 3 assert approx_eq: tensor([[249]]) \n",
      "              1.. tensor([[358.6237]], grad_fn=<IndexBackward>) tensor([[-358.8989]], grad_fn=<IndexBackward>) tensor([[121.8877]], grad_fn=<IndexBackward>) tensor([[-121.6938]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[-0.0813]], grad_fn=<IndexBackward>)\n",
      "yay -20\n",
      "complaint 2 assert approx_eq: tensor([[243],\n",
      "        [249]]) \n",
      "              1.. tensor([[-385.0499],\n",
      "        [ 357.4345]], grad_fn=<IndexBackward>) tensor([[ 385.3165],\n",
      "        [-357.7072]], grad_fn=<IndexBackward>) tensor([[-124.2852],\n",
      "        [ 121.2008]], grad_fn=<IndexBackward>) tensor([[ 124.0362],\n",
      "        [-121.0057]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[ 0.0176],\n",
      "        [-0.0776]], grad_fn=<IndexBackward>)\n",
      "complaint 1 assert approx_eq: tensor([[249]]) \n",
      "              1.. tensor([[357.2434]], grad_fn=<IndexBackward>) tensor([[-357.3991]], grad_fn=<IndexBackward>) tensor([[120.8822]], grad_fn=<IndexBackward>) tensor([[-120.6471]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0794]], grad_fn=<IndexBackward>)\n",
      "complaint 0 assert approx_eq: tensor([[249]]) \n",
      "              1.. tensor([[356.6099]], grad_fn=<IndexBackward>) tensor([[-356.7787]], grad_fn=<IndexBackward>) tensor([[120.6515]], grad_fn=<IndexBackward>) tensor([[-120.4209]], grad_fn=<IndexBackward>) \n",
      "              2.. tensor([[0.0618]], grad_fn=<IndexBackward>)\n",
      "complaint 0\n",
      "yay -80\n",
      "complaint -20\n",
      "yay -140\n",
      "complaint -40\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 503.55333638191223;\n",
      "mode_hat tensor(0.2446, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2851, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1314, requires_grad=True)\n",
      "yay -320\n",
      "complaint -60\n",
      "yay -380\n",
      "complaint -80\n",
      "yay -440\n",
      "complaint -100\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 858.5438076257706;\n",
      "mode_hat tensor(0.3518, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5373, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2170, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "complaint -120\n",
      "yay -740\n",
      "complaint -140\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 1110.8812679052353;\n",
      "mode_hat tensor(0.4521, requires_grad=True)\n",
      "ltscale_hat tensor(-0.7648, requires_grad=True)\n",
      "ldfraw_hat tensor(0.2201, requires_grad=True)\n",
      "yay -920\n",
      "complaint -160\n",
      "yay -980\n",
      "yay -1040\n",
      "complaint -180\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 531.3238716125488;\n",
      "mode_hat tensor(0.4650, requires_grad=True)\n",
      "ltscale_hat tensor(-0.9420, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1446, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "complaint -200\n",
      "yay -1340\n",
      "complaint -220\n",
      "yay -1400\n",
      "complaint -240\n",
      "yay -1460\n",
      "epoch 500 loss = 2343.1597797870636;\n",
      "mode_hat tensor(0.5467, requires_grad=True)\n",
      "ltscale_hat tensor(-1.1285, requires_grad=True)\n",
      "ldfraw_hat tensor(0.1257, requires_grad=True)\n",
      "Final mean_losses: 1000.5233471220272\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.2371, -4.2113], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "0.1257179081439972\n",
      "ltscale_hat:\n",
      "-1.1285210847854614\n",
      "mode_hat:\n",
      "0.5466898679733276\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 1448.0060443878174;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0050, requires_grad=True)\n",
      "epoch 100 loss = 837.5380700826645;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0680, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.0553, requires_grad=True)\n",
      "epoch 200 loss = 983.8233375549316;\n",
      "mode_hat tensor(0.5520, requires_grad=True)\n",
      "ltscale_hat tensor(-0.1139, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.1607, requires_grad=True)\n",
      "epoch 300 loss = 620.0973974466324;\n",
      "mode_hat tensor(0.5479, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0842, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.3084, requires_grad=True)\n",
      "epoch 400 loss = 849.1447448730469;\n",
      "mode_hat tensor(0.5458, requires_grad=True)\n",
      "ltscale_hat tensor(-0.2051, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.2629, requires_grad=True)\n",
      "epoch 500 loss = 944.8152375221252;\n",
      "mode_hat tensor(0.5419, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3029, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.4055, requires_grad=True)\n",
      "epoch 600 loss = 996.1676952838898;\n",
      "mode_hat tensor(0.5492, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3029, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6315, requires_grad=True)\n",
      "epoch 700 loss = 854.4724224805832;\n",
      "mode_hat tensor(0.5441, requires_grad=True)\n",
      "ltscale_hat tensor(-0.3235, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.6747, requires_grad=True)\n",
      "epoch 800 loss = 825.1698764562607;\n",
      "mode_hat tensor(0.5503, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4125, requires_grad=True)\n",
      "ldfraw_hat tensor(-0.7580, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean_losses: 959.2177777665873\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "full_tmode:\n",
      "tensor([-5.5877e+00,  1.6642e+00,  7.5992e-01,  4.0481e-01, -2.5331e-01,\n",
      "        -4.6420e+00,  4.0259e-02, -1.7532e+00,  6.2105e+00, -6.1214e-02,\n",
      "         1.8627e-01,  4.6547e+00,  1.2445e+00, -7.1969e-01,  3.7242e+00,\n",
      "         1.0401e-01, -1.8131e-01,  1.0049e-01,  9.4860e-01,  5.4469e+00,\n",
      "        -1.6185e+00, -3.7510e-01,  3.5656e+00,  1.1490e+00, -1.9292e+00,\n",
      "         5.8061e+00, -2.3552e+00,  1.6891e+00, -3.9071e-01, -4.3346e-01,\n",
      "        -4.9660e+00, -6.6037e+00, -4.3469e-02,  2.4780e+00,  3.0011e-01,\n",
      "        -2.4950e+00,  7.7398e-01,  2.3796e+00,  2.9001e-02,  3.5642e-01,\n",
      "        -3.2604e-01, -2.7054e-01,  2.3673e-01, -1.4536e+00, -5.9563e-01,\n",
      "        -4.9466e-02,  5.5332e-01, -5.4207e-01,  1.3947e+00,  8.1203e+00,\n",
      "         5.2905e-01,  2.0021e-01, -1.5040e+00, -2.0962e+00, -1.8171e-01,\n",
      "         1.1289e-01, -1.3754e+00,  3.2711e+00, -2.6816e+00, -1.0205e+00,\n",
      "         2.4173e+00,  1.5949e+00, -5.6435e+00, -7.1761e-01,  1.2719e-01,\n",
      "        -3.9513e-01, -2.5450e+00, -1.4228e+00,  1.6228e+00, -6.9139e-01,\n",
      "        -1.1036e+00,  2.7721e+00, -9.9246e-01,  1.1818e+00, -1.7146e+00,\n",
      "         3.1793e+00, -2.7950e+00,  8.2104e-01,  6.3403e-02,  4.0739e-01,\n",
      "         2.8209e-01, -2.1237e+00, -4.1912e-01, -5.0223e-01, -2.8851e-01,\n",
      "        -1.8579e+00, -5.7796e-01, -4.7086e+00,  1.1599e-01, -2.4040e+00,\n",
      "        -2.2826e+00, -2.3960e+00,  8.0001e-01, -3.0321e+00,  8.3122e-01,\n",
      "        -4.0437e+00, -8.7664e-01, -1.6247e+00, -2.0491e-01,  1.6596e+00,\n",
      "        -4.3746e-01,  1.5517e+00, -1.9040e+00, -5.5948e-01, -3.3871e-01,\n",
      "         3.0106e-01, -5.5680e-01,  2.8324e-02,  3.4868e-01,  1.6241e+00,\n",
      "        -1.2481e+00,  3.6225e-01,  5.1120e-01, -4.2383e+00,  1.9325e+00,\n",
      "        -1.0240e+00,  6.0667e-01,  4.6992e+00,  5.7942e-01, -2.5342e+00,\n",
      "         8.0078e-01, -1.0391e+00, -1.0416e+00,  2.7986e-01, -2.4951e+00,\n",
      "        -2.0156e+00,  8.6788e+00,  1.3216e+00,  6.7471e-01,  4.2429e+00,\n",
      "         5.3165e+00,  5.3836e-01, -2.0655e+00,  1.1391e+00, -1.4995e+00,\n",
      "         1.4360e+01, -3.0815e-01, -6.0906e-02,  7.3339e+00,  7.0839e-01,\n",
      "         1.2473e+00, -5.2682e+00,  8.3365e+00, -2.1413e+00,  3.2391e-01,\n",
      "         4.1061e-01,  1.2675e+01, -2.2688e+00, -5.2826e-01,  1.3654e+00,\n",
      "        -1.2878e+00, -5.1332e-02, -6.8582e+00,  1.4566e+01,  3.3227e-01,\n",
      "        -2.3721e+00,  2.4726e+00,  2.6319e+00, -1.5008e+00,  3.0352e+00,\n",
      "        -1.9461e+00,  1.7986e+00, -8.7449e-01, -1.8567e-02,  9.6995e-03,\n",
      "         1.1057e+00,  2.1025e+00,  6.1474e+00,  3.6078e+00, -3.3448e-02,\n",
      "         2.1330e-01, -2.4799e+00, -1.1884e+00,  2.6756e+00,  4.9471e-01,\n",
      "         4.9903e-01,  1.6504e+00,  2.4683e+00,  4.1655e-01, -5.9062e-02,\n",
      "        -9.4950e-01, -3.1580e+00, -1.4170e+00, -8.2741e-01,  6.2322e+00,\n",
      "        -1.1920e+00,  3.6353e+00,  7.6009e-01,  8.4336e+00, -2.5169e+00,\n",
      "        -3.1955e+00, -1.4090e+00,  1.2133e+00,  4.7998e-01, -7.3666e-01,\n",
      "         5.2153e-01, -8.3009e-01, -1.7237e+00,  5.7847e-01, -1.8862e+00,\n",
      "         1.7058e+00,  1.2326e+00,  4.8183e-01,  3.6171e+00,  3.4292e-01,\n",
      "        -2.3237e+00,  1.5046e+00, -8.6310e-01,  1.3729e+00,  9.5422e-02,\n",
      "        -1.0563e+00,  9.8609e-01,  1.7718e+00,  6.3785e-01,  1.1600e+00,\n",
      "         2.4994e+00, -1.3227e+00,  3.1831e+00, -1.0140e+00,  1.2422e-01,\n",
      "        -1.0134e+00, -3.7922e-01,  7.8291e-01,  1.4872e+00,  3.8297e-01,\n",
      "        -3.0627e-01,  2.4012e-01, -2.4802e+00, -5.2055e-01, -6.9742e-01,\n",
      "        -9.2815e-01,  2.9402e-01,  4.5353e-01, -2.1695e+00,  3.9882e+00,\n",
      "         9.9737e-01, -1.0062e+00,  1.5299e+00,  4.1474e+00,  1.0052e+00,\n",
      "        -5.0150e-01,  3.9282e-01, -2.3158e+00, -7.7193e+00,  1.8995e+00,\n",
      "        -7.9357e-01,  1.9309e-01, -5.1667e+00, -1.7464e-01,  6.0948e+00,\n",
      "         8.6217e-01, -4.6394e-01,  7.6898e-01, -2.0502e+00,  6.0760e-01,\n",
      "        -4.2448e-01, -8.4317e+00,  4.0108e-01, -3.4625e-01,  1.7112e+00,\n",
      "        -8.3491e-01, -7.2124e-02, -1.4031e+00,  4.8915e+00, -3.7289e+00,\n",
      "         2.8961e+00,  4.3632e+00,  9.9129e-01,  1.0763e+00, -7.1688e+00,\n",
      "        -3.7789e-01,  1.3290e+00,  1.5641e-01,  2.0965e+00, -1.0071e+00,\n",
      "        -9.7927e-01, -2.9996e+00, -4.3427e+00,  9.6639e-01, -1.1950e+00,\n",
      "         1.2035e+00, -1.3735e+00,  1.6421e+00, -2.2707e+00, -8.8593e-01,\n",
      "        -5.6863e+00, -6.3388e+00,  7.7407e-03, -1.1414e+00,  5.3440e+00,\n",
      "         2.0560e-01,  8.4674e-01, -8.5184e+00,  1.6399e-01, -8.7065e-01,\n",
      "         1.3314e-01, -3.7082e-01,  1.5572e-01,  4.5000e-01, -1.3775e+00,\n",
      "        -4.7080e+00, -4.4463e-01, -5.3668e-01,  1.1962e+00,  3.5559e-01,\n",
      "        -5.1545e-01,  1.5917e+00, -1.0701e+01,  2.5691e+00,  3.3109e+00,\n",
      "        -2.1802e+00, -5.4360e-01, -3.5410e-01, -8.9881e-02, -2.1080e-01,\n",
      "        -3.9304e+00,  1.1210e+00, -1.3662e+00,  5.7443e-01,  5.5118e-01,\n",
      "         2.1039e-02, -1.0373e+00, -2.6050e+00, -6.9452e-02,  4.6661e-01,\n",
      "        -2.3895e+00,  6.9682e-01,  6.4591e-01, -7.8744e-01,  1.7274e-01,\n",
      "        -1.4561e+00, -2.1060e+00,  2.3147e+00, -5.5361e-01,  1.7892e+00,\n",
      "         3.1764e+00,  5.2276e-01, -8.3994e-01, -3.7539e+00,  1.2510e+01,\n",
      "        -2.8278e+00, -5.8932e+00, -2.8842e-01, -4.7665e+00, -1.4819e-01,\n",
      "         7.8012e-01,  1.7927e+00,  1.0961e+00, -2.6787e+00,  2.1684e+00,\n",
      "         2.4700e+00, -1.0738e-01, -7.4294e-01,  4.0749e+00, -4.0781e+00,\n",
      "        -1.2990e+00,  1.1108e+00, -4.7836e-01, -3.2556e+00, -8.4532e-01,\n",
      "        -1.5642e+00,  3.9521e+00,  2.0372e+00,  8.1992e+00, -1.3502e-01,\n",
      "         5.5324e-01, -8.7806e-01, -1.5609e+00, -3.6137e+00, -1.2867e+00,\n",
      "         3.5803e-01,  8.8909e-01,  4.8994e-01,  1.7303e+00, -1.6050e-01,\n",
      "         5.5410e-04,  6.9540e-01,  5.9904e-01,  4.1153e+00, -3.2888e+00,\n",
      "        -4.5757e-01,  5.8500e-01, -5.5002e-01,  1.8119e+00,  2.1907e+00,\n",
      "        -1.0298e+01,  7.3368e-01,  3.6670e-01, -3.0992e+00, -5.3727e+00,\n",
      "        -7.5342e-02,  9.3085e-01, -4.0615e-01, -7.3233e-02, -7.8049e-01,\n",
      "        -6.2959e-01,  3.3780e+00, -6.6977e-01,  2.4946e-01, -1.9032e+00],\n",
      "       requires_grad=True)\n",
      "gammapsi:\n",
      "tensor([-4.3448, -4.2963], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "-0.7896541357040405\n",
      "ltscale_hat:\n",
      "-0.5035868883132935\n",
      "mode_hat:\n",
      "0.5385775566101074\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp-1.0.csv from file\n",
      "400\n",
      "tensor([-5.0434,  2.2334,  1.4021,  1.0256])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 40429.64134144783;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 78414.93270635605;\n",
      "mode_hat tensor(0.1392, requires_grad=True)\n",
      "ltscale_hat tensor(-0.5054, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4860, requires_grad=True)\n",
      "epoch 200 loss = 47102.9289470911;\n",
      "mode_hat tensor(0.2870, requires_grad=True)\n",
      "ltscale_hat tensor(-1.0046, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9610, requires_grad=True)\n",
      "epoch 300 loss = 101504.1116694808;\n",
      "mode_hat tensor(0.3693, requires_grad=True)\n",
      "ltscale_hat tensor(-1.4901, requires_grad=True)\n",
      "ldfraw_hat tensor(1.4150, requires_grad=True)\n",
      "epoch 400 loss = 1311.157504916191;\n",
      "mode_hat tensor(0.4800, requires_grad=True)\n",
      "ltscale_hat tensor(-1.9677, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8663, requires_grad=True)\n",
      "epoch 500 loss = 10524.242017805576;\n",
      "mode_hat tensor(0.5174, requires_grad=True)\n",
      "ltscale_hat tensor(-2.4249, requires_grad=True)\n",
      "ldfraw_hat tensor(2.2914, requires_grad=True)\n",
      "Final mean_losses: 49229.89604329944\n",
      "guidename meanfield\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(-1.), 't_scale': tensor(-1.)}\n",
      "ldfraw_hat:\n",
      "2.291445016860962\n",
      "ldfraw_sigma:\n",
      "0.9765577912330627\n",
      "ltscale_hat:\n",
      "-2.424931049346924\n",
      "ltscale_sigma:\n",
      "0.8875399231910706\n",
      "mode_hat:\n",
      "0.5174463987350464\n",
      "mode_sigma:\n",
      "0.46673908829689026\n",
      "t_part_hat:\n",
      "tensor([-0.2673,  0.2557,  0.2177,  0.1028, -0.0533, -0.1690,  0.0222, -0.1075,\n",
      "         0.2967,  0.0235,  0.1162,  0.2858,  0.1303, -0.1428,  0.2001,  0.0475,\n",
      "         0.0645,  0.1045,  0.2239,  0.2739, -0.1208, -0.0576,  0.2784,  0.1326,\n",
      "        -0.1950,  0.2044, -0.2112,  0.2538, -0.1094, -0.0380, -0.1903, -0.2779,\n",
      "         0.0430,  0.3113,  0.1277, -0.2132,  0.1490,  0.1288,  0.0189,  0.0460,\n",
      "         0.0018,  0.0153,  0.0889, -0.1401, -0.2096, -0.0026,  0.0041, -0.0545,\n",
      "         0.2472,  0.1835,  0.1880,  0.0281, -0.1578, -0.2199, -0.0947, -0.0670,\n",
      "        -0.0614,  0.3387, -0.2445, -0.1495,  0.1734,  0.2240, -0.3251, -0.0500,\n",
      "         0.1032, -0.0978, -0.1372, -0.2403,  0.2213, -0.0563, -0.0866,  0.1761,\n",
      "        -0.1068,  0.2132, -0.1573,  0.2604, -0.2214,  0.2105,  0.0220,  0.0840,\n",
      "         0.0572, -0.2477, -0.0685, -0.0328,  0.0641, -0.2140, -0.0064, -0.2043,\n",
      "         0.0964, -0.2875, -0.1060, -0.3366,  0.1008, -0.2004,  0.1283, -0.2378,\n",
      "        -0.1429, -0.2048, -0.0190,  0.2115, -0.0121,  0.2682, -0.2257, -0.0300,\n",
      "        -0.1410,  0.1207, -0.0810, -0.0450,  0.1713,  0.1016, -0.0558,  0.0981,\n",
      "         0.1321, -0.2950,  0.2522, -0.1782,  0.1377,  0.2156,  0.2319, -0.2371,\n",
      "         0.0590, -0.1979, -0.0603,  0.0629, -0.2299, -0.2229,  0.3249,  0.2240,\n",
      "         0.1834,  0.2465,  0.1837,  0.0966, -0.1913,  0.2379, -0.1527,  0.2911,\n",
      "         0.0151,  0.0429,  0.2593,  0.1872,  0.2016, -0.3437,  0.1756, -0.2206,\n",
      "         0.0218,  0.1411,  0.2948, -0.2885, -0.0273,  0.1750, -0.1983,  0.0145,\n",
      "        -0.2209,  0.3199,  0.1312, -0.3107,  0.2943,  0.1398, -0.0916,  0.2397,\n",
      "        -0.1704,  0.2786, -0.0694,  0.1064,  0.0541,  0.0887,  0.2797,  0.2034,\n",
      "         0.4226,  0.0642,  0.0453, -0.2521, -0.1850,  0.2493,  0.1359,  0.0858,\n",
      "         0.2083,  0.2733,  0.1619, -0.0196, -0.1449, -0.3409, -0.1944, -0.0742,\n",
      "         0.3973, -0.1060,  0.1530,  0.1621,  0.2922, -0.1462, -0.1931, -0.1770,\n",
      "         0.1611,  0.2114, -0.0105,  0.1723, -0.0331, -0.1941,  0.0738, -0.2116,\n",
      "         0.1820,  0.2455,  0.0605,  0.2019,  0.0296, -0.0963,  0.2305, -0.0394,\n",
      "         0.1506, -0.0554, -0.1387,  0.1303,  0.1825,  0.0948,  0.1245,  0.2805,\n",
      "        -0.1544,  0.3416, -0.2207,  0.0817, -0.2147,  0.0573,  0.1672,  0.2137,\n",
      "         0.0526,  0.0039,  0.0690, -0.2416, -0.1666, -0.0804, -0.0732,  0.1881,\n",
      "         0.2254, -0.2757,  0.2213,  0.2810, -0.0075,  0.0974,  0.2232,  0.2316,\n",
      "        -0.0709,  0.1792, -0.2715, -0.2415,  0.1805, -0.0560,  0.1272, -0.2252,\n",
      "         0.1478,  0.2235,  0.1512,  0.0507,  0.1444, -0.2076,  0.1732, -0.0562,\n",
      "        -0.3223,  0.0836, -0.0485,  0.1407, -0.0088, -0.0835, -0.1963,  0.2344,\n",
      "        -0.1640,  0.2012,  0.2265,  0.2123,  0.2877, -0.2333, -0.1022,  0.1956,\n",
      "         0.0230,  0.2278, -0.0540, -0.0657, -0.2954, -0.2645,  0.2111, -0.1510,\n",
      "         0.1714, -0.1306,  0.2345, -0.3289, -0.1580, -0.2400, -0.2696,  0.0629,\n",
      "        -0.2819,  0.2795,  0.2140,  0.1567, -0.3011,  0.0697, -0.1810,  0.1268,\n",
      "        -0.0506,  0.0325,  0.0196, -0.2278, -0.2391, -0.0905, -0.0321,  0.1315,\n",
      "        -0.0536,  0.0539,  0.2023, -0.2109,  0.2109,  0.1860, -0.3485, -0.0066,\n",
      "        -0.0665,  0.0549, -0.0933, -0.1214,  0.2473, -0.2723,  0.1264,  0.1055,\n",
      "        -0.0113, -0.2330, -0.2874,  0.0821,  0.0727, -0.2767,  0.1593,  0.1412,\n",
      "        -0.0429, -0.1553, -0.1627, -0.0296,  0.1882, -0.1349,  0.2813,  0.1306,\n",
      "         0.1302, -0.0541, -0.2896,  0.2924, -0.2512, -0.1977, -0.0173, -0.1701,\n",
      "        -0.0302,  0.1673,  0.2153,  0.0454, -0.1606,  0.3114,  0.1978, -0.0124,\n",
      "        -0.1133,  0.2366, -0.3461, -0.0701,  0.0335, -0.0787, -0.1939, -0.1885,\n",
      "        -0.2422,  0.2271,  0.2738,  0.1575,  0.1261,  0.0842, -0.2504, -0.2559,\n",
      "        -0.2891, -0.1653,  0.1132,  0.2252,  0.1870,  0.1756,  0.0042,  0.0100,\n",
      "         0.0772,  0.1425,  0.3735, -0.3046, -0.1184,  0.0529, -0.0465,  0.1842,\n",
      "         0.2321, -0.3475,  0.1234,  0.0428, -0.2123, -0.2505, -0.0655,  0.2182,\n",
      "        -0.0434,  0.0710, -0.1093, -0.0713,  0.2775, -0.1167,  0.0980, -0.1841],\n",
      "       requires_grad=True)\n",
      "t_part_sigma:\n",
      "tensor([0.9461, 1.0224, 0.9089, 0.9576, 0.8869, 0.9798, 0.9495, 0.9607, 1.0857,\n",
      "        0.9444, 1.0020, 1.0032, 1.0277, 1.0171, 1.0617, 0.8793, 0.9395, 0.9651,\n",
      "        0.9075, 0.9840, 0.9063, 0.9276, 0.9329, 0.8609, 1.0674, 1.0354, 0.9565,\n",
      "        0.8872, 0.8005, 0.9321, 1.0426, 0.9311, 0.8639, 0.9937, 0.9760, 1.0480,\n",
      "        1.0082, 0.9516, 0.9578, 0.9148, 0.9052, 0.9729, 0.8832, 1.0097, 0.8026,\n",
      "        0.7624, 1.0569, 0.9123, 0.8899, 0.9472, 0.9545, 0.8655, 0.8773, 0.9979,\n",
      "        0.8689, 1.1265, 0.9165, 1.0047, 1.0989, 0.8908, 1.0264, 1.0258, 0.9429,\n",
      "        1.0738, 1.0011, 1.0510, 1.0258, 0.8851, 0.9769, 1.0754, 1.0683, 1.1788,\n",
      "        0.9039, 1.0983, 1.0558, 1.1244, 1.1897, 0.8377, 1.0165, 0.9677, 0.9991,\n",
      "        0.8647, 0.8520, 1.1057, 0.9126, 0.9972, 0.9165, 0.9797, 0.9743, 0.9600,\n",
      "        0.9917, 1.0185, 1.0019, 1.0693, 1.0077, 1.0162, 0.8544, 1.0058, 0.9491,\n",
      "        0.9116, 0.9712, 1.0055, 1.0484, 0.9382, 0.8717, 0.8292, 0.9860, 1.1177,\n",
      "        0.9050, 1.0526, 1.0376, 0.8479, 0.9237, 1.0234, 1.1005, 1.0565, 0.9320,\n",
      "        1.1236, 0.9698, 0.8463, 0.9792, 1.1029, 0.8362, 0.9394, 1.0619, 0.9699,\n",
      "        1.0554, 0.9604, 0.9928, 1.0054, 0.9766, 0.9312, 1.1554, 1.0750, 0.9798,\n",
      "        1.0627, 0.9774, 0.9484, 1.0048, 0.9309, 1.0431, 0.9460, 1.0502, 0.9708,\n",
      "        0.9519, 0.9346, 0.8940, 0.9448, 0.9748, 0.9789, 0.9653, 0.9106, 0.9806,\n",
      "        1.0439, 1.0766, 0.9002, 0.9594, 1.1501, 0.9039, 1.0581, 1.0131, 0.9449,\n",
      "        0.8610, 0.9419, 1.0010, 1.2346, 0.9860, 1.0113, 1.0855, 0.9680, 0.8310,\n",
      "        1.0097, 0.9372, 1.0194, 0.9483, 0.9447, 1.0271, 0.9470, 0.8284, 0.8902,\n",
      "        1.0634, 0.9805, 0.9556, 0.9649, 0.9569, 1.0135, 1.0380, 0.9569, 0.9917,\n",
      "        0.9601, 1.0156, 0.9875, 1.2099, 0.8664, 1.0593, 0.8140, 0.9695, 1.0214,\n",
      "        0.9594, 1.0498, 1.1538, 1.0031, 0.9424, 0.8726, 0.9850, 0.9415, 0.9922,\n",
      "        0.8580, 0.8723, 1.0708, 1.0604, 0.9856, 0.9291, 0.9173, 1.0306, 1.0592,\n",
      "        1.0670, 1.1155, 0.9267, 0.9348, 0.8670, 0.9359, 0.9188, 0.9809, 0.9345,\n",
      "        0.8725, 0.9246, 1.0428, 0.9194, 0.9694, 0.9507, 0.9502, 1.0425, 1.0987,\n",
      "        1.0711, 1.0423, 0.9891, 0.9390, 1.1189, 1.0514, 0.8832, 0.9661, 0.9803,\n",
      "        1.1496, 1.0727, 1.0082, 0.9371, 1.0193, 1.0478, 0.9939, 0.9080, 0.8634,\n",
      "        1.0042, 1.0056, 0.9377, 0.9079, 0.9420, 0.9676, 1.0827, 1.0069, 0.9340,\n",
      "        0.9041, 0.9617, 1.0003, 0.9529, 0.9809, 1.0902, 1.2320, 0.9785, 0.9579,\n",
      "        0.9212, 0.9958, 0.9790, 1.0637, 0.9495, 0.9077, 1.0098, 0.9756, 1.0373,\n",
      "        1.0286, 1.0020, 1.0084, 0.8820, 1.0005, 1.0145, 1.0030, 1.0007, 0.8892,\n",
      "        0.9431, 1.1408, 0.8351, 0.9060, 1.0458, 0.9183, 0.9140, 0.8902, 0.9814,\n",
      "        1.0051, 1.0405, 0.9884, 0.9806, 0.8467, 0.9101, 0.9743, 1.0411, 1.1408,\n",
      "        0.9624, 1.0659, 0.9880, 1.0137, 1.0348, 1.0390, 0.8685, 1.0610, 0.9704,\n",
      "        1.0133, 0.8820, 0.8632, 0.9722, 0.9236, 0.8494, 0.8503, 1.2542, 0.9633,\n",
      "        0.9839, 0.9065, 0.9725, 1.0242, 0.9024, 0.8772, 0.9112, 1.1421, 1.0257,\n",
      "        0.8643, 1.0211, 1.0210, 0.9509, 1.0996, 1.1046, 1.0441, 0.9935, 0.9721,\n",
      "        0.8423, 1.0702, 1.1044, 1.0115, 0.9294, 0.9412, 1.0122, 0.8916, 1.0581,\n",
      "        0.9127, 0.9617, 1.1038, 1.0615, 1.0174, 0.9875, 0.9166, 1.0893, 0.8054,\n",
      "        0.9204, 1.0555, 0.9348, 1.0384, 1.0400, 0.9275, 0.8068, 1.1530, 1.0574,\n",
      "        0.9274, 0.9218, 0.9619, 0.8717, 0.9381, 1.0388, 0.8219, 0.8768, 0.9565,\n",
      "        1.0503, 1.0358, 0.9087, 1.0638, 0.9044, 1.0042, 0.9805, 0.8729, 0.9124,\n",
      "        1.0691, 1.0277, 0.9769, 0.8653, 0.9969, 1.0839, 0.9264, 1.0610, 0.8986,\n",
      "        1.0331, 0.8620, 0.9614, 0.8811], grad_fn=<AddBackward0>)\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay 7 fix_m_grad\n",
      "epoch 0 loss = 846.6325657367706;\n",
      "mode_hat tensor(-0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "yay 4 fix_m_grad\n",
      "yay 1 fix_m_grad\n",
      "yay -20\n",
      "yay -80\n",
      "yay -140\n",
      "yay -200\n",
      "yay -260\n",
      "epoch 100 loss = 750.2427287101746;\n",
      "mode_hat tensor(0.3088, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4777, requires_grad=True)\n",
      "ldfraw_hat tensor(0.5011, requires_grad=True)\n",
      "yay -320\n",
      "yay -380\n",
      "yay -440\n",
      "yay -500\n",
      "yay -560\n",
      "epoch 200 loss = 736.6217885017395;\n",
      "mode_hat tensor(0.4540, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8897, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9700, requires_grad=True)\n",
      "yay -620\n",
      "yay -680\n",
      "yay -740\n",
      "yay -800\n",
      "yay -860\n",
      "epoch 300 loss = 560.4170126914978;\n",
      "mode_hat tensor(0.5255, requires_grad=True)\n",
      "ltscale_hat tensor(-1.2243, requires_grad=True)\n",
      "ldfraw_hat tensor(1.3874, requires_grad=True)\n",
      "yay -920\n",
      "yay -980\n",
      "yay -1040\n",
      "yay -1100\n",
      "yay -1160\n",
      "epoch 400 loss = 624.2223567962646;\n",
      "mode_hat tensor(0.5633, requires_grad=True)\n",
      "ltscale_hat tensor(-1.5065, requires_grad=True)\n",
      "ldfraw_hat tensor(1.6909, requires_grad=True)\n",
      "yay -1220\n",
      "yay -1280\n",
      "yay -1340\n",
      "yay -1400\n",
      "yay -1460\n",
      "epoch 500 loss = 632.591667175293;\n",
      "mode_hat tensor(0.5637, requires_grad=True)\n",
      "ltscale_hat tensor(-1.7297, requires_grad=True)\n",
      "ldfraw_hat tensor(1.8658, requires_grad=True)\n",
      "yay -1520\n",
      "yay -1580\n",
      "yay -1640\n",
      "yay -1700\n",
      "Final mean_losses: 782.2950093539947\n",
      "guidename amortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "gammapsi:\n",
      "tensor([-4.3525, -4.3149], requires_grad=True)\n",
      "latentpsi:\n",
      "tensor([-4.6052], requires_grad=True)\n",
      "ldfraw_hat:\n",
      "2.009629249572754\n",
      "ltscale_hat:\n",
      "-1.8865422010421753\n",
      "mode_hat:\n",
      "0.6340110301971436\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 1 ['amortized_laplace', 'unamortized_laplace', 'meanfield'] {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "1\n",
      "testresults/scenario_N400_mu0.5_sigma-1.0_nu2.5+exp3.0.csv from file\n",
      "400\n",
      "tensor([-1.9552,  0.3457, -2.1957,  2.0225])\n",
      "Sizes: torch.Size([400]) torch.Size([400])\n",
      "guidename unamortized_laplace\n",
      "trueparams {'modal_effect': tensor(0.5000), 'df': tensor(3.), 't_scale': tensor(-1.)}\n",
      "esize torch.Size([400])\n",
      "epoch 0 loss = 2281.5376677513123;\n",
      "mode_hat tensor(0.0050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.0050, requires_grad=True)\n",
      "ldfraw_hat tensor(0.0050, requires_grad=True)\n",
      "epoch 100 loss = 770.7365003824234;\n",
      "mode_hat tensor(0.5050, requires_grad=True)\n",
      "ltscale_hat tensor(-0.4488, requires_grad=True)\n",
      "ldfraw_hat tensor(0.4995, requires_grad=True)\n",
      "epoch 200 loss = 733.8221480846405;\n",
      "mode_hat tensor(0.5340, requires_grad=True)\n",
      "ltscale_hat tensor(-0.8145, requires_grad=True)\n",
      "ldfraw_hat tensor(0.9438, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "#vals = MIDDF35\n",
    "guidenames = [\"amortized_laplace\",\"unamortized_laplace\",\"meanfield\"]#,\"meanfield\",]#,\"MLE\"]#,\"laplace\"\n",
    "if True:\n",
    "\n",
    "  for nsamps in [12,25,50,150,400]:\n",
    "    for aniter in range(1):\n",
    "        for nparticles in [1]:#,5]:\n",
    "            for trueparams in [ndom_fat_params,ndom_norm_params,]:#tdom_fat_params,tdom_norm_params,]:\n",
    "                for guidename in guidenames:\n",
    "                    #\n",
    "\n",
    "                    print(aniter,nparticles,guidenames,trueparams)\n",
    "                    result = trainGuide(guidename,nparticles,trueparams,\n",
    "                                        filename=\"testresults/demoT_2.csv\",\n",
    "                                      \n",
    "                                        subsample_N = nsamps)\n",
    "                    print(aniter,nparticles,guidenames)\n",
    "                    for line in range(10):\n",
    "                        print()\n",
    "                    \n",
    "else:\n",
    "    plt.plot([getMLE(.01 + x/100,1.,0,1.) for x in range(500)])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCMC, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running...\n",
      "/anaconda3/bin/python\n",
      "Reloading polytopize.\n",
      "addHess tested\n",
      "addHess tested\n",
      "making:\n",
      "1\n",
      "testresults/scenario_N44_mu1.0_sigma2.0_nu-1.0.csv from file\n",
      "44\n",
      "tensor([32.5364, -3.3454,  3.2929, -2.5415])\n",
      "{'hessian': tensor([[1., 0., 1.],\n",
      "        [0., 2., 0.],\n",
      "        [1., 0., 1.]]), 'logPosterior': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"running...\")\n",
    "\n",
    "import sys, os\n",
    "\n",
    "print(sys.executable)\n",
    "#print(sys.path)\n",
    "\n",
    "from importlib import reload\n",
    "import multisiteT #import *\n",
    "reload(multisiteT)\n",
    "from multisiteT import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"making:\")\n",
    "\n",
    "multisiteMod = createScenario(tdom_fat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-78d7c46ccca3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-78d7c46ccca3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    multisiteMod.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "multisiteMod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27889007329940796\n"
     ]
    }
   ],
   "source": [
    "maxError = torch.max(errors)\n",
    "print(float(maxError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
