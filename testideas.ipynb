{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick intro\n",
    "\n",
    "This is a jupyter notebook for testing / coding. So far, each code block is a separate test; unlike an ordinary notebook, they are not meant to run sequentially.\n",
    "\n",
    "First, test to see jupyter is running correctly at all:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi!!! you\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"hi!!! you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do grads apply through hessians?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor([ 0.7500,  6.7500, 18.7500, 36.7500, 60.7500], grad_fn=<MulBackward0>)\n",
      "tensor([0., 6., 0., 0., 0.])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import myhessian\n",
    "import torch\n",
    "ts = torch.tensor\n",
    "t = ts([i+.5 for i in range(5)], requires_grad=True)\n",
    "l = torch.sum(t**3)\n",
    "[lg] = torch.autograd.grad(l,t,create_graph=True,retain_graph=True)\n",
    "[lgg] = torch.autograd.grad(lg[1],t,create_graph=True,retain_graph=True)\n",
    "lgg2 = lgg.contiguous().view(-1)\n",
    "print(lgg2.size())\n",
    "lgg3 = torch.zeros(6,6)#,requires_grad=True)\n",
    "lgg3[1,1:].add_(lgg2.type_as(lgg3))\n",
    "print(lg)\n",
    "h = myhessian.hessian(l,t)\n",
    "l2 = torch.sum(lgg3)\n",
    "l2.backward()\n",
    "print(t.grad)\n",
    "print(lgg3.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you add grads post-hoc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x0000012984CDB400>\n",
      "tensor(2.)\n",
      "tensor(4.)\n",
      "tensor(6.)\n",
      "tensor(8.)\n",
      "tensor(16.)\n",
      "tensor(18.)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from torch import *\n",
    "\n",
    "t1 = torch.tensor(1., requires_grad=True)\n",
    "t1b = t1.detach().requires_grad_()\n",
    "t2 = 2 * t1b\n",
    "t3 = t2 * t1\n",
    "print(t2.grad_fn)\n",
    "temp = t2.grad_fn\n",
    "#t2.grad_fn = None\n",
    "t3.backward(retain_graph=True)\n",
    "print(t1.grad)\n",
    "t3.backward(retain_graph=True)\n",
    "print(t1.grad)\n",
    "#t2.requires_grad = False\n",
    "t3.backward(retain_graph=True)\n",
    "print(t1.grad)\n",
    "#t2.requires_grad = True\n",
    "t3.backward(retain_graph=True)\n",
    "print(t1.grad)\n",
    "t1.grad = t1.grad + t1b.grad\n",
    "print(t1.grad)\n",
    "t3.backward(retain_graph=True)\n",
    "print(t1.grad)\n",
    "t3.extra_attr = 3\n",
    "print(t3.extra_attr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do I have the Euler constant right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.3647)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0003)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyro\n",
    "from pyro import distributions as dist\n",
    "import torch\n",
    "\n",
    "EULER_CONSTANT = 0.5772156649015328606065120900824024310421\n",
    "gd = dist.Gumbel(torch.tensor(-EULER_CONSTANT),torch.tensor(1.))\n",
    "print(gd.sample())\n",
    "torch.mean(gd.sample([1000000]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the \"linearize then delinearize\" trick work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 2.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2222, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1250, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0800]],\n",
      "       grad_fn=<CopySlices>) tensor([2.0000, 2.0000, 2.0000, 2.0000, 0.0000, 1.0000, 1.3333, 1.5000, 1.6000],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<CopySlices>) tensor([2., 2., 2., 2., 0., 0., 0., 0., 0.], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import myhessian\n",
    "\n",
    "t1 = torch.ones(2,2,requires_grad = True)\n",
    "ys = []\n",
    "ws = []\n",
    "y2 = []\n",
    "for i in range(5):\n",
    "    ys.append(torch.ones(1,requires_grad = True) * i)\n",
    "    ws.append(ys[i] * (i+1))\n",
    "    y2.append(ws[i] / (i+1))\n",
    "    \n",
    "y = torch.cat(y2,0)\n",
    "output = torch.sum(t1**2) + torch.sum(y**2)\n",
    "\n",
    "\n",
    "hess,grad = myhessian.hessian(output,[t1]+ws,return_grad=True,allow_unused=True)\n",
    "\n",
    "print(hess,grad) \n",
    "#good graph\n",
    "\n",
    "t1 = torch.ones(2,2,requires_grad = True)\n",
    "ys = []\n",
    "ws = []\n",
    "y2 = []\n",
    "for i in range(5):\n",
    "    ys.append(torch.ones(1,requires_grad = True) * i)\n",
    "    ws.append(ys[i] * (i+1))\n",
    "    y2.append(ws[i] / (i+1))\n",
    "    \n",
    "y = torch.cat(ys,0)\n",
    "output = torch.sum(t1**2) + torch.sum(y**2)\n",
    "\n",
    "hess,grad = myhessian.hessian(output,[t1]+ws,return_grad=True,allow_unused=True)\n",
    "\n",
    "print(hess,grad) #bad graph too sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the values mean in format_shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:            \n",
      " Param Sites:            \n",
      "Sample Sites:            \n",
      "       a dist       |    \n",
      "        value       |    \n",
      "     log_prob       |    \n",
      "       b dist       | 2  \n",
      "        value       | 2  \n",
      "     log_prob       |    \n",
      " c_plate dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       c dist     2 |    \n",
      "        value     2 |    \n",
      "     log_prob     2 |    \n",
      " d_plate dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "       d dist     3 | 4 5\n",
      "        value     3 | 4 5\n",
      "     log_prob     3 |    \n",
      "  x_axis dist       |    \n",
      "        value     3 |    \n",
      "     log_prob       |    \n",
      "  y_axis dist       |    \n",
      "        value     2 |    \n",
      "     log_prob       |    \n",
      "       x dist   3 1 |    \n",
      "        value   3 1 |    \n",
      "     log_prob   3 1 |    \n",
      "       y dist 2 1 1 |    \n",
      "        value 2 1 1 |    \n",
      "     log_prob 2 1 1 |    \n",
      "      xy dist 2 3 1 |    \n",
      "        value 2 3 1 |    \n",
      "     log_prob 2 3 1 |    \n",
      "       z dist 2 3 1 | 5  \n",
      "        value 2 3 1 | 5  \n",
      "     log_prob 2 3 1 |    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "from torch.distributions import constraints\n",
    "from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Multinomial, Normal\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "import pyro.poutine as poutine\n",
    "from pyro.optim import Adam\n",
    "\n",
    "# We'll ue this helper to check our models are correct.\n",
    "def test_model(model, guide, loss):\n",
    "    pyro.clear_param_store()\n",
    "    loss.loss(model, guide)\n",
    "    \n",
    "def model1():\n",
    "    a = pyro.sample(\"a\", Normal(0, 1))\n",
    "    b = pyro.sample(\"b\", Normal(torch.zeros(2), 1).to_event(1))\n",
    "    with pyro.plate(\"c_plate\", 2):\n",
    "        c = pyro.sample(\"c\", Normal(torch.zeros(2), 1))\n",
    "    with pyro.plate(\"d_plate\", 3):\n",
    "        d = pyro.sample(\"d\", Multinomial(5,torch.ones(3,4,5)).to_event(1))\n",
    "    assert a.shape == ()       # batch_shape == ()     event_shape == ()\n",
    "    assert b.shape == (2,)     # batch_shape == ()     event_shape == (2,)\n",
    "    assert c.shape == (2,)     # batch_shape == (2,)   event_sahpe == ()\n",
    "    assert d.shape == (3,4,5)  # batch_shape == (3,)   event_shape == (4,5)\n",
    "\n",
    "    x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "    y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "    with x_axis:\n",
    "        x = pyro.sample(\"x\", Normal(0, 1))\n",
    "    with y_axis:\n",
    "        y = pyro.sample(\"y\", Normal(0, 1))\n",
    "    with x_axis, y_axis:\n",
    "        xy = pyro.sample(\"xy\", Normal(0, 1))\n",
    "        z = pyro.sample(\"z\", Normal(0, 1).expand([5]).to_event(1))\n",
    "    assert x.shape == (3, 1)        # batch_shape == (3,1)     event_shape == ()\n",
    "    assert y.shape == (2, 1, 1)     # batch_shape == (2,1,1)   event_shape == ()\n",
    "    assert xy.shape == (2, 3, 1)    # batch_shape == (2,3,1)   event_shape == ()\n",
    "    assert z.shape == (2, 3, 1, 5)  # batch_shape == (2,3,1)   event_shape == (5,)\n",
    "\n",
    "test_model(model1, model1, Trace_ELBO())\n",
    "\n",
    "trace = poutine.trace(model1).get_trace()\n",
    "trace.compute_log_prob()  # optional, but allows printing of log_prob shapes\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does my gumbel MLE function work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import demo #import *\n",
    "reload(demo)\n",
    "from demo import *\n",
    "import cProfile as profile\n",
    "\n",
    "print(\"hi\")\n",
    "\n",
    "print(lambertw(ts([0.])),lambertw(ts([1.])),lambertw(ts([50.])))\n",
    "print(\"hi\")\n",
    "\n",
    "testMLE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "draw some ellipses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipse(xy=(0, 0), width=2.0, height=2.0, angle=0)\n",
      "hi\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from draw_ellipses import *\n",
    "import torch\n",
    "\n",
    "\n",
    "fig, ax_nstd = plt.subplots(figsize=(6, 6))\n",
    "lims = [-5,5]\n",
    "ax_nstd.scatter(lims, lims, s=0.5)\n",
    "\n",
    "confidence_ellipse(torch.ones(2),torch.eye(2),ax_nstd,alpha=0.5, facecolor='pink', edgecolor='purple', zorder=0)\n",
    "print(\"hi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
